








three
style


When an architectural competition was announced for the New York Public Library on May 21, 1897, Dr. John Shaw Billings, the library’s executive director, was determined that in his building, design would not triumph over function. He had in mind Boston’s newly built public library, a beautiful but in his opinion poorly functioning building. Billings, an ex-army physician, was responsible for organizing the Surgeon General’s Library and a celebrated medical index. He was also an expert in hospital design, and was thus familiar with building construction. He drafted a plan for the new library whose most unorthodox feature was the location of the main reading room. It was not located near the main entrance, as was common practice, but on an upper floor, above the book stacks.
The terms of the architectural competition were strict and included detailed floor plans that the competitors were required to follow. There were two stages, intended to attract new talent as well as established firms. First, six architects were chosen from an open competition. These six then advanced to a second stage, where they competed against six invited firms that included not only McKim, Mead & White (the architects of the Boston Public Library), but also such luminaries as Peabody & Stearns, George B. Post, and an up-and-coming young firm, Carrère & Hastings. The up-and-comers carried the day. McKim, much to his chagrin, not only lost but placed third behind Howard & Cauldwell. It was his own fault, since he imperiously ignored the suggested plan and substituted his own arrangement. Carrère & Hastings conscientiously followed Billings’ requirements.
The projected budget for the new library was not large ($1.7 million) and Billings expected a relatively modest building.* That was not what he got. All three designs were monumental. Carrère & Hastings and Howard & Cauldwell used the Modern French style, which was more ornate and allowed for more articulation to the façade than the austere Classical style that McKim opted for. All incorporated giant columns rising the full height of the two floors—Corinthian in McKim’s case, Ionic in the other two (the completed building is Corinthian). The compositional strategies were roughly similar: a monumental stair led to an elevated main floor; the entrance was placed in the center (more understated in McKim’s elegant design); statuary and urns adorned the attic. All three entrants shared a sense of what was beautiful and what was appropriate, and all were concerned with conveying the same message of permanence, dignity, and of culture rooted in the past.
I mentioned the New York Public Library competition when I gave a public lecture in connection with a recent architectural competition for the new Salt Lake City Public Library. The library board had conducted a national search for an architect, visited new libraries across the country, and solicited proposals from prominent architects. They had narrowed their list to four firms: Charles Gwathmey and Robert Siegel are respected New York architects with a long record of university buildings and museums, including a new library of science, industry, and business for the New York Public Library system. Moshe Safdie had built major civic buildings in Israel, Canada, and the United States, and recently completed the public library in Vancouver, British Columbia. Moore Ruble Yudell is a Los Angeles firm founded by the late Charles Moore, with whom John Ruble and Buzz Yudell built several university libraries and a public library in Berlin. Will Bruder, the least well-known of the four, is a southwesterner and the architect of the new, well-regarded Phoenix Public Library.
I told my audience that I thought that the Salt Lake City library board would have a more difficult choice than their nineteenth-century New York counterparts. It was not a question of function. The Salt Lake City librarians had prepared an equally exhaustive program of requirements, so whichever architect was chosen commodity probably would be well served. As for firmness, I was reasonably sure that any of these experienced firms would build soundly. It was the consideration of delight that would make the selection harder. Gwathmey and Siegel design crisply detailed, understated buildings in a latter-day version of the International Style. Safdie, too, is a modernist, but he follows in the footsteps of Pei, and his buildings are frankly monumental—the Vancouver library had been likened to the Roman Coliseum. Moore Ruble Yudell’s work is different. Informal and animated, their eclectic Postmodern designs are likely to include ornament and architectural motifs drawn from their surroundings. Bruder, on the other hand, designs chic buildings that incorporate exposed structural elements, rough industrial materials, and sleek details. Building on the same site, fulfilling the same functional requirements, and using the same up-to-date construction technology, the four firms would produce libraries that would look different.
The library board awarded the commission to Moshe Safdie, and a year later the plans for the new building were unveiled. The new library will feature an unusual triangular-shaped main building and a curving wall-like structure that encloses a public square. A hundred years ago, it was taken for granted that the New York Public Library would be designed in some variant of the Classical style. Today a public library can take many guises. It can be relentlessly avant-garde, like the new $1.5 billion national library in Paris, where the books are housed in four L-shaped 22-story glass towers, and the readers are lodged in underground rooms, which the London Times described as “a series of rectangular salons (identical of course) where you can admire the ultra-smooth gray concrete, steel grille ceilings and the expanses of African veneer.”1 A new library can be comfortably Modernist, like the new British Library in London, which the Independent humorously described as “a giant municipal building that has made its way from Scandinavia, having crashed headfirst through an English brickworks on the way.”2 Tom Beeby’s handsome Harold T. Washington Library in Chicago, on the other hand, is distinctly old-fashioned, with rusticated stone walls and carved brick ornaments that are a literal evocation of the city’s nineteenth-century architectural tradition. Instead of trendy plastic or metal chairs, the reading areas are equipped with solid wood tables and traditional courthouse chairs. James Ingo Freed’s Main Public Library in San Francisco, on the other hand, is both old and new: the imposing granite and stainless steel exterior is more or less Classical on one façade, and more or less Modernist on another.
The coexistence of different architectural styles is nothing new. In a 1913 essay titled “Style in American Architecture,” Ralph Adams Cram identified no less than seven contemporary styles, although he called them “tendencies.” Five were traditional: McKim’s pure Classicism; the Beaux-Arts French Modern; Colonial, which was associated with houses but was also appearing in larger buildings such as the Johns Hopkins University campus; Cram’s own High Gothic; and a looser interpretation of the medieval style as practiced by his partner Goodhue. Two were new: steel-frame construction, which Cram described as an enfant terrible; and what he called the Secessionists—Frank Lloyd Wright in Chicago, the Greene brothers in Pasadena—who exhibited “a strongly developed enmity to archaeological forms of any kind.” Cram was not sanguine about the future, but he nevertheless concluded: “Chaos then confronts us, in that there is no single architectural following, but legion; and in that fact lies the honor of our art, for neither is society one, or ever at one with itself.”3
Cram is right: most historical periods are marked by stylistic confusion; it is stylistic consensus that is unusual. There was such a brief consensus in the late 1890s, when both architects and the American public, under the influence of the immensely popular World’s Columbian Exposition, embraced Classicism, at least for public buildings. That unanimity lasted long enough for the New York Public Library competition, but it began to unravel shortly after, as Cram’s essay makes clear. There was also a consensus in the 1920s, at least among progressive architects. That consensus did not last either. After 1940, Mies van der Rohe gave up the free-flowing plans and asymmetrical massing that had characterized the Barcelona Pavilion and the Tugendhat House, and began designing buildings whose details and materials were Modern but whose layout and composition were distinctly Classical. In the 1920s, Le Corbusier proclaimed the “Five Points of a New Architecture”: the building raised on stilts; the roof garden; the frame structure that allowed a free plan; the free façade; and the horizontal ribbon window. He, too, had second thoughts. Thirty years later, his wonderful chapel at Ronchamps had massive sculpted wall that concealed a concrete frame; the roof, far from being flat, resembled a billowing nun’s coif. Le Corbusier, who had coined the famous expression, “a house is a machine for living in,” now adopted distinctly un-machinelike building materials such as crudely finished concrete, exposed brick, roughened stucco, and fieldstone. This volte face gave rise to the so-called Brutalist style, which had a worldwide influence, shaping the work of architects as dissimilar as James Stirling and Paul Rudolph, and ultimately opening the door to Postmodern stylistic experiments such as Charles Moore’s little house in the Berkeley hills.
The inconstancy of the International Style practitioners should have been expected. The history of Western architecture is of architects searching for rules, only to bend and break them. Even Classicism, which appears at first glance to be highly regimented, is not immune. As far as we know, the ancient Greeks used only three orders: Doric, Ionic, and Corinthian. Vitruvius describes them, and also refers to a Tuscan order, which is a Roman invention. Roman, too, is the so-called Composite order, an ornate blend of Ionic and Corinthian. The vault, the arch, and the dome, unknown to the Greeks, were other Roman additions to the Classic canon. Architects have been stretching Classical rules ever since: breaking pediments, flattening pilasters, magnifying and shrinking columns, rusticating masonry. A sixteenth-century French architect, Philibert de l’Orme, invented a French order; Edwin Lutyens devised an order based on Mughal precedents for the Viceroy’s House in New Delhi; more recently, Allan Greenberg created an order for the offices of the Secretary of State that incorporated the Great Seal of the United States. Michael Graves designed Classical caryatids (columns carved in the shape of human figures) to support the pedimented front of an office building for the Walt Disney Company in Burbank. While the supports of the porch of the Erechtheon in Athens take the form of graceful maidens, Graves’ caryatids are the Seven Dwarfs.
The headquarters of a company whose logo is a pair of mouse ears obviously demands a different decorum from a temple. In the past, religious buildings and palaces required a narrow stylistic range. As architectural commissions grew to include civic and commercial buildings, warehouses, factories, shops and cinemas, houses and weekend houses—every sort of building—a single style no longer sufficed. Gothic is an evocative style for churches, but despite Walpole’s efforts it is ill-adapted to houses. Romanesque makes imposing city halls, but is too heavy to be applied to skyscrapers. The International Style makes striking small buildings but monotonous large ones. Shingle Style cottages are pleasing; a Shingle Style Home Depot is ridiculous. As Cram wisely observed, “Architecture is nothing unless it is intimately expressive, and if utterly different things clamor for voicing, different also must be their architectural manifestation.”4
The great architects—Brunelleschi, Palladio, Wren, Richardson, Lutyens—regularly looked to the past for inspiration. In 1965, Richard Meier built the Smith House, which has been called the first International Style revival building. Like all revivalists, Meier picks and chooses. At first glance, the Smith House has all the stylistic hallmarks of a Le Corbusier villa of the 1920s: a free plan, flat roof, white walls, pipe railings, horizontal ribbon windows, a ramp. Yet it is built out of wood and steel, not masonry. The white walls are painted wood siding, not stucco; the details are more refined, the plate-glass sheets are larger, the structure lighter. The result is an International Style that is filtered through American consciousness and shaped by American technology. It is like Thomas Jefferson building Classical columns out of wood—the same, but different.
Although art historians use terms like Gothic Revival and Greek Revival to distinguish later reincarnations of styles, architects look at history differently. “For the serious architect the past exists not as a legacy to be possessed through a self-conscious act of the ‘modern’ will,” writes Roger Scruton in The Aesthetics of Architecture, “but as an enduring fact, an ineliminable part of an extended present.”5 That is why architects, whether they are Inigo Jones or Louis Kahn, make architectural pilgrimages to the Mediterranean roots of Western architecture. Sketchbook in hand, they plumb the secrets of the master builders of the past. Consciousness of the past may also explain why architects tend to resist being categorized according to style; they instinctively understand that the history of architecture—including the present—is a continuity rather than a series of episodes.
Stylistic consistency is much admired today, but it was not always so. In 1419, Filippo Brunelleschi began the Foundling Hospital in Florence, whose delicate arcade of Corinthian columns surmounted by pedimented windows is generally considered the first building of the Renaissance. At the very same time, he was building a great dome over the crossing of the cathedral of Florence in a style that was not Classical but distinctly Gothic, pointed arches and all. The German architect Karl Friedrich Schinkel is best known for his severe Classical public buildings such as the superb Altes Museum in Berlin, but he also worked in other styles: Gothic in churches, and picturesque Italianate in villas. McKim, Mead & White favored the Classical style for public buildings and palatial residences, but built Norman parish churches, Shingle Style summer retreats, French Renaissance mansions, and American Colonial country houses. John Russell Pope, an eclectic master, designed beautiful picturesque Tudor, Georgian, and Colonial country estates. Edwin Lutyens was another Classicist whose residential work was eclectic.
Domestic architects had to be adaptable, because house styles changed according to fashion. In the United States, Tudor was popular in the 1900s, as was the Free Style; Cotswold and French Provincial appeared in the 1920s. After the 1930s, influenced by the restoration of Williamsburg, American Colonial returned to favor. The Cotswold style, with its relatively severe details and blunt forms, created a very different setting from French Provincial, which tended to have more delicate details, from Free Style with its almost rustic atmosphere, or from sturdy Colonial. Since historic styles carry cultural overtones, using different styles was also a way for architects—and clients—to say different things.
If architectural style is a language—an analogy that is deeply flawed—it is closer to slang than to grammatical prose. Architectural styles are mutable, unregulated, improvised. Architects break the rules, and invent new ones. In part, this is simply the irrepressible urge of creative individuals. In part, architects break stylistic rules because they can. After all, most of the rules that govern building design—fire codes, building codes, zoning laws, budgets, programmatic requirements, engineering norms—are outside the architect’s control; stylistic rules are firmly within his purview. Since architecture is so intensely competitive, doing something unexpected, unusual, or just different is a way to be noticed, to rise above the crowd.
In addition to historical styles, there have also been styles associated with individual architects. The Palladian style made its way from Andrea Palladio to Inigo Jones, from him to Colen Campbell and Lord Burlington, and thence to Thomas Jefferson. It reappears in the work of contemporary Classicists such as Allan Greenberg. H. H. Richardson’s influence was considerably shorter-lived, but for at least 20 years Richardsonian Romanesque rolled over the United States like an “aesthetic Juggernaut,” in Cram’s colorful phrase. Mies van der Rohe’s steel-and-glass style likewise prevailed for more than two decades, and his characteristic I-beam window mullion can still be seen in contemporary curtain walls.
Buildings like Jones’ Palladian Queen’s House in Greenwich, Adler & Sullivan’s Richardsonian Romanesque Auditorium Building in Chicago, and Gordon Bunshaft’s Miesian Lever House are not copies but satisfying originals. However, most personal styles are not easily adaptable. A building in Wright’s unmistakable Prairie style, for example, simply looks like a knock-off. Some personal styles are simply too obsessive, which is probably why Frank Furness and the equally idiosyncratic Barcelona architect Antonio Gaudí never attracted a following.
Inigo Jones consciously based his work on the architecture of Palladio, but he did not think of himself as working in the Palladian “style,” any more than Palladio would have referred to the Classical “style.” Although Renaissance architects described their architecture as all’antica—in the antique manner—they took it for granted that the history of architecture was a progression: the Romans improved on the Greeks, and they would improved on the Romans. According to the architecture historian Peter Collins, the use of the word style to designate the architecture of a particular period or country is relatively late. He cites James Stuart and Nicholas Revett’s Antiquities of Athens, published in 1762 and credited with inaugurating the Classical Revival in England. The authors, both architects, referred to “the Grecian and Roman style of building.”6
The Latin root of “style” is stilus. A stilus was the sharp-pointed tool used to write on wax tablets and, by inference, stilus also referred to the way that something was written. This sense of technique carried over to English, and the original meaning of style was those features of literary composition that belonged to the form rather than to the substance of the matter being expressed. The seventeenth-century English musical composer Samuel Wesley put it neatly: “Style is the dress of thought.” Jacques-François Blondel, who was Louis XV’s architect and who founded the first full-time school of architecture in Europe in 1750, adopted this literary meaning as a metaphor and described architectural style as a building’s character—for example, rustic, regal, or heroic. “Style in the organization of façades and in the decoration of rooms is the poetry of architecture,” he taught his students, “which alone makes all the architect’s compositions truly interesting.”7
Literary style described the way that something was written, expressed, or performed. Architectural style, in Blondel’s sense, describes the way that something was built. Although architecture is often defined in terms of abstractions such as space, light, and volume, buildings are above all physical artifacts. The experience of architecture is palpable: the grain of wood, the veined surface of marble, the cold precision of steel, the textured pattern of brick. But exactly what do we see when we look at brickwork? We see the joints between the bricks and the mortar (which can be flush, or scraped out to create shadows; the bonding patterns; the way that the bricks turn the corner; the surrounding of openings; and the connection between the brick wall and the foundation or the eaves. What we see are details.
Details are a major preoccupation of the architect. Once the overall form of a building is determined—“the masterly, correct, and magnificent play of masses brought together in light”—there remains the question not only of what materials are to be used and how these will be assembled, but also of how the hundreds of parts of the building are to be designed: from the door frames and the window sills to the railings and the baseboards.
The function of a baseboard is to cover the joint between the wall and the floor, and secondarily to protect the wall from scuffing. There are dozens of ways that this can be done. Baseboards can be prominent or discreet, a complicated assembly of board, cap and base, or a simple strip of hardwood. Or nothing—many modern architects dispense with baseboards altogether. The baseboards in my living room are twelve inches tall. They are not wood but cast iron, since they are really disguised radiators. My house was built in 1908, influenced by the British Free Style of Voysey and Baillie Scott, and to further preserve a simple, rustic atmosphere the architect had the baseboards/radiators painted to resemble wood.
Railings have a simple function—they must be sturdy enough to support us if we lean on them, and they must provide a secure hand-hold: if railings are open, the spaces between the supports and the rails should be small enough to prevent children from falling through. Classical railings, developed during the Renaissance, consist of balusters supporting a handrail. Balusters—little columns—can have a single or a double swelling curve, or a vase shape. Fabricated in wood or masonry, they can be round or square in cross-section, and plain or highly ornamented. Railings can be replaced by parapets with pierced screens. These can be stone or metal: bronze, wrought, or cast iron. The screens can be simple X-shapes, intertwining geometrical patterns, or complicated floral figures as in Art Nouveau staircases. Perhaps the simplest open railings are those of the great Adirondack camps, whose builders mimicked X-shaped wrought-iron railings in unpeeled rustic tree trunks.
Modern railings are usually metal. In his early villas, Le Corbusier used white-painted pipe railings to create a nautical image; in later buildings like the Carpenter Center for the Visual Arts at Harvard, flat steel bars take the place of pipes. The railings in Mies van der Rohe’s buildings usually have only a single intermediate rail, located precisely halfway between the handrail and the floor; the vertical stanchions, the handrail, and the rail are made of identical square steel bars. The railings in Louis Kahn buildings tend to be parapets, but where he is obliged to use an open railing the design is as simple as possible. I have seen a short stair railing that consisted of a single bronze bar, bent at each end to form the uprights. Richard Meier uses metal railings, too, but because there are sometimes as many as six horizontal rails, the visual effect is more pronounced—they resemble staffs in sheet music.
When Brutalism was in fashion, railings were correspondingly heavy: concrete beams, wide enough to sit on but unpleasant to the touch, or massive wood balustrades, as solid as fenders on a truck dock. The vogue among many younger architects today is toward lightness and exposed construction, and railings reflect that fashion, too. The screens of the railings of Peter Rose’s Canadian Center for Architecture in Montreal are industrial-looking perforated sheets of anodized aluminum, prominently bolted to the stanchions. Bernard Tschumi substitutes steel cables (complete with turnbuckles) for the intermediate horizontal rails of the ramp railings of Lerner Hall at Columbia University, another nautical reference, but to a yacht rather than a steamship. These solutions appear mannered compared to the simple railing that I. M. Pei designed for the East Building of the National Gallery. The stainless steel handrail highlights the solidity of the rose-colored Tennessee marble by appearing to float in mid-air, since it is supported by continuous sheets of tempered glass embedded in the floor.
The transparent railings of I. M. Pei’s East Building are understated, elegant, and luxurious—like the building. “Beauty will result from the form and correspondence of the whole with respect to the several parts,” taught Palladio, “of the parts with regard to each other, and of these again to the whole.”8 The successful relationship of the details to each other, and to the building is governed by the architect’s sense of style. That is why the architect of my house painted the radiators to resemble wood; a technologically inclined architect might have painted them silver; a minimalist would dispense with baseboards and hide the radiators in the wall. The role of details is not to complement architecture; details are architecture. “The aesthetic understanding [of architecture],” writes Roger Scruton, “is inseparable from a sense of detail.”9 Mies van der Rohe is supposed to have said “God is in the details.”* He did not mean that details are functionally important (although they are), or that good details prolong the life of a building (although they do). He meant that details are the soul of architecture. That is why, just as an archaeologist can reconstruct a pot from a few shards, or a paleontologist can surmise the form of a prehistoric animal from bone fragments, it is possible to divine the architect’s idea of a building by examining its details.
The house that Robert Venturi built for his mother in 1964 shook the foundations of the International Style; much of this effect was the result of details. Although Venturi obviously was working in a Modernist idiom—there is a strip window and a steel-pipe railing—he also incorporated distinctly un-Modernist features such as trim, both inside and out. Classical architects use a large variety of moldings—fillet, astragal, egg and dart, ogee—that can be combined and recombined to great decorative effect. The International Style, in its effort to do away with ornament, outlawed trim. Walls were flat planes. Windows had no frames. Joints between materials were simply hairline cracks. The conspicuous exterior dado, the baseboards, and the chair-rails in the Vanna Venturi House were hardly Classical moldings—they were merely boards with chamfered edges—yet they challenged the assumption that trim and Modernism were incompatible.
Coming through the front door of the Vanna Venturi House one immediately senses that it is an unusual place. A broad stair rises beside the fireplace, then peters out to almost nothing. The fireplace looks like an abstract sculpture, but it has a traditional mantelpiece. A free-standing column à la Corbusier stands beside a chair-rail. Then there is the furniture. Ever since the Tugendhat House—for which Mies had designed the furniture—it was taken for granted that modern houses required modern furniture. Venturi has explained that “I designed the house so my mother’s old furniture (c. 1925, plus some antiques) would look good in it.”10 Instead of the iconic bent-tube Breuer chairs, there are homely ladderback chairs around the dining table; instead of an Eames lounge chair and ottoman, a comfortable stuffed sofa. It is a contradictory atmosphere—the International Style willfully distorted through the lens of traditional bourgeois domesticity.
Whether one is looking up at the tall dome of the Pantheon, descending the spiraling vortex of Wright’s Guggenheim Museum, or standing in the living room of Venturi’s small house, the experience of architecture is above all the experience of being in a separate, distinct world. That is what distinguishes architecture from sculpture—it is not an object but a place. The sense of being in a special place that is a three-dimensional expression of the architect’s imagination is one of the distinctive pleasures of architecture. To create a strong sense of place, the surroundings must be all of a piece; space, mass, shapes, and materials must reflect the same sensibility. That is why details are so important. A jarring detail or an inconsistency—something “out of place”—and the fantasy begins to crumble. Yes, fantasy. Illusion has been a part of architecture ever since the ancient Greeks made columns with a gently swelling taper to deceive the eye. This is not to say that architecture is stage décor. When the wind blows, the canvas scenery blows over; the building resists the elements. Architecture surrounds and shelters us. It is the real world but it is also a vision.
•••
The Postmodern movement that followed the Vanna Venturi House was relatively short-lived but it had an important consequence: it broke the stranglehold of Modernism, leaving designers free to explore other forms of expression. The profusion of styles that ensued is demonstrated by the work of three gifted but vastly different architects, Allan Greenberg, Hugh Newell Jacobsen, and Enrique Norten.
Allan Greenberg is a confirmed Classicist. He does not consider this an anomaly. “To be truly modern,” he writes, “means finding the dynamic balance between eternal human values and the specific demands of the present. Classical architecture provides the means to achieve this balance because it is the most comprehensive architectural language that human beings have yet developed.”11 Although Greenberg looks to the past, his is not the attitude of an archeologist. Like Carrère & Hastings, and generations of architects before them, Greenberg approaches Classicism as a tradition to be studied, absorbed—then extended.
Early in his career, after emigrating to the United States from South Africa, Greenberg was employed writing design standards for courthouses, which led to an unusual commission: the conversion of an empty supermarket into a courthouse. He gave the commercial building in Manchester, Connecticut, a new façade dominated by a large arch, over-scaled voussoirs, and a pediment. Inside, the barrel-vaulted ceiling of the lobby was supported by a Tuscan order. Greenberg had graduated from Yale in 1965, and like many of his contemporaries was experimenting with the new freedom offered by Postmodernism. However, unlike Venturi and Moore, Greenberg was not coyly introducing Classical elements into a Modernist building; he was returning to Classical roots. From this modest beginning, over the next two decades, came a variety of commissions: a suite of rooms for the Secretary of State in the United States Department of State building, several college and university buildings, and a Roman Catholic church. His commercial work included a newspaper office building in Athens, Georgia, a new entrance for Bergdorf Goodman on Fifth Avenue in Manhattan, and a flagship store for Tommy Hilfiger in Beverly Hills. Greenberg is also known for large country houses, both in the United States and in Europe. Like Lutyens and John Russell Pope, he ventures stylistically farther afield in his residential work—using Georgian and American Colonial styles. One of his early houses was inspired by Mount Vernon, another by Palladio’s unfinished Villa Thiene. Several are picturesque rambling affairs whose relaxed informality recalls the best work of McKim, Mead & White.
One of my favorite Greenberg houses is a cottage set among windblown dunes on the eastern seaboard. Completed in 1992, the low-lying building is shingled, but it is not exactly Shingle Style. Recent Shingle Style buildings are often broken down into many small parts, giving them a fussy and nervous appearance. Such seaside cottages look as if a good wind could blow them away. Greenberg’s aim here is to make a heavyweight building of great solidity that is rooted firmly in the dune scrub. The one-story Atlantic façade is almost perfectly symmetrical: a large arched window flanked by two semi-circular bays, rotund sentinels standing against the ocean winds. The two-story landward side is more informal, ringed by a sheltered porch. Massivity informs the details: sturdy Tuscan columns, a heavy cornice at the eaves of the large roof, rugged window frames. The sense of robustness is accentuated by occasional delicacy: the arched window incorporates scrolled brackets that support an elegant reverse ogee molding at the eaves. Inside, the fireplace has a brick hearth, a slate lintel, and a wood surround, whose almost modern simplicity is softened by a cavetto molding beneath the mantelpiece. The ceiling is supported by exposed trusses of rough, reused timbers. Although most people would describe this house as “traditional,” this is not an exercise in a particular historical style. There is a nod here to the British Arts and Crafts architect  C. F. A. Voysey, and it is obvious that Greenberg has looked at Lutyens’ country houses. But this is a modern house, although designed by an architect with a Classical sensibility. It admirably fulfills Palladio’s call for a correspondence of the whole with the parts and the parts with the whole.
Hugh Newell Jacobsen studied at Yale under Louis Kahn, worked for Philip Johnson, and opened his own office in 1958. He established himself as a premier residential architect, winning commissions in the United States and abroad and receiving numerous design awards. Several of the awards were for restoration of historic buildings, notably the Renwick Gallery in Washington, D.C., and the Hôtel Talleyrand in Paris. A Modernist by training and inclination, Jacobsen was, nevertheless, affected by the winds of change unleashed by Venturi’s little house. Starting in 1980, he evolved a hybrid style in which American regional forms and materials are combined with International Style precision, spareness, and simplicity. A house on Nantucket in shingles and white trim looks vernacular until one notices the careful proportions and refined, elegant details such as tall French doors in the living room that slide into wall pockets that also conceal shutters and screen doors. A post-and-beam Caribbean guest house with broad overhangs has the ingenuous simplicity of a beach shack. The Palladian plan and temple-like pavilions of an Ohio residence pay homage to the local Greek Revival. An Ohio country house recalls a board-and-batten Gothic Revival farmhouse. “I endeavor to design buildings that express a sense of belonging,” Jacobsen says, “buildings that reflect or abstract the nearby architecture and the traditions dictated by the climate and local materials.”12
The Palmedo House, built in 1988, reinterprets the American Colonial architecture of its location—Long Island. At first glance, the six pavilions resemble a little village, a little Amish village, judging from the austere white wood siding, the prim details, and the identical pitched roofs. Each pavilion is a perfect little “house” with identical square and vertical multi-paned windows (that open by sliding into cunning wall pockets). This sounds precious, but Jacobsen is not a romantic. The central “house” contains the living room, a three-story space open to the roof. Although the multi-paned windows are present at an upper level of the wall, the corner of the room is glazed with large, mullionless sheets of plate glass, offering dramatic views of Long Island Sound. This is an International Style device, as is the economy of detail and the clean, cool, atmosphere of the interior. On the other hand, the fireplace, which in an orthodox International Style house would be painted brick or bush-hammered concrete, is decorously built into the wall, which gives the room a traditional, civilized air. The chief idea here is to highlight the tension between old and new, between the traditional clapboarded architecture and the demands of modern life. Whereas Greenberg seamlessly resolves this tension, Jacobsen allows it to surface. If this sounds like textbook Postmodernism, it is not. Jacobsen artlessly combines new and old without the slightest hint of irony.
Jacobsen reacts to the collapse of Modernism by seeking a compromise position, while Greenberg anchors himself in the certainties of Classicism. Enrique Norten, the youngest of the three, takes a different course—he is trying to put Modernism back together again. Norten, who studied at Cornell, established his office in his native Mexico City in 1985. In a relatively short time he produced an impressive body of work that includes institutional, commercial, and residential buildings. His major projects are a services building for the media giant TELEVISA and the National School of Theater. Both incorporate bulging, metal shell-roofs that recall the 1950s buildings of the French architect-engineer Jean Prouvé. Prouvé was intent on applying new methods of construction, particularly industrialization and prefabrication. His buildings, extremely light and assembled from standardized elements, were real “machines for living.” Norten, too, is preoccupied with industrial building technologies, the lighter the better. Double-tensed glass curtain walls are mysteriously supported by a steel-frame. Roofs hang by steel cables from steel masts. Slender, canted columns brace a glass-roofed portico. Railings, in a Norten design, are almost always opportunities for structural legerdemain: suspended sheets of glass, stretched steel cables, perforated metal screens.
In 1994, Norten built a house for himself and his family on a tight urban site in Mexico City. The three-story street façade is mostly a blank concrete wall; the wall facing the interior walled patio is entirely glass. The main living floor is open, except for the kitchen; the upper bedroom floor is shaded and given privacy by a redwood, louvered screen. A functionalist style pervades the house. The clinical cabinetwork is white-painted wood. A concrete wall in the dining room is bare save for the regular pattern of the formwork ties and the pour lines marks. The windows are large sections of plate glass in simple aluminum frames; a 10-foot section slides aside to entirely open the dining room to the patio. The sliding wall recalls the disappearing windows in Mies van der Rohe’s Tugendhat House, but the resemblance ends here. Mies’ spare interior is opulent and assertive; Norten’s is austere, almost monastic: a neutral background for family life. This is an unsentimental idea of the home. Not exactly a “machine for living,” but certainly machinelike in its precision and rational layout.
Like Greenberg and Jacobsen, Norten reflects on the past. Although his house has little to do formally with the International Style of the flat-roofed stucco villas of the 1920s—except for the white-painted circular steel columns—it shares that period’s ambitions; it is highly abstract, idealistic, technophile, and lacking in applied ornament. Decoration results not from trim, but from the surface quality of the different materials—concrete, red oak flooring, etched glass—and from the relentless articulation of structural connections. Norten’s buildings exhibit another feature of the International Style: they are placeless. That is, while they carefully respond to the specifics of the program and the site, they do not explicitly acknowledge their immediate regional context. Whether they are in Mexico or New Mexico—where Norten is building a heritage center—the style is the same: understated, coolly competent, cosmopolitan.
Whether one prefers the work of Greenberg, Jacobsen, or Norten is a matter of taste (I happen to like all three). The buildings are different, yet the three architects have something in common. They are serious about what they are doing, that is, their buildings exhibit a strong sense of conviction. They pay enormous attention to details. They are disciplined, but they understand their self-imposed rules well enough to occasionally break them. Moreover, while their architecture is built with a great sense of style, it is never merely stylized. That is because in their buildings, style—the manner of expression—is always in the service of content—that which is being expressed. Style without content quickly degenerates into caricature, like a speaker who makes grand gestures and rhetorical flourishes, but has nothing to say. The buildings of Greenberg, Jacobsen, and Norten, on the contrary, have a great deal to tell us about our past, our surroundings, and ourselves.
Greenberg, Jacobsen, and Norten do not describe what they do in terms of style. I think that there are a number of reasons that architects are uncomfortable talking about the subject. A suspicion of style is a heritage of the Modern Movement, which preached against the arbitrary dictates of style and fashion, while maintaining an unspoken but rigid stylistic consistency. So deep-rooted is this teaching that it remains a moral stricture on most architects, whether or not they are Modernists. Perhaps another reason for the reluctance to discuss style is fear. Fear that being linked to a particular style is to be put in a box—like most creative people, architects dislike being categorized. Also fear that talking about style will make architecture—a serious business—sound frivolous. Better to leave that to interior decorators and fashion designers, professions that architects regard with a mixture of disdain and envy. Finally, there is an unspoken fear of style because it is subject to the whims and the fancies of fashion. That fear, at least, seems to me to be ill-founded. An architecture that recognizes style—and fashion—would not be an architecture that is introspective and self-referential, as are so many contemporary buildings. It would be part of the world—not architecture for architects, but architecture for the rest of us. And that would not be a bad thing.

Coda
Richard Morris Hunt was the most celebrated American architect of the late nineteenth century. His preeminence is reflected by his appointment as the architect of two important national works: the centerpiece building of the Chicago World’s Columbian Exposition, and the pedestal for the Statue of Liberty. He was feted at home and abroad. Hunt was the first architect to receive an honorary doctorate from Harvard and the first American to receive a Gold Medal from the Royal Institute of British Architects, and he was made an honorary member of the French Académie and a Chevalier of the Legion of Honor. A hundred years later, his counterpart is Frank O. Gehry. Since being awarded the prestigious Pritzker Prize in 1989, Gehry has gone on to win more honors than any other living architect, including such major arts awards as the Dorothy and Lillian Gish Prize (a non-architectural award of which he is the first recipient) and the Japanese Praemium Imperiale, the Nobel of the art world. Even the staid American Institute of Architects, which had previously shunned Gehry in lieu of more mainstream practitioners, awarded him its top accolade, the AIA Gold Medal.
No pair of architects could be more dissimilar than this distinctly odd couple, the proper High Society favorite of the Gilded Age and the untidy bohemian from Santa Monica. Yet they bear comparison. They were both late bloomers. Gehry was 48 when he gained national recognition. Until then, he had been running his own office in Los Angeles for almost twenty years, building shopping centers, suburban offices, department stores, and apartments in competent but unremarkable renditions of L.A. modern. The project that brought him to national attention was his own remodeled house: a nondescript bungalow encased in an unsettling Cubist composition of unpainted plywood, corrugated metal, and chain-link fencing. The odd shapes and unorthodox materials marked Gehry as a maverick. That was in 1978. Unexpectedly, he attracted a broad range of commissions, not only residential clients, but also museums, public institutions, universities, corporations, and developers, and not only in the United States but around the world.
Hunt was 43 when he came into his own. He had established an architectural practice in New York in 1855, almost immediately on his return from the Ecole des Beaux-Arts. He was moderately successful, achieving local renown for the Tribune Building, an early New York skyscraper. Despite his Parisian background, Hunt worked in the prevalent Ruskinian Gothic style. Of his Presbyterian Hospital in downtown Manhattan, the architectural critic Montgomery Schuyler wrote: “The building is of Gothic design with very red brick, and very irregular stone dressings, which, it must be confessed regretfully, are not pleasing to the eye.”3 For his next project, the Lenox Library, Hunt tried something different. He borrowed from the French Neo-Grec style, popularized by Labrouste in the Bibliothèque Sainte Geneviève, adding Renaissance details and his own characteristically vigorous surface modeling. The result was a startling departure from convention, a monochrome limestone block of imposing dignity. The Lenox Library (which stood on Fifth Avenue on the site of the present-day Frick Collection) marked a shift in architectural taste, away from Ruskin to a grand and frankly aesthetic Classicism. The 1880s was a decade of great prosperity, and newly wealthy New Yorkers eagerly sought out Hunt’s architectural blend of good taste and ostentatious display. He obliged them in a string of high-profile commissions: magnificent mansions along Fifth Avenue, country houses on Long Island, and palatial “cottages” in Newport, Rhode Island. Hunt died in 1895, but in the last seven years of his life, he completed more than fifty projects.
Biltmore House in Asheville, North Carolina, is a good example of his stylistic prowess. Hunt modeled the design of this 250-room residence on the Château de Blois, whose style is not the severe Classicism of the Italian Renaissance favored by architects such as Charles McKim, but the more ornate and picturesque French Renaissance. To a modern visitor, the spires, turrets, and steep slate roofs of Biltmore recall Disneyland’s Sleeping Beauty Castle, which is not surprising since Disney also used a Loire Valley chateau—the Château d’Ussé—as his model. But the comparison does Hunt an injustice, for his design is neither prettified nor quaint. His client, George W. Vanderbilt, was a young bachelor (he married soon after the house was finished), and for him Hunt created an architecture that is robust, masculine, and immensely self-assured, not in the least like a fairytale.
Vanderbilt was drawn to French chateaux, which Hunt showed him during a whirlwind European tour, since young George and his wealthy family imagined themselves American aristocrats. There are coats of arms bearing Vs all over the house. Hunt provides his client with an imagined regal setting, but deals with the past in his own peculiar way. Although he modeled the building on Blois, he makes no attempt to create a replica of the sixteenth-century chateau, but draws details from other buildings of the period and recombines them into an original whole. Nor does he try to create the illusion that this is a sixteenth-century building—there is no artificial weathering, no aging effect no simulated historicism. The interior is modern, bright, and open. The focus of the main floor is a glass-roofed conservatory, a common nineteenth-century feature. The stonework of the house is impeccable, much crisper and more sharply defined than at Blois. Hunt was no antiquarian, and modern American technology abounds. The floors of fireproof hollow tile are supported by steel I-beams and the steep slate roofs by steel roof trusses. Cast iron replaces wrought iron and high-quality bricks, fired in the estate brickworks, back-up the limestone walls. Equally novel are the elevators and telephones, electrical lighting, hot and cold running water, and forced air central heating. There is no doubt that for Hunt, Biltmore is an up-to-the-minute modern building. That is part of its style, too.
Like Hunt, Frank Gehry enlists novel materials in his buildings. The Guggenheim Museum in Bilbao, Spain, for example, is clad in titanium, previously used chiefly for building aircraft. The metallic walls curve, twist, and turn. One part of the building slides under an adjoining bridge; another emerges from a reflecting pool. Bilbainos refer to the museum as the “artichoke,” which comes close to describing it, if you can imagine a gleaming, metallic artichoke more than two hundred feet high. The seeming disorder—a chaotic collision of forms—has no architectural precedent. This is not sculptural architecture, it is walk-in sculpture.
“The plan is the generator” preached Le Corbusier, but with Gehry, the plan is the result. He appears to design from the outside in. The building as a composition comes first, the interior spaces follow. This implies that he shoehorns functions into the building, which is not the case. The Guggenheim has three distinct types of gallery spaces: traditional, skylit rooms for displaying its permanent collection of early Modernist art; a long boat-like space for temporary installations; and 11 smaller galleries, each with its own character, each dedicated to the works of a selected living artist. The artichoke accommodates them all. The building may appear offhanded, but there is nothing haphazard about the way it is organized.
Gehry’s talent is his exceptional formal imagination; his skill as an architect is to reconcile the forms he imagines with the functional demands of his client. And, of course, to find ways to build those forms. This is generally done without fuss. The titanium sheets simply follow the churning surfaces like shingles on a Shingle Style roof; limestone is used in a similarly unaffected fashion, without articulated joints. Gehry shares a minimalist approach to details with the early architects of the International Style, but he deploys these details to different ends. By removing familiar elements such as coping strips, fascias, and trim, he accentuates the sculptural quality of his buildings. There are no roofs or walls or windows in the Guggenheim, there are only swirling and twisting planes of metal, stone, and glass. An architecture critic once described Gehry as “a smart man from Hollywood,” which nicely captures the architect’s blend of exuberant showmanship and canny behind-the-scenes savvy.
Although sophisticated building techniques and innovative materials play a major role in Gehry’s buildings, like Hunt, he keeps technology off center stage. In that regard, he repudiates the mannered industrial style that pervades the work of many contemporary architects. Neither is he nostalgic about the past. Gehry rejects both the moralistic functionalism of the International Style and the traditions of Classicism. Architects have broken rules in the past, but rarely this unequivocally and totally.
Gehry, like Hunt, has changed the course of architecture. That is, he has made us look at our surroundings in a different way. The world of Gehry’s buildings is, at first glance, an odd place. The line between order and disorder is a thin one, and it is difficult to know what is intended and what is accidental. But his colliding forms and agitated architecture are curiously unthreatening. This is the way we live today, Gehry seems to be saying, why not enjoy it?















two
in and out of fashion


Bryant Park, in midtown Manhattan, is the site of a bi-annual fashion show. Twice a year, in large white tents crammed with reporters, photographers, editors, and celebrity guests, models parade designers’ wares on the runway. Bryant Park is also a good place to observe an architectural fashion show. A row of Twenties beauties lines 40th Street, along the south side of the park. First is Ely Jacques Kahn’s French Renaissance office building, originally the headquarters of Scientific American. Its neighbor is the stately Classical Engineers Club. Then comes a flapper, Raymond Hood’s American Radiator Building, whose black brick and gold trim sets it apart from its neighbors. Charles Rich’s Bryant Park Studios, an elegant survivor of the late Gilded Age, is at the Sixth Avenue corner. The large north-facing windows and glazed penthouse are a reminder that this building was originally intended for artists.
Bryant Park Studios is built in an architectural style that was originally called Modern French but today is commonly referred to as Beaux-Arts, in recognition of the influential Ecole des Beaux-Arts in Paris. Starting with Richard Morris Hunt, during the second half of the nineteenth century many of the best American architects were graduates of the Ecole. H. H. Richardson and his protégé Charles Follen McKim were alumni, as well as McKim’s assistants, John M. Carrère and Thomas Hastings. Carrère and Hastings were the architects of the New York Public Library, whose stately presence commands the east side of Bryant Park. Narrow strips of windows indicate the book-stacks, above them nine thermal windows signal the vast reading room. In typical Beaux-Arts fashion, the façade manages to appear both grandly monumental and coolly rational, except for a curious row of little doorways high up the wall, which lack balconies or even railings and open into mid-air. The strange little sky-exits, which a friend who works at the library claims are for staff defenestration, provide a fanciful note to the great marble façade.*
A row of no-nonsense 1970s office blocks lines Sixth Avenue on the west side of the park. The largest is the New York Telephone Company Building, whose banal façade of gray-tinted glass and vertical strips of marble fills the block between 41st and 42nd Street. The north side of the park is dominated by the fifty-story W. R. Grace Building, designed by Gordon Bunshaft of Skidmore, Owings & Merrill in 1972. The swooping travertine façade appears to have been inspired by the buildings of Brasília. This bit of tropical flash is flanked by an undistinguished mirrored glass tower, and a generic brick-and-Colonial-trim box. Built 50 years apart, these commercial office blocks share a balefully functionalist approach to architecture. They are strictly off-the-rack buildings that only a developer could love.
Bryant Park also offers distant views of two of Manhattan’s most distinctive skyscrapers: the Chrysler Building and the Empire State Building. The Chrysler Building started life as a speculative office building. In 1927, the architect William Van Alen, influenced by the recent Parisian exhibition of the arts décoratifs, designed a skyscraper in a style that has come to be known as Art Deco. When the plans were finished, but before construction had begun, the design and the building site were bought by the automobile magnate Walter P. Chrysler. Chrysler wanted the building to serve as a billboard for his company. Van Alen obligingly grafted on eagle-head gargoyles (based on hood ornaments), winged radiator caps, a frieze of steel hubcaps, and black brick accents that suggest running boards. The tower’s most distinctive feature was its stainless-steel cap, which held the Cloud Club, a private dining room for Chrysler executives. Today, the flamboyant Chrysler Building is considered a brilliant emblem of the Jazz Age, but it was not an instant success. When it was built it was roundly criticized as frivolous and flashy. “A stunt design,” sniffed The New Yorker. The New York Times likewise derided the blatant commercialism of the architecture.
The Chrysler Building had the distinction of being the world’s tallest building—for a few months, until it was surpassed by the Empire State Building. Although designed at the same time as the Chrysler, the Empire State is quite different in appearance. Its exterior is the architectural equivalent of a gray flannel suit. There is no decoration. The plain limestone walls lack even traditional cornices; chrome-nickel steel mullions extend uninterrupted from the 6th to the 85th floor, accentuating the building’s height. “Ornament is crime” Adolf Loos had proclaimed years before, but the stripped-down appearance of the Empire State Building owed more to an accelerated building schedule—construction took less than eighteen months—than to architectural ideology. In fact, the architects of the skyscraper considered themselves traditionalists. Richmond H. Shreve worked for Carrère & Hastings on the New York Public Library, where he met William Lamb, a recent Ecole graduate. After Carrère’s unfortunate death in an auto accident and Hastings’ retirement, Shreve and Lamb took over the firm (for several years it was called Carrère & Hastings, Shreve & Lamb) and were eventually joined by Arthur Loomis Harmon, who had worked for McKim, Mead & White on the Metropolitan Museum of Art. Despite—or rather because of—their solid Classical roots, Shreve, Lamb and Harmon designed a beautifully proportioned building that became the most famous skyscraper in the world.
The Empire State Building has one whimsical touch. The final plans called for the skyscraper to end with a flat roof over the 85th floor—1,050 feet, precisely calculated to be two feet higher than the top of the Chrysler Building’s spire. Then, before construction began, the owners decided that two feet was not enough, and ordered the architects to add a 200-foot tower to the top of the building.* This was to be not merely a decorative spire but a functioning symbol of the modern age, a mooring tower for airships. Instead of dropping transatlantic travelers off at Lakehurst, N.J., the thousand-foot-long dirigibles would fly right into Manhattan and hook themselves up to the top of the Empire State Building. Passengers would disembark to an observation platform and descend by elevator to a lounge and customs area on the 86th floor. Most experts, including Hugo Eckener, commander of the Graf Zeppelin, doubted that it could be done. It was hard enough to dock the unwieldy leviathans at ground level, never mind 1,250 feet up in the air. The experts proved to be right, and no airship passengers ever landed atop the Empire State.1 Yet the rocket-shaped tower, with its cast aluminum buttresses and gleaming conical top, is the perfect fanciful crown for this rather solemn skyscraper.
Whimsy is absent from the tops of the 1970s office blocks around Bryant Park. They look as if the architects had lopped them off on a whim: “I can do 40 floors, or 42, or 45. Just tell me when to stop.” More recent skyscrapers around Bryant Park, no doubt emboldened by Philip Johnson’s Chippendale top on his AT&T Building, have more animated crowns. The hipped roof of a Fifth Avenue Postmodern high-rise adorned with circles and squares peeks out above the library. The top of the Bertelsmann Building is a slender spike. The new Condé Nast office tower has tilted forms resembling speaker cabinets on its roof. Pretty tame stuff compared to the more fanciful crowns of the 1920s buildings—neo-Gothic spires, Romanesque tile roofs, copper domes. The 58 floors of 500 Fifth Avenue (at the corner of Fifth Avenue and 42nd Street), which was designed by Shreve & Lamb prior to the Empire State Building, step back dramatically as they reach the building’s apex. Spiky, wrought-iron finials enliven the chateau-like roof of the Scientific American Building. An animated silhouette of black brick with gilded and red highlights crowns the Radiator Building. According to Hood, the dramatic effect (floodlit at night) suggested a “pile of coal, glowing at the top.”
Raymond M. Hood was the outstanding commercial architect of the 1920s. He and John Mead Howells won a celebrated international architectural competition for the Chicago Tribune tower in Chicago with a handsome Gothic design based on the Butter Tower of Rouen Cathedral. The Chicago Tribune competition led to several New York commissions, including the Radiator Building, the Daily News Building, and the McGraw-Hill Building. With these designs, Hood developed the distinctly American approach to skyscrapers that would influence Van Alen and a generation of skyscraper designers: tall buildings conceived as Nietzschean symbols of corporate power or, to put it more mundanely, architecture as advertising. Hood once pointed out that since modern office buildings would be amortized in only 20 years, architects had an opportunity to experiment. The Daily News is a robust pinnacle, with alternating vertical strips of masonry and glass. His final skyscraper, the McGraw-Hill Building, is a witty blue-green take on the International Style, complete with the company’s name in huge “Broadway” style lettering on the top. Hood was also one of the key designers in the team of architects responsible for Rockefeller Center. His influence is felt in the centerpiece tower, the 70-story cliff-like RCA Building. This twentieth-century abstracted version of medieval verticality is one of New York’s most evocative skyscrapers, unsurpassed since it was completed in 1934.

Bryant Park chronicles a hundred years of changing architectural fashions. Buildings are sometimes referred to as timeless, as if this were the highest praise one could bestow. That is nonsense. The best buildings, like the Chrysler or the New York Public Library or the RCA, are precisely of their time. That is part of the pleasure of looking at buildings from the past. They reflect old values and bygone virtues and vices: the self-confidence of the library, the cheerful boosterism of Chrysler, the sobriety of RCA. Even the bland goofiness of the Grace Building recalls the naïve optimism of an earlier era. That is why old buildings are precious, that is why we fight to preserve them. It is not only because we think them beautiful, or significant. It is also because they remind us of who we once were. And of who we might be again, for old buildings also inspire. The ruins of ancient Rome inspired the Renaissance architects. The palazzos of Renaissance Italy inspired Charles McKim. And the memory of McKim’s Pennsylvania Station inspired David Childs of Skidmore, Owings & Merrill to transform McKim’s old Post Office Building into a projected railroad terminal for the city.
Sometimes old buildings inspire us, sometimes the opposite is true. We look at an old building and ask ourselves, “What on earth were those people thinking of?” I cannot warm to heroic public buildings of the 1960s, for example. It is more than 35 years since Lincoln Center was built, enough time for the buildings to mellow, yet I can’t summon any sympathy for the colonnaded brutes. The idea of putting three theaters under one roof must have been compelling at one time, but when I visit the Kennedy Center in Washington, D.C., all I see are miles of red carpeting in those Brobdingnagian lobbies. Yet, who knows? Perhaps one day a future generation will see something in these buildings that eludes me.
The Kennedy Center was criticized from the start, but the dazzling décor of Radio City Music Hall, which opened in 1932—in the midst of the Depression—guaranteed its immediate success. Radio City became the most famous theater in the country, the Rockettes the most famous chorus line, “live from Radio City” the most famous dateline. In the late 1950s, when I visited New York City as a boy with my parents, Radio City was still one of the obligatory tourist sites. What I don’t remember is ever learning about Radio City as an architecture student. According to the reductive standards of my International Style teachers, its opulent materials, its glowing colors, and its very theatricality disqualified Radio City as architecture (never mind that it was a technologically sophisticated “machine for entertainment”). It was dismissed as kitsch. By 1978, Radio City had lost its glamour, and the owners of Rockefeller Center decided to demolish the aging hall. Thanks to preservationists’ efforts, the hall was saved from demolition and granted landmark status. Now, 20 years later, freshened by a masterful restoration, it is once again acclaimed as a masterpiece.
Radio City Music Hall is a reminder that it is not buildings that change, but architectural fashions. What seemed exciting in one decade, looks gaudy, if not downright embarrassing, in the next—or simply boring. When old buildings are torn down, the motive may be expediency or crass commercialism, but it may also be a desire for something new. This is as true of buildings as it is of women’s hats, pace Le Corbusier.
•••
Fashion has increasingly—and restrictively—become a term used in connection with women’s dress, as in “fashion designer” or “the fashion industry.” The Oxford English Dictionary defines fashion more broadly as “the mode of dress, etiquette, furniture, style of speech, etc., adopted in a society for the time being.” People have to cut their hair, eat, clothe themselves, decorate their homes—fashion affects how they do these things. According to the French historian Fernand Braudel, fashion affects everything. “It covers ideas as much as costume, the current phrase as much as the coquettish gesture, the manner of receiving at table, the care taken in sealing a letter.”2 There is no reason to think that architecture is immune.
If style is the language of architecture, fashion represents the wide—and swirling—cultural currents that shape and direct that language. Gothic architecture originated in France in the twelfth century, and remained in fashion in Europe for the next three hundred years. It was used in the great cathedrals, and in such secular masterpieces as the Doge’s Palace in Venice, and the Westminster Hall in London. One of the last great Italian Gothic buildings was Milan Cathedral, begun in 1385. It was so large that the domical vault and crossing were not built until 55 years later by the great architect Filippo Brunelleschi. By then the Renaissance was well under way, thanks to Brunelleschi’s Foundling Hospital in Florence, generally considered the first building designed in the revived Classical style. With the rediscovery of Greek and Roman Classicism, Gothic became distinctly unfashionable. The old monuments were preserved, but they were not admired. “A fantastical and licentious manner of building,” is how Christopher Wren characterized Gothic architecture. So general was the dissatisfaction, that Gothic came to stand for anything that was considered wild, barbarous, or crude.
In the mid-eighteenth century, the term Gothic reappeared, not in architecture but in literature. The Gothic romance, a type of novel, was usually set in the medieval past and involved the fantastic and the supernatural. Jane Austen’s heroine in Northanger Abbey is a devotee of such books and spends many hours in “the luxury of a raised, restless, and frightened imagination over the pages of Udolpho.” Austen is referring to Anne Radcliffe’s The Mysteries of Udolpho, one of the most popular Gothic romances of the day, whose setting is a mysterious castle in the Apennines. Such surroundings—monasteries, dungeons, castles—figured prominently in Gothic tales ever since Horace Walpole’s The Castle of Otranto, which was published in 1764 and is generally considered the first Gothic romance.
In her novel Austen pokes fun at the genre. The abbey of the title is not a haunted ruin in Italy but a converted medieval building in Gloucestershire, complete with modern fireplaces, comfortable furniture, and other domestic conveniences. This is a reminder that by 1798, when Northanger Abbey was written, the Gothic fashion had embraced architecture. Horace Walpole was responsible for that fashion, too. In the 1750s, he had begun a project to enlarge Strawberry Hill, his Thames-side villa near London. While his contemporaries built stately houses in a delicate Classical style that was popularized by Robert and James Adam, the young Walpole, who had an independent frame of mind, looked elsewhere for inspiration. He had been an undergraduate at King’s College, Cambridge and admired its extraordinary Gothic chapel. The exterior of his house was battlemented like a medieval castle. The interior combined historicism with a playful eclecticism. Motifs copied from medieval altar screens ornamented the rooms—stained glass was used in windows and papier-mâché fan-vaults covered the ceiling. Walpole’s extensive collection of historical and modern books, paintings, and curiosities was also mixed in.
Walpole, the Fourth Earl of Orford, spent his entire life enlarging his house. He eventually added a cloister, a gallery, and a tower. As he was an author and a public figure who corresponded with a wide circle of literary and artistic friends throughout Europe, the Gothic design of Strawberry Hill became famous among connoisseurs. (It also became a tourist attraction, much to Walpole’s chagrin.) Architects and their clients now saw medieval buildings as sources of inspiration, just as they had once looked to ancient Greece and Rome. The Gothic style became an established alternative for building country houses, and pointed arches appeared in décor and furniture. Gothic was “in” again.
The revived interest in the Middle Ages was complicated, for fashion is rarely one-dimensional. Gothic meant different things to different people (sometimes different things to the same people). Spooky Gothic novels appealed to readers. Medieval buildings appealed to the current taste for the romantic and the picturesque. Goethe’s 1772 essay on Strassburg Cathedral pointed the way; he admitted to being “a sworn enemy of the tangled arbitrariness of Gothick ornament,” but found himself overcome by the grandeur and mystery of the building, which he described as “a most sublime, wide-arching Tree of God.” The French architectural theorist Eugène Viollet-le-Duc, on the other hand, was attracted by what he interpreted as the rationalism of Gothic construction. So was his English counterpart, George Gilbert Scott, who considered Gothic more “modern” than Classical architecture, hence a more appropriate model for architects. Augustus Welby Pugin, who worked on the British Houses of Parliament, saw a moral dimension to Gothic. He considered medieval architecture to be the ideal of Christian civilization, much as Greece and Rome had been admired as the cradle of classical—but pagan—civilization. John Ruskin, too, considered Gothic a moral force, but since he also loved Venice, polychrome Ruskinian Gothic has many Italian overtones. This incongruity is particularly striking since in England especially (but also in France and Germany), the Gothic style was considered a homegrown product—as opposed to Mediterranean Classicism. This was another cultural appeal of Gothic: at a time of growing nationalism in northern Europe, it conveniently provided a “national” style.
In North America, Gothic was, if anything, even more popular. Canadians chose a British architect and the Gothic style for their Houses of Parliament, which stand on a dramatic bluff overlooking the Ottawa River. Anglophile Americans built Collegiate Gothic campuses, Gothic parish churches, and a Gothic National Cathedral in Washington, D.C. Ralph Adams Cram, who was devoted to High Gothic, built the nave and west front of New York City’s Cathedral Church of St. John the Divine, the largest Gothic structure in the world. Cram’s partner Bertram Goodhue used a looser Gothic style in the military academy at West Point, as did Cass Gilbert in the Woolworth Building—the so-called Cathedral of Commerce. By then the cultural attributes of Gothic had worn thin. Hood’s Chicago Tribune Building, completed in 1924, was one of the last prominent buildings designed in the Gothic style.
Gothic has not—so far—come back into fashion. Early in his career, Paul Rudolph designed a building for Wellesley College that attempted to relate architecturally to the Collegiate Gothic surroundings. It was his first large commission, and it was not a success. “Wellesley shook me,” Rudolph later recalled, “and I returned to the International Style in my next building.”3 Eero Saarinen built a Gothicized dormitory at Vasser. Philip Johnson and John Burgee designed a Gothic-inspired skyscraper in Pittsburgh that was a giant abstracted glass version of the British Houses of Parliament. This was one of several stylistic forays that Johnson and Burgee made in the 1980s, including a Chippendale-top skyscraper in New York, a French Provincial high-rise in Dallas, and a neo-Burnhamesque tower in Chicago. None is particularly satisfactory, perhaps because they lack conviction. Moshe Safdie’s National Gallery of Canada in Ottawa is more successful. It mimics the Gothic chapter house-cum-library of the adjacent parliament buildings in a crystalline structure of steel and glass. This episode in Safdie’s oeuvre was unique, however, and Gothicized forms do not reappear in his later buildings.
The Classical style has proved more durable. This has something to do with its remarkable adaptability. Whether building an administrative center for the British Raj or designing a station for the Pennsylvania Railroad workable solutions can be devised in the Classical tradition. The cultural overtones of the Classical style are even richer than those of Gothic; they include not only the ancient civilizations of Greece and Rome, but also Renaissance Italian humanism, seventeenth-century Parisian splendor, Georgian London elegance, and English country-house comfort. During the immediate postwar period monumental Classical buildings also acquired authoritarian associations, since they had been fashionable in Nazi Germany and Stalinist Soviet Union. If Gothic was considered a national style by some English architects in the 1800s, Classicism, rooted in the early days of the Republic, has a claim to being America’s national style. This is most evident in Washington, D.C. Except for brief flirtations with Victorian Gothic (the Smithsonian) and functionalist modernism (the Air and Space Museum), Classicism has remained in fashion for federal buildings ever since the construction of the Palladian White House. Washingtonian Classicism has taken many guises, ranging from the Jefferson Memorial (a small version of the Pantheon), to the severely abstract Federal Reserve Board Building. The Federal Triangle and the recent Ronald W. Reagan Building are modern interpretations of the Classical tradition.
While the architecture of federal Washington sometimes overwhelms foreign visitors, it is comfortably familiar to most Americans because of the popularity of a simplified version of Classicism—the so-called American Colonial style, which could more accurately be called American Georgian. In furnishings, décor, and above all in house design, this has been the dominant domestic fashion for the last hundred years. The origin of American Colonial can be dated with some accuracy. January 1874 was the inaugural issue of The New York Sketchbook of Architecture. It was edited by a youthful Charles McKim. The purpose of the publication, McKim wrote, was to document in sketches and photographs, “the beautiful, quaint, and picturesque features which belong to so many buildings, now almost disregarded, of our Colonial and Revolutionary Period.” McKim and his new partners, William Mead and Stanford White, made several sketching trips in New England. They were designers, not preservationists, and their interest was the inspiration found in old buildings. White clapboard walls, black shutters, and pedimented porches started to appear in McKim, Mead & White houses. The 1876 Centennial celebrations made the American public aware of its ancestral past. On a practical level, the understated, comfortable Colonial style was well-suited to prevailing domestic taste. It was also easily—and inexpensively—adapted to small houses. American Colonial remained the height of fashion until the 1940s. In a simplified form—the Cape Cod cottage—it reappeared in postwar Levittowns. It continues today, although the clapboard siding may be vinyl, the columns polystyrene, and the stamped metal shutters more likely symbolic than real.

“The Tribune and Radiator Buildings are both in the ‘vertical’ style or what is called ‘Gothic’ simply because I happened to make them so,” Raymond Hood once flippantly explained. “If at the time of designing them I had been under the spell of Italian campaniles or Chinese pagodas, I suppose the resulting compositions would have been ‘horizontal.’ ”4 Hood was no more comfortable discussing style than other architects. He left unexplained the question of what had put him “under the spell” of Gothic in the first place. It had happened early: Hood’s senior thesis at M.I.T.—he later also studied at the Ecole—had been a church in the Gothic style; his first employer was the Gothicist Ralph Adams Cram; and Hood assisted Bertram Goodhue on West Point. Later in life, Hood occasionally returned to the Gothic style, notably in the handsome Masonic Temple and Scottish Rite Cathedral in Scranton, Pennsylvania, but he never explained what broke the spell and led him to a more abstract style.
Like any successful architect, Hood had a strong sense of his changing time. It is easy to misunderstand the nature of that change. The abstraction that characterizes the Daily News Building and the RCA Building has little to do with new technology or changing functions. Those buildings are not any more “modern” than the Chicago Tribune tower, which had gargoyles and flying buttresses but was an advanced building in terms of planning and technology. Indeed, Hood’s Gothic design was more functionally advanced than Eliel Saarinen’s stylistically progressive second-place entry. It was not commodity and firmness that drove the changing aesthetic, but fashion. The public had a taste for simpler, forward-looking design, of which the International Style was but one expression. Art Deco, streamlined modern, and stripped Classicism were evidence of the same changing taste. Many industrial products of the 1930s displayed the same chic simplicity: Raymond Loewy’s curvilinear Coldspot refrigerator, Walter Dorwin Teague’s popular Kodak Brownie camera, Henry Dreyfuss’ Bell telephone, Loewy’s redesigned Coca-Cola bottle and the sleek Zippo cigarette lighter.
The medieval inventors of the Gothic style were likewise influenced by fashion. In the twelfth century, European cathedral builders abandoned the tried-and-true round arch in favor of the pointed arch. This change cannot be explained by functional or structural requirements, since the pointed arch provides only marginal structural advantages; and round-arch technology is perfectly capable of building tall naves, as Durham Cathedral and other magnificent Romanesque churches demonstrate. Cathedral builders obviously found something delightful in the pointed arch, which they used not only as a structural form, but in window tracery, in wood paneling, and even in choir-stall furniture and liturgical accessories. “[Gothic] was seized upon as essential not because it was materially essential, but because the pointed arch struck that note of fantasy which was what the mind of the age desired,” explains John Summerson. “It willfully destroyed the discipline of the round arch, which had become an incubus and a bore.”5 A note of fantasy? A bore? At this point, the eminent architectural historian sounds like a Harper’s Bazaar fashion critic.
Architectural reputations, as well as architecture, come under fashion’s sway. Hood, Ely Jacques Kahn, and Ralph Walker (the architect of the Irving Trust Building on Wall Street), all small men, were dubbed the “Three Little Napoleons of Architecture” by The New Yorker. Riding high in the 1920s, their careers were cut short by the Depression—Hood’s more so, since he died in 1934, only 53 years old. Rockefeller Center continued to be admired by the public, but because of his freewheeling approach to design, Hood was marginalized by modernist architectural historians. He was never forgiven for winning the Chicago Tribune competition and beating not only Saarinen, but such European avant-gardists as Adolf Loos, Bruno Taut, and even Walter Gropius, the founder of the Bauhaus and the guiding light of the International Style. Yet if I compare Hood’s RCA Building with Gropius’s Pan Am (today MetLife) Building, there is little doubt who was the more creative designer.
Looking at that monolith, bestriding Park Avenue without charm or grace, it is easy to forget that Gropius was once considered one of the great architects of the twentieth century. Architectural memory can be fickle. Thomas Ustick Walter is not a household name, but it should be—he was the architect of the U.S. Capitol dome, probably one of the most powerful symbols of American democracy. The Lincoln Memorial, designed by Henry Bacon, is another famous architectural icon. Bacon died in 1924, only two years after the memorial was dedicated, so he did not see the Classicism that he had learned at McKim’s knee slip out of fashion. At least Walter and Bacon were feted during their lifetimes. Edward Durrell Stone, an International Style wunderkind, developed an unfashionable interest in decoration at a time when architectural austerity was in vogue. And although he received large commissions (including the Kennedy Center for the Arts), he finished his career ignored if not actually ridiculed. In the mid-1960s, Paul Rudolph was probably the most promising young architect in the country. His robustly monumental Art and Architecture Building at Yale, where he was also chairman, reinvigorated postwar American architecture. A decade later, heroic monumentalism was out and Postmodernism was in. Although Rudolph continued to receive commissions in Asia, he was slighted in his own country. His contemporaries Gordon Bunshaft and Kevin Roche were awarded the Pritzker Prize, but Rudolph was passed over. By the time he died in 1997, he was virtually forgotten.
Yet Rudolph, a gifted designer, may be admitted to the architectural pantheon one day. Architectural reputations can rise and fall and rise again. The nineteenth-century Philadelphia architect Frank Furness designed Ruskinian Gothic buildings whose lively eclecticism anticipates James Stirling. Furness, an exceptional individual who won a Congressional Medal of Honor during the Civil War, dominated the Philadelphia architectural scene for 20 years. In 1891 he completed the University of Pennsylvania Library, a widely acclaimed brick and terracotta building with a dramatic four-story-high reading room. After the turn-of-the-century, with Classicism all the rage, Furness’ idiosyncratic brand of architecture became unfashionable. Although he lived until 1912, his practice languished. In time he was entirely forgotten, many of his buildings were demolished, others insensitively altered. As for the library, its tall reading room was crudely truncated by a suspended ceiling. In the 1950s, there was a revival of interest in Furness, which narrowly saved the library from demolition. Today, after a careful restoration, the library is unquestionably the best-loved building on the University of Pennsylvania campus—something about the spiky decoration and the willfully manipulated forms appeals to current sensibility. Furness has found an audience again.
The fate of Rudolph and Furness is a reminder that although architecture is susceptible to fashion, architects are not fashion designers. “I do not design a new architecture every Monday morning,” Mies van der Rohe is reputed to have said. This is often taken as a reflection of his serious commitment to his art. It was that, but it was something else, too. He might as well have said, “I cannot design a new architecture every Monday morning.” The Seagram Building is a masterpiece, not because Mies had a sudden inspiration, but because he had spent decades learning how to bring commodity, firmness, and delight into his particular version of balance; how to attach the travertine to the wall to create a particular effect; which metal fabricator could make a certain kind of handrail; and exactly how deep to make a window mullion to cast the right size of shadow. Buildings are extremely complicated artifacts, and the time necessary to cultivate and refine a particular manner of building cannot be underestimated. This is especially true when the manner of building is personal or unusual, as it was in the case of both Furness and Rudolph. They were not simply being stubborn or high-minded when they refused to adapt to changing fashions, they were being realistic.
Morris Lapidus is an architect who has lived long enough to see architectural fashions come full circle. In the 1950s, Lapidus designed many of the largest hotels in the Miami area: the Fontainebleau, the Americana, the Eden Roc. His flamboyant, eclectic designs were ridiculed by the architectural establishment, although they were popular with the public. Today, in a period of so-called entertainment architecture, when the world’s most celebrated architects design theme parks and casinos, Lapidus seems less like a maverick than a pioneer. “The father of us all,” Philip Johnson called him, with only slight exaggeration.
•••
Architecture changes at a bewildering pace. Consider only the last 50 years of museum design. The National Gallery of Art (1937-41) in Washington, D.C. and the Museum of Modern Art (1937-39) in New York City are almost exact contemporaries. In the MoMA design, Philip L. Goodwin and Edward Durrell Stone ignored the Classical tradition represented by John Russell Pope’s masterpiece. MoMA’s entrance was not up a broad flight of exterior steps but through a revolving door. Goodwin and Stone replaced the monumental rotunda by a nondescript lobby, the lofty galleries by low-ceilinged loft spaces, and limestone and marble by stucco and plasterboard. MoMA was to be the last word in avant-garde International Style, but it was scarcely finished when it was challenged by Frank Lloyd Wright’s Guggenheim Museum (1943-58), which rejected the banality of the white box by squeezing the entire museum into a dramatic sculptural spiral. Nothing could be further from the International Style than the mollusk-like exterior (especially if it had been tinted rose-red, as Wright initially wanted). In the Yale Center for British Art (1969-77), Louis I. Kahn likewise incorporated central skylit spaces, but he disavowed Wright’s loud anti-urban exterior by hugging the sidewalk and clothing his building in drab stainless steel panels. Kahn preached taming technology by consigning it to so-called servant spaces; in the Centre Georges Pompidou (1971-77), Piano and Rogers stood Kahn’s dictum on its head and gave the servants the run of the house. In the Neue Staatsgalerie (1977-83), James Stirling cheekily lifted architectural elements from both the Pompidou and the Guggenheim and combined them with a variety of historical styles. I. M. Pei’s impeccably crafted East Building of the National Gallery of Art (1976-78) in Washington, D.C., had not one exposed bolt, not one allusion to the past. Pei rejected both Stirling’s eclecticism and Piano and Rogers’ technological posturing. Instead he relied on abstract geometry for architectural effect. Frank O. Gehry’s California Aerospace Museum (1982-84) in Los Angeles is no less abstract and geometrical, but his forms bump and grind into each other almost as if by accident. “I really enjoy the awkwardness with which [the forms] touch,” Gehry observed, “as it reminds me of the cities we live in and the kind of awkwardnesses of city buildings sitting next to each other.”6 The cost of the East Building was $94.4 million; the Aerospace Museum was built on a tight budget of only $3.4 million. Lacking money for refinement, Gehry turned awkwardness into a virtue, and in the process disowned Pei’s fastidious brand of modernism. He was carefree where Pei was careful, spontaneous where Pei was studied, brash where Pei was genteel. The Aerospace Museum was clearly not a cheaper version of the East Building, it was something different.
“Fashion is also a search for a new language to discredit the old,” writes Fernand Braudel, “a way in which each generation can repudiate its immediate predecessor and distinguish itself from it.”7 This puts fashion in the right light: it may be fleeting, but it is not frivolous. As Braudel suggests, changes in fashion imply not only the creation of something new, but the destruction of something old. That is why new fashions are inevitably upsetting. Whether one is wearing a lounge-suit instead of a frock coat, or turning a baseball cap backwards, someone else is bound to be insulted. No less so in architecture. Replacing an Ionic column with a steel I-beam, or exposing air-conditioning ducts, or using common materials in uncommon ways are calculated affronts to honored conventions. “We are not like our fathers,” the architects say, “we are different.”
















the look of architecture






one
dressing up


Architecture is hard to define. Goethe called it music frozen in space, which, while it captures a sense of rhythm, is too one-dimensional. And it relegates the mother of the arts to an inferior position; just as well to describe music as melted architecture. Nietzsche believed that architecture reflected his pride, man’s triumph over gravity, and his will to power. This notion applies to many buildings, from Gothic cathedrals to skyscrapers, but it is too, well, Nietzschean. The British master Edwin Lutyens referred to architecture as a sort of play: “In architecture, Palladio is the game!” Le Corbusier described his art as “the masterly, correct and magnificent play of masses brought together in light,” which is a good description of one of his own buildings. I am partial to Sir Henry Wotton’s definition. Wotton, who lived a long time in Venice and was a lover of architecture though not an architect, published a treatise on the subject in 1642. “In Architecture, as in all other Operative Arts, the end must direct the Operation,” he wrote. “The end is to build well. Well-building hath three conditions: Commoditie, Firmeness, and Delight.”
Sir Henry’s description, which was based on the writings of the Roman architect Vitruvius, appeals to me because it emphasizes the complexity of the building art. To begin with, architecture has not one but three distinct purposes: to shelter human activity (commodity), to durably challenge gravity and the elements (firmness), and to be an object of beauty (delight). Architecture is always a synthesis of the three. However, the fulfillment of one purpose does not guarantee the satisfaction of the others. There are homely sturdy buildings and beautiful flimsy ones. A well-planned building can be ugly just as a beautiful building can function poorly. Form does not, contrary to Louis Sullivan’s hoary maxim, follow function.
Not only are function and form separate, over their long lives buildings can successfully accommodate a variety of uses. For example, some of the most famous museums (the Louvre, the Hermitage, the Belvedere) started life as royal palaces; the Uffizi in Florence is so named because it originally housed offices; and the Prado in Madrid was designed to be a museum of science, not art. The acclaimed Musée d’Orsay in Paris is housed in a railroad station. Two of my favorite small museums, the Frick Collection in New York City and the Phillips Collection in Washington, D.C., were built as residences. As historic preservation and adaptive reuse demonstrate, you can shop in a renovated warehouse, do office work in a converted loft, or live in a barn. Assuming, of course, that the warehouse, the loft, and the barn were well built. The material fabric of old buildings—the heavy beams, rough brick walls, and solid woodwork—is one of their chief pleasures. That is why we feel cheated by hollow walls, flimsy doors, and shaky balustrades. Buildings should last and feel as though they will.
One might assume that just as the highest-rated cars—Mercedes-Benz, BMW, Lexus—represent the highest standards of automobile technology, the most admired architecture would be the best built. This was generally true in the past, but in the twentieth century, when new materials and new aesthetic theories often have driven architects to cavalier experimentation, even celebrated architects have fallen short in that department. Le Corbusier’s white suburban villas, for example, were crudely finished in cement plaster on top of brick, and since the architect usually ignored (for aesthetic reasons) intrusive metal flashing and coping strips, the crude “machines for living” often aged poorly. Some Frank Lloyd Wright buildings have leaky skylights, sagging overhangs, and defective heating systems. This does not make them any less delightful to visit, but it must make them considerably less delightful to inhabit. Perhaps the most dramatic example of failed experimentation in recent years is the Centre Georges Pompidou in Paris, which opened in 1977. The building was widely praised for its architectural innovation—the British periodical Architectural Design called it “a seminal building of the Modern Movement.” The architects Renzo Piano and Richard Rogers turned the building literally inside-out. They dramatically hung pipes, ducts, fire stairs, elevators, and escalators from the exterior structure. These previously hidden elements were now exposed in plain sight—and exposed to the elements. The result might have been foreseen: after only twenty years, the French government was obliged to close the building for a two-year renovation. Although the authorities maintained that the renovation was required because of the unexpectedly large number of visitors, according to Le Monde almost half of the $90 million budget was spent on refurbishing the façade.
The University of Pennsylvania, where I teach, is the site of Louis I. Kahn’s A. N. Richards Medical Research Laboratory. This structural tour-de-force of precast concrete and brick brought its designer international acclaim. I remember traveling from Montreal to Philadelphia as a student to see the building a few years after it was built. My classmates and I particularly admired the exposed concrete structure and the explicit separation of what Kahn called “servant” and “served” spaces—massive brick ventilation shafts and delicate, glass-enclosed individual laboratories. However, The latter proved to be unpopular with their occupants. The large windows let in too much light (today, most are papered over with aluminum foil), cement dust from the exposed concrete beams falls on the lab tables, and the rigid plan has proved inflexible to changing needs.
The Richards Laboratory was built only 35 years ago. It is next to a student dormitory known as the Quad, a picturesque Jacobean Revival complex planned around a series of courtyards. This handsome building has been doing yeoman service for almost a century. The Quad was designed by the Philadelphia firm of Walter Cope and John Stewardson, whose work at the University of Pennsylvania, Princeton, and Bryn Mawr was largely responsible for the popularity of so-called Collegiate Gothic. Pleasing, well-loved—and well-built—the Quad is architecture of the highest order. Yet my classmates and I did not pay any attention to the dormitory when we visited Philadelphia years ago. We had never heard of Cope & Stewardson, despite their achievements and wide cultural influence. The architecture historians whom we studied—Siegfried Giedion, Nikolaus Pevsner, James Marston Fitch—favored innovators and experimenters, even if the innovations and experiments often failed. Put another way, most historians of modern architecture gave precedence to Delight over Commoditie and Firmeness. This may be because the appearance of a building was easier to assess (especially at a distance) than either its functional performance or material durability. Or maybe they were attracted chiefly to the aesthetic qualities of architecture. In any case, “imaginative, inventive, and revolutionary” were more likely accolades to be showered on important buildings than “accommodating, dependable, and sound.”
This is not to say that good architecture is merely utilitarian. One of the grandest spaces in Philadelphia is the concourse of Thirtieth Street Station, which was built in 1934 for the Pennsylvania Railroad by the accomplished Chicago architects Graham, Anderson, Probst & White, the successor firm of Daniel H. Burnham. The magnificent room, 290 feet long and almost 100 feet high, is covered by a flat coffered ceiling decorated in red, gold, and cream. Diffused light streams in from tall windows on both sides. Almost nothing in this memorable space—the gilded Art Deco chandeliers, the travertine walls, the massive Corinthian columns at each end—was a product of its rather mundane function: to provide a waiting space for people, before they descended the staircases that led to the platforms below. But the railroad station concourse in the heyday of railroad travel, was more than merely a place to get on and off trains. It was a gateway to the city, as well as a symbol of unreserved faith in modern transportation—and in the Pennsylvania Railroad. That is why it was appropriate for delight to take precedence over commodity.
Yet delight is not uniform. The Main Concourse of Grand Central Terminal in New York City, for example, offers different pleasures than Thirtieth Street Station. The monumental spaces are comparable in size and function. They are both well built. Similar spaces, similar materials, yet the experience of the two concourses is different. Both buildings are inspired by the Classical architecture of the past, but Grand Central, which opened in 1913, is a modified version of Beaux-Arts Classicism, whereas the Philadelphia station, despite the Corinthian columns, is simplified, abstracted, and stylized, what historians called “stripped Classicism.” As a result, Grand Central is dramatic, visually rich in its details, almost Wagnerian; Thirtieth Street is equally dramatic but in a way that is coolly geometrical and sleekly urbane—not Wagner, Cole Porter. Style is evident in the smallest details. It ensures a continuity between the great vaulted sky of Grand Central and the ticket counters, or between the Thirtieth Street chandeliers and the announcement boards at each track stair. It is the visual language of a building. Architectural style is the manner in which the architect communicates a particular kind of visual delight, in large ways and small.
Commodity, firmness, and delight are never evenly weighted. Sometimes one predominates, sometimes the other. Sometimes a waiting room needs to be a triumphal celebration of arrival and departure—sometimes it is just a waiting room. Sometimes it is necessary to compromise structural simplicity to achieve an esthetic effect. Sometimes functional requirements override other considerations; a laboratory that does not serve its scientists is a failed work of architecture, no matter how beautiful its design. A banal church is a greater failure than a banal factory. The art of building requires judiciously balancing Wotton’s three conditions.
The end must direct the operation. That is what distinguishes architecture from the fine arts of painting and sculpture “An artist can paint square wheels,” Paul Klee once observed, “but an architect must make them round.” Architecture, in this respect, is no different than other “operative arts” such as cooking. The creativity of the chef is likewise circumscribed by factors outside his control—the natural ingredients, the human palate, the chemistry of foods. The dish must be at once nourishing (commodity), cookable (firmness), and, of course, tasty (delight). (It should also look good, although the contemporary trend toward visually extravagant dishes seems to me an aberration). The art of cooking, like the art of architecture, lies in knowing how to establish the appropriate relations between the three conditions.

The experience of food is sensual. It is also first-hand. That is, while it’s fun to read recipes and look at photographs of table settings in Gourmet magazine, no one I know considers this a substitute for eating. The experience of buildings is sensual, too. Yet, many of us get our first glimpses of buildings—particularly celebrated buildings—as images in books, magazines, newspapers, public lectures, and exhibitions. One of the most famous buildings of the Modern movement, Ludwig Mies van der Rohe’s Barcelona Pavilion, was known almost entirely through photographs since it was built for an exhibition that lasted only seven months. Before photography, the Paimio Tubercolosis Sanatorium, located in a remote part of Finland, would have remained obscure; as it was, its stunning images brought the young Alvar Aalto worldwide recognition. The Sydney Opera House is another world-famous building that, at least outside Australia, relatively few people have seen first-hand. Yet photography tells us very little about how a building fulfills its function, or about how it is built. For example, the handrails in the often-photographed stairway of the Paimio sanatorium look like standard International Style metal pipes. In fact they are wood—much more pleasant to the touch—painted to look like metal. Well-known photographs of the Barcelona Pavilion show eight free-standing columns supporting a flat slab, and free-standing marble screens that carry no loads, a prototypical International Style structure. In reality, there are columns concealed within the screens, which are not slabs of marble but thin marble sheets attached to a masonry back-up wall. In other words, this 1929 building is an example of traditional layered construction, not of modernistic structural purism.1
In photographs, buildings are forever young. The ravages of time, weather, and use are banished. It is a shock to come across a revered architectural icon and to find the concrete stained, the painted window frames chipped, the tiles cracked. Of course, all buildings age, but some age more gracefully than others. A 450-year-old Palladio villa retains its beauty, despite peeling plaster and mossy stonework (perhaps it even looks more enchanting). Most modern buildings, on the other hand, lose their potency if they are not gleaming and machinelike.
Obviously, photography highlights the visual qualities of buildings and ignores commodity and firmness. Yet photography cannot completely communicate delight. A visitor to the Seagram Building in New York, for example, is surprised to discover the subtle relationship between Mies’ bronze tower and the Italian Renaissance façade of McKim, Mead & White’s Racquet and Tennis Club on the other side of Park Avenue. Equally deceptive are photographs of Frank Lloyd Wright’s work in Oak Park, since they give no hint of the comfortable suburban surroundings of his so-called prairie houses. As I student, I studied the buildings of Le Corbusier in black and white photographs, which did not prepare me for the shock of experiencing his often wildly polychrome interiors. Nor can photography communicate movement, which is such an integral part of the architectural experience (film is better at this, but not much). Nothing conveys the actual experience of a building like the real thing. To paraphrase Robert Hughes, a photograph of architecture is to architecture as telephone sex is to sex.
Never is modern architectural photography more misleading than in its portrayal of domestic interiors. Interiors are usually photographed empty or with minimal furnishings, before the owners have had the opportunity to move in and (presumably) defile the purity of the design. But even if the space is occupied, strict conventions prevail: furniture must be lined up just so; there must be no distractions, no half-empty tea cups, no crumpled newspapers, no abandoned children’s toys. Books on shelves are arranged to create interesting patterns, personal mementos are temporarily banished—everything must be neat. I once observed a photographer’s assistant during a photo shoot comb out the fringe of a rug. Such primping and visual editing sets off the architecture to best advantage. It also—not coincidentally—gives the impression that the designed interior is autonomous and self-contained: in other words, that it is a work of art. Markedly, these photographs never include human figures. People would be the greatest distraction of all.
The world of buildings depicted in books and magazines is a scaleless, self-sufficient place. The absence of people in architectural photographs has several effects. In the past, the proportions and dimensions of buildings were based on the human body. While this was done for philosophical reasons, it also ensured a direct relationship between architecture and people—it is why even very large Classical buildings feel comfortable. By removing people from buildings, architectural photography makes it possible to regard architecture as an abstraction, unrelated to humans. It is not merely that the conventions of modern architectural photography ideally communicate the intentions of most modern architects, it is also that they validate those intentions. People? Who needs them?
While I was writing Home, I discovered that the most useful historical sources for information about how people furnished and decorated their homes were often paintings. Not paintings in which the room was the subject, but portraits and domestic genre scenes. An example of the latter is James Tissot’s, “Hide and Seek,” which shows four little girls at play in a Victorian sitting room. The décor is exotic, an eclectic mixture of Persian rugs, Chinese porcelain pots, and tiger-skins and others furs scattered over the furniture.
Tissot was a French painter who settled in London in 1871. An easel in the corner suggests that this is his own house, in which case, the woman sunk deep into an easy chair, reading a newspaper may be his Irish mistress. John Singer Sargent’s masterpiece, “The Daughters of Edward Darley Boit,” painted in 1882, likewise shows four girls. Henry James described it as “the happy play-world of a family of charming children,” but the girls can hardly be said to be playing. Properly dressed in white pinafores, black socks, and patent leather shoes, they form a motionless tableau. The room, in an apartment in Paris, is stylishly bare, unadorned except for two immense Japanese vases and a red screen. The mood is entirely different in the Swedish painter Carl Larsson’s playful “Mother’s and the Cherubs’ Room,” which was included in Larsson’s famous book Ett Hem (At Home), published in 1899. The walls of his wife’s bedroom are wooden boards, whitewashed and decorated with a painted frieze of ribboned garlands; the ceiling, likewise wood, is painted green with red trim. The simple furniture is also painted in bright colors. Karin Larsson’s bed is separated from the children’s cots by a striped woven curtain. We see three of the Larsson girls in various stages of dress—and undress. That is appropriate, too, for naturalism and artlessness permeate this charming scene.
Such paintings are more faithful depictions of domestic surroundings than modern architectural photographs. For one thing, they are full of the signs of everyday life. A coat is thrown casually over a chair, there are crumbs on the table, Tissot’s little girl playing on the floor rumples the carpet. Moreover, in these interiors the architecture is in the background. It is a setting for human activity—just as it is in real life. Paintings also convey something about the atmosphere of the interior. Dutch seventeenth-century domestic paintings, for example, exude a prosperous air of bourgeois comfort and propriety. A hundred years later, François Boucher painted a middle-class French family gathering for morning coffee in a little room with japanned woodwork and gilded moldings. There is a sweet intimacy here that is absent in the Dutch interiors. An interior of the same period by Henry Walton shows an English gentleman at breakfast. He is sitting in a relaxed posture, wearing a riding-coat and boots, accompanied by his dog. The ambience is one of informal and relaxed country life.
As I studied such paintings, I started to see associations between the rooms and their inhabitants. The legs of the mahogany furniture in an English country house were as straight and unadorned as their owners’ riding boots. The arabesques and curlicues of the moldings and architectural ornaments in a French salon mirrored the flouncing ribbons that adorned the women’s dresses and the frills of the men’s shirts. The proper black broadcloth and white lace collars of the Dutch men and women echoed the spotless black-and-white checkerboard marble floors. I became convinced that a strong connection exists between the way that we decorate our homes and the way that we dress ourselves.
There are three distinct reasons for the intimate relationship between dress and décor. The first is technical. Décor, like dress, incorporates fabrics. Curtains, swags, and window-treatments are made of silk, damask, satin, brocade, wool, muslin, and velvet—so is clothing. Woven materials are used in tapestries, wall-hangings, carpets and upholstery as well as coats and skirts. Inevitably, the dressmaker’s techniques of embroidering, gathering, pleating, and trimming find their way into décor. This is why furniture skirts recall women’s skirts, and why the fringes, cords, and bobbins of nineteenth-century drapery recall ladies’ ballgowns. The delicate lace curtains and the billowing baldachin over a bed in a ladies’ boudoir matched the clothes in her dressing room.
The connection between décor and dress can be even more intimate, for architecture sometimes directly mimics dress. The garlands in eighteenth-century buildings are sculpted or painted versions of the sashes and flowered ornaments worn by men and women. The ancient Greeks incorporated elements of dress in temple architecture. This is most apparent in colonnades, which Vincent Scully has likened to hoplites massed in a phalanx.2 There is no doubt that Classical columns were given human attributes. Ancient authors likened the vertical flutes to the folds in a chiton, or tunic.3 Columns have capitals—that is, heads. The moldings of Doric capitals were sometimes painted to resemble headbands; Ionic and Corinthian capitals incorporated carved head garlands, and the curving tendrils of Corinthian capitals often look more like hair than foliage. Indeed, Vitruvius considered the Corinthian order “feminine,” as opposed to the sturdy masculine Doric. Sir Henry Wotton went so far as to call the Corinthian order “lascivious” and “decked like a wanton courtesan.”4
The second connection between dress and décor is social. In the 1890s, the famous English economist Alfred Marshall observed that as people earned more money, they wanted better food, better clothes and larger homes—both for social standing and comfort. Since homes and clothes are timeworn ways in which to convey status, there is a conformity in the types of materials and symbols used to convey social standing. If family coats of arms are displayed, they will be seen on wall medallions as well as on blazer buttons. If gold is treasured, the wealthy will wear gold braid and surround themselves with gilt moldings. If this is considered too flashy, other materials can convey status: stainless steel kitchen appliances and stainless steel watch bracelets. Diamonds may be forever, but fashions change. Today, leather is considered a luxury material, and is used both for expensive clothing and expensive sofas. A hundred years ago, leather was considered utilitarian; leather aprons and vests were worn only by workmen, and leather easy chairs were only found in smoking rooms and men’s clubs since leather was less flammable than fabric. But it was never used in salons or drawing rooms. When corduroy, originally used only in workingmen’s dress, became accepted by the middle class, it also showed up as upholstery. The current fashion for “natural” dress fabrics—cotton, wool, linen—has a counterpart in “natural” décor: exposed brick, oiled wood, polished concrete.
In a more general sense—and this has nothing to do with conspicuous consumption—both homes and clothes convey values. Carl Larsson’s home was a statement of both his and Karin’s naturalistic aesthetic ideals, so was James Tissot’s exotic sitting room. Whether or not we are artists, our homes, like our clothes, communicate who we are, or at least how we wish others to perceive us: starchly formal or comfortably casual, intensely avant-garde or resolutely traditional, bohemian or conservative, cosmopolitan or down-home. The Che Guevara poster on the wall and the embroidered denim jacket convey one set of values; Colonial break-fronts and penny loafers, another. That is why it is disconcerting if dress and décor are not in harmony. Sweat shirts and running shoes in a Louis Quinze drawing room send a decidedly mixed message, as does a three-piece suit on the deck of a Malibu beach bungalow.
The third connection between dress and décor concerns perception. Architecture, interior decoration, and fashion design are three distinct fields, yet we experience them with the same eye. Whether we look at dress or décor, we bring the same visual bias, the same sensibility, the same taste. This sensibility is not constant. Sometimes we appreciate simplicity, sometimes complexity. Fashionable seventeenth-century French eyes, for example, favored floral decorations and embroidery, and introduced the custom of having vases of fresh flowers in the home. English eyes in the midst of the Neoclassic revival sought fundamental simplicity and sobriety in men’s clothes as well as in architecture. Victorian eyes fancied dense patterns that were likely to show up in waistcoats and on wainscotting. Parisian eyes, in the early 1900s, admired the same neo-Empire motifs in dress and décor.*
Early twentieth-century eyes had their own particular sensibility. One of the great interiors of this period is the main living space of the Tugendhat House, designed by Mies Van der Rohe in 1928. The house stands outside Brno, Czechoslovakia. The exterior is a low-key International Style white box, but the interior is astonishing. The public rooms are contained in one large open space. A curved wall of macassar ebony defines the dining room, and a straight free-standing wall of onyx dorée separates the music room from the living room. The space is punctuated by slender cruciform columns covered in chromed metal. The east and south walls are floor-to-ceiling glass—a precursor of Mies’ famous glass house. The sense of openness is heightened when, at the touch of a button, fifteen-foot sections of the glass wall sink into the ground.
I have never seen the Tugendhat House, except in a handful of black-and-white photographs (the house was severely damaged during the Second World War). This is another case where photographs are a poor substitute. They do not convey the rich textures of the raw silk and velvet draperies, nor the vivid colors of the upholstery: emerald green leather and ruby-red velvet. Nor do they capture the sumptuous range of materials: onyx, pearwood, handwoven wool, chromed metal and (surprisingly) a linoleum floor. Since the surviving photographs do not show any human figures, they heighten the impression that the house was built yesterday, especially as the furniture, designed by the architect, is still in production.
Mies van der Rohe appears in a photograph taken in 1926. The place is Stuttgart, the site of the famous Weissenhof housing exhibition, which he planned, and where he brought together the leading exponents of the soon-to-be-christened International Style. One of these was Le Corbusier, who is also in the photograph. The two firebrands, who will soon set the architectural world on its ear, are deep in conversation. Le Corbusier smokes a pipe and sports a jaunty derby and a loose, short tweed coat. Mies, looking older than his forty years, wears a Homburg, a long dark ulster, and spats. This photograph puts the Tugendhat House in context. However “modern” the airy room appears to my eyes, it contained a considered and formal way of life that is as remote from me as waxed moustaches, Homburgs, and spats. It is in that context that Mies’ curious combination of ordered simplicity and sybaritic luxury must be understood.
Nothing could be less similar to the Tugendhat House than Charles Moore’s weekend house that he built for himself in the hills above Berkeley, California. I saw it in the summer of 1964, two years after it was built. While the Tugendhat House appears sexy and glamorous, the Moore house is at first glance downright rustic, a little barn, twenty-six feet square, capped by a saddle roof. It is an elegant little barn, however, with white-painted walls and large windows that open up the corners, not by disappearing into the ground but by sliding sideways like barn doors. The one-room interior contains a grand piano and a sunken bath that looks vaguely Roman, perhaps because the skylight above it is supported by four solid fir Tuscan columns (found by Moore at a demolition site). Four similar columns support a second skylight over a sitting area.
I admire the Tugendhat House, but I could not imagine living in it. That is, I could not imagine having to dress up sufficiently to feel at home. The Moore house, on the other hand, reflects a more compliant sensibility. Its floor-to-ceiling windows, spare detailing, and open interior mark it as a successor to the International Style. Yet the shingled roof and the Tuscan columns hearken back to older traditions. The little building manages to be comfortable, relaxed, archetypal, and vaguely ironic, all at the same time. The eclectic, Californian setting is both informal and formal. Put another way, it is a place where people who wear tweed jackets with jeans, or silk skirts with canvas espadrilles would fit right in.
The little Moore barn is an historic building. Together with Robert Venturi’s Vanna Venturi House, which was designed the same year, it marks the advent of an architectural style that became known as Postmodernism.5 One of the celebrated buildings of Postmodernism is James Stirling’s Neue Staatsgalerie in Stuttgart, which was completed in 1984. Stirling vastly expands Moore’s eclecticism, combining a bewildering mixture of forms; a Doric portico, a staid neoclassical wing that matches the existing museum, an Egyptian-looking curved cornice, a colorful Russian Constructivist entrance canopy, a curving steel-and-glass wall, and two huge blue ventilator funnels lifted straight from the Centre Georges Pompidou. The monumental façade of alternating bands of travertine and sandstone is undermined by oversized fiberglass handrails that look like pink sausages. I couldn’t understand this design, except as a tour-de-force, until I visited the building. It was a wintry Sunday, and the Staatsgalerie was packed—it is one of the most popular museums in Germany. Now the architecture made sense. This museum-cum-discotheque was the perfect setting for the eclectic crowd. We were wearing every type of dress imaginable: casual wear, business suits, ski parkas, work clothes. Some people dressed up for a Sunday visit to the museum, some dressed down. Stirling’s lively collage absorbed us all. I did not see any gentlemen in Homburgs and spats, but they would have fitted in, too.
A number of years ago I accompanied the architect Jack Diamond on a visit to a building that he had just completed at York University in Toronto. It was a student center, containing a food court and lounges on the main level and student organization offices on the second floor. The exterior of the building was decidedly traditional. Facing a landscaped common, the well-proportioned façade consisted of a colonnaded brick base supporting a row of double columns capped by a deep copper-lined cornice. Behind the colonnade, which was fitted with retractable glass panels that could be opened during warm weather, was a two-story-high hall lit by three large skylights. The exterior had a simplicity that reminded me of McKim, Mead & White, albeit without Classical ornament.
The interior was different, with many hallmarks of the International Style: no decoration, bare concrete, exposed structural beams, factory sash glazing and steel pipe railings. I assumed that the stark simplicity was the result of a restricted budget, and a desire to use materials that would withstand wear and tear. It seemed pretty banal to me, and although I didn’t say anything to Jack, I was disappointed. Yet as we walked around, I changed my mind. Although the décor was tough and unsentimental, it was not crude. There were sleek stainless-steel pendant lighting fixtures with suspended glass diffusers and stylish easy chairs covered in canvas. In the food court, the bar and counter tops were marble, the dining tables solid maple. Students were gathered around tables, lounging on the staircase, sprawled on the floor. The atmosphere was hard to pin down. This was not the precious, corporate modernism of Richard Meier, nor the contrived, technological wizardry of Norman Foster. It was certainly not the Calvinist minimalism that I associated with many trendy younger architects. I couldn’t put my finger on it until I realized that the functional but chic décor reminded me of the no-nonsense styling of a Benetton clothing store.
I happen to like Collegiate Gothic buildings. I like their dark rooms with wood paneling, hammer-beam ceilings, and traditional oak furniture. But seeing the York student center made me realize that whenever I walk through these old buildings I also experience a nagging dissatisfaction. It has to do with the students. The young men and women in baseball caps, shorts, stenciled sweat shirts, and iridescent nylon windbreakers just don’t fit in. They should be wearing boaters and blazers, tweeds and flannels. Of course, no student that I have ever seen—including at Oxford—dresses that way. I may deplore the loss of decorum, but as an architect I can’t do anything to change it. It is the building that must do the accommodating.
If the relationship between dress and décor is intimate, it is also one-sided. Interior decorators and architects will bridle at this, but there is no doubt that dress comes first. “People have always worn what they wanted to wear,” writes Anne Hollander, “fashion exists to keep fulfilling that desire.”6 And architecture must follow. For the truth is that a building—no matter how useful or well built or beautiful—that is not sympathetic to the way that people dress risks looking not merely anachronistic, but downright silly. Like it or not, architecture cannot escape fashion.










Chapter 9
The Persistently Innovative Econosphere
t is no accident that the words for economics and ecology have the same Greek root, “house.” Ecology and economics are, at root, the same. The economy of Homo habilis and Homo erectus, the stunning flaked flint tools of the Magdalinian culture of the magnificent Cro-Magnon in southern France , years ago when the large beasts had retreated southward from the glaciation, the invention and spread of writing in Mesopotamia, the Greek agora, and today’s global economy are all in the deepest sense merely the carrying on of the more diversified forms of trade that had their origins with the first autonomous agents and their communities over four billion years ago.
Economics has its roots in agency and the emergence of advantages of trade among autonomous agents. The advantages of trade predate the human economy by essentially the entire history of life on this planet. Advantages of trade are found in the metabolic exchange of legume root nodule and fungi, sugar for fixed nitrogen carried in amino acids. Advantages of trade were found among the mixed microbial and algal communities along the littoral of the earth’s oceans four billion years ago. The trading of the econosphere is an outgrowth of the trading of the biosphere.
Economics has considered itself the science of allocation of scarce resources. In doing so, it shortchanges its proper domain. Indeed, if we stand back and squint, it is easy to see the most awesome feature of an economy and its roots in autonomous agents: The most awesome feature of the econosphere, as of the biosphere  both built by communities of autonomous agents in their urgent plunging, lunging, sliding, gliding, hiding, trading, and providing  has been a blossoming diversity of molecular and organismic species and of novel ways of making a living that has persistently burgeoned into the adjacent possible. From tens of organic molecular species to tens of trillions; from one or a few species of autonomous agents to a standing diversity of some hundred million species and a total diversity some hundred to thousandfold larger of those creatures come and gone.
Homo erectus had fire and early tools. Homo habilis traded stone axe parts . million years ago. The diversity of Cro-Magnon goods and services in the south of France some , years ago may have numbered in the several hundreds to a few thousands. Today, surf the web and count the diversity of goods and services, the ways of making a living; it is in the millions.
Neither the biosphere nor the econosphere are merely about the distribution of limited resources, both are expressions of the immense creativity of the universe, and in particular, of autonomous agents as we exapt molecularly, morphologically, and technologically in untold, unforetellable ways persistently into the adjacent possible. Jobs and job holders jointly coevolve into existence in the econosphere in an ever-expanding web of diverse complexity.
One of the most striking facts about current economic theory is that it has no account of this persistent secular explosion of diversity of goods, services, and ways of making a living. Strange, is it not, that we have no theory of these overwhelming facts of the biosphere and econosphere? Strange, is it not, that we pay no attention to one of the most profound features of the world right smack in front of our collective nose? And consistent with this strangeness, the most comprehensive theory, the rock foundation of modern economics, the beautiful “competitive general equilibrium” theory of Arrow and Debreu, does not and cannot discuss this explosion, perhaps the most important feature of the economy.
General Competitive Equilibrium and Its Limitations
So we begin with an outline of competitive general equilibrium as the cornerstone conceptual framework of modern economics. Ken Arrow is a friend. As one of the inventors of the framework, Ken is more at liberty to be a critic than the two generations of economists who have followed in his footsteps. My best reading of Ken’s view, which I share, is that competitive general equilibrium is, at present, the only overarching framework we have to think about the economy as a whole. Yet Ken suspects that that framework is incomplete; I agree.
Competitive general equilibrium grows out of a conceptual framework in which the core question is how prices form such that markets clear. Recall the famous supply-and-demand curves for a single good (Figure .). As a function of increasing price, plotted on the x-axis, supply, plotted on the y-axis, increases from low to high. More companies are willing to create widgets as the price per widget increases. On the other hand, demand, where demand is also plotted on the y-axis, decreases from high to low as prices increase. Fewer customers are willing to buy widgets as the price per widget increases.
As the figure shows, the supply-and-demand curves cross at some price. At that price, the markets “clear,” that is, all the widgets supplied are purchased. The price at which markets clear is the “equilibrium price.”
For a single good, the problem is simple. But consider bread and butter. Since many of us like butter on our bread, the demand for butter depends not only on the price and hence the supply of butter, but also on the price of bread, hence on the supply of bread. And vice versa, the demand for bread depends upon the price of butter and hence on the supply of butter. For thousands of goods, where the demand for any one good depends upon the price of many goods and the supply of any one good depends upon the price of many goods, it is not so obvious that there is a price for each good such that all markets clear.
But worse, the supply or demand for bread today may be dierent than the supply or demand for bread tomorrow. And still worse, the supply or demand for bread tomorrow may depend on all sorts of odd contingent facts. For example, if severe cold kills the winter wheat next month, the supply of bread will drop; if a bumper crop of winter wheat comes available globally because of weather or suddenly improved irrigation and farming practices worldwide, the supply will go up.
Arrow and Debreu made brilliant steps. First, they consider a space of all possible dated and contingent goods. One of their examples of a “dated contingent good” is “ ton of wheat delivered in Chicago on May , , under the condition that the average rainfall in Nebraska for the six preceding months has been percent less than normal for the past fifty years and that the Boston Red Sox won the World Series the previous year.”
In the Arrow-Debreu theory, we are to imagine an auctioneer, who at a defined beginning of time, say, this morning, holds an auction covering all possible dated contingent goods. All suppliers and customers gather at this imaginary auction, bidding ensues for all possible dated contingent goods, with values calculated under dierent hypotheses about the probabilities that the dierent dated contingencies will come about. At the end of an imaginary hour of frantic bargaining, the auction closes. All participants now have contracts to buy or sell all possible dated contingent goods, each at a fixed price. Everybody hustles home to watch Good Morning America. And, wondrously, however the future unfolds, whether there’s rain, sun, or snow in Nebraska, the dated contingent contracts that are appropriate come due, the contracts are fulfilled at the preestablished price for each contract, and all markets clear.
It is mind-boggling that Arrow and Debreu proved these results. The core means of the solution depends upon what mathematicians call “fixed-point theorems.” A beginning case is your hair, particularly for males, where short hair makes the fixed point easy to see. When you comb your hair in a normal fashion, there is a point roughly on top of your head, slightly to the back, where a roughly circular swirl of hair occurs (ignoring baldness) around a fixed point where typically a bit of scalp shows through.
A general theorem considers hair on a spherical surface and combing the hair in any way you want. You cannot avoid a fixed point. More generally, replace hair by arrows, with tails and heads, where each arrow is a line with an arrow head at one end, drawn on the surface of the sphere. The arrows may bend if you like. Each arrow can be thought of as mapping the point on the sphere at the tail of that arrow to the point of the sphere at the tip of that arrow. So the arrows are a mapping of the surface of the sphere onto itself. For a continuous mapping, such that there is a mapping from each point on the sphere, a general fixed-point theorem proves that there must be at least one point on the surface of the sphere that maps onto itself  that point is a fixed point under the arrow mapping.
The wonderful Arrow-Debreu general competitive equilibrium theorems depend on such a fixed point. In a space where all possible dated contingent goods can be prestated and all possible markets for trade of all such goods exist, a fixed point also exists that corresponds to a price at which all such markets clear, however the future unfolds. Arrow and Debreu won the Nobel Prize for their work, and won it deservedly. It is a beautiful theory. Yet there are important critiques of general competitive equilibrium. For example, the theorem depends on “complete markets,” that is, markets to trade all possible dated contingent goods, and fine economists have raised issues about how well the theory works if markets are incomplete, as indeed they are.
I pose, however, a wider set of issues. The overarching feature of the economy over the past million years or so is the secular increase in the diversity of goods and services, from a dozen to a dozen million or more today. Nowhere does general competitive equilibrium speak about this. Nor can the theory speak about the growth in diversity of goods and services, for it assumes at the outset that one can finitely prestate all possible dated contingent goods. Then the theory uses complete markets and a fixed-point theorem to prove that a price exists such that markets clear.
But we have seen grounds to be deeply suspicious of the claim that we can finitely prestate all possible exaptations  whether they be new organic functionalities or new goods  that arise in a biosphere or an econosphere, such as Gertrude learning to fly in her terrified leap from the pine tree million years ago last Friday or the engineers working on the tractor suddenly realizing that the engine block itself could serve as the chassis.
I do not believe for a moment that we can finitely prestate all possible goods and services. Indeed, economists intuitively know this. They distinguish between normal uncertainty and “Knightian uncertainty.” Normal uncertainty is the kind we are familiar with in probability theory concerning flipping coins. I am unsure whether in flips there will be heads and tails. Thanks to lots of work, I can now calculate the probability of any outcome in the finitely prestated space of possible outcomes.
Knightian uncertainty concerns those cases where we do not yet know the possible outcomes. Knightian uncertainty has rested in an epistemologically uncomfortable place in economics and elsewhere. Why? Because we have not realized that we cannot finitely prestate the configuration space of a biosphere or an econo-sphere; by contrast, Newton, Laplace, Boltzmann, Einstein, and perhaps Bohr have all more or less presupposed that we can finitely prestate the configuration space of any domain open to scientific enquiry. After all, as I have noted, we can and do prestate the N configuration space for a liter of N gas particles.
From this point of view, the wonderful Arrow-Debreu theory is fundamentally flawed.
Moreover, general competitive equilibrium, seen as a culmination of one central strand of economic theory, is too limited. Insofar as economics is concerned with understanding the establishment of prices at which markets clear, general competitive equilibrium was a masterpiece. But insofar as economics is or should be concerned with how and why economies increase the diversity of goods and services, the reigning theory is a nonstarter. And since the growth in wealth per capita over the past million years is deeply related to the growth in the diversity of technology and goods and services, contemporary economics is clearly inadequate.
We need a theory of the persistent coming into existence of new goods and services and extinction of old goods and services, rather like the persistent emergence of new species in an ecosystem and extinction of old species. In the previous chapter, we discussed ecosystems as self-organized critical. We discussed the bio-sphere and econosphere as advancing into the adjacent possible in self-organized critical small and large bursts of avalanches of speciation and extinction events. We discussed the power law distribution of extinction events in the biological record. And we discussed the power law distribution of lifetimes of species and genera.
But the econosphere has similar extinction and speciation events. Consider my favorite example: The introduction of the automobile drove the horse, as a mode of transport, extinct. With the horse went the barn, the buggy, the stable, the smithy, the saddlery, the Pony Express. With the car came paved roads, an oil and gas industry, motels, fast-food restaurants, and suburbia. The Austrian economist, Joseph Schumpeter, called these gales of creative destruction, where old goods die and new ones are born. One bets that Schumpeterian gales of creative destruction come in a power law distribution, with many small avalanches and few large ones. More, if species and genera have a power law distribution of lifetimes, what of firms? Firms do show a similar power law distribution of lifetimes. Most firms die young, some last a long time. We may bet that technologies show similar avalanches of speciation and extinction events and lifetime distributions.
The parallels are at least tantalizing, and probably more than that. While the mechanisms of heritable variation dier and the selection criteria dier, organisms in the biosphere and firms and individuals in the econosphere are busy trying to make a living and explore new ways of making a living. In both cases, the puzzling conditions for the evolutionary cocreation and coassembly of increasing diversity are present. The biosphere and econosphere are persistently transforming, persistently inventing, persistently dying, persistently getting on with it, and, on average, persistently diversifying. And into a framework of such a diversifying set of goods and services we must graft the central insights of general competitive equilibrium as the approximate short-timescale mechanism that achieves a rough-and-ready approximate clearing of markets at each stage of the evolution of the economy.
A rough hypothetical biological example may help understand market clearing in a more relaxed formal framework than general competitive equilibrium. Consider two bacterial species, red and blue. Suppose the red species secretes a red metabolite, at metabolic cost to itself, that aids the replication rate of the blue species. Conversely, suppose the blue species secretes a dierent blue metabolite, at metabolic cost to itself, that increases the replication rate of the red species. Then the conditions for a mutualism are possible. Roughly stated, if blue helps red more than it costs itself, and vice versa, a mixed community of blue and red bacteria may grow. How will it happen? And is there an optimal “exchange rate” of blue-secreted metabolite to red-secreted metabolite, where that exchange rate is the analogue of price?
Well, it can and does happen. Here is the gedankenexperiment: Imagine an ordered set of blue mutant bacteria that secrete dierent amounts of the blue metabolite that helps the red bacteria. Say the range of secretion is from to molecules per minute per blue bacterium, with metabolic cost to the blue bacteria proportional to the number of molecules secreted. Conversely, imagine mutant red bacteria that secrete from to of the red molecules valuable to the blue bacteria, at a similar cost proportional to the number of molecules secreted.
Now create a large, square petri plate with rows and columns drawn on the plastic below to guide your experimental hands. Arrange the rows, numbered to to correspond to blue bacteria secreting to molecules a second. Arrange the columns, numbered to to correspond to the red bacteria secreting to molecules a second. Into each of the x cells on your square petri plate, place exactly one red and one blue bacterium with the corresponding secretion rates. Thus, in the upper left, bacteria that are low blue and low red secretors are coplated onto each square. On the lower left, high blue and low red secretors are coplated. On the upper right, low blue and high red secretors are coplated. And in the lower right corner, high red and high blue bacteria are coplated.
Go for lunch, and dinner, and come back the next day. In general, among the , coplated pairs of bacteria, while all , colonies will have grown, a single pair will have grown to the largest mixed red-blue bacterial colony. Say the largest mixed red-blue colony corresponds to red secreting molecules per second, blue secreting molecules per second.
This gedankenexperiment is important, for the exchange ratio of red and blue molecules is the analogue of price, the ratio of trading of oranges for apples. And there exists a ratio, red molecules to blue molecules per second, that maximizes the growth of the mixed red-blue bacterial colony. Since the fastest growing mixed red-blue colony will exponentially outgrow all others and dominate our gedankenexperiment petri plate, this red-blue pair establishes “price” in the system at red to blue molecules. Further, in the fastest growing red-blue colony, where red secretes molecules and blue secretes molecules per second, both the red and blue bacteria in that mixed colony are replicating at the identical optimum rate. As discussed in chapter , using a rough mapping of biology to economics, that rate of replication of a bacterium corresponds to economic utility and the increased the rate of replication corresponds to increased economic utility. The red and blue bacteria not only establish price, but they also share equally the advantages of trade present along the Pareto-ecient contract curve in the Edgeworth box discussed in chapter .
Mutualists in the biosphere have been hacking out rough price equilibria for millions of years and have done so without foresight and without the Arrow-Debreu fixed-point theorems. Indeed, critters have been hacking out rough price equilibria even as exaptations and new ways of living have come into existence and old ways have perished. Presumably, these rough biological price equilibria are reached because in the short and intermediate term they optimize the fitness of both of the mutualists. And the markets clear, in the sense that all the red molecules are exchanged for blue molecules per second. But it’s a self-organized critical world out there, with small and large avalanches of speciation and extinction events in the biosphere and econosphere, and equilibrium price or no, most species and technologies, job holders and jobs, are no longer among us to mumble about advantages of trade.
I confess I am happier with this image of prices established in local, rough-and-ready ways at many points in an ecosystem or economy than with the beautiful fixed-point theorems of general competitive equilibrium. Bacteria and horseshoe crabs keep establishing rough price equilibria in their mutualisms without a prespecified space of ways of making a living. If they can do it, so can we mere humans. Getting on with it in the absence of predefined configuration spaces has been the persistent provenance of autonomous agents since we stumbled into existence.
Rational Expectations and Its Limitations
Actually, there has been a major extension of general competitive equilibrium called “rational expectations.” Like general competitive equilibrium, this theory too is beautiful but, I think, deeply flawed.
Rational expectations grew, in part, out of an attempt to understand actual trading on stock exchanges. Under general competitive equilibrium, little trading should occur and stock prices should hover in the vicinity of their fundamental value, typically understood as the discounted present value of the future revenue stream from the stock. But, in fact, abundant trading does occur, and speculative bubbles and crashes occur. Rational expectations theory is built up around another fixed-point theorem. Rational expectations theory assumes a set of economic agents with beliefs about how the economy is working. The agents base their economic actions on those beliefs. A fixed point can exist under which the actions of the agents, given their beliefs about the economy, exactly create the expected economic behavior. So, under rational expectations one can understand bubbles. It is rational to believe that prices are going above fundamental value and thus to invest, and the investments sustain the bubble for a period of time.
Meanwhile, Homo economicus has been thought to be infinitely rational. In the Arrow-Debreu setting, such infinitely rational agents bargain and achieve the best equilibrium price for each dated contingent good. In rational expectations, the agents figure out how the economy is working and behave in such a way that the expected economic system is the one that arises. The theories and actions of the agents self-consistently create an economy fitting the theories under which the agents operate.
But beautiful as these fixed-point theorems are, there are two troubles in the rational expectations framework. First, the beautiful fixed points may not be stable to minor fluctuations in agent behaviors. Under fluctuations, the economic system may progressively veer away from the fixed point into a feared conceptual no-man’s-land. Second, achieving the fixed points seems to demand excessive rationality to fit real human agents. So it appears necessary to extend rational expectations.
One direction was broached thirty years ago, when economist Herb Simon introduced the terms “satisficing,” and “bounded rationality.” Both seem sensible but have been problematic. Satisficing suggests that agents do not optimize but do well enough; yet it has been hard to make this concept pay o. It has also been hard to make advances with the concept of bounded rationality for the simple reason that there is one way, typically, of being infinitely smart and indefinitely many ways of being rather stupid. What determines the patterns of bounded stupidity? How should economic theory proceed?
Natural Rationality Is Bounded
I suspect that there may be a natural extension to rational expectations applicable to human and any strategic agents, and I report a body of work suggested by me but largely carried out by Vince Darley at Harvard for his doctoral thesis. Two virtues of our eorts are to find a natural bound to infinite rationality and a natural sense of satisficing.
The core ideas stated for human agents are these: Suppose you have a sequence of events, say, the price of corn by month, and want to predict next month’s price of corn. Suppose you have data for twenty months. Now, Fourier invented his famous decomposition, which states that any wiggly line on a blackboard can be approximated with arbitrary accuracy by a weighted sum of sine and cosine waves of dierent wavelengths and phase osets, chosen out of the infinite number of possible sine and cosine functions with all possible wavelengths.
Now, you could try to “fit” the data on the corn prices with the first Fourier “mode,” namely the average price. But presumably if the twenty prices vary a fair amount, that average will not predict the twenty-first month’s price very well. You have “underfit the data.” Or you could use twenty or more Fourier modes, all dierent wavelengths, with dierent phase osets, and you would, roughly, wind up drawing a straight line between the adjacent pairs of points in the twenty-period series. This procedure will not help too much in predicting the twenty-first period. You have “overfit” the data by using too many Fourier modes.
Typically, optimal prediction of the twenty-first period price will be achieved by using two to five Fourier modes, each of dierent wavelength and dierent phase oset. As is well known in the art, you have neither underfit nor overfit your data.
This fact suggests that the optimal prediction of a short sequence of data is obtained by a model of intermediate complexity  a few Fourier modes, neither a single one nor very many. The sense of bounded rationality Vince and I want to advocate is that optimal prediction of a limited time series is achieved with models using only a few Fourier modes, or their analogs in other basis sets  models of modest, or bounded, complexity.
The rest of the theory Vince and I have developed goes to show that agents who have theories of one another and act selfishly based on those theories will typically create a persistently changing pattern of actions. Therefore, they persistently create a nonstationary world in which only the relatively recent past has valid data. Thus, there is always only a limited amount of valid data on which to base theories, and the agents, in turn, must always build models of intermediate, bounded complexity to avoid over- or underfitting the meager valid data.
Natural rationality is, in this sense, bounded. It is bounded because we mutually create nonstationary worlds. What happens is that the agents act under their theories. But in due course some agent acts in a way that falsifies the theories of one or more other agents. These agents either are stubborn or change their theories. If they change their theories of the first agent, then typically they also change their actions. In turn, those changes disconfirm the theory of the first agent, and perhaps still other agents. So the agents wind up in a space of coevolving theories and actions with no fixed-point, stable steady states, which means that past actions are a poor guide to future actions by an agent since his theories, and hence his action plans, have changed. But this means that the agents mutually create a “nonstationary” time series of actions (nonstationary just means that the statistical characteristics of the time series keep changing because the agents keep changing their theories and actions). In turn, the agents typically have only a modest amount of relatively recent data that is still valid and reliable on which to base their next theories of one another. Given only a modest amount of valid and reliable data, the agents must avoid overfitting or underfitting that smallish amount of data, so they must use theories of intermediate complexity  for example, four Fourier modes to fit the data, not one or twenty.
Vince and I want to say that natural rationality is bounded to models of intermediate complexity because we collectively and persistently create nonstationary worlds together. In the agent-based computer models Vince has created for his thesis, just this behavior is seen. Indeed, we allow agents to evolve how much of the past history of the interactions they will pay attention to and how complex their models of one another will be  one, four, or fifty Fourier modes. Agents evolve in a history and complexity space to find currently optimal amounts of history and complexity to use to optimally predict their neighbors. In our little world, the agents evolve to use a modest history, ignoring the distant past, and only modestly complex theories of one another.
We have found evidence of a further, perhaps generic, property that appears to drive such systems to settle down, then change in a sudden burst. As the system of agents and actions settles down to some repeatable behavior, an increasingly wide range of alternative theories, simple and very complex, fit the same data. But the complex theories, with many Fourier modes, attempt to predict fine details of the repeatable behavior. As those theories become more complex, they are more fragile because they can be disconfirmed by ever more minor fluctuations in the repeatable behavior. Sooner or later such a fluctuation happens, and the agents with the complex disconfirmed theories change theories and actions radically, setting up a vast avalanche of changes of theories and actions that sweeps the system, driving the collective behavior far from any repeatable pattern. In these new circumstances, only a small subset of theories fits the current facts, so the diversity, and complexity, of theories in the population of agents plummets, and the system finds its way back to some repeatable pattern of behavior.
In short, there appears to be not only a bounded complexity in our rationality, but a fragility - stability cyclic oscillation in our joint theories and actions as well. In these terms, the system of agents and theories never settles down to a fixed-point equilibrium in which markets clear. Instead, the system repeatedly fluctuates away from the contract curve then returns to new points in the vicinity of the contract curve. Hence, in precisely the sense of repeatedly fluctuating away from a contract curve then returning to its vicinity, the system does not achieve an optimizing price equilibrium, but satisfices.
The bounded complexity issues would seem to apply to any coevolving autonomous agents that are able to make theories of one another and base actions on those theories. The tiger chasing the gazelle and the starfish predating the trilobite are, we suppose, Popperian creatures able to formulate hypotheses about their worlds that may sometimes die in their stead. Presumably all such autonomous agents, under persistent mutation and selection, would opt for changeable models of one another of bounded complexity.
While these steps are only a beginning to go beyond rational expectations in economics, they seem promising. Whatever natural, or unnatural, games autonomous agents are playing as they and we coevolve in a biosphere or econo-sphere, nonstationarity arises on many levels. Here we see it at the level of the agents’ theories of one another and the actions based on those theories. Perhaps this is just part of how the world works. Given the semantic import of yuck and yum, and the reality of natural games for fox and hare, for E. coli and paramecium, these changing theories and actions are part of the fabric of history of the market, the savannah, and the small pond.
Natural rationality is bounded by the very nonstationarity of the worlds we cocreate as we coexapt.
Technology Graphs and Economic Webs
Life takes its unexpected turns. I have been an academic scientist, a biologist, for thirty years at the University of Chicago, the National Institutes of Health, the University of Pennsylvania, then twelve stunningly exciting years at the Santa Fe Institute. After thirty years, I’ve written the canonical hundred or more scientific articles, was fortunate enough to receive a MacArthur Fellowship, during whose five years my IQ went up and then slumped back to normal as the funding ended, invented and patented this and that, and published two previous books of which I am proud, Origins of Order and At Home in the Universe, both by Oxford University Press.
I thought Origins and At Home were largely about the challenge of extending Darwinism to an account of evolution that embraced both self-organization and natural selection in some new, still poorly understood marriage. One hundred and forty years after Darwin, after all, we still have only inklings about the kinds of systems that are capable of adaptation. What principles, if any, govern the coevolutionary assembly of complex systems such as ecosystems or British common law, where a new finding by a judge alters precedent in ways that ricochet in small and large avalanches through the law? If new determinations by judges did not have any wider impact, the law could not evolve. If every new determination altered interpretation of precedents throughout the entire corpus of common law, the law also could not evolve.
My rough bet is that systems capable of coevolutionary construction, such as British common law, can evolve and accumulate complexity because they are somehow self-organized critical, and a power law distribution of avalanches of implications of new precedent ricochet in the law and in other complex coevolving systems to allow complexity to accumulate. Indeed, based on self-organized criticality, and more particularly on the analysis of the NK fitness landscape model discussed in Origins and At Home and the “patches” version of the NK model discussed in At Home, I am rather persuaded that adapting systems can best exploit the trade-o between exploitation and exploration at a rough phase transition between order and chaos. Here power law distributions of small and large avalanches of change can and do propagate through the system as it adapts.
So saying, and having published Origins and then At Home, I was rather surprised to find business people approaching me. The consulting companies of McKinsey, Coopers and Lybrand, Anderson, and Ernst and Young began visiting the Santa Fe Institute to learn about the “new sciences of complexity.” In due course, Chris Meyer at the Center for Business Innovation at Ernst and Young asked me if I might be interested in forming a fifty-fifty partnership with E and Y to discover if complexity science, that nuanced term, could be applied in the practical world. I found myself deeply intrigued. Was the work of my colleagues and myself mere theory or did it have application in real biospheres and econospheres? Why not plunge in and try my best to find out, to do it right, even knowing how early was the stage of the science we had been inventing.
Bios Group Inc., the partnership with Ernst and Young, is now just three-and-a-half years old. We have grown to over seventy people, heading, we hope, for a hundred. Our annual revenues are running at $ million. We have a hopeful eye on $ to $ million this year with clients ranging from Texas Instruments, for whom we invented a novel adaptive chip, to the U.S. Marine Corps with its concern for adaptive combat, to Unilever, the NASDAQ stock market, Honda, Boeing, Johnson and Johnson, Procter & Gamble, Kellogg, Southwest Airlines, the Joint Chiefs of Sta, and others. We have spun out a biotechnology company, CIStem Molecular, that aims to clone the small cis acting DNA regions that control turning genes on and o in development and disease; a European daughter company, Euro-Bios; as well as EXA, a company spun out with NASDAQ to make tools for financial markets. I’m deeply glad to be chairman of the board and chief scientist of Bios, to be working with a very creative group of colleagues, and to be finding routes in the practical world where our ideas do, in fact, apply.
I mention Bios and my involvement because some of the science we have done bears on diverse aspects of practical economics and even begins to suggest pathways beyond the limitations of the Arrow-Debreu theory. I begin with Boeing, which came to Bios wondering how to design and build airplanes in a year rather than seven years. Out of what modular parts and processes, wonder Boeing folks, might it be possible to assemble a family of related aircraft for a diversity of markets?
The obvious approach was to invent “Lego World.” As founding general partner and chief scientist, I duly authorized the expenditure of $. to buy a largish box of Lego parts. (In truth, I fib. I actually won the Lego box at our first Bios Christmas party.)
Most of the readers of this book will be familiar with Lego. It is a construction game consisting of snap-together, plastic parts, based on square blocks that graduate in size, for example, x , x , x , and x blocks. The blocks can be assembled into wonderfully complex structures, as many delighted children and adults have discovered.
But what might Lego World be? What, indeed. Well, consider a large pile of Lego blocks on a bare wooden table. Consider these blocks the “primitive parts.” Now consider all the primitive construction or deconstruction operations, pressing two parts together or adding a primitive part to a growing assemblage, or taking a part o another part or o an assemblage.
Consider the pile of unassembled bare Lego parts as the founder set, and place in “rank ” all the unique Lego objects that can be constructed from the founder set in a single construction step. Thus, a x can be attached in a specific overlapping way to a x . Now place in rank all the unique Lego objects that can be constructed from the founder set in two construction (or deconstruction) steps. Similarly, consider ranks , , ,   .   .   .   , , , ,, ,,,   .   .   .   .
A set of primitive parts and the transformations of those parts into other objects is a “technology graph.” In fact, a technology graph is deeply similar to a chemical-reaction bipartite graph from a founder set of organic molecules, where the molecules are the objects and the reaction hyperedges linking substrate and products are the transformations among the objects. The graph is “bipartite” because there are two types of entities, nodes, and hyperedges, representing objects and transformations.
The first thing to notice about the Lego World technology graph is that it might extend o to infinity, given an infinite number of primitive Lego parts.
The second thing to notice is that within Lego World an adjacent possible relative to any actual set of primitive and more complex Lego structures is perfectly definable. The adjacent possible is just that set of unique novel objects, not yet constructed, that can be constructed from the current set of Lego objects in a single construction step. Of course, within the limited world of Lego we can think of the technologically adjacent possible from any actual. A Lego economy might flow persistently from simple primitive objects into the adjacent possible, building up evermore complex objects.
A third feature is that we might consider specific Lego machines, made of Lego parts, each able to carry out one or more of the primitive gluing or ungluing operations. Lego World could build up the machine tools to build other objects including other tools.
Indeed, in Origins of Order and At Home in the Universe, I borrowed theoretical chemist Walter Fontana’s algorithmic chemistry and defined a mathematical analogue of Lego World, namely a “grammar model” of an economy. In that model, binary symbol strings represented goods and services, as do Lego objects in Lego World. In a grammar model, “grammar” specifies how symbol strings act on symbol strings, rather like machines on inputs, to produce new symbol strings. In Lego World, the grammar is specified by the ways primitive blocks can be attached or unattached and by any designation of which Lego objects can carry out which primitive construction operations. The grammar in question may be simple and “context-insensitive” or a far richer “context-sensitive” grammar in which what objects can be added in what ways to dierent objects depends upon the small or large context surrounding those blocks. In short, in a context-sensitive grammar, the objects and transformations rules are sensitive to the context of the objects and previous transformations themselves.
Before proceeding with current uses of Lego World and its intellectual children, notice that Lego World, like the grammar models in Origins and At Home, can become the locus of an economy, in which the sets of goods and services can expand over time and in which speciation and extinction events occur. In Origins and At Home, I built upon a suggestion of economist Paul Romer, and specified that each symbol string  or here, each Lego object  has some utility to a single consumer. The utility of each object to the consumer is subjected to exponential discounting over time. A Lego house today is worth more than a Lego house tomorrow and still more than a Lego house two days from now. And for simplicity’s sake, the total utility of a bundle of goods is the sum of their discounted utilities to the consumer.
Next, I invoked a “social planner.” The task of the social planner is to plan a pattern of production activities over time that optimizes the discounted happiness of the consumer. A standard approach is to adopt a finite planning horizon. The social planner thinks ahead, say, ten periods, finds that pattern of construction activities over time that creates the sequence of symbol-string goods, or Lego objects, that maximizes the time-discounted happiness of the consumer. Then, the social planner initiates the first-period plan, making the first set of objects. Next, the planner considers a ten-period planning horizon from period to period , deduces the optimal second-period plan, taking account of the newly considered eleventh period, and carries out the second-period plan.
Because the total utility to the consumer is a simple sum of the discounted utilities of all the possible goods in the economy, finding the optimal plan at any period is just a linear programming problem, and the results are a fixed ratio of construction activities of all the objects produced at that period. The fixed ratio of the activities is the mirror of price, relative to one good, taken as the arbitrary “currency,” or “numeraire.”
Over time, the model economy ticks forward. At each period, in general, only some of the possible goods and services are constructed. The others do not make the consumer happy enough. Over time, new goods and services come into existence, and old ones go out of existence in small and large avalanches of speciation and extinction events.
Thus, a grammar model, or a physical instantiation of a grammar model such as Lego World, is a toy world with a technology graph of objects and transformations. With the addition of utilities to the dierent objects for one consumer or a set of consumers and a social planner  or more generally, with a set of utilities for the objects that may dier among consumers and with dierent costs and scaling of costs with sizes of production runs of dierent Lego objects  a market economy can be constructed. With defined start-up costs, costs of borrowing money, and bankruptcy rules, a model economy with an evolving set of goods and services can be created and studied.
In general, such economies will advance persistently into the adjacent possible. And because the number of unique Lego objects in each rank is larger than the number in the preceding rank, the diversity of opportunities and objects tends to increase as ever more complex objects are constructed.
More generally, we need to consider “complements” and “substitutes.” Screw and screwdriver are complements; screw and nail are substitutes. Complements must be used together to create value; substitutes replace one another. Rather obviously, the complements and substitutes of any good or service constitute the economic niche in which that good or service lives. New goods enter the economy, typically, as complements and substitutes for existing goods. There is just no point in inventing the channel changer before the television set is invented and television programming is developed.
An economic web is just the set of goods and services in an economy, linked by red lines between substitutes and green lines between complements.
As we have seen, over the past million years, and even the past hundred years, the diversity of the economic web has increased. Why? Because, as in Lego World, the more objects there are in the economy, the more complement and substitute relations exist among those objects, as well as potential new objects in the adjacent possible. If there are N objects, the number of potential complement or substitute relations scales at least as N squared since each object might be a complement or substitute of any object. Thus, as the diversity of the objects in the web increases, the diversity of prospective niches for new goods and services increases even more rapidly! The very diversity of the economic web is autocatalytic.
If this view is correct, then diversity of goods and services is a major driver of economic growth. Indeed, I believe that the role of diversity of goods and services is the major unrecognized factor driving economic growth. Jane Jacobs had made the same point in her thoughtful books about the relation between economic growth and economic diversity of cities and their hinterlands. Economist Jose Scheinkman, now chairman of economics at the University of Chicago, and his colleagues studied a number of cities, normalized for total capitalization, and found that economic growth correlated with economic diversity in the city. In a similar spirit, microfinancing of a linked diversity of cottage businesses in the third world and the first world seems to be achieving local economic growth where more massive eorts at education and infrastructure, Aswan dams and power grids, seem to fail.
Indeed, in the same way in an ecosystem, organisms create niches for other organisms. I suspect, therefore, that over the past . billion years, the growth of diversity of species is autocatalytic, for the number of possible niches increases more rapidly than the number of species filling niches. And in the linking of spontaneous and nonspontaneous processes, the universe as a whole advances autocatalytically into its adjacent possible, driven by the very increase of diversity by which novel displacements from equilibrium come into existence, are detected, are coupled to, and come to drive the endergonic creation of novel kinds of molecules and other entities. Economic growth is part and parcel of the creativity of the universe as a whole.
Think of the Wright brothers’ airplane. It was a recombination between an airfoil, a light gasoline engine, bicycle wheels, and a propeller. The more objects an economy has, the more novel objects can be constructed. When we were working with rough stone in the Lower Paleolithic, we pretty much mastered everything that could be done until pressure flaking came along. Most forms of simple stone tools that could be made were made. Today, the adjacent possible of goods and services is so vast that the economy, stumbling and lunging into the future adjacent possible, will only construct an ever smaller subset of the technologically possible.
The economy is ever more historically contingent   .   .   . As the biosphere is ever more historically contingent   .   .   . As, I suspect, the universe is ever more historically contingent.
We are on a trajectory, given a classical N-dimensional phase space, where the dimensionality of the adjacent possible does seem to increase secularly and the universe is not about to repeat itself in its nonergodic flow.
A fourth law?
I now discuss an algorithmic model of the real economic web, the one outside in the bustling world of the shopping mall, of mergers and acquisitions. While powerful, however, no algorithmic model is complete, for neither the biosphere nor the econosphere is finitely prestatable. Indeed, the eort to design and construct an algorithmic model of the real economic web will simultaneously help us see the weakness of any finite description.
It all hangs on object-oriented programming. 
A case in point is the recent advent of Java, an object-based language, which, as of February had a library of some eighty thousand Java objects. Goodness knows how fast this library of objects is growing. Among the Java objects are “carburetor” objects, “engine block” objects, and “piston” objects, and objects come with “functional” descriptors, such as “is a,” “has a,” “does a,” “needs a,” “uses a.”
Both implicitly and, with modest work, explicitly, the “piston” object can discover that it fits into the cylinder hole in the “engine block” object to create a completed piston in a cylinder. The “carburetor” object can discover that it is to be located on top of the “engine block” object, connected to certain “gas line” objects in certain ways.
The physical engine block and piston, in reality, are complements, used together to create value. Thus, the representations of the engine block and piston as algorithmic Java objects, together with algorithmic “search engines” to match the corresponding “is a,” “has a,” “does a,” functions of complements and even substitutes, can as a matter of principle  and practicality  create an image of the real complements and substitutes in the real economic web.
In a fundamental sense, an appropriate set of Java objects, together with search engines for complements and substitutes matching “is a,” “has a,” “does a,” constitutes a grammar of objects and linkings or transformations among objects. The grammar may be context independent or context sensitive or richer.
In short, properly carried out, Java objects and the proper search engines can create a technology graph of all the objects and transformed objects constructible from any founder set of objects. The Java objects are like Lego World. And Lego World, stated in terms of building simple combinatorial objects, is logically similar to a set of objectives that must be achieved by a military force to carry out its total objective. Entities and operations are deeply similar, as we will explore further below. Technology graphs concern objects and actions, things and objectives, products and processes in a single framework.
Therefore, in principle, we have begun to specify a means to characterize large patches of the global economic web. Let each of very many firms, at dierent levels of disaggregation, create Java objects proper to their activities, building materials, partially processed materials, partially achieved objectives, and objectives including products. Let these Java objects be characterized by appropriate “is a,” “has a,” “does a,” lists, with adequate search engines looking for complements and substitutes. The result is a distributed web of Java objects linked functionally in at least many or most of the ways that are actually in use as complements and substitutes creating the millions of dierent goods and services in the current economy.
Much is of interest about such data on the real economic web. Among other features, any such graph has graph-typical characteristics. Some goods are central to the web, the car, computer, and so forth. Others are peripheral, such as the hula hoop and pet rock. Presumably, location of its products in the web structure has a great deal to do with the strategic position of a firm.
But there is more, for the economic web states its own adjacent possible. Given the Queen Mary and an umbrella, the umbrella placed in the smoke stack of the Queen Mary is in the adjacent possible. Not much use. But what about a small umbrella on the back of a Cessna that opens upon landing: Ah, an air brake is a possible new good in the adjacent possible a few steps from here.
And still more. What are the statistics of the transformation of an economic web over time as new goods and services arise in the niches aorded by existing goods and services, and drive old goods and services extinct? No one makes Roman siege engines these days. Cruise missiles do the job better.
I believe such object-based economic web tools will come into existence in the near future. Indeed, Bios Group is involved in inventing and making them. And I believe that such tools will be very powerful means of coordinating activities within supply chains and within the larger economy when linked by automated markets.
But I do not believe any such algorithmic tool can be complete. Consider the case of the engineers discovering that the engine block is so rigid that the block itself can serve as the chassis for the tractor they are trying to invent. That exaptation seems a genuine discovery. Now imagine that we had had Java object models of all the parts that were to go into the tractor: engine block objects, carburetor objects, piston objects. If, among the properties of the engine block  the proud “is a,” “has a,” “does a,” features  we had not listed ahead of time the very rigidity of the engine block or if that rigidity was not deducible from the other listed properties, then my vaunted economic web model with its algorithmically accessible adjacent possible could not have ever come up with the suggestion: Use the engine block, due to its rigidity, as the chassis.
You see again that unless there is a finite predescription of all the potentially relevant properties of a real physical object, our algorithmic approach can be powerful, but incomplete. Yet I cannot see how to construct such a finite predescription of all the potentially relevant properties of a real physical object in the real universe.
The world is richer than all our dreams, Horatio.
I must say to Arrow and Debreu, “Gentlemen, the set of goods and services is not finitely prestatable, so fixed-point theorems are of limited use.”
And to my economist colleagues: Consider the economy as forever becoming, burgeoning with new ways of making a living, new ways of creating value and advantages of trade, while old ways go extinct. This too is the proper subject for your study, not just allocation of scarce resources and achievement of market-clearing prices. The economy, like the biosphere, is about persistent creativity in ways of making a living.
I find it intriguing to note certain parallels from our prior discussion of autonomous agents and propagating organization. At the level of molecular autonomous agents, I made the point repeatedly that work is the constrained release of energy and that autonomous agents do carry out work to construct the constraints on the release of energy such that the energy is released along specific channels and such that specific couplings of nonequilibrium energy sources to propagating organization arise. Think then of the role of laws and contracts, whose constraints enable the linked flow of economic activities down particular corridors of activities. The web of economic activities flows down channels whose constraints are largely legal in nature. The coming into existence of the enabling constraints of law is as central to economic development and growth as any other aspect of the bubbling activity.
Robust Constructibility
My first purpose in investing in an entire box of Legos was to explore and define concepts of “robust constructibility.” We have succeeded, but run into fascinating problems of a general phase transition in problem solvability. In turn, this very phase transition suggests that in a coconstructing biosphere or econosphere rather specific restrictions arise and are respected by critters and firms, creatures and cognoscenti.
Recall the Lego founder set, and the rings, rank , rank ,   .   .   .   , rank ,,   .   .   .   each containing the unique Lego objects first constructible from the founder set in a number of steps equal to the rank of that ring. Suppose a given Lego house is first constructible in twenty steps, hence, lies in rank . Now, it might be the case that there is a single construction pathway from the founder set to the Lego house in twenty steps. It might also be the case that there are thousands of construction pathways to the Lego house in twenty steps. In the latter case, intuitively, construction of the Lego house is robust. If one way is blocked, say because x blocks are temporarily used up, then a neighboring pathway will allow the Lego house to be constructed without delay, that is, in twenty steps, using other block sizes.
A related sense of robustly constructibility concerns how the number of ways to construct the Lego house increases if we take more than the minimum twenty steps, say, twenty-one, twenty-two, twenty-three,   .   .   .   steps. The number of ways may not increase at all or very slowly or hyperexponentially. If the number of ways increases very rapidly, it might be worth using twenty-two steps to make the Lego house, for it would be virtually impossible to block construction even if several types of building blocks and machines were temporarily broken.
But recall Boeing’s question. They wanted to build a family of related objects. Hence, let us define still another related sense of robustly constructible.
Consider a family of Lego objects, a house, and a house with a chimney. Now consider each of the many ways from the founder set to build the Lego house. For each such way to build the Lego house, consider how to change construction minimally in order to build the Lego house with the chimney. Perhaps the chimney can just be added to the completed Lego house. More likely, it would be necessary to partially deconstruct that completed Lego house, then go on to construct the house with the chimney. So there is a last branch point during construction on the way both to the Lego house and the Lego house with the chimney.
The branch point object and/or operation that is simultaneously on the way to the house and the house with the chimney is an interesting intermediate-complexity object or operation because it is polyfunctional. It can be used in at least two further ways.
When we build a house, we all know that boards and nails are primitive objects and the completed house is the finished object. But some intermediate objects, say, framed windows and framed walls, are commonly used. Why? Because they are intermediate objects that are polyfunctional. The technology graph and its branch points are identifying the intermediate-complexity polyfunctional objects for us.
But things are more subtle. It might be the case that from the last branch point on a way to make both the house and the house with the chimney there is only a single pathway forward to the house and there is only a single pathway forward to the house with the chimney. Not robust. Stupid stopping spot. Either pathway can readily be blocked. Suppose instead we consider an intermediate object three steps prior to the last branch point on the way outward from the founder set. Ah, perhaps there are thousands of ways to complete the house and to complete the house with the chimney. Any single blockage or small set of blockages is readily overcome. The house, or the house with the chimney, can be built without delay if all  x blocks are temporarily out of stock. Now this is a smart, robust, intermediate-complexity polyfunctional object-objective. And it may cost no more to stockpile such smart intermediate objects!
So, here is a new view of process design and inventory control.
Bios colleague Jim Herriot has made a delightful little Java computer model to show technology graphs in action. The program shows a “chair” object, a “seat” object, a “back” object, and a “leg” object. In addition, there are “foam” and “padding” objects, two “attachment” objects, a set of “screw” objects, “nail” objects, “wood” objects, a “saw” object, a “hammer” object, and a “screwdriver” object. Each object comes with its own characteristic set of “is a,” “has a,” “does a,” features.
The program assembles coherent technology graphs and chair-assembly pathways as follows: An object tries a connection, shown by a black line, to another object. In eect, the chair object extends a line to the screw object as it says, “I need a lean-on! I need a lean-on!” The screw object responds, “I do twist holds, I do twist holds!” There is no match. After many random tries, the “chair” object extends a black line to the “back” object. “I need a lean-on, I need a lean-on,” says the “chair” object. “I do lean-ons, I do lean-ons,” cries the “back” object with cybernetic joy. The black line becomes a yellow line as a contract is signed between the “chair” and “back” objects. In a similar way, the “back” object needs “padding” and “wood” objects, and either the complementary pair “nail and hammer” objects or their substitutes, “screw and screwdriver” objects, to carry out an “attachment” operation.
In due course, the conditions are met to begin construction of partial objects on the way to the entire chair. Legs, then backs, begin to be assembled as screws and nails are used up. Eventually, a seat is constructed too, and the first chair triumphantly follows.
All goes well until all the screws are used up. The seat, having relied on screws and screwdrivers to attach padding, goes nuts and looks about frantically, asking the screwdriver to work on nails. No luck. Eventually, the seat tries nails and hammers jointly, and that complementary pair works. More chairs are constructed, then nails run out and failures propagate throughout the system.
Not a metaphor, the technology graph. Rather, a new tool to understand the general principles of robust constructibility, the structure of economic webs, a knowledge-management tool for a firm, a new hunk of basic science. Indeed, one of the interesting features of technology graphs is that they constitute the proper conceptual framework to consider process and product design simultaneously. As far as I can tell, we have not had such a conceptual framework before.
Nor is the technology graph limited to manufacturing. The same general principles apply, for example, in military or other logistic operations. Technology graphs, in these other contexts, become the sequential set of requirements needed to meet subobjectives that robustly culminate in the achievement of an overall objective. Taking hill after diverting gracefully from orders to take hill is logically related to making the house with the chimney after starting to make the house without the chimney.
A Phase Transition in Problem Solvability
Part of the basic science of technology graphs stems from generic phase transitions in problem solvability in many combinatorial optimization or satisficing problems in biology and economics. I turn now to discuss these generic phase transitions.
I begin with a metaphor. You are in the Alps. A yellow bromine fog is present. Anyone in the fog for more than a microsecond will die. There are three regimes: the “dead,” the “living dead,” and the “survivable.”
The “dead”: The bromine fog is higher than Mont Blanc. Unfortunately, everyone dies.
The “living dead”: The bromine fog has drifted lower and Mont Blanc, the Eiger, and the Matterhorn jut into the sunlight. Hikers near these three peaks are alive.
But consider that even mountains are not fixed. Plate tectonics can deform the mountainous landscape. Or, in the terms of the last chapter, the mountainous fitness landscape of a species or a firm or an armed force can change and persistently deform due to coevolution when other species or firms or adversaries change strategies. If the mountainous landscape deforms, Mont Blanc, the Eiger, and the Matterhorn will eventually dip into the bromine fog. As this happens, perhaps new peaks jut into the sunshine. But those peaks will typically be far away from Mont Blanc, the Eiger, and the Matterhorn.
Alas, the hikers near those three initial peaks will die as they are dipped into the lethal fog and are too far from the newly emerged sun drenched peaks to reach them. This “isolated peaks regime” is the living dead regime.
But there is a third regime a phase transition away.
The survivable regime: Let the bromine fog drift lower. More and more peaks jut into the sunshine. At some point, some magical point, as more peaks emerge into the sunshine, quite suddenly, a hiker can walk all the way across the Alps in the sunshine.
This is a phase transition from the isolated peaks regime. A connected web  mathematically, a percolating web  of connected “solutions” has emerged suddenly as the fog lowers. Now consider hikers striding across the Alps, knapsacks and hearts full. If plate tectonics rather slowly deforms the landscape, then whenever hikers are about to be dipped into the lethal bromine fog, they can take a sideways step in some direction and remain in the sunshine.
The percolating web of solutions regime is persistently survivable. In fitness landscape terms, if you are evolving on a fitness landscape that is deforming and are in your survivable regime, you can continue to exist by stepping somewhere from wherever you happen to find yourself.
This phase transition is generic to hard combinatorial optimization problems. A case in point is the well-known job shop problem. The job shop problem posits M machines and O objects. The idea is to build the O objects on the machines. Each object requires being on each machine in some set order for some fixed period of time. Perhaps object must be on machine for minutes, then machine for minutes, then machine for minutes. In turn, object must be on machine for minutes, then machine for minutes, and so on.
A schedule is an assignment of objects to machines such that all objects are constructed. The total length of time it takes to construct the set of objects is called the “makespan.” We may consider, for each schedule, a definition of neighboring schedules, such as swapping the order in which two objects are assigned to a given machine. Given the set of possible schedules, the neighborhood relation between schedules, and the makespan of each schedule, there is a makespan fitness landscape over the space of schedules of the job shop problem.
We want to minimize makespan. But to keep our mountainous landscape metaphor where high peaks are good, let us consider optimizing eciency by minimizing makespan. So schedules with low makespan correspond to points of high eciency on the job-shop fitness landscape. Clearly, short makespan makes the problem hard, long makespan makes the problem easy. So long makespan is like the bromine fog being low, while short makespan is like the bromine fog being high.
Does the phase transition occur in typical job shop problems as makespan is tuned from long to short? Figure . shows the results Vince Darley obtained. The figure plots makespan, short to long, on the x-axis and the number of schedules at a given makespan on the y-axis.
As you can see, for long enough makespan, as makespan decreases there are roughly a constant number of schedules at each makespan. But at a critically short makespan, the number of solutions starts to fall abruptly. The corner where the curve starts to turn is the phase transition between the survivable regime for longer makespans and the isolated peaks/living dead regime for shorter makespans. (I cheat slightly, the sharpness of the corner increases as the size of the job shop problem increases in numbers of machines, M, and objects, O.)
There are a number of direct tests for this phase transition. In the survivable regime, at longer makespans and lower eciency than the phase transition makespan, start with a given schedule at a given makespan. Now examine all “nearby” schedules and test if any is of an equal or better makespan. Continue to “walk” across the space of schedules via neighbors to test if there is a connected web of schedules with makespans at least as good as our initial schedule’s makespan. Either the web percolates across the space of solutions or it does not. If the web percolates, then the initial schedule was in the survivable regime. If only isolated regions of neighboring schedules of the same approximate makespan are found, then you are in the isolated peaks regime.
A second test looks at the “Hausdorf dimensionality” of the acceptable solutions at a given makespan or better. The Hausdorf dimension is computed by considering an initial schedule at a given makespan, then by considering from among all the -mutant neighbor schedules the number of them that are of the same or better makespan as the initial schedule’s makespan, then doing the same among all the -mutant neighbor schedules. The Hausdorf dimension of the acceptable set of schedules at that makespan and point in the job shop space is the ratio of the logarithm of the -mutant acceptable schedules to the logarithm of the -mutant acceptable schedules. In eect, the Hausdorf dimension shows how rapidly  in how many dimensions of the job-shop schedule space  acceptable schedules of a given makespan or better are growing. In the survivable regime, the Hausdorf dimension, on average, is greater than .. In the isolated peaks regime, averaged over the job shop space, the Hausdorf dimension is less than .. At the phase transition, the dimensionality is ..
The phase transition I have just noted is generic for many or most hard combinatorial optimization problems. It is not true for all fitness landscapes. For example, it would not hold on a conical Fujiyama landscape. But the Fuji landscape corresponds to a simple, typically linear, optimization problem. Hard combinatorial optimization problems are multipeaked due to conflicting constraints.
A further interesting connection relates the statistics of search on the job shop landscape to learning curves in economics. Learning curves, well known in arenas from airplane manufacture to diamond cutting to cigar manufacture, show that every time the total output of a plant is doubled, the cost per unit falls by a rough constant percentage, typically to percent. If the logarithm of the cost per unit is plotted on the y-axis and the logarithm of the cumulative number of units produced is plotted on the x-axis, one gets a typical straight-line power law that decreases downward to the right.
The fascinating thing is that this feature probably reflects the statistics of search for fitter variants on rugged, correlated fitness landscapes such as the job shop problem. Typically, in such problems, every time a fitter -mutant variant is found, the fraction of -mutant variants that are still fitter falls by a constant fraction, while the improvement achieved at each step is typically a constant fraction of the improvement achieved at the last step. These properties yield the learning curve. My colleagues Jose Lobo, Phil Auerswald, Karl Shell, Bill Macready, and I have published a number of papers on the application of the statistics of rugged landscapes and learning curves.
But there is another even more important point. We can control the statistical structure of the problem spaces we face such that the problem space is more readily solvable. We can, and do, tune the structure of the problems we solve. The capacity to tune landscape structure shows up in the job shop problem. In most cases, improving the structure of the problem space requires relaxing conflicting constraints to move the problem into the survivable regime at the makespan, or eciency, you require. For a specific case, in my statement of the job shop problem, I asserted that the O objects must each have access to the M machines in some fixed order.
Now simple observation and experience tells you that you can put on your shirt and pants in either order, but you had better put on your socks before your shoes. In other words, some steps in life are permutable, others are not. Suppose in our job shop problem, a fixed fraction, P, of the steps in the construction of each of the O objects were jointly permutable. As P increases and more steps are permutable, the conflicting constraints in the total problem are reduced. But this in turn means that the entire space of solutions improves, that is, the entire space shifts toward lower makespan, or higher eciency.
And now the relation to the bromine fog metaphor can be stated clearly. As the number of permutable steps increases, the conflicting constraints are reduced. The entire makespan-eciency landscape is lifted higher, the peaks are higher, and the landscape, with fewer conflicting constraints, is smoother. All in all, the result is that the percolating web of solutions where the hikers can walk all across the Alps occurs at a higher eciency and shorter makespan.
In terms of Figure ., the capacity to permute steps in the job shop problem shifts the phase transition point leftward, toward shorter makespan. Equivalently, if one wants to shift the curve in Figure . to the left, purchase a computable number of machines that are polyfunctional so that the same machine can be used for more than one job. That too reduces conflicting constraints.
There is another view of this generic phase transition between solvable and nonsolvable that again highlights the role of having alternative ways of doing things, robustly constructible strategies that are not easily blocked. In addition, the same simple model, the Ksat model discussed in the previous chapter, begins to account for at least the following anecdotal observation, which is apparently typical: Colleagues at Unilever noted to us that if they have a plant that manufactures dierent types of a product, say, toothpaste, then the plant does well when the diversity of products grows from three to four to ten to twenty to twenty-five, but at twenty-seven dierent toothpastes, the plant suddenly fails. So rather abruptly, as product diversity in a given plant increases, the system fails. 
Why? Presumably it is the same phase transition in problem solvability.
Consider again the Ksat problem, taken as a model for community assembly in the last chapter based on the work of Bruce Sawhill and Tim Keitt. Figure . repeats the Ksat problem and shows again the phase transition.
Recall that a Ksat problem consists in a logical statement with V variables, in C clauses, in normal disjunctive form: (A v A) and (A v A) and (not A v A). As we discussed in the previous chapter, a normal disjunctive expression with C clauses, V variables in total, and K variables per clause is satisfiable if there is an assignment of true or false to each of the V variables, such that the expression as a whole is true.
The normal disjunctive form makes it clear that as there is an increase in the number of alternative ways, K, of carrying out a task, or making a clause true, it is easier to satisfy the combined expression. More generally, as noted in the last chapter and shown in Figure ., there is a phase transition in the probability that a random Ksat expression with V variables, K per clause, and C clauses can be satisfied by some assignment of true or false to the V variables. The phase transition occurs in the horizontal axis, labeled C/V, which is the mean number of clauses in which any variable occurs. Obviously, as C/V increases, conflicting constraints increase. The phase transition from easily solvable to virtually impossible to solve occurs at a point on the C/V axis equal to log x raised to the K power, or . x K. Hence, as K increases, the phase transition shifts outward to greater C/V values.
But Figure . gives us an intuitive understanding of Unilever’s problem, in fact, the problem is far more general than Unilever’s assembly plants. Think of each clause, (A v A), et cetera, as a way to make one of the toothpaste products, and think of the conjunction, (A v A) and (A v A) and   .   .   .   , as the way to make all twenty-seven toothpastes. Then as the number of clauses, hence toothpaste products, increases for a given plant with V variables to use in making these dierent products, all of a sudden the conjoint problem will have so many conflicting constraints that it will cross the phase transition from solvable to insolvable.
Moreover, for any given number of clauses and V variables, if a given assignment of true or false to the V variables satisfies the Ksat problem, we can ask if any of the -mutant neighbor assignments of true and false to the V variables that change the truth value assigned to one of the V variables also satisfy the Ksat problem. Thus, we can study the phase transition from a survivable percolating web of solutions regime when V/C is lower to an isolated peaks regime as V/C increases to virtual impossibility for high V/C.
Thus, just as in the job shop problem, as product diversity increases for a fixed plant, a phase transition from survivable to unsurvivable will occur because the conflicting constraints will increase with C/V. The resulting landscape becomes more rugged, the peaks lower, the yellow bromine fog rises from the survivable to the living dead to the dead regime, covering Mont Blanc and all hikers in the Alps (Figure .).
But this takes us back to the technology graph and robust constructibility. Recall from above that the Lego house and Lego house with a chimney might be robustly constructible from wisely chosen intermediate-complexity objects on the pathway to both houses, with thousands of ways to get there. At no extra cost, we might choose to stockpile that intermediate-complexity polyfunctional object rather than another choice.
But intermediate-complexity polyfunctional objects are just what allows multiple pathways, multiple permutations of construction steps to our two final objects. Hence, these same smart intermediate objects reduce the conflicting constraints in the fitness landscape over the construction space to make our desired set of objects, or our set of toothpastes. Lowering the conflicting constraints makes the eciency peaks of the fitness landscapes higher, hence, allows survivable operations at a higher level of product diversity.
Thus, by use of the technology graph to design both products and processes, we can choose a family of products and construction pathways with highly redundant intermediate objects. That choice makes the problem space easy to solve rather than hard to solve. We have thereby tuned the statistical structure of our problem space into a survivable regime. Furthermore, we can test whether our choice of construction pathways to the house and/or house with a chimney is robustly survivable or in the living dead–isolated peaks regime. We need merely use the technology graph to test for percolating sets of -mutant neighboring pathways of construction of the same objects and the average Hausdorf dimension of such pathways.
No need to operate in the isolated peaks regime. Indeed, if you face loss of parts and machines, you had best locate back from the phase transition, deep enough into the survivable regime to survive. And if you are a military force fighting against an enemy whose strategy changes persistently deform your payo landscape and whose eorts are to destroy your capacity to fight, you had best operate even further back from the phase transition in the survivable regime. Indeed, the normal disjunctive form in Figure . is a rough image of the complexity of a campaign you can fight  the number of clauses that must be jointly satisfied to meet your objectives, where each clause is a subobjective and there are K alternative ways to meet that objective using V weapon systems.
Just as warfare and the economy as a whole have much in common, warfare and the biosphere have much in common. If you are a species coevolving with other species, you had best operate back from the phase transition well into the survivable regime.
There is a message: If you must make a living, for God’s sake, make your problem space survivable!
This brings us back to a point made in early chapters. Recall the no-free-lunch theorem proved by Bill Macready and David Wolpert. Given a family of all possible fitness landscapes, on average, no search algorithm outperforms any other search algorithm. Hill climbing is, on average, no better than random search in finding high peaks, when averaged over all possible fitness landscapes.
The no-free-lunch theorem led me to wonder about the following: We organisms use mutation, recombination, and selection in evolution, and we pay twofold fitness for sex and recombination to boot. But recombination is only a useful search procedure on smooth enough fitness landscapes where the high peaks snuggle rather near one another.
In turn, this led me to wonder where such nice fitness landscapes arise in evolution, for not all fitness landscapes are so blessedly smooth. Some are random. Some are anticorrelated.
In turn, this led me to think about and discuss natural games, or ways of making a living. Since ways of making a living evolve with the organisms making those livings, we got to the winning games are the games the winners play. Which led me to suggest that those ways of making a living that are well searched out and exploited by the search mechanisms organisms happen to use  mutation, recombination, and selection  will be ways of making a living that are well populated by organisms and similar species. Ways of making a living that cannot be well searched out by organisms and their mutation recombination search procedures will not be well populated.
So we came to the reasonable conclusion that a biosphere of autonomous agents is a self-consistently self-constructing whole, in which agents, ways of making a living, and ways of searching for how to make a living all work together to coconstruct the biosphere. Happily, we are picking the problems we can manage to solve. Of course, if we could not solve our chosen ways to make livings, we would be dead.
And there is, I think, a molecular clue that the biosphere is persistently coconstructing itself in the survivable regime for a propagating set of lineages. We have just characterized the survivable percolating web regime where the fitness landscape of each creature deforms due to the adaptive moves of other creatures, but there are always neighboring ways of surviving. Genetically, those neighboring ways are one or a few mutations or recombinations away from where the species population is right now. If the biosphere has coconstructed itself such that most species are in a survivable regime, then as coevolution occurs, most species will persist but may well transform, for example, to daughter species. One would guess that this mildly turbulent process is rather continuous, perhaps with some self-organized critical bursts on a power law scale.
The “molecular clock hypothesis” seems to fit these facts. If one compares hemoglobins from humans, chimps, horses, whales, and so on, in general, the longer ago we diverged from one another in the evolutionary record, the more amino acid mutations distinguish the hemoglobins of the two species involved. Our hemoglobin is very similar to chimp hemoglobin and quite dierent from the whale. So good is this correlation that, within given protein families, it is argued that mutations accumulate with timelike clockwork, hence the molecular clock hypothesis, in which a number of amino acid dierences can be taken as a surrogate for time from the most common ancestor. Dierent protein family clocks seem to run at dierent rates.
There is evidence that the clock does not run quite smoothly. John Gillespie, a population biologist now at the University of California at Davis, showed some years ago that amino acid substitutions seemed to come in short bursts that accumulate over long periods of time to a rough molecular clock that “stutters.” Gillespie argued that fitness landscapes were episodically shifting and the bursts of amino acid substitutions were adaptive runs toward nearby newly formed peaks. I agree and suggest that the near accuracy of the molecular clock data over hundreds of millions of years and virtually all species strongly suggests that the biosphere has coconstructed itself such that species, even as they speciate and go extinct, are, as lineages, in the persistently survivable regime.
We as organisms have, in fact, constructed our ways of making a living such that those problem spaces are typically, but not always, solvable as coevolution proceeds. And, on average, the same thing holds for the econosphere. As old ways of making a living go extinct, new ones persistently enter. We too, it appears, have coconstructed our econosphere such that our ways of making a living, and discovering new ways of making a living, are manageable, probably in a self-organized critical manner, with small and large speciation and extinction events.
And there is a corollary: If you are lucky enough to be in the survivable regime, you can survive by being adaptable. What is required to be adaptable as an organism or organization? We discussed this in the last chapter. A good guess is that an organism or organization needs to be poised in an ordered regime, near the edge of chaos, where a power law distribution of small and large avalanches of change propagates through the system such that it optimizes the persistent balance between exploration and exploitation on ever-shifting, coevolving fitness landscapes.
Laws for any biosphere extend, presumably, to laws for any economy. Nor should that be surprising. The economy is based on advantages of trade. But those advantages accrue no more to humans exchanging apples and oranges than to root nodules and fungi exchanging sugar and fixed nitrogen such that both make enhanced livings. Thus, economics must partake of the vast creativity of the universe. Molecules, species, and economic systems are advancing into an adjacent possible. In all cases, one senses a secular trend for diversity to increase, hence for the dimensionality of the adjacent possible to increase in our nonergodic journey.
Perhaps again we glimpse a fourth law.









Chapter 8
Candidate Laws for the Coconstruction of a Biosphere
or the purpose of our discussion here, grant that molecular autonomous agents propagate organization and evolve by the roughly familiar Darwinian aegis of mutation and selection. These agents  coevolving with one another, discovering displacements from equilibrium that can be used to accomplish work, making records of such sources of energy, then linking those exergonic reactions to endergonic reactions  are the means by which our biosphere has come into being, actually coconstructed by the activities, accidents, striving, and failures of these autonomous agents, exapting persistently into their adjacent possible.
Yes. But how does a biosphere get itself constructed? Are there laws? Are there laws that might hold for any biosphere? Laws of a general biology, wherever autonomous agents swirl into existence and change forever the begetting of the universe?
No one knows. Yet is seems reasonable to expect such laws and honorable to begin, even now, to seek them. At worst we will be wrong. Rather more stunningly, we may be right. It is surely enough if at this early state we can even begin to formulate candidate general laws. Our eorts will only improve over time.
In the present chapter, I consider four candidate general laws for any biosphere. Because the science is more advanced than some of the material in the previous chapters, I will be able to describe it in somewhat more detail. That which is more worked out is, I hope, a signature of how the glimmered science of the past seven chapters may develop.
Coevolutionarily constructible communities of molecular autonomous agents may evolve to four apparently dierent phase transitions:
Law .Communities of autonomous agents will evolve to the dynamical “edge of chaos” within and between members of the community, thereby simultaneously achieving an optimal coarse graining of each agent’s world that maximizes the capacity of each agent to discriminate and act without trembling hands.
Law .A coassembling community of agents, on a short timescale with respect to coevolution, will assemble to a self-organized critical state with some maximum number of species per community. In the vicinity of that maximum, a power law distribution of avalanches of local extinction events will occur. As the maximum is approached the net rate of entry of new species slows, then halts.
Law .On a coevolutionary timescale, coevolving autonomous agents as a community attain a self-organized critical state by tuning landscape structure (ways of making a living) and coupling between landscapes, yielding a global power law distribution of extinction and speciation events and a power law distribution of species lifetimes.
Law .Autonomous agents will evolve such that causally local communities are on a generalized “subcritical-supracritical boundary” exhibiting a generalized self-organized critical average for the sustained expansion of the adjacent possible of the eective phase space of the community.
Candidate Law 1: The Dynamical Edge of Chaos
Molecular autonomous agents, for example, free-living cells, are parallel-processing molecular dynamical systems. A bacterium such as E. coli has on the order of three thousand structural genes. The diversity of molecular species in E. coli includes perhaps a thousand small molecules in metabolism, the genes, RNA and protein species, lipids, large carbohydrates, and so forth. For the sake of argument, let’s say there are about five thousand molecular species in E. coli. Perhaps the number is larger.
A cell is a parallel-processing dynamical system. That is to say, the cell carries out a wide variety of molecular activities, including the turning on and o of transcription of genes into RNA; the processing of that RNA into mature messenger RNA; the translation of that RNA into proteins, the activities of many of those proteins as enzymes to catalyze reaction, the modification of the activities of enzymes by chemical events such as phosphorylation and dephosphorylation; the building of structural components such as bilipid membrane, and microtubule assembly and disassembly; and the construction of proteins and other receptors. These receptors are located transmembrane at the cell boundary and elsewhere in the cell, including on nuclear membranes of eukaryotes, such that signal molecules can be detected and responded to.
So, lots of activities are going on all the time, in parallel, in your typical E. coli, yeast, or your own pancreatic cells. The proper conceptual framework to think about all this activity is the “state space” of the system. If we ignore geometry, that is, the locations of molecules relative to one another in the cell  which is a big idealization  then the state space of a cell consists of a list of all the molecular species and their “activities” or “concentrations.”
In the following, I will focus on the behavior of the genetic regulatory network. It has been known since the seminal work of Jacob and Monod in and , work for which they won the Nobel Prize, that genes can turn one another on and o. In more detail, the protein made by one gene can diuse in the cell and bind to a DNA site, called a “cis acting site,” near a second gene. Genes that encode proteins are the structural genes; the binding of the protein, or several proteins at a set of nearby cis sites, can turn the second structural gene on or o. More generally, the binding of diusible factors, called “trans acting factors,” to cis sites, can tune graded rates of transcription of the nearby structural gene.
The human cell is estimated to have about eighty to a hundred thousand structural genes and between ten thousand to perhaps a hundred thousand cis acting sites. In general, any structural gene may be regulated by zero to ten dierent trans acting factors that may bind at one or more nearby cis acting sites. Therefore, the human genomic system is a highly complex web of regulatory connections and interactions by which the activities of genes turn one another on and o, or more generally tune one another’s activity.
It is the joint dynamical behavior of such genetic networks, plus the remaining cellular network of proteins and other molecular interactions, that controls cell behavior, including development from the fertilized egg to the adult.
In the past three decades, considerable theoretical insight has been achieved with respect to the expected behaviors of such large genetic regulatory networks. I discuss the relations to experimental evidence briefly below.
Boolean Networks
To take a very simple case, we consider the N genes of a cell and idealize further to imagine that at any moment in time a gene is either actively transcribing into RNA, with active = , or it is not transcribing, so is inactive, hence . Thus, the genes are treated as binary, or “Boolean,” variables. A Boolean network is a model genetic network with N binary, or Boolean, genes, each receiving regulatory inputs from some among the N genes and each governed by a Boolean function on its inputs telling the activities of its inputs for which it should turn on or o.
The Boolean idealization is severe, but it is a very useful place to start. If the human genome has , structural genes and each can be on or o, then the number of possible patterns, or “states,” of gene activity in the human genome is a staggering , or about ,. That is, a human cell could, in principle, be in any one of a , states of gene activity. Its state space is ,. There has only been seconds since the big bang. If it took merely a second to turn a gene on or o, then no human cell could have explored more than an infinitesimally tiny fraction of its state space, ,, even if it had been chugging along since the big bang.
That cannot be what cells do. Something must confine their “flow” in their state space. And, indeed, what confines their flow is precisely the genetic regulatory network by which genes turn one another on and o.
Very good work shows that such networks can exist in three broad regimes: an ordered regime, a chaotic regime, and near a phase transition between order and chaos. All the evidence suggests that cells have evolved to lie in the ordered regime, fairly near the edge of chaos. Communities of cells may lie even closer to the edge of chaos. The hypothesis that cells and communities of cells lie in the ordered regime near the phase transition to chaos is candidate law .
To understand this candidate law, I need to describe to you the structure and behaviors of model genetic networks. Thereby we can characterize the ordered, chaotic, and edge-of-chaos regimes.
To take a very simple case, we consider a cell with three genes, A, B, and C. In this simplest Boolean idealization, there are three genes, each of which can be on or o, hence, there are two raised to the third, or eight possible states of gene activities: (), (), (), (), (), (), (), (), where the ordering of the three symbols stands for the activity states of ABC, respectively.
The most general description of a dynamical system consists in specifying its state space, then identifying for each state which state or states it changes into. For a deterministic dynamical system, each state changes into a unique successor state. For a nondeterministic system, single states can change to two or more successor states. Which of the successor states is chosen in the nondeterministic system is given by some random process such as flipping a coin.
Figure .a shows an arbitrary deterministic state space among the eight states of three genes, A, B, C. For each state, I have chosen its successor state at random.
Figure .a shows several characteristic features of these very simple Boolean dynamical systems. First, note that the system is parallel processing. More than a single gene changes its activity value from to or to on many of the state transitions. Next, there is a finite number of states, here, eight. Each state has a unique successor. Over time, if the system is released from any initial state, it will follow a trajectory of states through state space. Since there is a finite number of states, eventually the trajectory must hit a state previously encountered on the trajectory. But the system is deterministic, thus once the trajectory reenters a state previously encountered, it will follow a recurrent loop of states in state space, called a “state cycle.”
In general, the length of a state cycle can be a single state that reenters itself, a “steady state,” or all of the states in the state space may lie on a single, long cycle that traverses all the states of the state space or state cycles may be any length between these two limits.
A second typical property of such a parallel-processing Boolean system is that more than one state cycle may exist. In the present example, three state cycles exist in the state space.
State cycles are called “attractors” because they typically attract the flow of other states into themselves. This is shown in the first state cycle, where the states () and () flow into the state cycle, but are not on it. These two states are called “transients.” Transient states are encountered on trajectories flowing to state cycle attractors, but are not encountered again once the attractor is reached, assuming no perturbations occur to the system.
The set of states flowing into a state cycle attractor plus that state cycle is called the “basin of attraction” of the attractor.
The set of attractors are jointly the asymptotic long-term alternative behaviors of the network. If released from any initial state, the system ultimately winds up cycling on one of its attractors.
Thus in discrete-valued deterministic networks  here, binary ones  each state lies in a single basin of attraction, so the basins of attraction partition the state space into disjoint sets of states.
The simple example of Figure .b allows us to show another feature of such synchronous Boolean networks  here, synchronous means that all the binary variables change value at the same clocked moment. Since each state has a unique successor state, we can write a table of all the states and for each, its unique successor.
Figure .b shows the state transitions for each state, at time T, to the state it transforms to one clocked moment later, at time T + .
But Figure .b also shows for each gene, in order (ABC), the Boolean rule, or Boolean function, of the three genes, A, B, C, that turns each on and o as a function of the values of itself and the other two genes.
As it happens, genes A and B have Boolean functions that depend on all three genes, A, B, and C. By examination, however, gene C has a Boolean function that depends only on genes A and C, not on gene B. To say that the activity of gene C depends only on A and C and not B means that once the combinations of activities of A and C are defined at a moment T, the next activity of C at T + is indepen-dent of whether B is on or o at time T. Indeed, the Boolean function is C = (not A or not C); that is, gene C will turn on at the next moment if at the current moment either A is not active or C is not active or both are not active.
From Figure .c, after simplifying Boolean expressions as we just did for gene C, we can write down the “wiring diagram” of inputs among the three genes. Since A and B depend upon all three genes, each receives a regulatory input from all three genes. Gene C, however, receives inputs only from itself and gene A.
The combination of Figures .d and .c, respectively, shows for each gene the inputs to that gene and the logical or Boolean function by which it turns on and o. Thus, the combination of .c and d is the genetic network among the genes.
Order, Chaos, and the Edge of Chaos
As noted above, thirty years of work by many scientists  initially on synchronous Boolean networks but now generalized to a wider family of model genetic systems, including some where genes can exhibit continuously graded levels of activity as their inputs turn gradually up or down  all show the same simple, general results: There are three broad regimes of behavior. A number of very simple properties of networks, involving connectivity of the network and simple biases on the Boolean functions, control which regime a network lies in.
The Ordered Regime
Figure . shows a hypothetical movie of a network in the ordered regime. Let the network be released from an arbitrary initial state and flow along a trajectory toward a state cycle attractor. If a gene is rapidly turning on and o, or twinkling, call it green. If the gene is frozen in the active or frozen in the inactive value for a long time, say, fifty state transitions or more, call it red. In particular, once the system is on its state cycle, the twinkling genes that turn on and o on the state cycle would be green and those genes frozen on or frozen o, red.
Initially, just after release from some random initial state, most genes are twinkling, hence green. As the network approaches its state cycle, more and more genes turn red, hence are frozen on or frozen o. By the time the system has reached its state cycle attractor, the majority of the genes are colored red (Figure .a).
Most critically, if one considers the subset of red genes, they form a giant “percolating cluster” whose size scales linearly with the size of the entire network. In eect, the frozen red component is a “frozen red sea,” which spans the entire network and typically leaves behind isolated twinkling green islands.
The Chaotic Regime
In the chaotic regime, the same movie shows that the majority of the genes remain green, twinkling on and o (Figure .c). So a vast, twinkling green sea spans the network, typically leaving behind isolated frozen red islands.
The Edge of Chaos
As parameters of the network discussed below are tuned from the chaotic regime toward the ordered regime, the green percolating sea becomes smaller and eventually fragments into two or many isolated green islands. The point of fragmentation of the green sea into green islands constitutes a phase transition from the chaotic to the ordered regime. This phase transition is sometimes called the edge of chaos (Figure .b).
Several critical features distinguish the ordered from the chaotic regime. In the ordered regime, the lengths of state cycle attractors scales polynomially with the number of genes. Remarkably, in the ordered regime near the phase transition to chaos there is evidence for universal scaling in which the number of states on a state cycle scales as the square root of the number of genes. This scaling, which I first discovered over thirty years ago, still staggers me. If the human genome has , genes, it has a state space of , or , states. Yet if the human genomic system lies in the ordered regime near the phase transition to chaos, it will settle down and cycle among the square root of ,, or about states!
Now, states is very very small compared to ,. The overwhelming order of the ordered regime, I believe, keeps cells from wandering all over their state spaces for eternities beyond eternities. In fact, it takes about one to ten minutes to turn a eukaryotic gene on or o, so it would take a cell from to , minutes, or from about . hours to about hours, to traverse its state cycle attractor. This is right in the biological ballpark. For example, the cell division cycle of dierent human cell types is in the range of to hours.
By contrast, in the chaotic regime state cycle lengths scale exponentially with the size of the network. The deepest one can go into the chaotic regime is to assign at random the successor state for each state. In that case, in general, each gene is a Boolean function of all N genes. In this case, the typical state cycle length is the square root of the number of states in the state space. For the human genome with , states, a typical state cycle length would be the square root, hence ,. Remember, it is only seconds since the big bang. State cycle attractors of lengths ,? Not in my body, thank you very much.
In the first two articles I wrote on the subject of random Boolean nets, as long ago as and , I plotted cell cycle lengths from organisms as diverse as bacteria, yeast, worms, plants, and simple and complex animals. These progressively more complex organisms have progressively more DNA per cell and more genes per cell. If the Boolean net theory is on the right track, and if cell cycles are a reasonable proxy for expected state cycle times as a function of the number of genes, then cell cycle time should scale as a square root function of the number of genes. This prediction is actually pretty much correct. Indeed, a plot of median cell cycle time versus total DNA per cell is a square root function from bacteria to human cells.
But there are caveats: The number of genes in cells may not be proportional to the amount of DNA per cell. Some DNA is “junk.” A plausible estimate of the number of genes per cell is now available for many organisms. On this basis, cell cycle time scales somewhere between a square root and a linear  that is, directly proportional  function of estimated genes per cell. So without yet invoking natural selection to tune the structure and logic, the theory of random Boolean nets is already quite close to the data.
A second critical feature that distinguishes the ordered from the chaotic regime is what happens when the activity of a single gene is transiently reversed. I would note that such transient reversals happen all the time in normal development. For example, a single hormone enters a cell, then the nucleus, then binds to a nuclear genetic site and transiently changes the activity of some gene. Typically, the results unleash a cascade of alterations of gene activities. These cascades of alterations guide development and cell dierentiation. In the ordered regime, these cascades tend to be smallish. In the chaotic regime, the cascades are typically huge. In real cells, the cascades tend to be smallish. More, we can actually predict their size distribution.
Let’s define a gene as “damaged” if after an initial gene has had its activity reversed for a single moment the gene in question ever behaves dierently than it would have had the perturbed gene been left undisturbed. In eect, damage shows that perturbation of a gene aects the behavior of the damaged gene. Imagine damaged genes purple. If a gene has misbehaved once, it is purple, whether it stops misbehaving or keeps misbehaving.
Given this definition of damage, we can consider in detail two identical copies of a network, in the same state, running at the same speed. Now pick a model gene at random. If it is on, flip it o. It is o, flip it on. Color it purple since you have damaged it.
Now watch the unperturbed and perturbed copies of the network, and consider purple any gene that ever does something dierent in the perturbed network compared to the unperturbed network. In general, you will see a purple avalanche spread out from the initially perturbed gene. The purple avalanche will spread out in some way, then must eventually stop. For example, at a maximum, all the genes turn purple. Thus, we can define the size of a given damage avalanche as the number of genes that turned purple, hence misbehaved at least once.
In the ordered regime, something magic happens. If one of the frozen red genes is perturbed, typically no avalanche spreads from that purple gene. If an avalanche spreads at all, it is tiny.
By contrast, if a twinkling green gene in one of the isolated green islands is perturbed and turned purple, a purple avalanche spreads to some or all of the twinkling green genes in that island. But the avalanche stops at the boundaries of the green island since damage avalanches cannot propagate through the frozen red percolating sea.
Because purple avalanches cannot propagate through the frozen red percolating sea, the green islands are functionally isolated from one another. The consequence is that there is a characteristic size distribution of avalanches in the ordered regime and a very dierent distribution in the chaotic regime.
Figure .a schematizes the distribution of avalanches for networks in the ordered regime very near the phase transition to chaos. The figure plots the logarithm of the size of the avalanche on the x-axis and the logarithm of the number of instances of avalanches of each size on the y-axis. As you can see, the size distribution shows up as a straight line in this log log plot, sloping down to the right. Hence, the distribution is a power law distribution, with many small and few large avalanches of change propagating through the network. In addition, there is a finite cuto and thus a largest-size avalanche, which seems to scale as a square root function of the total number of genes in the network. Deeper in the ordered regime, the size distribution of avalanches remains a power law, but the slope down to the right becomes steeper, so there are fewer big avalanches compared to small avalanches.
If a human genome is in the ordered regime near the phase transition to chaos and harbors some , genes, then the largest avalanches should be about two times the square root of the number of genes, hence x , or about genes. This is probably about right. In the fruit fly, Drosophila melanogaster, with about , genes, the largest avalanches should be about twice the square root of ,, or x , or . The largest avalanche I am aware of occurs when the moulting hormone ecdysone acts on the salivary glands and induces changes in about of the “pus” in the polytene chromosomes. If each pu is a single gene, as most geneticists think, then ecdysone unleashes an avalanche altering the activities of genes.
No comparative data yet show whether the size distribution of avalanches in real organisms is a power law, nor whether the largest avalanches scale as a square root function of the number of genes in the organism. But these hypotheses are fully testable using today’s experimental techniques.
Nevertheless, these predictions do roughly fit one’s expectation as a biologist. Most genes if perturbed should unleash no avalanches or just small avalanches, fewer genes should unleash larger avalanches, and some modest fraction of the genes at most should be open to alteration by transient alteration in the activity of any single gene. Thus, this typical, or “generic,” behavior of parallel-processing networks in the ordered regime closely fits the known data and our informed intuitions.
The chaotic regime contrasts starkly with the ordered regime. Its expected behaviors are not biologically plausible. The chaotic regime diers from the ordered regime for a simple reason. In the chaotic regime, the twinkling green sea percolates. If a single green gene is perturbed and turned purple, that perturbation usually unleashes a purple avalanche that spreads through much of the percolating green sea. Huge damage avalanches are unleashed by single gene perturbations.
These huge avalanches are exactly the signature of the famous “butterfly eect” seen in the weather, where a small initial change can have large-scale consequences. In short, the spreading purple avalanches constitute “sensitivity to initial conditions.” On the other hand, it is important to distinguish between low-dimensional chaos, characterized by three or four variables governed by three or four equations, and the high-dimensional chaos, shown in large-model genetic networks with tens of thousands of gene variables. In high-dimensional networks of genes modeled as binary variables, chaos shows up as the enormous avalanches of damage that spread from one to many of the variables of the model network.
Figure .b schematizes the size distribution of avalanches in the chaotic regime. Unlike the ordered regime, there is a spike of huge avalanches where to percent of the genes are damaged. In a cell, this would correspond to a hormone changing the activity of a single gene and , to , genes downstream changing their activities. This does not happen.
As in the ordered regime, however, in the chaotic regime there is also a power law distribution of small avalanches, present in addition to the vast avalanches that rocket through the green sea. Presumably, these small avalanches occur when green genes near the filigreed “coasts” of red frozen islands are perturbed and the purple avalanche is trapped on the fingers of the red beaches.
A third feature, a convergence versus divergence along flows in state space that characterizes the ordered versus chaotic regime, is perhaps the most important to our future discussions. In the ordered regime, initially nearby states lie on trajectories that tend to converge in state space. In the chaotic regime, initially nearby states tend to lie on trajectories that diverge in state space. At the edge of chaos, initially nearby states tend to lie on trajectories that neither converge nor diverge in state space.
These behaviors are conveniently shown in a recurrence map, which I call a “Derrida curve” since physicist Bernard Derrida of Saclay, France, first showed it to me. In Derrida and Pomeau were also the first to find analytic proof of the ordered and chaotic regimes and the phase transition between them.
Consider two states of a Boolean network with five genes and the successors to each of those states:
state () ’ () state ’
state () ’ () state ’
We can define the “Hamming distance” between state and state , the number of binary variables by which the two states dier. Here the Hamming distance is , since gene is in state and in state . In addition, we can define the normalized Hamming distance, Dt, between these two initial states at time t as the fraction of binary variables by which they dier. Hence, Dt is / = .. Similarly, we can define the normalized Hamming distance between the two successor states at time t + . In the case above, D(t + ) = / = ..
Then we can compare Dt and D(t + ) and ask if the initial distance at time T decreased or increased at time T + . In the current case, the initial distance increased from . to . at the next moment, T + . In short, the two initially nearby states, diering in the activity of a single gene, spread further apart one moment later. Indeed, this spreading is the first time step of the spreading of a purple avalanche of damage.
To characterize Boolean networks with respect to the ordered and chaotic regime, it is convenient to take thousands of random pairs of states at dierent initial distances, Dt, where Dt can vary from . to .. For each pair of initial states, run the Boolean network forward one moment, discover the two successor states of the two initial states, and compute D(t + ) for that pair of initial states. Average the D(t + ) values for the thousands of pairs of initial states at each initial distance, Dt. The typical results are shown in Figure ..
Figure . is a recurrence map, with Dt shown on the x-axis, D(t + ) shown on the y-axis. Thus, for an initial pair of states at Dt = ., if the successor states have spread apart, say to D(t + ) = ., a dot in the xy plane at x = ., y = . records this event. The averaged set of these dots for the thousands of pairs of initial states at all dierent initial distances is the average recurrence map for the network.
In Figure ., the main diagonal, running at a -degree angle from the lower-left corner, which corresponds to Dt = and D(t + ) = , shows the condition where D(t + ) = Dt. If a dot lies on the main diagonal, then the distance between the initial states is the same as the distance between the successor states. The two initial states lie on trajectories that neither diverge nor converge in state space.
In the chaotic regime, nearby states lie on trajectories that diverge further apart in state space, so the recurrence map lies above the main diagonal for small initial distances. For large initial distances, even networks in the chaotic regime have the property that states tend to lie on trajectories that converge. The degree to which the Derrida recurrence curve lies above the main diagonal for small Dt is a measure of how deeply into the chaotic regime the network lies. Deep into the chaotic regime, nearby states, hence small Dt, diverge swiftly. Thus, the recurrence curve is well above the main diagonal for small values of Dt.
By contrast, in the ordered regime, as shown in Figure ., the Derrida recurrence curve is below the main diagonal for small Dt, that is, initial states that are close lie on trajectories that converge. At the phase transition between order and chaos, the Derrida recurrence curve begins, at Dt = , tangent to the main diagonal, then falls below it as Dt increases.
In summary, in the ordered regime, nearby states tend to lie on trajectories that converge in state space. At the phase transition, nearby states tend to lie on trajectories that neither converge nor diverge. In the chaotic regime, nearby states tend to diverge.
As I will shortly discuss below, it is plausible to think that autonomous agents, and communities of autonomous agents, evolve such that they lie in the ordered regime near the phase transition to chaos. A major reason for this intuition is that under such circumstances flow in state space is mildly convergent. In turn, this will allow the autonomous agents to make the maximum number of reliable discriminations and reliable actions, hence, to play the most sophisticated natural games by which to earn their livings.
The three features that characterize the phase transition between order and chaos seem by good numerical evidence to coincide. That is, when parameters discussed below are tuned from the chaotic to the ordered regime such that the green sea is just breaking up into green islands, simultaneously, the Derrida curve changes from the chaotic regime to become tangent with the main diagonal for small values of Dt. And at just this point, state cycle lengths switch from scaling exponentially to scaling polynomially with the number of genes.
At least three simple parameters tune whether networks are in the ordered or chaotic regimes. Therefore it is important that evolution can readily tune whether genomic systems lie in the ordered or chaotic regime by tuning any of these three parameters. Even more important, evolution seems to have done just that and tuned cells into the ordered regime. Since cells are our only example of evolved autonomous agents, the data support my candidate first law that autonomous agents and communities of autonomous agents will evolve to the ordered regime near the phase transition to chaos.
The simplest parameter to tune is the number of inputs, K, per gene. I showed numerically in , and Derrida and Pomeau showed analytically in , that if K = or less, networks lie in the ordered regime. Derrida and Pomeau showed that K = is the edge of chaos phase transition. For K greater than , networks lie in the chaotic regime.
Already this is worth the excited attention I gave it so long ago. For the results show that a network with randomly chosen logic nevertheless behaves with exquisite order. Say, a network of , genes is constructed at random, with the simple limitation that each model gene have K = inputs but that the wiring diagram be chosen at random, and the Boolean function assigned to each gene among the possible Boolean functions of K = inputs is also chosen, once and for all, at random, this spaghetti mess of a network with its tangle of , wires connecting the genes in some mad scramble will straighten itself out.
The system settles down to cycle among about states out of , or ,! Order for free, I keep saying. Selection need not struggle against all odds to achieve cells that behave with overwhelming order. That order lies to hand for selection’s further craftings.
There are two further known parameters that can tune networks from the chaotic to the ordered regime if K is greater than . Both are biases on the Boolean functions. Remarkably, real cells show dramatic evidence of one of these two biases, which I call “canalyzing Boolean functions.” I discuss this canalyzing bias second.
The first bias is characterized by a parameter Derrida and colleagues called “P.” Consider in Figure .c, the Boolean function for gene A. It has five values and three values. The parameter P is defined as the number of instances of the majority value over the full set of cases. Hence, P for gene A = /. For gene B, the Boolean function has seven values and one value. Its P is /. For gene C there are six values and two values. Its P is /.
By definition, P for a Boolean function can vary from . to ., when the majority fraction varies from half to all the possible cases. Derrida and colleagues showed that, in general, when K > , P can be tuned upward from . to some critical value, Pc, where networks pass from the chaotic to the ordered regime. The critical value of P as a function of K is shown in Figure .a. Universal scaling for cycle lengths as a square root function of the number of genes has been established along the phase transition in the PK plane.
The second bias in Boolean functions are the canalyzing Boolean functions. Consider gene C in Figure .c. If gene A is , gene C will be at the next moment no matter what the activities of gene B or C may be. If gene A is , gene C may be or at the next moment, depending on the prior state of gene C itself.
Gene C is governed by a canalyzing Boolean function. Canalyzing Boolean functions have at least one input with at least one value that suces to guarantee the next state of the regulated gene, regardless of the values of all other inputs. By inspection, if A is now, then C is guaranteed to be a moment later. So the Boolean function is canalyzing, and I call A a canalyzing input to C. Note that gene C is also a canalyzing input to gene C.
Look next at the Boolean function for gene B in Figure .c. If gene A is , then gene B is sure to be the next moment, regardless of the activities of B and C. So A is a canalyzing input to B. But if B is , that too assures that B will be at the next moment. So B is a canalyzing input to itself. And similarly, if gene C is , gene B is sure to be the next moment. Gene B has three canalyzing inputs. By contrast, gene A in Figure .c has no canalyzing input, so is not a canalyzing Boolean function. No value of A alone, B alone, or C alone suces to guarantee the next activity of gene A.
In general, Boolean functions of K inputs may have ,,,   .   .   .     K canalyzing inputs. Numerical evidence shows that, for K > inputs per gene, a sucient bias toward a high fraction of genes with a sucient number of canalyzing inputs drives networks from the chaotic into the ordered regime. Figure .b shows the phase transition curve in the CK plane.
Before turning back to biology, it is essential to stress that the results noted above for synchronous Boolean networks extend to asynchronous Boolean networks and, more critically, extend to a family of model gene networks in which the genes have graded levels of activity. This is important because the on-o Boolean idealization is quite severe. Real genes show graded levels of activities as a function of the concentrations of their trans acting inputs and the bound states of their cis regulatory loci. If our results were fragile in that they depended upon the Boolean, on-o idealization, we could not trust them to inform us about real cells. Glass and Hill have examined a model with continuously graded levels of gene activity, the “piecewise linear model,” and found the same qualitative behaviors. In particular, the same phase transition occurs as a function of K, P, and C. The striking dierence, however, is that deep in the ordered regime of the piecewise linear case, the genes of the twinkling green islands settle down to steady states that dier on dierent attractors. Near the phase transition to chaos, the green islands begin to exhibit sustained “limit cycle” oscillations that become chaotic in the chaotic regime.
Thus, there is now good general evidence that the ordered and chaotic regimes and the phase transition between them are deeply characteristic of some enormous class of parallel-processing nonlinear dynamical systems.
The Biology
But what of real cells? We have no conclusive evidence, yet an abundance of telling hints. If I am not yet entirely convinced and if I am  as I am  biased, I nevertheless become increasingly confident that cells, and probably communities of cells, do live in the ordered regime near the edge of chaos. Not only does the evidence point this way, but cells should live near the edge of chaos. Why? As remarked already, the intuition is simple. Being autonomous agents, cells must, as individuals living in communities, make the maximum number of reliable discriminations possible and act on them reliably, without “trembling hands.” Just inside the edge of chaos seems the ideal place.
Intuitively, slightly convergent flow in state space allows classification, for when two states converge on a single successor state, those two states have been classified as “equivalent” by the network. Slightly convergent flow would seem to allow the maximum number of reliable classifications in the face of a noisy environment. The convergent flow buers the system against the noise of the environment.
And what of trembling hands? No point making superb discriminations, seeing the stag deer, drawing your bow, aiming the arrow, then shooting yourself in the foot. Again, slightly convergent flow in state space to buer external and internal noise seems ideal.
So what about cells? My colleagues Steven Harris, Bruce Sawhill, and Andrew Wuensche, and I have carried out work over the past several years that has analyzed actual gene regulatory rules for eukaryotic genes drawn from a variety of eukaryotic organisms  yeast, Drosophila, maize, mouse, and so forth. The results show a very strong statistical bias in favor of genes governed disproportionately by canalyzing Boolean functions. When we have constructed model networks with the observed bias toward canalyzing functions, such networks lie modestly in the ordered regime by the Derrida curve and other criteria noted above.
It all began at the Santa Fe Institute several years ago. Steve Harris, a molecular biologist from Texas was visiting. I told him about canalyzing functions. “Never,” said Steve. Seeing my opportunity I replied, “You have a good genetics library, want to read a bunch of papers and analyze the transcription rules of genes with three or four or five known regulatory inputs?”
I didn’t think Steve would say yes, for the reading of over a hundred papers in the subsequent years, and cataloging the detailed results, was going to be a substantial task.
“Sure,” he replied.
Some months later, Harris called. “Hey, the results for genes with K = inputs look interesting! There is a bias toward canalyzing functions.”
“Never,” I said.
“I’ll send the data,” was the reply.
Steve had carefully read about sixty papers on regulated genes with K = known inputs, where the data was available at the level of actual binding of trans acting factors to cis sites and the turning on of transcription. A gene with K = known inputs has, in the Boolean idealization, to the rd, or , possible on-o states of those inputs, as we have seen. In virtually all the cases used, Steve had good data for all eight input states. He warranted the Boolean idealization had its problems, but found that in many cases the response of a gene was nonlinear to its inputs. Thus, gene A might be turned on percent by factor and percent by factor , but percent by both factors at the same concentration. It looks like the Boolean “and” function, where the regulated gene is “on” at the next moment only if both inputs are “on” now.
We need some mathematical facts. The number of Boolean functions of K inputs is to the to the K, (K). For K = , there are Boolean functions. For K = , there are Boolean functions. For K = , there are , Boolean functions. For K = , there are over a billion Boolean functions.
A Boolean function with K inputs, as noted, can have , , ,   .   .   .    K canalyzing inputs. But, as K increases, the number of Boolean functions that are canalyzing at all, on or more inputs, declines dramatically, as shown in Figure .. In particular, . percent of the Boolean functions of K = inputs are canalyzing. But only percent of the Boolean functions of K = inputs are canalyzing. Only percent of the , Boolean functions of K = inputs are canalyzing. Only less than percent of the billion or so Boolean functions of K = inputs are canalyzing.
This shift means that we can test if there is a bias in sampled eukaryotic genes. Indeed, in more detail, among the K = Boolean functions, percent have no canalyzing inputs and a decreasing fraction of the Boolean functions have , , or canalyzing inputs, as you can see in Figure ..
Also plotted on Figure . is the observed fraction of eukaryotic genes with K = inputs. The observed curve is the opposite from the curve expected if K = genes were regulated by Boolean rules drawn at random from among the functions. Indeed, fully percent of the observed cases have canalyzing inputs, while the expected fraction would be only peercent if rules were drawn at random.
One does not need fancy statistics, but they readily confirm that the observed distribution is sharply shifted to large numbers of canalyzing inputs per gene. Figure . shows similar results for genes with K = known inputs. Again, the shift toward genes regulated with a high number of canalyzing inputs is apparent and strongly statistically significant. Data for K = and K = genes shows the same bias, but the cases are too few to be statistically significant.
But there remains analysis to be done. Recall the P parameter. Networks with high P values, where genes are mostly turned on or turned o by their inputs, also lie in the ordered regime. Moreover, there is an overlap but nonidentity between the classes of Boolean functions of high P values and Boolean functions with or more canalyzing inputs. When we analyzed our samples of genes, they also had high P values compared to a random distribution of Boolean functions with K = or K = inputs.
In order to discriminate whether the observed bias was toward high canalyzing inputs or high P values or both, we carried out a “residual analysis.” That is, we classified all K = Boolean functions into dierent P classes, P = /, P = /, P = /, P = /. Within each P class, some Boolean functions have , , , or canalyzing inputs. Therefore, among all the Boolean functions for K = within a given P class, there is some distribution of Boolean functions with , , , or canalyzing inputs. Thus, we asked, within a given P class, if the real genes showed a residual bias toward a high number of canalyzing inputs per gene compared to what would happen if real genes were governed by Boolean rules drawn at random with respect to canalization. The answer for K = and K = genes is overwhelmingly yes.
In short, if we control for P classes, there is a very strong and very statistically significant residual bias toward high numbers of canalyzing inputs per gene. Conversely, when we controlled for canalyzing input classes and tested for a residual bias toward high P values, there was no sign whatsoever of such a bias. Thus, it appears that evolution has, in fact, tuned the choices of Boolean rules used to govern genes with K = and K = known inputs, as well as genes with K = and K = inputs that we have sampled, sharply in favor of a high bias toward usage of Boolean rules that are canalyzing functions.
The main caveat to hold in mind, in addition to misreading the articles or the articles being a nonrandom sample of published data, is that genes governed by canalyzing functions may have more easily detected genetic eects, hence, be noticed and studied. Only future work with randomly chosen structural genes will overcome this source of bias. Despite the caveat, I am quite convinced by the data. In particular, genes governed by high P values would also have easily detected genetic eects, yet there is no such bias in the data.
Tentatively, eukaryotic genes are governed by rules biased toward many canalyzing inputs per gene. Why? Either chemical simplicity or natural selection or both, I think.
Now let’s examine the consequences. We know that networks with K = , K = , or more inputs per gene are generically in the chaotic regime if Boolean functions are chosen randomly from the full range of possible functions of K = , K = , or more inputs. We have observed a substantial bias toward canalyzing functions. Does this bias suce to tune networks with K = , or K = or more genes into the ordered regime?
Our group constructed large networks of genes, using Wuensche’s wonderful DDlab program, available on line, to examine model systems with up to , genes. When we made networks with K = or K = inputs and randomly chosen Boolean functions, their Derrida curves, as expected, were in the chaotic regime, a percolating green sea existed, and vast purple avalanches careened around the system.
When we made networks with K = or K = inputs, tuned to the exact distribution of fractions of genes with , , , , or canalyzing inputs, the results (Figure .a) show that such networks are clearly in the ordered regime. The Derrida curve is below the main diagonal. Therefore, in such networks a percolating frozen red sea exists, leaving behind isolated green islands, and the distribution of purple damage avalanches is a power law with a finite cuto at about times the square root of the number of genes (Figure .b). This last predicts that the largest avalanches of gene changes if any single gene is perturbed in humans should be about genes. This fits presently known data.
We even have tentative evidence of detailed evolutionary tuning. As the number of inputs per gene increases, a gradually decreasing fraction of the Boolean functions must be canalyzing to cross the phase transition into the ordered regime. Although the data are too few to warrant conclusion, the fraction of canalyzing inputs for K = , K = , and K = eukaryotic genes trends downward as K increases along the curve needed to remain just within the ordered regime. This decrease as K increases results in the virtual identity of the K=3 Data, K=4 Data, and K=5 Data curves in Figure 8.9a. If so, only natural selection can have tuned it thus.
There are other clues, reported in Origins of Order and At Home in the Universe in some detail, that support the hypothesis that cells lie in the ordered regime. This interpretation is based on the assumption that the dierent cell types of a higher eukaryote correspond to the dierent state cycle attractors of the network. One attractor is a liver cell, another is a kidney cell, and so forth.
•The percolating frozen core that is identical on all attractors of the Boolean network is likely to correspond to the core set of genes whose expression is known to be identical on all cell types, commonly thought to be housekeeping genes.
•The typical dierences in gene activity patterns in model cell type attractors, usually a few percent, mirror the data for real cells.
•The number of state cycle attractors robustly scales as a square root function of the number of genes in the ordered regime. The number of cell types in real cells scales as roughly a square root to a linear function of the estimated number of genes in that organism, from yeast to sponge to worm to man. Indeed, the square root of , is about , and Bruce Alberts and colleagues quote the number of cell types in humans as .
•The expected power law size distribution of avalanches of gene changes after perturbation of a single gene’s activity seems plausible and fits the still sparse data.
•Model cell types are homeostatically stable to most small perturbations. So are real cell types.
•If a state cycle attractor is a cell type, then cellular dierentiation from one to another cell type corresponds to a perturbation that causes the cell type to leave one attractor and flow to another attractor. In the ordered regime, any cell type can only directly reach a few adjacent cell types and may, by a succession of perturbations, eventually dierentiate along branching developmental pathways to a larger number of cell types. Precisely this pattern of branching dierentiation is known in all multicelled organisms.
There are other data, but perhaps that will suce. I believe the initial evidence strongly suggests that eukaryotic cells are in the ordered regime, not too far from the phase transition to chaos.
This hypothesis, which I here tentatively adopt as a candidate general law for any biosphere  a very long jump to be sure  is now open to direct tests. Current technology, based on Aymetrix chips, displays the DNA from thousands of dierent genes in a two-dimensional array. RNA can be sampled from small tissue fragments, or even single cells, and, via a few steps, caused to bind through Watson–Crick base pairing to the corresponding DNA sequence. In this way, the transcribed RNA abundances of thousands of genes can be sampled simultaneously. Thus, we can now follow the RNA states of cells over time, in normal and diseased states, treated and nontreated states, and so forth. Companies such as Incyte are doing just this and selling the data to the large pharmaceutical companies for analysis.
But then we can clone controllable cis sites such as promoters into cells at one or more randomly chosen sites and study the eects of transiently perturbing the activities of one or a few genes. Is the Derrida curve below the main diagonal or not? Does a power law distribution of avalanches of change erupt or not? We can use the data to find the genes in the same isolated green islands, for avalanches should be confined to one island and overlap if started at dierent genes in the same island. More, patterns of gene activities that change will change in correlated ways for genes in the same green island, but not for genes in dierent green islands.
Remarkably, recent evidence suggests just such correlated patterns of gene activity changes. John Welsh has analyzed the transcription patterns of almost , dierent genes in a specific cell type, the human melanocyte, from newborn children, subjected to the eight possible dierent combinations of three distinct modes of perturbation. Welsh could, in principle, distinguish increases, decreases, or no change in the abundances of gene transcripts for his nearly , genes. Of these, , showed no detectable change, about showed changes. Given eight treatment regimes, the control, and the seven other treatments consisting of all combinations of one or more of his three perturbations, in principle, there are three raised to the seventh power, or about ,, possible patterns of response. But, surprisingly, the genes showed only patterns. Already this is unexpected.
But the most interesting result is that, of the patterns, fall into eight mirror-symmetric pairs: Under some conditions, one set of genes increases in transcript abundance while a second set of genes decreases in transcript abundance. Under other of the seven perturbing conditions, the roles are reversed, and the first set of genes decreases in transcript abundance while the second set increases in transcript abundance. Welsh found eight such mirror symmetric pairs of sets of genes, suggesting at least eight dierent coordinated sets of genes, each coregulated, yet each buered from the other sets of genes.
It may be that Welsh has found the first evidence of genes lying in eight dierent green islands, buered from one another by the percolating red frozen structure. If the green islands exist, they are the paragraph structure of the genome. They are the midsize decision-taking subcircuits of the genome. For each such island, cut o from influence by other islands by the frozen red structure, has its own alternative attractors, two for this island, five for that island, seven for a third island. The total number of attractors for the entire network is then x x = . And if so, cell types are a kind of combinatorial code of the choices made by the dierent islands.
And yet more: My colleague Marc Ballivet, with a minor bit of help from me, has come up with a means to rapidly clone most or all cis sites from cells. If the thousands of cis sites can be cloned, each can be used to anity purify the trans factors binding it. Other biologists are learning how to construct small genetic circuits. By our means or others, the medicine of the twenty-first century will learn to control the activities of genes in genetic networks, hence, control tissue regeneration and dierentiation. We enter the “postgenomic” era.
I return to my candidate law and remark next that cells typically do not live alone; they live in communities of single-celled organisms or other simple multicellular organisms, or they live in tissues in highly complex multicellular organisms. Thus, any candidate law must be considered with respect to a community of autonomous agents.
Consider an ecosystem with dierent species of bacteria. Each species may secrete dierent chemical species, S, that impinge on a subset, C, of the other cell species. In Figure . I show a three-dimensional coordinate system. One axis shows the order-chaos axis for a single isolated bacterium, measured by Derrida curve criteria, with order on the left, near the origin, and chaos on the right. The remaining axes show C and S.
If a given cell is at the phase transition between order and chaos, and additional molecular inputs, S per cell, come from C dierent types of cells, the total connectivity in the cell is raised from KN to KN + CS. The results will typically drive that cell into the chaotic regime. Indeed, the entire community will be driven into the chaotic regime.
Hence, in the coordinate system of Figure ., Igor Yakushin at Bios Group has shown that a hyperbolic surface, as shown, separates the ordered regime from the chaotic regime. Cells can buer themselves from chemical perturbations from other species by retreating deeper into the ordered regime. This can be accomplished by increasing the number of canalyzing inputs per gene. And indeed, as described above, individual eukaryotic cells do appear to lie well within the ordered regime, perhaps as buering for the fact that such cells, like yeast, live in microbial communities or, like human cells, live in tissues where each cell is bombarded with chemical signals from other cells in the same body.
It is a plausible conjecture that communities of cells, and tissues, come to lie on the phase transition surface between order and chaos. The hypothesis is readily tested. If so, perturbations of a single gene in one type of cell should trigger a power law distribution of avalanches of changes of gene activities that spreads from the perturbed gene to other genes in that cell and species, and to cells of other species. Further, the Derrida curve of the total community should be at the phase transition.
A final numerical test is under way. The aim of the numerical test is to check whether cells and communities that lie at the phase transition would, in fact, make the maximum number of reliable discriminations and act without trembling hands.
Cells that are yammering at one another probably never reach their attractors. Pick a subset, M, of the states in each cell in the community as its “action” states. Now release the community, numerically, somewhere on the edge-of-chaos surface. Over a long period of time, the M action states will be encountered in some order, yielding some probability distribution of transitions between pairs of the M states, as each cell is perturbed by S chemical signals from C other cell types. The transitions among the M action states of each cell can be written in a matrix showing the transition probabilities between any pair of the M states. From this it is possible to calculate the mutual information, MI, between pairs of the M action states.
MI is H(A) + H(B) - H(AB). Here H(A) is the entropy of A, H(B) the entropy of B, and H (AB) is the joint entropy of A and B. If A and B are occurring randomly with respect to one another, then H(AB) equals the sum of H(A) + H(B), so MI is . If either A or B is unchanging, MI is again . But if A and B are changing in correlated ways, MI is positive. Hence, we can ask what value of M maximizes the mutual information among the M states, how is that related to cell and community position on the edge-of-chaos phase transition in Figure ., and how well does the mutual information among the M action states correlate with the mutual information in the patterns of CS input signals arriving at each cell type? More broadly, can selection maximize both M and that mutual information correlation and, if so, for what value of M and where on or o the phase transition surface in Figure .?
I do not know the answers but hope the optimal point lies on the phase transition surface, for such selected mutual information correlation would begin to show that such communities of cells with such regulatory networks can indeed make the maximum number of reliable discriminations and act on them without trembling hands to make a complex living in a complex world.
Candidate Law 2: Community Assembly Reaches a Self-Organized Critical State
First, a foray into self-organized criticality, a concept that will drive the rest of this chapter.
Per Bak and his colleagues in published a paper concerned with sand piles. One is to take a large, flat table, supply lots of sand, and gently let sand fall from on high onto the table. As the sand piles up, it eventually reaches the rest angle for sand and also extends to the boundaries of the table. You keep adding sand slowly. Sand-slide avalanches begin to form and sand drops to the floor. Measure the size distribution of the avalanches and a power law distribution is revealed, with many small avalanches and few large avalanches (Figure .).
Power law distributions can, in fact, arise in many ways. One of those ways is at a phase transition, for example, in a ferromagnet at the phase transition temperature. Above the phase transition temperature, the magnetic spins line up randomly with one another and keep flipping. Below the phase transition temperature, the ferromagnet tends to line up with magnetic spins all pointing the same way, say, north pole upward, hence, the material is magnetized. At the phase transition temperature, something magic and “universal” occur: clusters of spins oriented the same way arise, and the clusters have a power law distribution of sizes. The power law distribution implies that there is no preferred size scale in the system. If there were a preferred size scale, clusters would be distributed exponentially in size, setting a size scale at which clusters at that size were half as likely as tiny clusters of spins.
So too for the sand pile. There is no preferred size scale revealed by the power law distribution of sand slide avalanche sizes. The big dierence is that clever physicists tuned the temperature of the ferromagnet to the critical phase transition temperature. Per and company tuned nothing, they merely let sand drop randomly and gently onto the sand pile, and the sand pile tuned itself to criticality, hence the name: self-organized criticality.
Many of us have fallen in love with these results. Many are critical as well. I am on the pro side of the debate. I know the theory does not apply to real sand, with its rough edges, and works well with short-grain Swedish rice, but I love it anyway. Newton’s law of universal gravitation does not work for bits of paper and cannon balls falling from the Tower of Pisa  wind resistance, you see. The bits of paper do not hit the ground at the same time as do the cannon balls. Most theories have ceterus paribus clauses. But I suspect Per and friends have found a deep truth about how nonequilibrium systems self-organize.
The remaining three of the four candidate laws apply versions of this idea. Even law above is a version. Selection tunes communities of cells to the phase transition between order and chaos where a power law distribution of damage avalanches on all scales propagate across the system.
The claims coming next are not my own work, but derive from fine eorts by ecologists Stuart Pimm, Mack Post, and more recently, Bruce Sawhill and Tim Keitt, making use of work by physicist Scott Kirkpatrick and his colleagues.
First, the early work of Stuart Pimm and Mack Post, done in the late s: They were concerned with community assembly of organisms into a local ecosystem (Figure .). They ignored long-term coevolution and made use of the Lotka-Volterra equations. These equations basically say, for any species, what other species it eats, how readily it turns the eaten prey into an extra copy of itself, and how fast it reproduces on its own without eating. Plants, herbivores, and carnivores are readily represented.
Stuart and Mack did a surprising study with an astonishing and still poorly understood result. They made a pile of hypothetical critters in a computer, each governed by some plausible Lotka-Volterra equation whose parameters were drawn at random from some distribution. Then, with fond hopes, Stuart and Mack randomly chose species, one after another and tossed them into the computational equivalent of east Kansas. (“Kansas is a place for people who like subtlety,” my friend Wes Jackson once told a group of us visiting his Land Institute in Kansas in January. We observed subtly dierent shades of brown grass, trees, dirt, dust, hawks, mice, and agreed.)
What Stuart and Mack found was this: When the first few species were tossed into east Kansas in silico, they tested whether these few could coexist by running the corresponding Lotka-Volterra equations of all the species simultaneously to see if the hypothetical species all sustained abundances above zero. For example, the model community might go to a steady-state ratio of four species or might enter a limit cycle oscillation or some chaotic dynamics with a strange attractor that remains above zero for all species.
Dandy, the mock community was stable. They kept adding randomly chosen species. At first, it was easy to add new species, but it became progressively harder until no more species could be added. The deep mystery is, why? It is not a lack of food or energy. Furthermore, on the way to assembling the community, Stuart and Mack began to notice that as the community filled up, addition of one species could make one or more other species go locally extinct. They began to find evidence of power law distributions of such extinction events.
Why? No one knows for sure, and Stuart has some wonderful ideas discussed in his fine book, The Balance of Nature. But I am going to move on to the recent ideas of Bruce Sawhill and Tim Keitt, which build on the work of physicist Scott Kirkpatrick. Scott is famous for coinventing the Sherrington-Kirkpatrick spin-glass model and hangs out at IBM being smart. Not long ago, he took up what is called the “Ksat” problem.
Here is the Ksat problem. Consider some logical formula, or expression, as in our Boolean net. Any Boolean expression can be cast in “normal disjunctive form”; an example is (A or A) and (A or A) and (not A or not A). In such an expression the variables between brackets constitute a “clause,” so this logical expression has three clauses. The clauses are linked by “and.” Thus, for the entire statement to be true, all three clauses must be true. Within each clause, variables are linked by the logical “or,” symbolized with v. (A v A) is true if A is true, if A is true, or if both A and A are true.
Now we can ask if the above expression can be satisfied by some assignment of true or false, or , to the four variables, A, A, A, and A. The answer is yes since if A = true and A = true and A = false, then all clauses are satisfied. On the other hand, consider (A) and (not A). There is no assignment of true or false to A that makes both clauses true since they contradict one another. More generally, an expression in normal disjunctive form, with K variables (A v A v   .   .   .    Ak) in each clause, a total of C clauses and a total of V variables A, A,   .   .   .    Av may or may not be satisfiable.
The wonderful result that Scott and friends showed is a phase transition from Ksat expressions that are almost certainly satisfiable to Ksat expressions that are almost certainly not satisfiable (Figure .).
In Figure ., the horizontal axis is labeled C/V. Thus, the x-axis shows the ratio of clauses to variables, hence, on average, how many clauses each variable is in. Obviously, as each variable is in more and more of the C clauses, with randomly assigned truth requirements, Vi versus not-Vi, the chance that the set of clauses can be jointly satisfied gets harder. On the other hand, as K goes up, there are more variables per clause, any one of which, if satisfied, satisfies the clause since the variables within a clause are joined by “or.” Thus, as K goes up, the problem gets easier.
Remarkably, there is a phase transition on the C/V axis at ln x (K) or . x K. As shown in Figure ., for C/V values less than this phase transition value, the expression is almost certainly satisfiable. As C/V passes the . x K critical value, the probability that the expression can be satisfied plunges to near zero.
Now, the idea that Bruce and Tim had was that building a community with random critters having random food and niche requirements is like the Ksat problem. They consider S species. Each species’ niche includes some of the S species that it eats and some that eat or kill it. Thus, species S must eat S or S or S to survive, but can survive on its own only in the absence of S, which poisons the chloroplasts that allow S to be an autotroph. In disjunctive form, the requirements for species S to survive are (S v S v S) and (not S).
Bruce and Tim did numerical experiments for dierent values of S and K and C where again K is the number of alternative species any given species could eat. (S v S v S) corresponds to K = .They found the same phase transition. As more and more species are added, there are more potential interactions among the species since the pairwise possibilities increase as the square of the total species diversity. As this occurs, each species appears in an increasing number of clauses, so as C/V increases, at some point the satisfiability of the Ksat system went from easy to hard. It became hard, then impossible, to add new species. The community filled up because the Ksat problem went from easy to impossible.
I find this line of thinking rather interesting. Given rather general assumptions on the probability per pair of species of who eats or kills what, assigned more or less randomly, then as the number of species, hence pairs of species increase, such communities can fill up in the presence of persistent attempts at invasion. Bruce and Tim may have found the underlying reason for Stuart and Mack’s earlier results. Moreover, Bruce and Tim have found reasonable numerical evidence for small and large avalanches of local extinction events upon entry of new species while the community was filling up.
Meanwhile, experimental work assembling communities of real organisms shows much the same results. Communities tend to fill up and do exhibit small and large local extinction events.
Candidate Law 3: Coevolutionary Tuning of Fitness Landscapes and Organisms to a Self-Organized Critical State
Begin with a well-stated claim of Darwin: gradualism. Species evolve, argued Darwin, by the gradual accumulation of useful variations that were gradually sifted by natural selection.
Darwin is correct about contemporary life, and presumably about ancient life, based on the record. In fact, for current life forms, seven decades of hard work by geneticists, working with organisms as disparate as mouse, fruit fly, maize, yeast, and many other eukaryotes, demonstrates conclusively that most mutations are of minor eect. For example, the fruit fly, Drosophila melanogaster, upon which I worked for twelve years, has the abdominal bristles alluded to above. A modest number of mutants exist that slightly increase or slightly decrease the number of abdominal bristles. The flies don’t seem to mind, at least in the odd security of my and other biologists’ laboratories.
More rarely, there are mutants of rather dramatic eect, none more so than the famous homeotic mutants of Drosophila, which fascinated me and many others. Here a single mutant can change an antenna into a leg or an eye to a wing or a head to the genitalia. These survive perfectly well in the laboratory as well, but one expects would not fare well in the real world.
Therefore, most of the heritable variation cast up by mutation is of minor eect, and gradual variation is persistent grist for the selection mill. Somehow, current organisms have contrived themselves to be such that most mutations are of minor eect. But is it necessarily the case that all complex systems have the property that most mutations are of minor eect? And if not, where does the gradualism of Darwinian selection come from?
Importantly, it is easy to create systems that are not readily adaptable by mutation and selection. What follows is not quite a theorem (and was discussed in At Home in the Universe), but it will do. Many of the readers of this book are competent programmers. Consider a typical program, say written in C, Java, or some other language. Perhaps it computes something as simple as the square roots of the first two million integers. Perhaps it simulates an ecosystem. Whatever that program does, imagine trying to evolve it by making random mutations in the code.
We all know what would happen. Most mutations of a computer program are of major eect. The program won’t compile. If it compiles, it generates some vast stream of symbolic nonsense or goes into an undetected infinite loop and “hangs.”
And we can make the matter substantially worse by eliminating redundancy in the code. Any computer program can be written as a sequence of binary, and , symbols, where that sequence represents the input data to the program and the program itself.
Now, a well-known area of computer science considers how redundant a program is; for example, a simple redundancy would duplicate each binary symbol. Computer scientists talk of eliminating the redundancy of a computer code to achieve the most compressed possible code. A fascinating theorem states that there is no proof that a given computer program is maximally compressed, but that if it is maximally compressed, it is in a rigorous sense not detectably dierent from a random sequence of binary digits.
Figure . shows a four-dimensional Boolean hypercube with all two to the fourth, or sixteen, possible binary sequences of length four, ranging from () to (). Each sequence is on one of the sixteen vertices of the hypercube and connected to four -mutant neighbors achieved by changing a single binary symbol among the four from to or from to . Imagine that the minimal program we were considering were a -long binary sequence. Then that minimal program could be represented as a single vertex on the -dimensional Boolean hypercube with to the th = to the th dierent sequences, hence vertices. A remarkable theorem due to Gregory Chaiten shows that if there is a minimal program with binary symbols, there is at most about one such minimal -bit symbol sequences. In short, only a single vertex on the -dimensional Boolean hypercube corresponds to the desired minimal program. Now consider each of the other -bit sequences on the hypercube as a computer program. (Consider a gedankenexperiment, a thought experiment, for I have not carried out the actual computer experiment, and no one has been able to prove my following plausible, probably true, conjecture.) Run each binary sequence as the input data and program on our universal computer. Measure in some sense how far away the printout of that program is from the correct program for some finite chunk of the correct program’s printout. If one started with the correct program, my bet is that since all redundancy has been removed, any single mutation to the code will randomize what the code does. Distant -bit binary strings will, on average, be as good or bad an approximation of the correct program as its -mutant variants.
If one thinks of the measure of how close the output of a binary string program is to the correct program as the “fitness” of that trial binary string, then the fitness can be thought of as a height. The distribution of heights over the -dimensional Boolean hypercube therefore creates a fitness landscape. In fact, my conjecture amounts to stating that the resulting fitness landscape is completely random. Neighboring points have fitnesses that have no correlation.
Assume my conjecture is true. There are theorems stating that there is no way to hill climb to the global peak, the single correct program, by accumulating mutants that gradually improve the program. Indeed, the only way to find the single good program is, eectively, to search the entire -dimensional Boolean hypercube. You’d have to look at most of the vertices on that cube to find the working program. The problem is, as they say, NP hard, meaning the size of the problem scales exponentially in the length of the binary symbol sequence. But a single example makes a general point: Not all complex systems can be assembled by an evolutionary process!
It follows that only some complex systems can be assembled by an evolutionary process. And it turns out that an evolutionary process based on mutation, recombination, and selection, the genetic search mechanisms of current life, does very well on a special kind of fitness landscape, where the high peaks tend to cluster near one another and the sides of the peaks are reasonably smooth, rather like the high Alps.
Then, as I first asked in chapter , where do such correlated fitness landscapes come from? More generally, I recall the no-free-lunch theorem of Bill Macready and David Wolpert. Macready and Wolpert wondered whether, averaged over all possible fitness landscapes, some search algorithms, such as mutation and selection, on average outperform all other search algorithms, such as random search on the landscape or hill descending or picking birthdays, taking their square, and jumping that distance in a randomly chosen direction.
The no-free-lunch theorem proves that, averaged over all landscapes, no search algorithm outperforms any other. Well, my goodness! On average, random search and hill descending do just as well as hill climbing in finding peaks of high fitness. And here we organisms are, stuck using mutation, recombination, and selection. Yet organisms and ecosystems seem to be pretty complex. Once again, where did the “good” landscapes come from, the ones that Darwinian gradualism works so well in searching?
In chapter I was led by the above to define natural games as ways of making a living. Naturally, ways of making a living have evolved as organisms have evolved. So rather easily one gets to the conclusion that the winning games are the games that winners play.
And, as noted in chapter , those ways of making a living that set problems that are well searched out by the search mechanisms of organisms  mutation, recombination, and selection  will be well searched out. Many sibling species will arise and lineages will branch. There will be many species making livings and many cases of livings being made that are well searched out by the search mechanisms of organisms.
In short, there must be a self-consistent coconstruction of a biosphere in which organisms, ways of making a living, and search mechanisms jointly and self-consistently come into existence. Organisms are not solving arbitrary problems. We are solving the kinds of problems we can solve given our solution procedures. How could it be otherwise?
So, somehow  and we will have to seek plausible mechanisms  organisms are tuning the statistical structure of the fitness landscapes they are searching in evolution. But the problem is very much more complex than merely searching a fixed fitness landscape. Fitness landscapes are not fixed. If the abiotic environment changes, the fitness landscape of organisms changes, buckles, and deforms.
Worse, organisms coevolve. My favorite example remains the frog and the fly. If the frog develops a sticky tongue, the fitness of the fly is altered. But so too is the fitness landscape of the fly, what it should do next. It should develop slippery feet, or sticky stu dissolver or a better sense of smell to smell sticky stu before the frog gets too close or   .   .   .
So, due to coevolution, the fitness landscape of each species heaves and deforms as other species make their adaptive moves.
A Sojourn to Coevolution in the NK Model
These results were presented in At Home in the Universe but are needed here. Since they are publicly available, I will be brief.
The NK model is a simple toy world in which an organism has N genes. Each gene comes in two “alleles,” or versions, or . Each allele of each gene makes a contribution to the fitness of the organism that depends on the allele of that gene and upon the alleles of K other genes. In genetics, these K other genes are called “epistatic” inputs to the fitness contribution of a given gene. The to the N combinations of alleles of the N genes are therefore located on the vertices of the N-dimensional hypercube, like Figure .. The fitness of each type of organism, or vertex, is written on that vertex and can be thought of as a height. Hence, the NK model creates a fitness landscape over the N-dimensional Boolean hypercube. To keep matters simple, I assume all critters have a single chromosome, that is, are haploids. When they are not feeling sexy, bacteria will do as an example.
Having chosen N and K, say N = and K = , the rest is done at random in the hopes that generic features of N and K will show up in the resulting statistical structure of the fitness landscape (Figure .a–c). In one limiting case, the K inputs to each of the N genes are chosen at random from among the N. Each gene has two alleles, and . The fitness contribution of that gene is aected by which of its alleles occurs and by which of the or alleles of K other epistatic input genes occurs. Thus, each gene’s fitness contribution is aected by K + genes.
To study the generic features of such systems, I assign, once and for all, a random “fitness contribution” to each of the to the (K + ) combinations of allele states aecting each of the N genes. The fitness contribution is drawn from the uniform interval between . and .. Thus, instead of the Boolean functions described above showing when genes turn on and o, here I obtain a column vector for each of the to the (K + ) allele states aecting a given gene, and in each position is a random decimal. Once this is done for each of the N genes, it remains to define the fitness of an organism with a specific allele at each of the N genes. I define this as the average of the fitness contributions of the N genes. The results yield a fitness landscape over the N-dimensional hypercube (Figure .c).
I will briefly summarize results for the structure of NK landscapes. When K = , each of the N sites is independent. There is an optimal allele at each site and hence a globally optimal genotype. Any other genotype is suboptimal, but can steadily climb to the peak by flipping any gene in a less favorable allele to the opposite, more favorable state, or . So the landscape is like Fujiyama, single peaked with smooth sides.
When K is the maximum value, N - , as in Figure .a–c, then each gene influences the fitness contribution of every gene. This is the totally interconnected system. Since fitness values are assigned at random for the to the (K + ), or to the N input configurations when K = N - , it is easy to show that the resulting fitness landscape is fully random.
A main feature of random landscapes is that there are nearly exponentially many local peaks, indeed the number of local peaks is to N/(N + ). For N = , there are local peaks on the landscape. Finding the global peak by hill climbing is improbable, and the system becomes trapped on a local peak. Other features include the lengths of walks via fitter neighbors to nearby peaks, which scales as the logarithm of N, and the way directions uphill dwindle on walks uphill. At each step uphill, the fraction of directions uphill is cut in half, yielding exponential slowing in the rate of finding fitter variants, hence, rather general laws about the rate of improvement slowing exponentially that we will discuss in the next chapter on “learning curves” in economics.
Now, on to coevolution and the evolution of the structure of fitness landscapes. Figure . shows a frog and fly, each characterized by an NK landscape, coupled together. Each of the N genes in the frog receives inputs from K genes in the frog and C genes in the fly, and vice versa. Thus, the sticky tongue of the frog aects the fitness of the fly via the presence or absence in the fly of slippery feet, sticky stu dissolver, or a strong sense of smell for sticky frog tongues. To accommodate the C couplings, each gene in the frog looks at K + C inputs and has its table of random fitness contributions augmented with new random decimals. So too for the fly feeling the eects of the frog.
Now, when the frog population moves by mutation and selection uphill on the frog landscape, those moves distort the fly’s landscape, and vice versa. Coevolution is a game of coupled deforming landscapes. Figure .a–c show coevolution in model ecosystems with four, eight, and sixteen species. Due to landscape deformations as species coevolve, an adaptive move by one species can cause the fitness of other species to decrease. In general, such coevolving systems can behave in two regimes, an ordered regime and a chaotic regime, separated by a phase transition.
In Figure .a the four-species ecosystem eventually settles down to a state where fitnesses stop changing. This corresponds to an ordered regime or unchanging evolutionary stable state in which each species has evolved to a local peak on its fitness landscape that is consistent with the peaks occupied by its ecosystem neighbors. Once attained, each species is better o not changing so long as its neighbors do not change. By contrast, in the eight- and sixteen-species ecosystems, Figures .b and c, fitnesses continue to jostle up and down as species evolve in a chaotic regime, each species chasing the adaptive peaks on its landscape that retreat  due to adaptive moves of other species  faster than each species can attain the peaks on its own landscape.
A major point of the coevolving NK landscape model is that the creatures can tune the structure of their fitness landscapes, each for its own selfish advantage. Yet, as if by an invisible hand, the tuned landscape structure works for the average benefit of all. This toy model is, to date, the only example I know in which creatures tune the structure of their fitness landscapes such that all evolve in problem spaces where, in some sense, they can search those spaces well self-consistently with their search mechanisms.
Here is how the toy model works. Each species is represented by a single individual. Hence, the species is assumed to be isogenic, except during the rapid evolution to fitter genotypes that happens as a fitter mutant of a species steps from one point to another point on the landscape. Very rapidly, it outreproduces its less-fit cousins. Hence, in this limit, the entire species can be said to hop between points on the landscape.
At each move of the computer program, any of four events may happen. A given species is chosen at random. First, it may do nothing. Second, it may change its genotype, and if the result is that it is fitter in interacting with its ecosystem neighbors, that innovation will be accepted. The creature has evolved on its landscape and probably deformed the landscapes of its neighbors. Third, the critter can change the ruggedness of its landscape by increasing K or decreasing K. Landscapes become more rugged and multipeaked as K increases. The move altering K is accepted only if that move makes the current genotype of the creature fitter. Hence, altering the ruggedness of the fitness landscape must pay o for the creature immediately and is accepted selfishly. The fourth thing that can happen is rather mean. A random other creature, say, Godzilla, is chosen to attempt to invade the current species niche. A copy of Godzilla, Godzilla’, connects to the first species’ ecosystem neighbors and has a go. If Godzilla’ is fitter when coupled to the first species’ econeighbors than that species, that species goes extinct in its niche and is replaced by Godzilla’.
By the fourth mechanism, if Godzilla’ happens to have a beneficial landscape ruggedness due to its K value, that good landscape ruggedness has now replicated from the initial Godzilla to its copy. So good landscape ruggedness can spread, by natural selection, through the model ecosystem, hence, landscape ruggedness can evolve.
The results are shown in Figure .. Indeed, landscape ruggedness does evolve to an intermediate ruggedness. During this evolution, the mean interval between extinction events increases dramatically, hence, the mean number of extinction events decreases. In this sense, all the creatures that remain become fitter due to the coevolutionary tuning of landscape ruggedness. In addition, when Godzilla’ replaces the hapless species that now goes extinct, its econeighbors find themselves interacting with Godzilla’ itself. They may not be as fit interacting with Godzilla’ as with the first species, hence, they too may be invaded and driven extinct in turn.
In short, avalanches of extinction events can propagate. Figure . shows that the distribution is a power law, with many small and few large extinction events. Moreover, once a new species comes into existence, say, Godzilla’, it may not fare well in its new niche, hence, may go extinct soon. But if it lasts in its niche, it may be well adapted, hence, resistant to being driven extinct. The results (Figure .a) are a power law distribution of species lifetimes.
Thus, this model shows an invisible hand in which natural selection, acting on individuals only, tunes landscape ruggedness. All players are, on average, fitter in the sense of surviving as species for much longer periods, yet the ecosystem appears self-organized critical with a power law distribution of extinction events. Species lifetime distributions are also power laws.
Does this model apply to the real world? There is now considerable evidence that over the past million years the size distribution of extinction events in the record, in terms of the number of species going extinct per -million-year period, is best understood as a power law, with many small and few large extinction events, (Figure .). Furthermore, the lifetime distribution of species, as well as genera and families, is, indeed, a power law (Figure .a,b).
I have discussed my own model primarily to focus on the fact that coevolution by self-natural selection alone acting on individuals alone can tune landscape ruggedness so those landscapes are self-consistently well searched by the creatures searching them and their search mechanisms. We can, and presumably do, self-consistently coconstruct ourselves, our niches (and hence problem spaces), and our search mechanisms such that, on average, we propagate ourselves and our descendants. It has worked for . billion years. Were our fitness landscapes such that we could not search them, we would not be here. We coconstruct our ways of making a living and search out better ways of making a living while we jiggle one another.
The NK model is but one crude model of coevolving organisms and their coupled deforming landscapes. More generally, each organism has traits that are aected by many genes, the polygeny discussed above, and each gene aects many traits, the pleiotropy alluded to above. It is interesting to note that were organisms to evolve to a position below but near the biological reality that is the proper analogue of the Ksat phase transition, such a location might well achieve the gradualism and capacity to persistently evolve that Darwin noted and that we observe. Both the gradualism and capacity to evolve are related to the number of alternative assignments of true or false to the V variables that satisfy the Ksat normal disjunctive form. If there are connected pathways from one such assignment via -Hamming-mutant neighboring assignments that all satisfy the normal disjunctive form, then adaptive walks via alternatives genotypes are available, all of which roughly generate the same organism. Gradualism is achieved. Polygeny and pleiotropy tune landscape ruggedness and deformability, which tune coevolutionary dynamics, perhaps to a self-organized critical state of an ecosystem.
There are, in short, dimly understood laws that allow the coevolutionary construction of accumulating complexity. And it appears that such coevolution typically is self-organized critical. The NK coevolutionary model is not the only example of a model exhibiting self-organized critical behavior of model ecosystems. Bak and colleagues, Ricard Solé, and others have created elegant models aiming in the same direction. In particular, Solé’s model comes closest to fitting the actual slopes of the observed power laws, which are -.
Candidate Law 4: Expanding the Adjacent Possible in a Self-Organized Critical Way
How does the biosphere, collectively, broach and persistently invade the adjacent possible at the chemical, morphological, and behavioral levels?
I suspect there is a general law and mentioned it in the last section of the previous chapter. It is my hoped-for fourth law of thermodynamics for self-constructing biospheres. We enter the adjacent possible, hence expand the workspace of our biosphere, on average, as fast as we can.
Recall the Noah’s Vessel experiment, with two of every species ground up in a blender, breaking all cell membranes, comingling the trillion or so proteins of the hundred million species with the thousands of small molecule metabolites. A supracritical explosion of chemical diversity would presumably ensue. As I noted, life has learned to avoid that fate. Cells are subcritical. Were they not, then any new chemical that chanced to enter the cells of Fredricka the fern would unleash a cascade of synthesis of novel molecular species, some of which would presumably kill poor Fredricka. Best defense? Stay subcritical. Why mess with that mess?
But recall that a mixed microbial community should be able to be driven to the subcritical-supracritical boundary by increasing the diversity of microbial species present and/or hitting the community with a sucient diversity of novel small molecule species. My argument follows that if the community is supracritical, the novel cascading molecular species will kill o some of the microbial species, thereby lowering the community toward the subcritical regime. On the other hand, mutation and immigration should drive the community toward the supracritical regime. Do mixed microbial communities hover on the subcritical-supracritical boundary? We have seen other reasons that bound a community’s complexity, including Ksat problems noted in this chapter. So a better question is: Can microbial communities be driven supracritical? And if so, are they often near that boundary?
Of course, I do not know, but the hypothesis is testable. Increase the diversity of species and test for the diversity of synthesized small molecules, say, by gas chromatography. A colleague and I once devised such an experiment with mixtures of increasingly diverse moss species, planning to measure the molecular diversity of gas species evolved as a function of community diversity and the diversity in gas species introduced to the community. We went skiing instead. I still like the lines of the experiment. It could be carried out directly with mixed microbial communities as well.
As noted in the previous chapter, there must be some interplay in the entry into the adjacent possible that gates the exploration by the capacity of natural selection to trim away the losers. I described the Manfred Eigen–Peter Schuster error catastrophe. If the mutation rate in a population of viruses is low, by successive rare successful mutations the population climbs steadily uphill, then becomes trapped on or in the near vicinity of a local peak.
But let the mutation rate be increased. The population on the peak is deformed by the rapid accumulation of mutations and diuses away from the peak into the lowlands of poor fitness. Tuning the mutation rate compared to the selection advantage of the fitness peak compared to nearby values on the fitness landscape tunes this error catastrophe. Above a critical ratio of the selective advantage at the peak to the mutation rate, the population remains near the peak. If the mutation rate is slightly higher, the population diuses into the high-dimensional hinterlands, lost adrift in sequence space.
The error catastrophe is, of course, rather general. Eigen and Schuster consider a fixed high-dimensional sequence space, like our N-dimensional Boolean hypercube, which can be regarded as a sequence space in which molecules have only two “nucleotides” and , C and G.
But what about an ever enlarging space of possibilities, expanding into an ever larger adjacent possible? Here too the rate of exploration of novel possibilities must be gradual enough that natural selection can weed out the losers. If not, the biosphere as a whole would diuse into new ways of making a living so rapidly that selection would not be able to control the exploration, and we would soon falter.
So a general balance must be struck. We broach the adjacent possible by those exaptations that are not, I hold, finitely describable beforehand and do so at a rate that manages to work. We gate our entry into the adjacent possible.
Globally, for the entire biosphere, this suggests that we enter the adjacent possible about as fast as we can get away with it. On average, the global diversity of the biosphere has increased secularly. Indeed, it would be fascinating to know what has happened to microbial diversity in . billion years. There are bacteria eating rocks down there two miles below the surface, in hot thermal vents, in the cold of Antarctic frozen tundra and lake edges, all over the place.
I do not know the form of the law that governs this exploration. Perhaps it is locally self-organized critical in communities, multiplied by the number of eectively independent local communities in the biosphere. But I can make out a law in which the adjacent possible is invaded, such that diversity and coconstructed, coevolved complexity accumulate, on average, as fast as it can.
I can sense a fourth law of thermodynamics for self-constructing systems of autonomous agents. Biospheres enlarge their workspace, the diversity of what can happen next, the actual and adjacent possible, on average, as fast as they can. Clues include the fact, noted above, that for the adjacent possible of a N-dimensional phase space to increase as the biosphere’s trajectory travels among microstates, a secular increase in the symmetry splittings of microstate volumes must occur, such that dierent subvolumes go to dierent adjacent possible microstates. Eventually, such subvolumes hit the Heisenberg uncertainty limit. As I noted, organisms do touch that limit all over the place in the subtle distinctions that we make, turning genes on and o, smell sensors on and o, and eyes on and o, this way and that.
The whole of this chapter suggests that autonomous agents coevolve to be as capable as possible of making the most diverse discriminations and actions, take advantage of the most unexpected exaptations, coevolve as readily as possible to coconstruct the blossoming diversity that is, and remains, Darwin’s “tangled bank.” I sense a fourth law in which the workspace of the biosphere expands, on average, as fast as it can in this coconstructing biosphere.
A fourth law for any biosphere? I hope so.









Chapter 7
The Nonergodic Universe:
The Possibility of New Laws
rom a biosphere and its mysteries, this investigation now steps gingerly toward the cosmos. Caveat lector: I am not a physicist.
Our now familiar liter of gas particles at room temperature comes to equilibrium rapidly, certainly on the order of hours or days. “Equilibrium” means, roughly, that the macroscopic properties of the system, such as temperature and pressure, have stopped changing, except for small “square root N” fluctuations away from equilibrium that soon dissipate back toward equilibrium. As we have noted, thanks to the ergodic hypothesis, the gas system ultimately visits each macrostate at a number of times proportional to the number of microstates in that macrostate. For equilibrium with respect to all macroscopic properties to have been attained, it is not necessary that all microstates have been sampled, of course, but that the statistical distribution of microstates approaches the equilibrium distribution.
Physicist Richard Feynman noted that equilibrium is when “all the fast things have happened, and the slow ones have not.” His dictum suggests, accurately, that the notion of equilibrium is not quite so self-evident.
The aim of the current chapter is to explore the profound failure, on the scale of a suciently large closed thermodynamic system and, a fortiori, the open system of the biosphere, to come close to equilibrium on vastly long time scales with respect to the lifetime of the universe. The main facts are known to physicists, of course. The universe is vastly nonergodic above modest levels of molecular complexity, let alone with respect to gross motions of parts of the universe with respect to one another.
Given that the universe is actually nonergodic, nonrepeating, and in macroscopically important ways, over a time scale vastly longer than the lifetime of the universe, we are entitled to broach the question of whether there might be general laws governing some or all aspects of this nonergodic behavior. No one knows, but I will raise a possibility that has a chance to be true for a biosphere. There is little harm in wondering if it might hint at a fourth law of thermodynamics for self-constructing systems such as biospheres.
The Actual and the Adjacent Possible
I now want to reintroduce a central concept of alarming simplicity. Consider all the kinds of organic molecules on, within, or in the vicinity of the Earth, say, out to twice the radius of the moon. Call that set of organic molecules the “actual.”
Now recall the concept of a reaction graph, a bipartite graph with nodes representing chemical species and lines called hyperedges leading from each set of substrates to a box and from the box to the product species of that particular reaction. Recall that we utilized arrows on the lines to distinguish substrates from products, but that the direction of flow of the reaction depended upon the displacement of the substrates and products of that reaction from the equilibrium concentrations for that reaction. That equilibrium ratio corresponds to the concentrations of substrates versus products, where the net rate of production of products from substrates equals the net rate of production of substrates from products.
The reaction graph is just the set of all the molecular species and all the hyperedges representing all the reactions among the species. Thus, consider the reaction graph among the molecular species in the actual, where at present presumably hundreds of trillions of molecular species exist.
Now consider the adjacent possible of the reaction graph of the actual. The adjacent possible consists of all those molecular species that are not members of the actual, but are one reaction step away from the actual. That is, the adjacent possible comprises just those molecular species that are not present in the vicinity of the Earth out to twice the radius to the moon, but can be synthesized from the actual molecular species in a single reaction step from substrates in the actual to products in the adjacent possible.
Note that the adjacent possible is indefinitely expandable. Once members have been realized in the current adjacent possible, a new adjacent possible, accessible from the enlarged actual that includes the novel molecules from the former adjacent possible, becomes available.
Note that the biosphere has been expanding, on average, into the adjacent possible for . billion years. Presumably, when life started there was a modest variety of a few tens to a few hundreds of organic molecular species  methane, hydrogen, cyanide, the familiar list. If there are now a standing diversity of million species and each had a hundred thousand genes and genes in each species were at least slightly dierent from genes in all other species, then, not counting molecular diversity within species, the number of genes is trillion. Given RNA, protein, polysaccharides, lipids, and other organic molecular species, the diversity is likely to be hundreds of trillions or more.
Something has obviously happened in the past . billion years. The biosphere has expanded, indeed, more or less persistently exploded, into the ever-expanding adjacent possible. The secular diversity of organic molecular species has increased, on average, over the past . billion years.
It is more than slightly interesting that this fact is clearly true, that it is rarely remarked upon, and that we have no particular theory for this expansion. Indeed, I note for future reference that the standing diversity of species in the biosphere has, on average, with noticeable crashes in large extinction events, increased over the past . billion years. And among us mere humans, the diversity of ways of making a living has increased dramatically over the past million years, the past hundred thousand years, and even over the past thousand years. If you wanted a rabbit for dinner thirty thousand years ago, you bloody well went out and caught a rabbit. Now most of us can go buy a rabbit dinner. Something again has happened. At the level of species and ways of making a living in the “econosphere,” the actual has expanded into a persistent adjacent possible.
We are all parts of the universe. So, in our little hunk of the universe, with the sun shining beatifically upon us, rather remarkable goings on have occurred. Indeed, the biosphere may be one of the most complex things in the universe.
Now a second simple point. The molecular species of the actual exist. Those in the adjacent possible do not exist  at least within the volume of the universe we are talking about, which we can expand in a moment to be the actual molecular diversity of the entire universe, not just our tiny patch of it.
The chemical potential of a single reaction with a single set of substrates and no products is perfectly definable, both the enthalpy and entropy. But we hardly need that sophistication. The substrates are present in the actual, and the products are not present in the actual, but only in the adjacent possible. It follows that every such reaction couple is displaced from its equilibrium in the direction of an excess of substrates compared to its products. This displacement constitutes a chemical potential driving the reaction toward equilibrium. The simple conclusion is that there is a real chemical potential from the actual to the adjacent possible. Other things being equal, the total system “wants” to flow into the adjacent possible.
If there are to trillion organic molecules in the biosphere and each pair of organic molecules can undergo at least one two substrate–two product reaction, then the diversity of reactions is the square of the diversity of molecular species, hence about x = . Some substantial fraction of these reactions flow from the actual to the adjacent possible. The total chemical potential from the actual into the adjacent possible is hard to estimate, but it is certainly not small.
The Nonergodicity of the Universe
A further point is of fundamental importance, in my view. The universe, at levels of complexity of complex organic molecules, is vastly nonergodic.
Consider the number of possible proteins of length . That is, we consider proteins made of the familiar kinds of standard encoded amino acids and, thus, linear chains of such amino acids. Since there are choices at each of positions, the number of possible proteins of length is raised to the th power, or approximately raised to the th power, .
Now let’s consider the estimated number of particles in the known universe, which is . Thus, the maximum number of pairwise collisions that could occur in any instant, ignoring distances between particles, is that number squared, or . A fast reaction occurs in a femtosecond, or one part in seconds. Then the number of pairwise collisions and reactions that can have occurred since the estimated time of the big bang fourteen billion years ago is times the number of femtoseconds since the big bang, which is about .
The total number of reactions on a femtosecond timescale cannot be larger than , a very very big number. But is infinitesimally small compared to the number of possible proteins of length , namely, . In short, the known universe has not had time since the big bang to create all possible proteins of length once. Indeed the time required to create all possible proteins at least once is at least the ratio of possible proteins to the maximum number of reactions that can have occurred in the lifetime of the universe, or times the lifetime of the universe.
Let that sink in. It would take at least to the th times the current lifetime of the universe for the universe to manage to make all possible proteins of length at least once. Obviously, with respect to proteins of length the universe is vastly nonergodic. It cannot have equilibrated over all these possible dierent molecules.
At a level of complexity above atomic nuclei, once into the realm of complex molecules, the universe will not, cannot, come to equilibrium, on vastly long timescales compared to its historical age. Indeed, the giant cold molecular clouds in galaxies, about degrees absolute in temperature, are highly complex mixtures of molecular species, many carbonaceous, as well as the birthplace of stars. We will return in a moment to wonder about whether a galaxy, considered as a closed thermodynamic system, reaches equilibrium chemically.
What about the arbitrary restriction to a femtosecond? The fastest known timescale is the Planck timescale, one in to the rd parts of a second, or seconds. At the Planck timescale, therefore, the universe can have created at most proteins of length compared to such proteins. It would take the known universe, chunking along on the Planck timescale, times its current lifetime to make all proteins of length .
Now many biological proteins are of length , or even amino acids. Hence the number of possible proteins of length does its now familiar hyperastronomical combinatorial explosion to or . The universe can have managed to make to the of these at the Planck timescale.
Forget it. The universe is vastly nonequilibrium, vastly nonergodic at the level of complex organic molecules. A fortiori, the universe is vastly nonergodic at the level of species, languages, legal systems, and Chevrolet trucks.
It follows that, even if we consider the universe as a whole, at the levels of molecular and organizational complexity of proteins and up, the universe is kinetically trapped. It has gotten where it has gotten from wherever it started, by whatever process of flow into a persistently expanding adjacent possible, but cannot have gotten everywhere. The ergodic hypothesis fails us here on any relevant timescale.
More, the biosphere, and the universe as a whole, may well be kinetically trapped into an evermore astonishingly small region of the entire space of the possible it might have reached. Stated otherwise, the set of actual small molecules and large molecules such as proteins that do exist now is presumably an increasingly tiny subvolume of the total set that might have arisen by now in the biosphere or the universe since the big bang.
This nonergodicity is puzzling. Just what, for example, does this mean with respect to the second law stating that thermodynamically isolated chemical systems approach equilibrium and their entropy increases to a maximum? In the familiar setting of a liter of gas at room temperature, equilibrium of macroscopic features is attained rapidly, and small macroscopic fluctuations such as deviation from chemical equilibrium among a fixed set of molecular species damp out fairly rapidly. By contrast, consider a giant cold molecular cloud in a spiral galaxy with about a hundred million solar masses; ignore gravitational eects and just consider the ongoing complex chemical reactions on the complex dust particles that exist in those clouds. The specific molecular configurations that arise almost certainly include molecular species that are ever unique in the history of the universe. If we may consider unique molecular species as macroscopic features of the cloud, then these fluctuations in macroscopic properties do not damp out; rather, they form the nexus for the generation of still new, unique molecular species. A specific cloud, like our biosphere, presumably becomes kinetically trapped into a very special set of complex molecular species that happen to have formed as the cloud evolves.
In short, since the relevant timescale for the ergodic hypothesis to hold is vastly longer than the actual present history of the universe, the macroscopic features of the universe with respect to the specific sets of complex molecules that exist on this planet  in giant cold molecular clouds, and so forth  are kinetically trapped into an infinitesimal subset of those molecular species that might have come into existence in an ensemble of dierent histories of the universe.
My quip above about the nonergodicity of the universe with respect to species, languages, legal systems, and Chevrolet trucks was not a jest. We noted in the previous chapter that autonomous agents can form hierarchies  hypercycles made of replicators linked in a cycle of mutual benefit are but the simplest case. The symbiotic construction of eukaryotic cells by merging of dierent bacterial forms to create mitochondria and chloroplasts and perhaps cell nuclei are another case. So too are multicelled organisms such as starfish and ourselves. These hierarchically complex autonomous agents have, do, and will invade an adjacent possible, definable at least at the chemical level, but also on morphological levels, behavioral levels, and beyond. At all levels, the biosphere has been invading a persistent adjacent possible for . billion years.
Which leads to an odd thought: The indefinite hierarchy upward in complexity is a “sink” where the burgeoning order of the universe constructed by such agents can be “dumped.” The biosphere has been doing this dumping for . billion years.
Now here are some further odd thoughts. There is an absolute zero temperature. You cannot get colder than absolute zero, where the only motions are quantum in nature. Because there is an absolute zero, and the extraction of work via the use of heat dierences, as in the Carnot cycle, requires dumping heat from a hotter to a colder reservoir, such “work cycles” require an ever colder sink and are bound to arrest at absolute zero. So, more or less, follows the dreaded “heat death” of the universe.
On the other hand, as we have just seen, the universe is vastly nonergodic at levels of complexity of complex organic molecules upward to autonomous agents coevolving with one another and beyond. There appears to be no upper bound on this complexity  there is no obvious upper bound that limits this sink, as absolute zero limits work cycles in heat engines. So it may begin to be worth raising the question whether the universe can expand into an adjacent possible for vastly longer periods than the current lifetime of the universe, becoming evermore kinetically trapped, thus evermore specific and more refinely dierentiated.
Formalizing the Adjacent Possible
It is helpful to attempt to formalize the concept of the adjacent possible. I will do so using classical physics and the now familiar concept of a N-dimensional phase space. Recall that our particles in the liter box had three positional variables and three momenta, or velocity variables, hence, six numbers per particle. For an N particle system, this is the familiar N-dimensional phase space.
Let’s just go ahead and define the classical N-dimensional phase space for a region of real space, including the sphere centered on the Earth out to twice the orbit of the moon and containing the positions and momenta of all particles from the Earth out to twice the orbit of the moon. Physicists always assure us that this makes sense. As usual, we can break this classical N-dimensional phase space into a very large number of tiny “cells,” each also N-dimensional. At any moment, the Earth-centered N system, call it the “Earth system,” is in one of these tiny cells, or microstates. Over time, the Earth system  or a larger one including the entire solar system or our galaxy or the local cluster of galaxies  flows from microstate to microstate. By our arguments above and ignoring gravity  a grave mistake in itself  clearly our Earth system has and will flow nonergodically in this phase space for vastly long time periods.
Now, the total adjacent possible to the current microstate of our Earth system is just the total number of microstates that are adjacent to our current microstate. And that number is very large indeed, for it is on the order of N. Say there are particles in the Earth system, a very crude guess, then the total number of adjacent possible microstates is about raised to the to the st power. In short, in principle the next state of our chunk of the universe is drawn from among raised to the to the st power neighboring microstates.
Now let’s define the real adjacent possible. Each point in our current microstate in its classical N-dimensional phase space lies on a specific trajectory that eventually either stays in the current microstate or leaves the current microstate to flow to one particular adjacent microstate. Consider all the points in the current microstate, and for each, draw a red arrow to the neighboring microstate into which that point flows. Then the real adjacent possible is the collection of all neighboring microstates reached by all the red arrows leaving our current microstate.
This is a perfectly fine definition in classical physics. The real adjacent possible from the current microstate might be a single adjacent microstate into which all arrows flow. That would mean that all the points in the current microstate lie on trajectories flowing to the same adjacent microstate.
Or the real adjacent possible might be the case that arrows flow from the current microstate to two adjacent microstates. That would mean that the points in the current microstate can be partitioned into two classes, perhaps lying in distinct regions of the current microstate. One class of points flows to one of the adjacent microstates; the other class flows along trajectories to the other adjacent microstate. But the implication of the existence of two classes of points in our microstate is that its symmetry is broken  the space is broken into two regions, each of which may be compact or be intermixed and intertwined volumes. One volume flows to one adjacent possible microstate; the other flows to the other adjacent microstate.
More generally, we can define the dimensionality of the real adjacent possible with respect to any microstate in the Earth system as the number of adjacent microstates into which flow occurs from somewhere within the current microstate. The dimensionality of the adjacent possible from a given microstate might be as low as or as large as the mathematical number of adjacent microstates, raised to the raised to the st power.
Clearly, the larger the dimension of the adjacent possible, the more symmetries have been broken within the current microstate, for it is broken into at least as many volumes internally as the dimensionality of the adjacent possible from that microstate. Of course, in the case of a classical deterministic N-dimensional phase space, the Earth system flows from its current microstate to only one of the real adjacent possible microstates.
It is interesting to remark that at some point if the dimensionality of the adjacent possible of a microstate of the Earth system increases enough, the volume within a microstate corresponding to flow to a specific adjacent possible microstate will become small enough that it must run up against Heisenberg’s “uncertainty principle.” Then at the quantum level the current microstate can have an amplitude to flow to many of the adjacent possible microstates. Which way the current microstate flows is then no longer deterministic, but a matter of throws of the quantum dice.
Historical Expansion into the Adjacent Possible and Hints of a Law
Let’s now ask whether we think that the dimensionality of the adjacent possible of the Earth’s biosphere has increased or decreased in the past . billion years. Consider as a start a liter of living bacteria and a liter of their dead, homogenized molecular components. In the living system, small fluctuations in chemical concentrations within cells are turning myriad genes on and o in the complex system of genetic regulatory networks known to exist in bacteria.
An example of a small section of the genetic network is the lactose operon in E. coli. The lactose operon contains three structural genes, that is, genes encoding proteins, and two nearby small sequences of DNA, called a “promoter” and an “operator.” The promoter and operator act to regulate the transcription of the structural genes into RNA. Normally, a repressor protein synthesized from a distant gene binds to the operator, blocking transcription of the structural genes from the promoter. In the presence of lactose, however, the lactose binds to the repressor protein and changes its configuration such that the repressor leaves the operator, freeing it. In that condition, other proteins bound at the promoter are able to transcribe the structural genes of the lactose operon. Included among these is the enzyme beta-galactosidase. Beta-galactosidase metabolizes lactose. Thus, the cell normally does not make the beta-galactosidase enzyme, yet in the presence of the metabolite for which that enzyme is required, the lactose operon works to turn on synthesis of the very enzyme that metabolizes lactose. But the fact that small changes in the internal lactose concentration within E. coli turn on synthesis of the lactose operon, including the beta-galactosidase that metabolizes lactose, is precisely the kind of “threshold event”  the operon switches on or does not switch on  that constitutes the breaking of symmetries in the current microstate of the liter of living bacteria. Mathematically, the thresholds become “separatrices” in the chemical state spaces of the bacteria, on one side of which the lactose operon turns on and on the other side of which it does not.
In fact, the lactose operon system is a bistable switch. Once the operon is switched on, one of the three structural proteins is a permease that enhances transport of lactose into the cell. Thus, once the operon is activated, it will remain active, even if the concentration of lactose outside the cell is lowered from an initial high level required to activate the operon to some intermediate concentration. At that intermediate external concentration, the cell can be stably in two states, lactose operon active or lactose operon inactive. Then small fluctuations of internal lactose concentration that cross the internal threshold separatrix concentration can cause the cell to jump from one to the other state of activity and remain in the other state for a relatively long time.
For the liter of living bacteria, the number of adjacent possible microstates is on the order of at least the number of dierent on-o combinations of activities of genes and metabolic products of which all the genetic regulatory networks of all the cells are capable. It seems obvious that the number of real adjacent possible microstates, hence the dimensionality of the adjacent possible from the current microstate of the liter of living bacteria, is very much larger than the dimensionality of the adjacent possible of the liter of dead and homogenized bacteria at the same temperature.
This simple observation suggests that in the past . billion years since life arose and autonomous agents began coconstructing a biosphere linking exergonic and endergonic reactions into a diversifying web of ways of making a living, as the molecular diversity, species diversity, and behavioral diversity has increased, the dimensionality of the adjacent possible of the biosphere as a whole, and most typical chunks of it, has increased dramatically.
With respect to my comment above about the broken symmetries eventually hitting the Heisenberg uncertainty limit on the volumes in each microstate, it is probably of more than passing interest that real living entities, cells, do straddle the classical and quantum boundary. One photon hitting a visual pigment molecule can beget a neural response. In short, real living systems straddle the quantum classical boundary. If there is a tendency of coevolving autonomous agents to increase the diversity of alternative events that can occur, then living entities must eventually hit the Heisenberg uncertainty limit and abide at least partially in the quantum realm.
Indeed, the hypothesis that living entities must eventually abut and even transgress the Heisenberg uncertainty limit and abide partially in the quantum realm leads to an intriguing hypothesis. In chapter we will consider “quantum decoherence.” This is a quite well-established phenomenon in which the quantum amplitudes propagating along dierent possible pathways between the same initial and final state can lose phase information. This loss of phase information then prevents the constructive and destructive interference that is the hallmark of quantum phenomena. The loss of the capacity for interference would mark the transition to classical behavior. Many physicists now think that such decoherence constitutes a modern interpretation of the famous “collapse of the wave function” during a measurement event, as posited by the Copenhagen school. The collapse of the wave function converts the propagating superposition of quantum possibilities into an actual, classical event.
The persistent intermingling of quantum and classical phenomena in a living cell might require quantum coherence, but that coherence is widely doubted at the normal temperatures of cells and organisms. On the other hand, persistent intermingling of quantum and classical phenomena might well occur and not require quantum coherence if the timescale of decoherence is close to or overlaps the timescales of cellular-molecular phenomena. Recent calculations suggest that the timescale of decoherence of a protein in water at room temperature might be on the order of seconds. Thus, it is interesting that proteins and other organic molecules have modes of motion on timescales over many orders of magnitude, spanning from tens of seconds down to second or less. Thus, the timescale of decoherence is almost the same as the rapid molecular motions in cells. It does not seem totally implausible that cells persistently abide in both the quantum and classical realms, in which the persistently propagating superposition of amplitudes for alternative molecular motions decohere on very rapid timescales and thereby help choose the now classical microstates of proteins and their motions as those proteins couple their coordinated dance with one another to carry out the alternative behaviors that guide a cell in its next set of actions, its adjacent possible. In short, cells may feel their way into the adjacent possible by quantum superpositions of many simultaneous quantum possibilities, which decohere to generate specific classical choices. Such a hypothesis should be testable.
More, at the high risk of saying something that might be related to the subject of consciousness, the persistent decoherence of persistently propagating superpositions of quantum possibility amplitudes such that the decoherent alternative becomes actualized as the now classical choice does have at least the feel of mind acting on matter. Perhaps cells “prehend” their adjacent possible quantum mechanically, decohere, and act classically. Perhaps there is an internal perspective from which cells know their world.
Having now defined the dimensionality of the adjacent possible and noted that the biosphere and universe as a whole is vastly nonergodic, hence, kinetically trapped in a small region of its total space of possibilities, it is fair to wonder whether general laws may govern this nonergodic flow. Given that the dimensionality of the adjacent possible of the biosphere has expanded in the past . billion years, I want to make the obvious conjecture at a law: Our biosphere and any biosphere expands the dimensionality of its adjacent possible, on average, as rapidly as it can.
I will return just below to think about bounds on this expansion. For, as we will see, it seems reasonable that if the expansion were too rapid, the system would destroy the propagating organization of autonomous agents whose coevolution and increasing diversity is what drives expansion into the adjacent possible and tends secularly to increase that dimensionality. Autonomous agents persistently stumble onto new ways of making a living with one another and exploit those new ways. The biosphere’s advance into the adjacent possible is just exaptation over and over again.
In fact, it seems reasonable to think of the “workspace” of the biosphere, that is, what can happen next, as its actual plus its real adjacent possible. It seems likely, and I do conjecture, that the biosphere is expanding its workspace, on average, as fast as it can do so without destroying itself in the process.
And brazen biologist that I am, I begin to wonder whether the universe as a whole in its nonergodic flow might be expanding the dimensionality of its total workspace including its adjacent possible as a secular trend. If so, then since the big bang, the universe persistently diversifies and becomes more complex in such a way that the diversity of dierent possible next events keeps increasing as rapidly, on average, as is possible. The greater the current diversity of matter, processes, and sources of energy, the more ways there are for these to couple to generate yet further novelty, further symmetry breakings. For this to be correct, time would have to have a directionality toward persistently broken symmetries. And an arrow of time would lie in this directionality. In chapter I return to these issues. There may be grounds to understand why the universe is so complex. In a generalization of our image of a self-constructing biosphere, the universe may construct itself to be as complex and diverse as possible.
If one could ever show such a law, a law in which the diversity and complexity of the universe naturally increases in some optimal manner, that would be impressive. Some fourth law of thermodynamics? An arrow of time? In short, one intriguing hypothesis about the arrow of time is that the nonergodic universe as a whole constructs itself persistently into an expanding adjacent possible, persistently expanding its workspace. This is in sharp contrast to the familiar idea that the persistent increase in entropy of the second law of thermodynamics is the cause of the arrow of time. But the second law only makes sense for systems and timescales for which the ergodic hypothesis holds. The ergodic hypothesis does not seem to hold for the present universe and its rough timescale, at levels of complexity of molecular species and above. Perhaps we are missing something big, right in front of us.
The nonergodicity of the universe as a whole and the biosphere in particular is interesting from another point of view. History enters when the space of the possible that might have been explored is larger, or vastly larger, than what has actually occurred. Precisely because the actual of the biosphere is so tiny compared to what might have occurred in the past . billion years and because autonomous agents can evolve by heritable variations that induce propagating frozen accidents in descendant lineages, the biosphere is profoundly contingent upon history.
Bounds on the Growth of the Biosphere’s Adjacent Possible
The first point to discuss about critical limits to the growth of the dimensionality of the adjacent possible is that major extinction events have occurred. Presumably the molecular diversity and certainly the species and behavioral diversity of the biosphere were devastated during such events. There are two schools of thoughts on these extinctions: the catastrophists and the endogenists. The catastrophists point to meteors, like the monster that hit o the coast of the Yucatan at the end of the dinosaur era, presumably, but not certainly, causing their extinction. The endogenists, including me, admit some big rocks plummeted but note the power law distribution in the size of extinction events, with many small ones and few large ones, and see in these signs self-organized criticality models, discussed in the next chapter, in which many small and few large extinction events arise from the endogenous coevolutionary behavior of ecosystems.
Particularly if we who favor endogenous dynamics are correct, I am precluded from arguing that biospheres endogenously always increase their adjacent possible. For I, among others, predict endogenous biosphere shenanigans among coevolving autonomous agents as the causes of small and giant extinction events. If there is any trend to increase the adjacent possible, it can only be a secular trend. More, any such expansion must ultimately be limited on Earth. One cannot have fewer than one member per species disporting themselves on, in, and around this globe. Each species member does occupy a hunk of three-dimensional space and the planet is only so big.
But I am more concerned with a probable endogenous self-regulation of any advance into the adjacent possible. If that advance into the adjacent possible were to take place too rapidly, it would tend to destroy the organismic propagating organization that is the expansion’s foundation and persistent wellspring.
Recall the concept of a supracritical chemical reaction system. Such systems persistently generate molecular novelty. As we saw in discussing the origin-of-life problem, at a critical diversity of molecular species and potential catalysts, a phase transition occurs in which the catalyzed reactions form a giant connected component. Molecular species flow from the founder set actual into a persistently expanding adjacent possible.
I am fond of telling the Noah’s Vessel experiment, hypothetical though it is. I ask, thereby, whether the biosphere is supracritical. Take two of every species, all hundred million of them, male and female, normalizing a bit for mass (so you have small bits of hippos and elephants per fly). Dump them all into a large blender and homogenize the hell out of them, breaking all tissue and cell boundaries, spilling out the stu of life into a common, homogenized liquor.
The small molecule diversity in the blender is presumably on the order of billions, the protein and polymer diversity is on the order of hundreds of trillions, thus . Assuming that any pair of molecular species can undergo at least one two substrate–two product reaction, the total number of reactions is, as noted above, the square of the molecular diversity, so is about . If the probability that any one protein species catalyzes any one reaction is, say, one in a trillion, or , then the expected number of catalyzed reactions is just the product of the number of reactions times the number of potential protein catalysts, divided by the probability that a given protein catalyzes a given reaction. This yields reactions times proteins divided by , which equals . In short, virtually all possible reactions will be catalyzed by something. Indeed, on average, each possible reaction will find dierent protein catalysts. A vast sustained explosion into the adjacent possible would occur. Ergo, the biosphere is supracritical. More precisely, the biosphere would be supracritical if all molecular species could be in eective contact with one another on short timescales. But all molecular species do not come in contact with one another willy-nilly, for molecular species are packaged into cells.
It is critical to note that individual cells are not supracritical. The crude argument says that a cell’s metabolism has about organic molecules. Consider squirting a novel molecule, Q, into a cell. Presumably Q can be one member of two substrates with each of these organic molecules. Thus, addition of Q to the cell aords about novel reactions. Let the protein diversity of the cell be bounded by the human number of genes at ,. Any such protein has evolved for some tasks, but may contain molecular nooks and crannies that can serve as novel catalytic sites. The expected number of novel catalyzed reactions due to the presence of Q is given by the product of the number of potential protein catalysts times the number of novel reactions made available by injection of Q into the cell, divided by the probability that any protein catalyzes any given reaction. The product of potential catalysts (the proteins) and the reactions is ,,, or . The best current guess at the probability that a randomly chosen protein catalyzes a randomly chosen reaction comes from the probability that a monoclonal antibody canalyzes a reaction and, as discussed above, is about one in a billion. If so, the expected number of the novel reactions that will be catalyzed when Q is squirted into a cell is ,, divided by ,,,, or .. Since . is less than , on average, no chains of novel reactions are catalyzed and cells are subcritical.
If the probability of catalysis is one only in a trillion (as used in the calculation to see if the biosphere as a whole is supracritical), rather than one in a billion, then cells are even more deeply subcritical. With catalysis only one in a trillion, the expected number of catalyzed reactions in a cell upon addition of Q is ..
So cells are subcritical. It is a very good thing indeed that cells are subcritical. If cells were supracritical, they would forever generate molecular diversity internal to themselves. Many of the novel molecular species would poison the cell. In short, cells must remain subcritical and cells in communities must remain subcritical, or else the rate of generation of molecular diversity would overwhelm the capacity of natural selection to winnow out the winners from the losers. Everything would die. All propagating organization in the biosphere would rip itself apart in a torrential, if brief, burst of molecular creativity.
In short, the adjacent possible would explode rapidly, but everything around would bite the dust. If cells were supracritical, propagating organization would poison its own propagation.
The fact that cells almost certainly are not supracritical and that the biosphere as a homogenized whole, via the Noah’s Vessel experiment, clearly is supracritical, means that the fact that each cell is somewhat isolated from the other and that each has bounded molecular diversity is not an accident. Were it not so, we would not be here.
But what of a microbial community? Consider such a community with N species. As the diversity of species increases, the total molecular diversity of the community increases. At some point, the community as a whole might become chemically supracritical. A novel molecular species, Q, introduced into one species would be sequestered, leave the cell unchanged and be taken up by other cells or lost in the soil, or undergo a reaction to form a known or a novel species. At some diversity of species  N and some rich onslaught of novel molecular species, Q, R, S ,   .   .   .     the community will become supracritical. At that stage, molecular diversity in the community increases rapidly. If concentrations of novel molecular species are high enough, say nanomolar or picomolar, then some of the N species will be poisoned. The species diversity of the local community will fall. Presumably, this process can suce such that the diversity of a causally connected local community falls suciently low that the community is not supracritical.
The inverse argument allows the diversity of the community to increase by immigration or mutation of current members. This suggests a possible tendency of local communities to move toward the subcritical-supracritical boundary.
In short, an endogenous process almost certainly limits the rate of generation of molecular diversity such that cells and local communities are not supracritical. The rate of generation of molecular novelty must be suciently slow that natural selection can work on heritable variants to pick winners from losers. The point I am making is that it seems reasonable that endogenous processes in local communities gate the rate of exploration of the molecular adjacent possible, keeping it slow enough that natural selection can persistently pick current winners from losers. If so, the biosphere gates its own rate of entry into the molecular adjacent possible. On these arguments, the biosphere may advance into the adjacent possible as fast as it can get away with doing so.
Indeed, it is helpful to frame the current discussion as a generalization of a famous phase transition discussed by Manfred Eigen and Peter Schuster called the “error catastrophe.” Eigen and Schuster were considering a population of replicators, say viruses or bacteria, evolving on a fitness landscape with many peaks of high fitness, valleys of low fitness, and ridges. In general, if the mutation rate is low enough, a population located at one point on the landscape will have a few mutants, one or two of which are fitter. These will replicate faster than the less fit cousins, eventually replacing them, so the population as a whole will move to the new point of higher fitness on the landscape. If the process is continued, the population will climb steadfastly uphill to a local fitness peak and remain in its vicinity.
But if the mutation rate is then gradually increased, at some point the population “melts” o the fitness peak and wanders away across the fitness landscape. This melting is the error catastrophe phase transition. Eigen and Schuster elegantly relate the known mutation rates of viruses to the sizes of their genomes and show that viruses are close to but below the error threshold where selection can still overcome the melting. Bacteria, which are metabolically far more complex that viruses, are even more conservative than viruses; their mutation rate is well below the error catastrophe. It is not known why bacteria and higher cells have a mutation rate so far below the error catastrophe. Perhaps were the mutation rate of bacteria higher their communities would become supracritical. And that would be lethal.
Thus, the bounding of mutation rates and community diversity suggests that cells and communities avoid being supracritical, which in turn bounds and gates the entry into the adjacent possible by any local community. On the other hand, the biosphere as a whole is comprised of many dierent local communities. The rate of exploration of the adjacent possible globally must be bounded such that a generalized Eigen-Schuster error catastrophe, melting the population or community away from adequate organization to survive and propagate, does not occur.
All of this suggests the hypothesis that a biosphere expands into the adjacent possible, as a secular trend, about as fast as it can get away with such exploration, subject to the requirement that selection must on average be strong enough and fast enough to slightly more than oset the rate of exploration of novelty.
It is interesting that the same feature may occur in the economy as a whole. We hear of future shock. Roughly, what we fear is that the rate of technological change will overwhelm us. But will it? Or is there a self-regulating mechanism that gates our rate of entry into the technological adjacent possible?
The latter, I think. Consider this: Why does an innovation get itself introduced? Because someone thinks he or she can make money introducing that innovation. But if the person or firm making the innovation and introducing it to the global or village markets faced a product life cycle that was so very rapid that neither they nor others in the economy could absorb the innovations and make livings, the firms in question would go broke. We will only broach the technological adjacent possible at that rate at which we can make a living doing so. We gate our entry into the technological future.
Thus, it appears that the biosphere and the econosphere have endogenous mechanisms that gate the exploration of the adjacent possible such that, on average, such explorations do successfully find new ways of making a living, new natural and business games, at a rate that can be selected by natural selection, or its economic analogue of success or failure, at a rate that is sustainable. It is a further plausible hypothesis that the rate of exploration of the adjacent possible endogenously converges to the rate that is maximally sustainable.
I close this chapter with a surprising calculation and conjecture by Harold Morowitz, a biophysicist at George Mason University. Morowitz considers the atoms that form organic molecules, C, H, N, O, P, S: carbon, hydrogen, nitrogen, oxygen, phosphorus, and sulphur. He then considers molecules of these elements and the kinds of bonds that can form between the elements. There are two kinds of bonds, chain-terminating bonds, like a terminal hydroxyl group, -OH, and chain-extending bonds, like C=C. Chain-extending bonds will tend to make a molecular system with many kinds of molecules even more diverse. Chain-terminating bonds will tend to limit the diversity of molecular species that can form.
Morowitz then considers the equilibrium ratio of chain-extending bonds to all bonds, chain-extending plus chain-terminating, that would occur as a function of temperature, or equivalently, the energy per unit volume of the system. At very high temperatures, the system is a plasma, and chain-terminating bonds are vastly more predominant at equilibrium than chain-extending bonds. At very low temperatures, chain-terminating bonds predominate overwhelmingly.
If one plots the equilibrium ratio of chain-extending bonds to all bonds as a function of temperature, or energy per unit volume, the curve goes up, reaches a single peak, then trends downward. Thus, there is an optimal temperature, or energy per unit volume, where the equilibrium ratio of bonds maximizes the ratio of chain-extending chemical bonds to all bonds. Morowitz’s remarkable conclusion is that the maximum of this curve, where chain-extending bonds are as abundant as possible at equilibrium, corresponds quite closely to the average energy per unit volume of the biosphere of the Earth!
Even if the calculation is crude, I find this result deeply interesting. It suggests that, somehow, the biosphere has achieved an energy per unit volume such that at equilibrium chain-extending bonds are maximized. But this means that the energy requirements to form a biosphere of high molecular diversity are minimized!
It is as if the biosphere has managed to get itself to an energy per unit volume that permits the maximum expansion of molecular diversity and, thus, the maximum expansion of the workspace of the biosphere. How might that happen? We can consider the plausible versions of the Gaia hypothesis in which a simple model planet has black or white daisies. The relative abundances of these tunes the albedo, or reflective power, of the planet, hence, the fraction of solar energy absorbed by the biosphere. Simple models show that the ratio of black and white daisies can evolve to maximize their joint fitness, thereby tuning the energy per unit volume of the biosphere.
Morowitz’s calculation should be taken cautiously. My conclusions based on his almost back-of-the-envelope calculation should be taken even more cautiously. The arguments are cogent but unestablished. On the other hand, the biosphere has exploded in molecular diversity, the workspace of the biosphere has expanded, the adjacent possible of the biosphere has expanded. It is certainly interesting if the energy per unit volume of the biosphere is roughly that which makes this expansion as energetically inexpensive as possible for the autonomous agents coevolving with one another, exapting to new forms of making a living playing natural games, as we coconstruct our biosphere.
In summary, I hold out the very interesting conjecture that the biosphere as a whole evolves as a secular trend to expand its workspace, including the dimensionality of the adjacent possible as fast as is sustainably possible. If so, we have broached a tentative law for any biosphere. In the next chapter I discuss three further candidate laws. Treat all of them with great caution. It is enough if at this stage we can even begin to formulate tentative laws for all biospheres. A general biology is hardly begun, let alone explored.









Chapter 6
Emergence and Story:
Beyond Newton, Einstein, and Bohr?
How brazen a chapter subtitle: “Beyond Newton, Einstein, and Bohr?” Yet hints we shall find, for the science of Newton, Einstein, and Bohr remains innocent of the propagating coconstructing organization of autonomous agents, of nonequilibrium systems building a biosphere. Yet surely the biosphere is part of the universe and any general laws of the universe must necessarily encompass bio-spheres here, and if a general biology is necessary, elsewhere in the vastness we glimpse.
And “emergence and story”? What manner of foolishness is this? Story? Surely story is not the stuV of science. I’m not so sure. Story is the natural way we autonomous agents talk about our raw getting on with it, mucking through, making a living. If story is not the stuV of science yet is about how we get on with making our ever-changing livings, then science, not story, must change. Our making our ever-changing livings is part of the unfolding of the physical universe.
Would you rather be Einstein or Shakespeare? I’m not sure whose genius is the more awesome. I come, hesitantly, to believe we need both science and story to make sense of a universe in which we agents, part of the universe, get on with our embodied know-how, we who strut and fret our hour upon the stage. Then are heard no more? Hardly. Our successes and failures trickle, tumble, and torrentially build the future of our biosphere. We Americans, fearful of Sputnik, land men and mass on the moon. Parting, we leave mass on the moon and thereby change the orbital dynamics of the solar system and beyond. Calculate that, Newton, genius that you were. From what initial and boundary conditions would you, could you, start?
But again, we have not had, nor have we yet, a theory of the propagating coconstructing organization that is a biosphere built of autonomous agents and their shenanigans.
Oh, confusion. Perhaps a certain confusion is healthy. We have not tried to embrace all of this at once before.
Hierarchies of Autonomous Agents
For a start, there appears to be an indefinite hierarchy of autonomous agents. At least in our biosphere, there is a considerable hierarchy of autonomous agents. Consider first a single-cell organism, prokaryote, cells without nuclei such as E. coli in your gut. E. coli, my canonical autonomous agent. Next, consider a eukaryote, yeast, also in your gut, also an autonomous agent. In the passage from prokaryote to eukaryotic cell, it appears that a collection of autonomous agents came to live together permanently. Eukaryotes contain mitochondria, and plant cells contain plastids with chlorophyll. In both cases, these intracellular organelles carry their own DNA, with a slightly modified genetic code in the case of mitochondria. These facts have suggested to Lynn Margulis the now rather well-accepted hypothesis that eukaryotic cells are symbionts of two or more earlier separate autonomous agents that contributed the mitochondria, the plastids, and perhaps the nuclear structure of eukaryotes into a single novel reproducing entity, the eukaryotic cell.
The eukaryotic cell, then, is a well-behaved society of autonomous agents that are now symbiotic, hence, the eukaryotic cell is a higher-order autonomous agent, comprised of lower-order autonomous agents.
But life has burgeoned beyond single-celled creatures. The sea is filled with eukaryotic colonial organisms = multicellular, usually capable of sexual reproduction but also capable of asexual reproduction by budding clumps of cells that reform the various organs, feeding tubes, mouths, stinging cells, musculature, nerve system. Blessed proliferating profusion of ways of being.
And of course, since about 1.6 billion years ago, and surely since the Ediacrin 600 million years ago, and the Cambrian period 540 million years ago, there have come to exist us multicellular sexually reproducing juggernauts.
Tyrannosaurus rex really was a juggernaut of an autonomous agent. A blue whale isn’t so trifling either. Neither is the wide-flung stand of aspen astride the hillsides above Santa Fe, largest single stand of aspen in the United States, presumably all or most of which is a linked set of trees sprouting from the spreading roots of some initial individual. Julius Rebek, a chemist now at the Scripps Institute, is fond of saying that the biggest molecule he knows of is Number 7 Illinois coal, a massive hunk of coal several miles long and wide and hundreds of feet deep. Maybe Number 7 Illinois coal is from a single, clonally linked stand of aspen cousins.
So we confront a hierarchy of autonomous agents. If our definition of an autonomous agent should include that it be “an individual” capable of reproducing, then maybe whales are about as big as such agents get in the current biosphere. That’s a long way up in mass and molecules from the minimal autonomous agent I sketched in chapter 3.
How far can the hierarchy go? Who knows.
Perhaps the simplest step in this hierarchy would be the hypothetical, and now almost experimentally realized, hypercycle invented by Manfred Eigen and Peter Schuster. The hypothetical hypercycle consists of a set of replicating RNA sequences, say A, B, C, and D, each of which is actually a plus and minus strand that are template complements. But in addition to A, B,C, and D each replicating individually, A helps B replicate, B helps C replicate, C helps D replicate, and D helps A replicate. Thinking of each plus/minus RNA strand pair as a replicating cycle of two template strands, these replicating cycles are linked in the ABCD hypercycle.
In fact, the hypercycle is a small society of molecular replicators that help one another replicate, hence, it is a higher-order molecular replicating system. Reza Ghadiri has nearly created a peptide hypercycle and probably soon will achieve a real experimental example. While the hypercycle of Eigen and Schuster does not yet fulfill my definition of an autonomous agent because no work cycles are done, nevertheless we have no trouble imagining a hypercycle of autonomous agents. Indeed, presumably, the eukaryotic cell is more or less just such a hypercycle.
We have beginning mathematical models that reveal something about this hierarchical organization = although the best current models are curiously limited despite their brilliance.
Walter Fontana is a theoretical chemist trained by Peter Schuster in Vienna. Walter came to the Santa Fe Institute and made a major intellectual step called “Alchemy.” In chapter 2, I described the emergence of autocatalytic sets of molecular species in a chemical reaction graph. By rather independent intellectual routes that began with physicist John McCaskill’s eVorts to create a computer soup of Turing machines that “operated” on one another, Walter invented “algorithmic chemistry.” Naturally, and most naturally in Santa Fe, where one can be healed by means known nowhere else in the universe, Walter nicknamed algorithmic chemistry “Alchemy.” Unlike the alchemy of Newton’s time, Walter’s works.
Here is alchemy: Walter borrowed a computer language known as “lisp.” Lisp expressions can operate on one another. So expression 1 encounters expression 2. At random, it is decided if 1 will operate on 2 or 2 will operate on 1. Whichever way, after the operation, the lisp expression that was operated on typically is transformed into a new lisp expression.
You see the analogy to chemistry. The transformation of the lisp expression to a new lisp expression is rather like a chemical reaction. The operating lisp expression that does the transformation is rather like an enzyme catalyzing a reaction.
So Walter let loose a pot full of 10,000 lisp expressions in a computer. These merrily bumped into one another creating new lisp expressions. Walter, as a good theoretical chemist from the Eigen-Schuster tradition, imagined his algorithmic chemistry in a “chemostat” that would hold the total number of lisp expressions at a constant 10,000. So if extra lisp expressions drove the total above 10,000, Walter randomly chose enough lisp expressions to eliminate from the pot to keep the total at 10,000. This pruning back to a total of 10,000 provides a selection pressure for lisp expressions that are formed more often than average.
Walter let loose the floodgates of his alchemical world. A torrent of ever new lisp expressions, then, stunningly, a few, then more often, one sees an enlarging population of a subset of already-seen lisp expressions.
What had Walter found? The first thing he found were “copiers,” that is, lisp expressions that could copy any lisp expression, including themselves. Once such replicators emerged, they took over Walter’s steaming pot of lisp expressions. Indeed, such a lisp expression is rather like Jack Szostak’s hoped-for RNA polymerase, able to copy any RNA sequence, including itself. Walter called such copiers “type-1” organizations.
Could other self-reproducing organizations emerge? Walter “cheated” and simply disallowed copier replicators to occur. Bereft of copiers, Walter’s soup ripped forward again. Again novel lisp expressions came forth in profusion. Again, after a while, a recurrent set of lisp expressions emerged.
What had Walter found? He found collectively autocatalytic sets of lisp expressions, essentially identical to my collectively autocatalytic sets of polymers. Walter called these “type-2” organizations. In each such collectively autocatalytic lisp set, each expression is formed by the action of some lisp expression on some lisp expression in the set. The set as a whole is collectively reproducing.
But could one find a hierarchy beyond type-2 organizations? Further research has gotten as far as a kind of type-3 organization, which consists of two or more type-2 organizations that jointly coexist and create a kind of mutual glue of lisp expressions. The glue would not be formed by either type-2 organization alone but is the conjoint construction of the plurality of type-2 organizations.
So a modest hierarchy of algorithmic chemical systems has been found. The type-3 organizations seem analogical to eukaryotic cells that harbor diVerent replicators, mitochondria, plasmids, nuclei, in a common mutual glue of cytoplasm and shared processes.
Curiously, no higher-order organization has yet been seen. It is deeply interesting to me that no one knows why. What is limiting the persistent emergence of novel reproducing algorithmic systems?
Indeed, there are now a modest diversity of algorithmic models, such as Tom Ray’s “Tierra.” In Tierra, computer strings live in the memory core, reproduce, and fight one another for space in the core. A “reaper” kills random critters. Evolution to form a variety of parasites and hyperparasites occurs, including some slightly hierarchical agents. Interestingly, again the total diversity of types of critters is limited.
As John McCaskill, another theoretical physicist-chemist in the Eigen-Schuster group, points out, no one has succeeded so far in creating an algorithmic system of reproducing entities that generates impressive hierarchical agents or persistent, increasingly complex organization. Again, no one knows why.
It is possible that the constraint to algorithmic critters may be the problem. Indeed, I will suggest that the biosphere is richer than that which can, in the normal senses I know, be called algorithmic. That which is algorithmic is eVectively constructable by a formal procedure that begins with definable input “data” and is operated upon by a “program” in the Turing or von Neumann sense. But I will argue that we cannot prestate some biological analogue of the input data, nor is there some biological analogue of the program governing the unfolding of a biosphere. I will argue that the configuration space of a biosphere cannot be finitely prestated, that persistent novelty occurs in the biosphere and universe as a whole. And I will opine that if we cannot finitely prestate the configuration space of a biosphere, then something is odd with how we have been taught to do our science, for in Newtonian physics, Einstein’s physics, and Bohr’s physics, one can finitely prestate the configuration space in question. In chapter 10, borrowing on joint work with quantum gravity scholar and friend, Lee Smolin, I will suggest that if we cannot prestate the configuration space of a universe then “time” is real and necessary, and that the way a universe constructs itself may have analogies to the way a biosphere constructs itself.
Remember, a propagating organization that builds itself and persistently ramifies in a nonequilibrium setting is not yet a concept that we understand. We have matter, energy, and entropy, but no clear notion of propagating organization in the sense we here struggle to articulate. And because the way a biosphere gets on with constructing itself may not be algorithmic, it may be that story is part of how we must, in fact, make sense of the persistent emergence of novelty in the biosphere.
Well, that’s a mouthful. We’ll have to struggle below to see if it makes sense and might be correct.
I want to return to Walter Fontana’s algorithmic chemistry to note an interesting feature. Let’s define higher-order machines in Walter’s chemistry. We might think of “bundles” of lisp expressions, where an “input bundle” of lisp expressions is fed into an “assembly-line bundle” of lisp expressions to yield an “output bundle.” Nothing prevents our consideration of such bundles. Given a set of possible initial lisp expressions, say, N diVerent expressions, the diVerent subsets, or bundles, that are possible are just two raised to the Nth power. This 2N set is called the “power set” of the N symbol strings. A bundle acting on a bundle may produce a bundle. In general, this is just a mapping on the power set in which “machine bundles” act on input bundles to yield output bundles; that is, the set of possible input bundles, machines, and output bundles is the set of possible mappings of the power set into itself.
Well, obviously one could get bundles of lisp expressions = complex assembly lines of lisp expressions acting as machines on complex ordered sets of bundled input lisp expressions to yield ordered sets of bundled output lisp expressions. Here the “ordering” of the lisp expressions would define the assembly-line sequence of operations of the machine lisp bundle, and the ordering of lisp expressions in the input bundle would define the order in which the machine acted on the set of lisp expressions in the input bundle. And just as obviously, if Walter got type-1 and type-2 autocatalytic sets of simple lisp expressions, one could get type-1 and type 2-autocatalytic sets of machine lisp bundles operating on one another. And if sets of machines could be ordered into “units” to act on sets of input bundles to yield sets of output bundles, still higher-order autocatalytic sets of type-1 and type-2 should emerge.
Why didn’t Walter find these higher-order entities? I suspect part of the answer is because nothing in his algorithmic chemistry abets the ordering of lisp expressions into ordered sets treated as units and machines by one another. The collective properties of ordered sets of lisp expressions are not recognized and acted upon as collective objects by Walter’s soup of lisp expressions.
But such limitations seem not to hinder the biosphere. We do witness the emergence of molecular assembly lines and molecular assemblages whose collective properties are recognized and acted upon by natural selection. The transcription and translation of the DNA code to messenger RNA and protein is one example. But there are others. Many enzymes form ordered arrays of multimolecular complexes in which a substrate is progressively passed from one to another active site along an analogy to an assembly line. These higher-order complexes of molecular devices arise because natural selection is able to act upon the collective properties of such molecular aggregates when those collective properties augment adaptive fitness. In eVect, natural selection recognizes the life context in which the collective behaviors of these higher-order molecular structures are advantageous.
It is important to stress an obvious feature of the biosphere, in contrast to the algorithmic computational systems of Fontana, Ray, and others. The algorithmic systems manipulate symbols according to discrete, well-defined transformation rules, a kind of algebra-mapping symbols or symbol strings into symbol strings.
In contrast, the biosphere is built up of the doings, the embodied know-how, carryings on of autonomous agents = real physical molecular systems grafting a flow of matter and energy, constraint construction, and organization into their persistent coevolution. As we will see below = where I give grounds to think that we cannot prestate the configuration space of a biosphere, hence cannot prestate the adaptations that may come to exist in an evolving biosphere = real macroscopic physical systems that are autonomous agents may not be constrained in what they can produce, as is a formal mathematical algebraic symbol system. If so, then the “algorithmic freedom” of a biosphere is deeply important, for the science of Newton, Einstein, and Bohr all suppose prediction by algorithmic calculation.
Indeed, I suspect that the persistent innovations in a biosphere stem in no small measure from the fact that while we cannot prestate the configuration space of a biosphere, the categories relevant to its unfolding novel functionalities, the biosphere is not hampered by our failure at categorization. Unlike the well-defined and formal transformation rules of an algebra or a calculational process such as lisp, the transformation rules of the biosphere enlarge and change in ways that cannot be prespecified. As concrete examples, consider the evolution of the genetic code and consider the structure of eukaryotic chromosomes, whose complex coordinated behaviors underlie both normal mitotic cell division and the astonishing sequence of meiotic reduction cell divisions in which maternal and paternal homologue chromosomes synapse, undergo recombination, and separate such that the final sperm or egg cell receives, at random, only one homologue of each parental chromosome. The emergence of these complex macromolecular systems has altered the way evolution itself unfolds.
Richard Palmer, a physicist at Duke University and the Santa Fe Institute, has commented to me that physics is used to distinguishing the initial and boundary conditions from the “laws.” But in the evolution of a biosphere, the emergence of systems such as the genetic code and meiosis seems rather like the emergence of new laws. This has led Palmer to wonder whether the distinction between initial and boundary conditions and laws is really as clean as it appears in, say, Newtonian physics.
The Furniture of the Universe
All of this has, somehow, to do with the question of “the furniture of the universe” and with the troublesome questions of “emergence” and “reductionism.” These are contentious issues. Philosophers and others have struggled with these issues for years. I state merely some of their outlines.
There is a strong form of reductionism, the “x is ‘nothing but’ y” version. We met an example of this form of reductionism earlier in the eVorts to make good on sense data and logical atomism, where the hope was to build up an epistemology based on the least questionable propositions, namely reports of sense data, “I seem to hear a middle C note now,” “This seems to feel like a hard, flat surface.” Then the statement, “A Windsor rocker is in the living room,” is nothing but a finitely prespecified list of statements about sense data.
On this definition of reductionism, a higher-level concept is reduced to a lower-level language if the truth of a defined set of statements in the lower language is both necessary and suYcient for the truth of a statement in the higher language. If this could be done, then the higher-level statement is nothing but a shorthand for the list of necessary and suYcient statements in the lower, reducing, language. Thus, the truth of the statement, “There is a Windsor chair in my oYce,” would be reduced to the truth of some specifiable set of statements about sense data. As we saw, this eVort failed in the case of statements about physical objects and sense data. While it is relatively easy to find suYcient sense data statements, it appears to be impossible to finitely specify a set of necessary and suYcient sense data statements whose truth would be interchangeable with true statements about the Windsor chair in my oYce.
Wittgenstein wrote persuasively that the same systematic diYculty was lodged in attempts to reduce one language game to another, for example, from a description of a legal event to a description in terms of mere human actions to a description in terms of physical events. As we noted earlier, legal descriptions involve a web of concepts concerning guilt, innocence, responsibility, evidence, admissible procedure that are absent from a description of human actions outside of the legal framework. And descriptions of human actions = and, a fortiori, descriptions of the doings of autonomous agents, even bacteria acting on their own behalf to get dinner = seem to involve a diVerent language game than mere descriptions in terms of physical events.
Among other critical features of the action-and-doing language game is that, compared to a hypothetical “complete” physical description, the action-and-doing description picks out the relevant features with respect to the goals of the autonomous agent. Interestingly, once we are at Dennett’s level of Popperian creatures, which can have internal models of, and plans for, the future and can have their models die in their stead, we seem to have arrived at a level of organization in which action-and-goal talk becomes essential. Is there a finitely prestatable set of statements about physical events that is jointly necessary and suYcient for the truth of the statement, “The cheetah is hunting the gazelle”? Like other eVorts, we will find suYcient conditions but be hard pressed to find jointly necessary and suYcient conditions.
The dictionary hints at where our reductionism ideas may go wrong: Every word in the dictionary is defined in terms of other words. How could it be otherwise? Concepts are defined in webs, somehow tacked onto the real world by ostensive definitions = definitions given by pointing to examples. We carve up the world in a variety of ways, Wittgenstein’s language games, that appear not to be reducible to one another in the strict sense of necessary and suYcient conditions. And this, in turn, underlies the question whether legal systems and human actions are parts of the furniture of the universe, somehow above or in addition to the locations and motions of atoms and fields.
Even at the level of basic physical theory, the same issues arise. For example, classical thermodynamics is a well-defined science in its own right. Ludwig Boltzmann, Willard Gibbs, and others struggled to invent statistical mechanics, based on Newtonian laws operating on a set of idealized particles in the 6N-dimensional phase space we have discussed. It is generally seen as a triumph that the classical thermodynamic concepts of temperature, pressure, and entropy were reduced to statistical features of idealized sets of gas particles: temperature becoming the average kinetic energy of the particles, pressure the momentum transferred to the walls of the vessel, and entropy a measure of the number of microstates per macrostate.
But before complete triumph is declared, we should ask whether statistical mechanics constitutes a set of necessary and suYcient statements with respect to classical thermodynamics. The answer appears to be no. While statistical mechanics based on Newtonian forces yields a set of suYcient conditions, that statistical mechanics is not jointly necessary and suYcient. David Gross and other physicist colleagues have confirmed to me that one could construct diVerent, consistent statistical mechanics based on particles following non-Newtonian laws, all of which would be interpretable as reductions of classical thermodynamics. So, even at the heart, where reduction is supposed to have taken place, there seems to be no finitely prestateable set of necessary and suYcient conditions on a lower level over a set of possible statistical mechanics that would jointly suYce for a reduction of classical thermodynamics.
The same problem arises with Darwinian theory. Darwin tells us that evolution occurs by reproduction with heritable variation and natural selection. Our biology, based on DNA and RNA and proteins, is an instantiation, a suYcient condition for Darwinian evolution. Could we now state all possible physical systems that might be capable of replication, heritable variation, and natural selection? I think not.
There is a weaker sense of reductionism, namely the casting of an account of a higher-level object, concept, or phenomenon in terms of a suYcient, but not necessary and suYcient, set of conditions at a lower level. In this sense, statistical mechanics surely does “account for” classical mechanics. Many argue that this weaker sense of reductionism suYces. Well, suYces for what? That is a bit harder to be clear about. Roughly, the temptation is to say, “Temperature is nothing but the average kinetic energy of the atoms in the system”; that is, we appear to reduce the ontological furniture of the universe.
I suspect that this familiar ontological move is not always warranted. Let’s take some cases that Phil Anderson uses to exemplify “emergence.” Gold is a yellow, malleable metal familiar to all of us. Nowhere in the quantum mechanical description of atomic gold are these macroscopic properties to be found. Moreover, there is no deductive way to arrive at these macroscopic collective properties from the underlying quantum mechanics of atoms of gold. Rather, we observe the macroscopic properties, find lawful features of those properties, then attempt to link them to suYcient conditions in our quantum mechanical description of matter.
Another class of cases Anderson refers to is broken symmetries. A familiar example would be a pole standing vertically on an horizontal slab on the earth’s surface. The vertical pole is unstable in the face of gravity and will soon fall. It might fall and point in any direction. Hence, the system has the full symmetry of the plane prior to the falling of the pole. In due course, the pole does fall over and points in some specific direction. Thereby, the symmetry of the system prior to falling has been broken. We cannot deduce from the symmetry of the initial state how that symmetry will be broken.
Phil entitled his article relevant to this issue of emergence “More Is DiVerent.”
Let’s try it with my definition of autonomous agents. As I have already hinted, systems capable of self-reproduction and thermodynamic work cycles are presumably not limited to our current DNA, RNA, protein-based cells. Almost certainly, pure protein and small molecule systems can be autonomous agents. Almost certainly, pure RNA and small molecule systems can be autonomous agents. But perhaps self-gravitating systems, lasing systems, and a variety of other physical systems can be autonomous agents.
Again, we can give several suYcient conditions, but apparently we cannot finitely prespecify a set of necessary and suYcient conditions that would allow us to prespecify all the possible patterns of construction, constraint, and organization of physical processes and matter flows that would constitute an autonomous agent.
On the other hand, my definition does seem to aVord a “postconstruction” test. Bring us a candidate autonomous agent, and we can ask of it: Do you reproduce yourself and carry out at least one thermodynamic work cycle? The answer is either yes or no and is an objective fact about the entity in question. So one begins to see a pattern here. We may not be able to finitely prespecify all the possible systems that constitute an autonomous agent, but we can recognize one when we see it. We can give suYcient, but not necessary and suYcient conditions, for all physical realizations of an autonomous agent, and we can check any specific candidate case. Further, any specific candidate case either is, or is not, an autonomous agent. The statement, “The bacterium is an autonomous agent,” is either true or false.
Based on this, I want to say that autonomous agents are parts of the ontological furniture of the universe. I also want to say, with Phil Anderson, that emergence is real and utterly nonmysterious.
On this view of emergence, the autonomous agent is more than the sum of its parts, but not in the sense that the behavior of the autonomous agent is not explicable as the total organization of the parts organized into the whole agent in its environment. Rather, an autonomous agent is more than the sum of its parts in the sense that a wide variety = indeed, an indefinite variety = of physical systems could be autonomous agents in the same sense, self-reproducing systems carrying out at least one work cycle.
Now we can turn to causality. The “nothing but” version of reduction, “an autonomous agent is nothing but   .   .   .   ,” has tended historically to see causality as running only upward, from the behaviors of atoms to their causal consequences in the behavior of larger entities such as tigers.
But I find myself troubled by this view and will provide an example of why. Millions of years ago, the last female trilobite, Tomasina, was hurrying to find a good place to lay her eggs. Suddenly, Tomasina saw a hideous starfish, named Darthvader, dead ahead. “Left or right? What shall I do?” she wondered. Tomasina jumped left. Darthvader jumped right, caught Tomasina, killed her, and devoured her and her eggs.
There are no more trilobites. Moreover, when Tomasina died, she took with her the unique proteins and small molecules that were trilobite molecular species. These kinds of molecules are gone from the biosphere. So too are descendant mutant molecules that might have arisen from further speciation from Tomasina’s tribe. Furthermore, other chemical reactions, which might have been catalyzed transforming some molecular species to others that Tomasina’s molecules and those of her descendants might have catalyzed, have perhaps never come to be in the biosphere that has evolved over the succeeding eons.
Now, Tomasina is lost as an entire organism acting in an environment. Yet the causal consequences of her wrong guess of direction to jump have propagated downward to lower levels of organization, namely the molecular species of which the biosphere is composed.
Downward causation is real and nonmystical. There are now more old tires along roadsides than wagon wheels. The car has replaced the Conestoga.
I distrust a reductionism that sees causality as bottom up. In what sense is Tomasina nothing but the atoms and their locations and motions in three-dimensional space of which she was comprised? The concepts of atoms in motion in three-dimensional space do not appear to entail the concepts of an autonomous agent, self-consistent constraint construction, release of energy, propagating work tasks, and the closure of catalysis, tasks, and other features that constitutes the propagating organization that is an autonomous agent or a coevolving ecology of autonomous agents. In one sense, of course, there is nothing but the atoms in motion in three-dimensional-space in Tomasina. But the historical coming into existence of life in the universe, of autonomous agents, and of the propagating organization that is Tomasina and her bioworld is nowhere accounted for by Newton’s laws. What, after all, do Newton’s laws of motion have to do with a suYcient account of Tomasina’s jump to the left rather than the right? Is Tomasina as a whole organism part of the furniture of the universe? Yes.
Adaptations, Exaptations, and the Impossibility to Finitely Prestate the Configuration Space of a Biosphere
One contentious issue leads us to another. And now I hope to trouble you deeply.
Tomasina was but one of many lineages of creatures evolving much as Darwin taught us, by heritable variation and natural selection. Let’s turn to a Darwinian account of the function of the heart. Roughly, Darwin would say, the function of the heart is to pump blood. Namely, Darwin would say, this causal consequence of the heart is the virtue for which it was, and persistently is, selected by natural selection. I tend to think Darwin’s account of the heart is correct. Notice that the form of the account is ontological. Hearts came into existence, somehow, and are sustained because it is advantageous to organisms to have a means to pump blood.
But the heart has other causal consequences. For example, the heart makes heart sounds as its valves open and close. Presumably, heart sounds are not the causal consequences of the heart upon which natural selection has acted. Heart sounds are not the function of the heart.
It is precisely this point, that the function of a part of an organism is a subset of its causal consequences, to which I appealed earlier in stating that in an autonomous agent discerning the work task done by the constrained release of energy required finding the subset of causal consequences of that work task that were functionally important to the life cycle of the autonomous agent in its environment and, therefore, were presumably selected and sustained by natural selection. My point was that we cannot know the functions of parts except in the context of the whole autonomous agent in its environment.
But now we come to a more radical issue, Darwinian preadaptations, or in Stephen J. Gould’s term, “exaptations.” Darwin noted that in an appropriate environment a causal consequence of a part of an organism that had not been of selective significance might come to be of selective significance and hence be selected. Thereupon, that newly important causal consequence would be a new function available to the organism.
Take a fanciful case in point. The human heart not only makes heart sounds, but it also is a set of resonant chambers. Suppose you were in Los Angeles, felt something odd in your chest, and thought, “My God! An earthquake!” You did whatever the right thing was and survived, alone among millions. Your heart happened to be preadapted to pick up earthquake pretremors. Now suppose you marry and have children who inherit your fatefully preadapted heart, and suppose earthquakes arose often enough for this new capacity to oVer survival advantage to you and your oVspring. Soon a subspecies of Homo sapiens would arise with earthquake detectors in their chest. Not bad.
Now, evolution by such preadaptations, or exaptations, are not rare; they are the grist of adaptive evolution. Thus arose the lung, the ear, flight, presumably most major adaptations and presumably many or even all minor ones as well. It suYces for my purposes that many adaptations arise as Darwin’s preadaptations, or Gould’s exaptations.
Here now is my troublesome question. Do you think that you could state, ahead of time, all the possible causal consequences of bits and pieces of organisms that might in some odd circumstances or another turn out to be preadaptations and hence be selected and come to exist in the biosphere? Stated more starkly, do you think that you can finitely prestate all the context-dependent causal consequences of parts of all possible organisms that might be preadaptations, hence be selected and come to exist in the biosphere?
I believe, and it is a matter of central importance if I am correct, that the answer is no. I do not think it is possible to finitely prestate all the context-dependent causal consequences of parts of creatures that might turn out to be useful in some weird environment and hence be selected. I’m not yet certain how to prove that this is not possible, although I will have a try at it below.
Another way of stating what I am driving at is this: Is there a finitely prestatable set of all the possible potential biological functions? Again, I think the answer is no. Yet another way of stating this is to say that there is no finite prestatement of the configuration space of a biosphere. We cannot say ahead of time all the possible constellations of matter, energy, process, and organization that is a kind of “basis set” for a biosphere in the sense that the atomic chart of the elements is a finite basis set for all of chemistry.
It is time for a story. A particularly ugly squirrel named Gertrude was atop a tree 65,433,872 years ago. Gertrude was ugly because she had folds of skin from her forearms stretching to her hind limbs. So ugly was Gertrude that she was shunned by the other squirrels and was sadly alone atop a magnolia tree eating lunch. But just yards away, high in a pine, was Bertha, an owl. Bertha spotted Gertrude and thought, “Lunch!” Bertha flashed downward through shafts of light toward Gertrude. Gertrude looked suddenly up and was terrified. “GAAAAAAH,” she cried and jumped in desperation from the top of the magnolia tree, flinging her arms and legs wide in terror.
And Gertrude flew! Yes, she flew away from the magnolia tree, eluding the bewildered Bertha. Later that month, Gertrude was married in a civil ceremony to a handsome squirrel, as she had become a heroine, was no longer shunned, and was considered a prize mate. Her odd flaps turned out to be a consequence of a simple Mendelian dominant gene, hence her kids had the same wondrous capacity to fly.
And that is how flying squirrels got their wings, more or less.
Now, after the fact, after Gertrude jumped in terror from the magnolia tree, we would all say in wonder, “Did you see what Gertrude just did?!” And we would tell the story of Gertrude. But could we have said beforehand that Gertrude’s ugly skin flaps would happen to be of use that day? Perhaps, perhaps not. Could we have said it four billion years ago? Or said it today about all possible future exaptations? No. Was some known law of physics violated by Gertrude? No.
Now a story about tractors: It is said, and I choose to believe it true, that some engineers were hard at it trying to invent the tractor. “Good idea, a tractor,” was the collective wisdom. Needing lots of power, the engineers began with a huge engine block and sought to mount the block on a chassis. But the engine block was so massive that it crushed chassis after chassis. The engineers were stumped. Then one day, one of the engineers said, “You know, the engine block is so rigid, we could use the engine block itself as the chassis and hang everything else oV the engine block. And so that’s how the tractor got its chassis. And the chassis is just another Darwinian preadaptation, or Gouldian exaptation.
A brief history of the origin of writing: In the early Near East, loans of sheep and goats were common. The borrower would give the lender a small, closed vessel of baked clay, containing a number of stones equal to the number of borrowed sheep. Upon return of the sheep, the vessel would be broken open and the stones counted to make sure as many sheep were returned as had been borrowed.
But sometimes the clay vessels were broken accidentally by the lender before the time of return of the sheep. When the vessel was broken, sometimes the stones would fall out and become lost. The lender could not be sure he had recovered all his sheep. So people started making scratch marks near the top of the vessel before they baked the clay, to denote the number of stones placed inside the closed vessel. One day it dawned on someone that with the scratch marks on the surface of the clay vessel the stones inside were not needed. They smoothed the clay and began keeping notes of loaned sheep by marks baked into the clay. Cuneiform writing began.
Do you think you could finitely prestate all the context-dependent causal consequences of human artifacts that might turn out to be useful in some odd environment or for some odd purpose? I don’t think so. It is not that we cannot finitely prestate some infinite things. For example, Fourier had a wonderful idea. “Sine and cosines, you know,” he muttered to himself in French. “All possible wavelengths, out to infinity, down to infinitesimal, all possible phase oVsets.   .   .   . Haha!” And Fourier proved his theorem that any wiggly line on a plane surface could be approximated to arbitrary accuracy with a weighted set of phase-oVset sines and cosines drawn from the infinite basis set of all sine and cosine functions. Fourier finitely prestated an infinite basis set for all continuous diVerentiable wiggly lines on long blackboards.
But can we finitely prestate all possible exaptations for all possible organisms, or even the current organisms, in our biosphere? Again, while I’m still not certain how to prove my claim, I claim the answer is no. We cannot prestate the configuration space of the biosphere. But notice our failure is not hindering the biosphere from exapting all the time. Gertrude did it. And every bacterium whose molecules wiggle in a useful way that turn out to detect a source of energy or danger or opportunity in some novel fashion tends to be selected for that novel functionality. Look at the rate of emergence of bacteria resistant to our antibiotics and the myriad unexpected ways such resistance arises at the molecular level. Who could have foretold the ways?
The example of the common emergence of Darwinian preadaptations in the biosphere may point to an interesting connection with the diYculty Fontana and others have had achieving the persistent emergence of more complexity in algorithmic models such as alchemy and Tierra. Gertrude did fly, and thereby the capacity of her folds of skin to function as wings were selected. Flying squirrels came to exist in the universe. Restated, a property of Gertrude = indeed, here a collective property of her atomic constituents = made itself manifest in the real physical world in a context that lent survival advantage to Gertrude. Were we to have a formal algorithmic description of a formal simulated algorithmic Gertrude that did not have as an algorithmic consequence that her skin flaps might function as wings, then the emergence of the higher-order category of “winged squirrel” could not be derived algorithmically. Similarly, were we to have a formal description of an engine block that did not include its rigidity, we could not algorithmically derive that the engine block could be used as a chassis.
But, we might ask, could we not have a complete physical description of Gertrude or the engine block such that all possible properties might be derived from that complete physical description? The answer is almost certainly no. It is an old philosophic realization that there is no finite description of a simple physical object in its context. For example, the coVee table in my living room is made of three wooden planks, four short squat legs, runners between all pairs of legs. The middle board has a crack in it some eight inches long, a quarter of an inch wide at the end of the board, narrowing to nothing along a particular curved arc. A second crack, smaller, is six inches from the first crack. A cracker is on the table. A personal computer is on the table. The first crack is seven feet from the door. The second crack is seven feet six inches from the door. Both cracks are 256,000 miles from the moon and 4.3 light years from the nearest star. A dead grasshopper is on the table to the left of the end of the first crack and about 4.3 light years from the nearest star. A mote of dust hovers an inch above the table, two inches from a leaf that drifts down from a ficus in the living room.
You get the sense that there is no complete description of the table. Why does it matter? Because I myself made an exaptation of which I am deeply proud. You see, I was worried one day that my wife or adult son might knock my PC oV the table, so I wedged the power cord into the first crack and plugged the cord into a floor socket. Thereby, my PC worked on the table, and couldn’t be knocked oV easily. You can understand my pride here, as with my Rube Goldberg device to water my bean field.
But even this tiny invention, this tiny exaptation, could not readily have been finitely prestated. How would one, in describing all the context-dependent features of the table, happen to list the crack and its distance to the floor socket that happen to turn out to be relevant for my brilliant solution of a sudden problem? In short, there seems to be no finitely prestatable eVective procedure to list all the context-dependent features of objects and organs that might prove useful for some oddball purpose by some organism. My invention, the tractor invention, the cuneiform invention, and Gertrude’s invention were all genuine novelties in the universe.
This brings us to a wondrous set of issues. You see, we have indeed been taught by our physicist friends to do science by prestating the configuration space in question. Consider our now rather tired example of statistical mechanics with Avogadro’s number of gas particles in a liter container. First, note that we can finitely specify ahead of time the 6N-dimensional configuration space of the gas, that is, all the positions and momenta of the N gas particles in three-dimensional-space inside the liter box. Then Boltzmann assumed the ergodic hypothesis about wandering all over the configuration space, did the calculations, and, lo, statistical mechanics is upon us.
Now Newtonian mechanics: Prestate the initial and boundary conditions, the particles and force laws, and with them the possible configuration space and calculate away. So too in general relativity: Given Einstein’s equations, prestate the initial and boundary conditions and seek solutions. Solutions are possible universes. The set of possible solutions is the configuration space allowed by general relativity. And in quantum mechanics, one talks of specifying the classical conditions of the experiment, and thereby the configuration space of the quantum system, preparing an initial state, and using Schrödinger’s equation to propagate amplitudes for the entire future evolution in the configuration space for all conceivable observables. Again in quantum mechanics, in any specific context the configuration space is to be finitely prestatable, then we follow the deterministic time evolution of the Schrödinger equation in configuration space, square the resulting amplitudes to predict the probabilities of measurements, and then carry out macroscopic measurements. We know the configuration space ahead of time.
But what if we cannot prestate the configuration space of a biosphere? In that case, the way Newton taught us to do science is not the whole story. We cannot calculate as he did. And, in fact, biologists do not often do science as Newton taught. We carry on an odd mixture of historical analysis of the actual branching pathways of evolution; a dollop of theory about evolutionary landscapes, molecular evolution and coevolution, and ecosystems; and a lot of detailed experimental work to understand how actual creatures develop, how their life cycles unfold, how they assemble into ecosystems, and so forth.
And biologists tell stories. If I am right, if the biosphere is getting on with it, muddling along, exapting, creating, and destroying ways of making a living, then there is a central need to tell stories. If we cannot have all the categories that may be of relevance finitely prestated ahead of time, how else should we talk about the emergence in the biosphere or in our history = a piece of the biosphere = of new relevant categories, new functionalities, new ways of making a living? These are the doings of autonomous agents. Stories not only are relevant, they are how we tell ourselves what happened and its significance = its semantic import.
In short, we do not deduce our lives; we live them. Stories are our mode of making sense of the context-dependent actions of us as autonomous agents. And metaphor? If we cannot deduce it all, if the biosphere’s ramblings are richer than the algorithmic, then metaphor must be part of our cognitive capacity to guide action in the absence of deduction.
Indeed, in biology itself the “narrative stance” is gaining in popularity. “Did you see what Gertrude pulled oV? That’s how flying squirrels evolved! Dominant Mendelian gene, you see, easily selected once the right environmental conditions arose.” The propagating exapting biosphere is getting on with it, and it appears that we crucially need stories to do some of the telling of that getting on with it.
How odd. C. P. Snow wrote of the two cultures, science and the humanities, never to mix. Our inability to prestate the configuration space of a biosphere foretells a deepening of science, a search for story and historical contingency, yet a place for natural laws.
Forever Creative
In this chapter I have been trying to say, argue, articulate the possibility that a bio-sphere is profoundly generative = somehow fundamentally always creative. The cornerstone of this dawning near conviction lies in the belief I now hold with some confidence that we cannot finitely prestate the configuration space of a biosphere. New variables = the genetic code, recombination, Gertrude’s wings, writing, the tractor = persistently emerge. New language games and living games emerge. What is the status of my claim that we cannot finitely prestate the configuration space of a biosphere? I do think my claim is true. But why? I am not sure. It is wise to explore some possible reasons.
A first possibility is that the biosphere, like a complex algorithm, unfolds in ways that cannot be foretold. Recall that for many algorithms the behavior of the algorithm cannot be prestated in any form more compressed than simply watching the program unfold. The famous “halting problem” is the classic example. For many algorithms that are to compute an answer, then halt, we cannot say ahead of time whether the computer will halt in finite time.
I do not think the biosphere is akin to this diYculty with many algorithms. If we consider such algorithms, the building blocks of the algorithms = for example, the binary symbols 1 and 0; the operations of addition, subtraction, multiplication, division, exponentiation, and root taking; and control operations such as, “If such and such, then do so and so, otherwise do this,” and “Do loops” = are well-stated, crisp, mathematical primitives. Our uncertainty about the unfolding of an algorithm does not lie in uncertainty about the primitives, but about the consequences of the arrangements of these agreed upon primitives in a given computer code. For example, will the algorithm based on those primitives halt or not halt in finite time?
But among the exaptations in a biosphere are those that appear to alter the primitive objects and control operations. Thus, the evolution of chromosomes that replicate and partition to daughter cells, the evolution of the genetic code, and the evolution of controlled recombination all seem to be the evolution of the generative machinery of evolution itself. Insofar as this is true, our incapacity to prestate the configuration space of the biosphere is not a failure to prestate the consequences of the primitives, it appears to be a failure to prestate the primitives themselves.
Let’s consider the possibility that the incapacity to finitely prestate the configuration space of a biosphere is related to Godel’s theorem. Godel demonstrated that for axiomatic systems as rich or richer than arithmetic, given a set of axioms, there were always statements that were true but not formally derivable from the axioms. In addition, Godel showed that it was always possible to enrich the axiom set, and from that enriched axiom set, it would be possible to prove the formally true but unprovable statements in the formal system. On the other hand, he also showed that the new enriched axiom system would itself have still further formally true but unprovable statements.
I am not persuaded that the uncertainty about the configuration space of a biosphere is analogous to true but formally undecidable statements in a formal system. I base this upon an analogy between formal proof and causal consequences. The same parallel was pointed out by Robert Rosen in his book Life Itself. If we are to represent causal consequences by a formal system, then the concept of a proof derived by formal procedures from axioms = or more generally, the concept of a trajectory in a state space, where successive states along a trajectory are derived by a formal procedure such as integration of the diVerential equations representing the system = is the natural way to represent causal consequence. If this parallelism is taken seriously, then statements in a formal language that are true but unprovable in that formal language can have no causal pathway = that is, proof = from the axioms to the desired consequence. But this analogy seems to fail with respect to the evolution of the biosphere. There is a perfectly fine causal account of Gertrude and her maiden flight. We can reconstruct that account after the fact, even if we could not have predicted it. Thus, it does not seem that our diYculty in prestating all exaptations is the same as the mathematical fact of formally undecidable statements in an axiom system.
On the other hand, there may be a parallel between the exaptations of which we have spoken and Godel’s theorem and the augmentation of the axiom set such that formerly unprovable statements become provable. That is, the emergence of novel exaptations in evolution do seem rather like the emergence of novel primitive objects and primitive control operations = hence, novel axioms. In the examples above, the emergence of the genetic code and the emergence of chromosomes that duplicate and partition daughter chromosomes into two daughter cells, the evolution of controlled recombination, seem to become instantiated as “biological laws,” even though they are entirely historically contingent. Changing the biological laws in evolution seems rather like the generation of a novel axiom from which new consequences can be derived.
On this interpretation, my claim that we cannot finitely prestate the configuration space of a biosphere becomes the claim that the biosphere keeps generating new “causal axioms” from which it generates novel forms. Then just as we do not know where the new axioms of a formal system come from, save as the free invention of the logician involved, so it would seem that we cannot prestate the new generative exaptations that allow evolution to drive in new directions. I am not entirely persuaded by this analogy to finding ever new axioms in Godel’s theorem, but it does have some coherence.
Indeed, the failure to be able to prestate the configuration space of the biosphere may be yet deeper. I will take a stab at a proof. I begin by vitiating my assumption that one cannot prestate the configuration space of a biosphere, then try to show that the implications are that the number of potentially relevant properties is vastly hyperastronomical and that there is no way in the lifetime of the universe for any knower within the universe to enumerate, let alone work with, all the possible properties or categories and their causal consequences.
Let’s restrict attention to a model of a molecule, a square 10 x 10 array of magnetic dipoles, called spins, that can point only up or down. So our little system has 100 spins. Thus, I begin by vitiating my assertion and telling us what the configuration space is: it has something to do with the spin configurations. Well, how many diVerent spin configurations are there? Two raised to the 100th power. Now what might we want to call a “category” or a “property”? A sensible thought is that a category or class is some collection of the possible spin configurations, say, the configuration with all spins up plus all the configurations with no more than two spins down. How many such possible classes are there? The answer is the power set, 2 raised to the 2 raised to the 100.
This is a gargantuan number. It corresponds roughly to 10 raised to the 10 raised to the 29th. That is, the number of possible static categories of our tiny 100-spin system is about 10 raised to the power written with 1 with 29 zeros after it. By comparison, the estimated number of particles in the known universe is about 10 raised to the 80th power.
But we have so far considered only static categories = possible subsets of states of the 100-spin system. Suppose the spins can flip. Then the spin system can pass from one configuration to another. Suppose that the motions of the spin system are confined to closed cycles in the space of configurations, that is, simple orbits. Each of our 10 to the 10 to the 29 static categories is a set of one or more spin configurations. The number of possible orbits through that set is the factorial of the number of members of the set. The number of orbits among configurations that constitute the power set of classes of the 100 spins is vastly larger than the number of static categories.
On the other hand, arbitrary motion among spin states may be unreasonable. Instead, the flow among spin configurations may be constrained by the energy couplings among the spins. Physicists will properly talk of the “Hamiltonian function” that gives the energy of each spin configuration. Grant such a Hamiltonian, say a spin-glass Hamiltonian, where a spin glass is a disordered magnetic material. Then the system at finite temperature may wander through the square root of its 2⁄‚‚ states, hence about 10⁄ﬁ states in some complex patterns.
Now consider two such molecular systems, each merely 10 x 10 spins, each governed by a spin-glass Hamiltonian function, and let the two molecular systems interact in an aqueous medium. As the two touch one another and jiggle near one another, the coupled system performs some very complex dance of spin motions. In general, the equations describing that motion cannot be solved analytically but would have to be solved by numerical simulation. That is, there is no short description of the behavior of the system of equations, they must instead be solved by an algorithmic system that follows the trajectory in the state space of the system by tiny incremental steps. It becomes easy to conjure multimolecular systems, indeed autonomous agents are examples, in which even if the Hamiltonian for each single system and all the coupled systems were known, it would not be possible to compute the detailed dynamics of the coupled spin system in the lifetime of the universe.
But it is just such detailed wiggling by the coupled system that allows discovery of the preadaptation that a particular wiggling of one molecule senses a subset of states of another molecule and is useful for some survival purpose. The behaviors of the collective set of molecules among the coevolving autonomous agents stumble upon, then reinforce by heritable variation, the odd molecular motions that capture photons, that sense energy sources, that are the fine-grained molecular exaptations that are the daily stuV of evolution.
We cannot compute it. There is a sense in which the computations are transfinite = not infinite, but so vastly large that they cannot be carried out by any computational system in the universe. Indeed, one can consider the known radius of the universe at the Planck length and Planck timescale, and can imagine all the events that have happened within any causally connected light cone that might, therefore, carry out a computation. While vast, there are combinatorial problems that are still vaster. Presumably, no physical process in the unfolding universe could have foreknowledge of all features of such problems. Nor would there be an eVective procedure to prepare the cosmic computer in a proper initial state, read in the data, and read out its computation.
My best bet is that the incapacity to finitely prestate the configuration space of a biosphere is deeply related to the incapacity to enumerate and predict all the possible detailed dynamics of coupled molecular systems by any computational system in the universe. In turn, this incapacity is, I suspect, deeply related to the gargantuan nonergodicity of the historical universe that I discuss in the next chapter. And as we shall see in detail, the exaptations of Gertrude and others leaves macroscopic living footprints, propagating frozen accidents, on the history of the universe. The universe in its persistent becoming is richer than all our dreamings.









Chapter 5
A Physics of Semantics?
ach of the chapters of Investigations broaches new territory. Each is tentative and incomplete, pointing but not fully adequate. Yet, I persistently hope, it is better to light one candle against   .   .   .   what? the darkness? the veil beyond which we have had no framework of questions before? There are grounds, reasoned about by the best of philosophers and scientists of the past several centuries, to doubt a physics of semantics. We are on shaky ground. Yet when the first hard frost comes, when the birches have been swung, their crimson leaves scattered carelessly, when crystals splint shallow ponds and old egrets stand dark watch the coming dawn, long-legged, knowing how winter is thin, when the first phase transition of water to ice forms slight solidity across meadow streams, small creatures of flesh and concept tiptoe gingerly to some far side where, perhaps, something new is to be found.
We have lacked a physical definition of an autonomous agent, able to manipulate the universe on its own behalf  the egret whose foreboding of winter leads to lifted wing and steady, powerful flight. The egret is as much a part of physical reality as the atom, and perhaps more than the vaunted quark. But autonomous agents, we who do daily manipulate the world on our own behalf, we to whom “intentionality” and “purpose” are so inevitably attributed by our common languages, we are, by my definition of autonomous agents, also nothing but physical systems with a peculiar organization of processes and properties. If the concept of autonomous agents were something like a useful  or more, a proper  definition of life itself, then autonomous agents span the gap from the merely physical to that new realm of the merely physical where “purpose” is ascribed by all of us to one another.
Semantics enters with purpose. For this to be true, it is not necessary that the carriers of purpose, say, the same bacterium heading upstream in the glucose gradient, be conscious.
I hope my definition of an autonomous agent is useful, an autocatalytic system carrying out a work cycle, now rather broadened by the realization that autonomous agents also do often detect and measure and record displacements of external systems from equilibrium that can be used to extract work, then do extract work, propagating work and constraint construction, from their environment.
Know-how
Bring ourselves empathetically and objectively back three billion years to the mixed microbial community flourishing right about where most of us are now, plus or minus a modicum of layers of surface crustal material.
I want to say that the autonomous agents comprising that community had, individually and collectively, the embodied know-how to get on with making a living in the natural games that constituted their world. Indeed, as I have emphasized before, a biosphere is a self-consistent coconstruction of autonomous agents, ways of making a living, and the search procedures, mutation, recombination, as well as behavioral search open to autonomous agents. Those means of making a living that were well searched out and mastered by the agents and their search procedures became the kinds of “jobs” that were widely filled, the abundant niches of the bio-sphere. There is in this whole self-constructing system a wider know-how, beyond the know-how of any single autonomous agent spinning eagerly in its microenvironment. Yet, clearly, the know-how is distributed. There is no autonomous agent, no one, who knows how the whole system works, any more than anyone at present knows how the global economic system works in its myriad interactions, deals, steals, hopes, and frustrations.
What in the world is “know-how”? Philosophers distinguish between “know-how” and “know that.” I know how to tie my shoes and am learning how to play jazz drums. “Know that” concerns propositions, most conveniently, human propositions. I know that the moon is  they tell me  not made of green cheese. I know that the earth circles the sun, that the earth is roughly spherical, that chairs are used to sit on. “Know that” brings with it the standard and nonstandard issues of the truth or falseness of propositions as they report states of the world. Perhaps higher primates who are trained to manipulate simple symbols with apparent reference to the world also can “know that” with respect to propositions.
Unlike “know that,” “know-how” does not involve propositions about the world. “Know-how” involves procedural knowledge about how to get on in the world. The cheetah streaking after the wildebeest, the athletic genius high jumping, have the know-how to do it.
Does a bacterium know how to make a living in its world? I certainly want to say yes, without attributing consciousness in any way. Watch the myriad subtle turnings on and o of genes, metabolic switching, mechanical twitching, sensing of glucose gradient, swimming and tumbling upstream to higher glucose concentrations. It knows how all right, even if it cannot talk about how it gets on with its business. But then, try to talk about tying your shoes or the skilled driving when you become aware some dozens of miles down the road that you have accomplished the tasks without paying the slightest focused attention.
Thank God for know-how. Know that is a thin veneer on a four-billion-year-old know-how skill abundant in the biosphere. But any autonomous agent proliferating alone or in a congery of other agents, it would seem, is also graced by the selfsame know-how. If we synthesize autonomous agents in the next decades and they coevolve under our rapt gaze over months or years into a modestly complex ecosystem brimming with novel life forms, they too will know how to make a living in their mutually created world plus the boundary conditions we more or less intelligently impose on them.
The know-how is, in these terms, nothing but another view of the propagating closures of catalysis, work tasks, sensing, recording, and acting that we now recognize as inherent in the doings of autonomous agents. The know-how is not outside that propagating organization. The know-how is the propagating organization.
Semantics
All of which brings us, inevitably, to the brink of semantics.
It is simple at its roots, you see. An incoming molecular species arriving in the interior of an autonomous agent really is (i) food; (ii) poison; (iii) a signal; (iv) neutral; (v) something else. 
Once there is an autonomous agent, there is a semantics from its privileged point of view. The incoming molecule is “yuck” or “yum.” I think the major conceptual step to yuck or yum is unavoidable once there is an autonomous agent. And I think we have roughly the Darwinian criteria in mind. If yum, then there will probably be more of this type of agent, osprings of the first. If yuck, it is not so likely this lineage will prosper.
Once yuck and yum, we are not far from C. S. Pierce’s meaning-laden semiotic triad: sign, signified, significans. Like it or not, the glucose gradient is a sign, a predictor, of “more glucose that way.” Granted, the glucose is not an arbitrary symbol, any more than a cloud is an arbitrary symbol of rain. In this restricted sense, signs are causally correlated with that which is signified. By contrast, the relation between the word “chair” and that which it signifies, and on which I am now sitting, is arbitrary. But can chemical signals in bacterial and plant and human communities be arbitrary from a chemical causal point of view? If so, can “mere chemicals” be signs in the full Piercean sense?
I believe it is clear that mere chemistry in an autonomous agent can harbor symbols and signs in the full senses of the words. Consider first the famous genetic code. Triplets of nucleotides in an RNA molecule stand for specific amino acids that will end up incorporated into a protein. The detailed causal machinery involves transfer RNA molecules with their anticodon site and the distant site to which amino acids are attached, the aminoacyle transferase enzymes that charge the amino acid binding site of each transfer RNA with the proper amino acid among the twenty amino acids, the binding of the charged transfer RNA’s anticodon site to the proper RNA code word triplet, the ribosome that glides between adjacent charged transfer RNA molecules and links the successive amino acids into the growing polypeptide chain that hangs free in the cytoplasm, tethered by the ribosome to the messenger RNA molecule as it is “translated.”
The arbitrariness of the genetic code is exemplified by the evolution of novel transfer RNA molecules, which translate a given messenger RNA code word triplet into a dierent amino acid. As J. Monod properly emphasized three decades ago in a slightly dierent context concerning activation and inhibition of enzymes at allosteric sites on the enzyme that are distant from the catalytic site, the relation of chemical structures that achieve control of catalysis are utterly arbitrary with respect to the chemical structures that undergo the catalysis. The same is true of the transfer RNA where the anticodon site is distant from the amino acid binding site. Because of this, which amino acid is charged onto a particular transfer RNA is utterly arbitrary and controlled by the aminoacyle transferase enzyme that does the charging, plus the structure of the amino acid binding site on the transfer RNA. Both of these can be altered without altering the anticodon-codon matching mechanism. In short, chemistry allows arbitrary organizations of control relations.
It seems fully legitimate to assign the concepts of sign, signified, and significans to the genetic code. It seems legitimate to extend that notion to much of the subtle signaling, chemical and otherwise, within and between autonomous agents, as exemplified by plants that upon infestation by a particular insect secrete a secondary metabolite chemical that “warns” other members of the same species that an insect infestation is happening and to turn on defensive anti-insect secondary metabolites.
The calculus that is Claude Shannon’s elegant information theory has always been about reduction of uncertainty about the statistics of the source of a set of symbols. Nowhere in the core of Shannon’s work concerning the encoding and transmission of information does the meaning, or semantics, of the information enter. This is no criticism, and is widely known and appreciated. There is, however, just a hint of semantics in Shannon’s view that the semantics resides in the “decoder.”
I cannot buy Shannon’s view unless the decoder is an autonomous agent. If not, then the decoder merely transforms a bit string sent along a communication channel into some other discrete or continuous dynamics  perhaps a set of water-filled bowls is drained by turning on a machine that opens valves between the bowls and to the outside world in particular ways. The patterns of bowl drainage upon receipt of the binary string messages sent along the communication channel constitutes the decoding.
But if the recipient is an autonomous agent such as a bacterium and the incoming molecule is a symbol-sign of a paramecium or an amoeba on the roam and the bacterium swims away and avoids becoming dinner, that sequence of events seems laden with semantics. If only the bacterium could tell us: “Did you see that truck of a paramecium coming at me? I’ve run into that one before! I ducked under a boulder, and he never sensed me. I made it home. Pass me some more glucose please, Martha.”
I will return in the next chapter to discuss such stories, for I will say that we cannot prestate the configuration space of a biosphere and, therefore, cannot deduce that which will unfold. Thus, among other things, we must tell stories to understand the oriented actions of agents in their worlds. Do not be overly quick to accuse me of anthropomorphizing. I too know the risks, including the common claim that we can always in principle translate from “intentional talk” to the fully predictive causal account of the events in question. But patience. Not only are we unable to prestate the configuration space of a biosphere and predict what will unfold, but we also cannot even translate  in the sense of necessary and sucient conditions  from legal talk to normal intentional talk, let alone from legal talk of Henderson found guilty of murder to a physical talk about sound-wave forms monitored and masses at space-time lines as a description.
Then let’s just be naive for the moment. The semantics of the yuck or yum coming into a simple autonomous agent  say, an early bacterium  is somehow linked with the embodied know-how of that agent in making a living, or failing to make a living, in its world. The semantics of an event is some subset of the fully embroidered, context-dependent set of causal implications of the event, or signal, in question.
“For want of a nail, the shoe was lost; for want of the shoe, the horse was lost; and for want of the horse, the rider was lost,” more or less, said Benjamin Franklin. The semantics of the nail is some subset of this embroidered context-dependent set of implications of the event, or signal, in question to the autonomous agents in the coevolving system.
It seems hard to ascribe purpose, in the sense of acting on its own behalf, to a stone or a chair and easy with respect to an alga. Of course, there is a sense in which my attribution of semantics to autonomous agents is purely tautological. After all, I began by stating that a bacterium swimming upstream in the glucose gradient was acting on its own behalf in an environment, defined an autonomous agent as a physical system able to act on its own behalf, then asked what a physical system must be such that it can act on its own behalf. Now, five chapters later, it is hardly an independent deduction that autonomous agents are the proposed organization of matter, energy, and organization to which purposes can be ascribed in the sense of being able to act on their own behalf. My definition is a definitional circle.
On the other hand, while the definition is circular, like F = MA and Darwin’s “natural selection” and “fitness,” that does not mean that the set of codefined concepts surrounding my definition of an autonomous agent as a reproducing system that does a work cycle fails to touch the real world. Stones and chairs are not, by my definition, autonomous agents. All living cells are. And the stunning fact directly before us, every day, is that autonomous agents do manipulate the world on their own behalf. Watch a pair of nesting birds build their nest.
In short, once we have autonomous agents and yuck and yum, it appears that semantics enters the universe as the agents coevolve and behave on their own behalf with one another in the unfolding of a biosphere.
Knowing
What about “knowing”?
Daniel Dennett, in his fine book Darwin’s Dangerous Idea, advances a hierarchy of forms of “knowing,” if I may use that term, that have arisen in evolution by Darwinian means. I find his hierarchy congenial and informative. Dennett envisions evolution as a sequence of kinds of construction cranes that bit by bit build up higher-order entities via variation and natural selection.
I do not disagree, although I have placed far greater emphasis on the roles of self-organization in evolution. Here, in Investigations, I am trying to point at the mysterious but utterly natural hopefulness in which an increasing diversity of broken symmetries in the universe creates the diversity of structures and processes that can constitute and identify ramified and ramifying sources of energy, detect those sources of energy, create devices and processes that couple to those sources of energy, and generate yet more diversity that propagates macroscopic order even further. I wonder, in short, at the naturalness and self-generaticity of Dennett’s cranes building cranes building cranes in biospheres, perhaps planetary geologies, and beyond.
But back to the past. Dennett distinguishes “Darwinian creatures,” “Pavlovian creatures,” “Popperian creatures,” and “Gregorian creatures.” A simple autonomous agent, say, a bacterium, is a Darwinian creature. In its simplest version, the creature evolves by mutation, also recombination and natural selection. For the moment, no behavioral learning is to be considered. So one (or a colony or an ecosystem) of Darwinian creatures adapts more or less as Darwin told us.
At the next level up, say, aplysia, a nervous system is present, and the creature is capable of stimulus-response learning, à la Pavlov. Indeed, aplysia can learn very simple conditioned stimuli  the later analogue is the bell causing the dog to salivate in “expectation” of food.
At the next level (Dennett, perhaps properly, reserves this for us vertebrates) is the Popperian creature. Popperian creatures, in Dennett’s fine phrase, have “internal models” of their world and can “run the internal model” with the clutch disengaged, rather than running the model in real time in the real world. This allows us lucky Popperian creatures to allow our “hypotheses to die in our stead.” I love that image.
Beyond the Popperian is the Gregorian creature  namely, at least humans. Dennett makes the wonderful argument that we utilize our tools  literally stone knives, arrows, digging sticks, machine tools  to enlarge our shared world of facts and processes. This enlarged shared world gives us more know-how, and more know that. Cultural evolution, at some point, begins to burst out-of-bounds. Hard rock music jangles the minarets of Iran. Who knows what new cultural forms will blossom? Chinese cooking lands in Cuba, and Cuban-Chinese cuisine is invented. What’s next under the sun? Who can say?
I very much like Dennett’s ladder of know-how, and eventual know that. Without invoking consciousness, not because it is not worth invoking but because so little sensible has ever been said on the subject, it seems worth asking how much of this hierarchy could be realized by simple molecular systems, even without evoking nerve cells.
I would think a lot of this hierarchy could find molecular realizations. For example, bacteria and amoebae do have a kind of Pavlovian learning already, for they have receptors that accommodate to a constant level of a given signal ligand and sense instead a change from the current level. This is not yet the association of a more or less arbitrary conditioned stimulus with an unconditioned stimulus, but I can imagine chemistry to accomplish the latter. As neurons are supposed to proliferate and form novel synaptic connections that survive if used and to mediate the linkage of conditioned to unconditioned stimulus, why not envision a complex chemistry, say, very complex carbohydrate-synthesis patterns sustained by complex sets of enzymes whose activities are modulated by the dierent carbohydrates themselves, which is true of contemporary carbohydrate metabolism. Such a system might blindly try out variant patterns of synthesis until it could establish a self-sustaining web linking the carbohydrates, the enzymes, and certain protein receptors mediating the linkage between unconditioned and conditioned stimulus, then maintain that linkage by positive feedback loops. The image is not too far from how it is imagined that “idiotype” and “anti-idiotype” immune networks work to sustain synthesis of a set of desired antibodies against an incoming pathogen. In such networks, for which there is modestly good evidence, a given first antibody serves as an antigen that stimulates the body to produce a second antibody that binds to the unique amino acid sequences, called the “idiotype” of the first antibody. In turn, the second “anti-idiotype” antibody stimulates a third, which stimulates a fourth. But this series is likely to form feedback loops because the first and third antibody can often both bind to the same site on the second antibody, hence, the first and third antibodies are similar shapes in shape space. It is not much of a stretch to think of the immune system as a conditioned stimulus response system.
Popperian creatures? Why cannot the molecular-sensing and hypothesis-testing churning concerns of the bacterium as it senses a paramecium churn twenty cycles before kicking in the rotary motor, or not, such that the wee bacterium hides under a boulder of a grain of sand until the beast passes by? Are nerves necessary? Plants, as noted, are said to signal one another with complex secondary metabolites to characterize the particular kinds of insects infesting the glade. There are arbitrary structural relations between the metabolite and the insect, just as symbols in human language are often arbitrary with respect to the signified. Not bad for nerveless nonvertebrates.
I do get stuck at Gregorian creatures. Even here, the free and open creating of new symbol strings in a language, wherever new sentences can be created, is not that fundamentally dierent from the persistent open creation of new kinds of molecules in the biosphere as a whole. If the conversation we recent two-legged ones are having with respect to our digging sticks and atomic bombs is impressive, so too is the chemical conversation in any full-fledged ecosystem, where we are all instrumental in the lives of one another.
I suppose I am naively driven to consider that the biosphere, with its urgent diversity in which, emboldened by all our know-how, we do get on with a very rich conversation, may very early already have harbored all the levels of which Dennett speaks. We humans are just more gregarious with our vocal cords and e-mail, I guess. Smart place, a biosphere, lots to talk about. Four billion years of yammering. Slapstick comedy may have started a long time ago.
Ethics
And what of ethics? Does a whi of ethical issue arise with autonomous agents? Yuck or yum from my point of view if I am an autonomous agent. There are deep reasons for caution. Hume told us long ago about the “naturalistic fallacy”: One cannot deduce “ought” from “is.” From the fact that mothers care for their young, we cannot deduce that they ought to do so, Hume argued. From the fact that Hitler set out to conquer Europe and more and to kill Jewry, we cannot deduce that he ought to have done so.
Indeed, Hume’s injunction underlies the caution of scientists about making ethical statements. We scientists find the facts. You citizens across the globe can argue the ethics. But if Hume warns us not to deduce ought from is, where do values come from at all? Hume’s injunction against deduction from is to ought nevertheless began by recognizing the legitimacy of the category “ought.”
The eorts following Hume to understand the meaning of ethical assertions have been long, twisted, arduous. Following the dictates of the logical positivists of the Vienna Circle that only those statements capable of verification were meaningful, philosophers as famous as G. E. Moore came to wonder if ethical assertions were merely emotive utterances. “It is wrong to kill.” Becomes, “Agggah!” Does the positivist argument seem persuasive? It has always amused me that the core injunction of the logical positivists, “only those statements that are empirically verifiable are meaningful,” is itself not empirically verifiable. One is reminded of something about hoisting and petards. 
John Rawls of Harvard has argued eloquently that our human notions of fairness derive from what we would all “contractually” agree to, were we to know before birth that we would all be born with diering abilities and endowments. Thus “equality before the law” is one contract that Rawls commends to us. “Equality before the law” is far more refined than the yuck or yum of the bacterium. The emergence of ethics in the evolution of life on this planet is a fascinating issue.
I will content myself with wondering where “value” and the rudiments of “intentionality” come from in the physical universe in the first place and leave social contracts for other eorts. Where is the place of value in a world of fact? 
So, a short soliloquy. Facts are know-that statements. But know-how preceded know that. While fully aware of Hume’s injunction, I think that from the autonomous agent’s perspective, yuck or yum is primary, unavoidable, and of the deepest importance to that agent. I suppose we apply the Darwinian criteria. Too much yuck, this one and its progeny are gone from the future of the biosphere. Without attributing consciousness to an E. coli, or an autonomous agent we may create in the near future, I cannot help but feel that the rudiments of value are present once autonomous agents are around.
And again without attributing consciousness, once an autonomous agent is around is the rudiment of intentionality present? If so, another cornerstone of ethical activity has been laid. Ethical behavior requires first the logical possibility of behavior for which one is responsible. You are not responsible for acts and eects beyond your control. To act ethically, you must first be able to act at all.
But what are “acts” in the first place? Daniel Yamins is a brilliant young mathematician. Now entering Harvard, Dan spent a summer with me at the Santa Fe Institute before he learned to drive, after an earlier summer spent in the laboratory of Jack Szostak at Harvard, where, at age fourteen, Dan was learning to evolve RNA molecules to bind arbitrary ligands. Dan and I struggled that summer to make the distinction between the “doings” of an autonomous agent and mere happenings in and around the autonomous agent. Note we say the E. coli is swimming upstream in the glucose gradient to get dinner. But all sorts of molecular vibrational, rotational, and translational motions are occurring. What are actions and what are mere happenings?
I do not think we were successful in drawing a clean distinction between doings and happenings with clear mathematics. But I sense that the distinction between doings and happenings, Dan’s happy phrasing, is relevant for E. coli, tigers, us, trees, and autonomous agents in general. We will meet a similar problem in the next chapter when we attempt to distinguish between the function of a part of an organism and the other causal consequences of that part of the organism.
Strange and interesting, is it not, that these issues all seem to arise with autonomous agents but not otherwise? Granted that we here seem to confront the language game circularity alluded to earlier, yet I do truly think that the rudiments of semantics, intentionality, value, and ethics arise with autonomous agents. I do not think those rudiments suce to jump over Hume’s naturalistic fallacy. We cannot deduce ought from is in any concrete context, but I think we have the categories of ought and is in the physical universe once we have autonomous agents.









Chapter 4
Propagating Organization
his book, with its curious title, Investigations, seeks new questions about the universe. It is not always that everything is hidden and science must ferret out the mysteries by scouring for unknown facts, although often science proceeds in the manner of finding new facts. Rather it can be the case that the world is bluntly in front of us, but we lack the questions of the world that would allow us to see. There are stories, perhaps merely stories, of the response to early Spanish ships in the Caribbean by native inhabitants. The ships were not seen  there was no concept for them.
Bluntly in front of us: The closure of catalytic and work tasks in an autonomous agent by which it genuinely constructs a rough second copy from small building blocks by adroit linking of exergonic and endergonic processes. A cell, or colony of cells, is propagating this organization of process.
My aim in the current chapter is to begin to investigate what we might mean, and hence see, by propagating organization. No easy journey, this. I will begin with Maxwell’s demon and why measurement of a system only pays in a nonequilibrium setting. In a nonequilibrium setting, the measurements can be stored and used to extract work from the measured system. Maxwell’s demon is the clearest place in physics where matter, energy, and information come together. Yet, we will find the demon and his eorts at measurement tantalizingly incomplete: You see, only some features of a nonequilibrium system, if measured, reveal displacements from equilibrium from which work can, in principle, be extracted. Other features, even if measured, are useless for detecting such energy sources from which work can be extracted. Thus, whatever the demon’s eorts, there remain the issues of just what features of a nonequilibrium system the demon must measure such that work can be extracted, how the demon knows to measure those features rather than other useless features, and how, once measured, couplings come into existence in the universe that actually extract work. Not good enough, I shall say, to assert that in principle, work can be extracted. How does work come to be extracted?
A simple example of a device that detects displacements from equilibrium and extracts work is a windmill. The vane on the windmill in eect measures the direction of the wind and pivots the windmill such that its fan blades are perpendicular to the wind. In turn, the wind does work on the blades, causing the windmill to rotate. The system as a whole measures a deviation from equilibrium (here, the direction of the wind), orients the entire system such that extraction of work by the wind is possible for the device, and it actually extracts work. The windmill turns.
The universe as a whole  from galaxies to planetary systems, and certainly our and any other biospheres  is filled with entities that measure displacements from equilibrium that are sources of energy, those entities actually do extract work. Think of the teeming busyness of a coevolving mixed microbial community of long ago, successfully linking exergonic and endergonic reactions fired by the sun and other high-energy sources. That community measured displacements from equilibrium, extracted work, and inhabited Manhattan three billion years ago, literally building high-rise microbial mat ecosystems. Its microbial descendants are constructing similar high-rise structures in the Sea of Cortez and on the Great Barrier Reef of Australia today.
Where did all this come from, this measuring of useful displacements from equilibrium from which work can be extracted, the devices coupling to such measurements, and the extraction of work used to build up new kinds of devices that measure new kinds of displacements from equilibrium to extract work in new ways? Yet a biosphere, actually constructing itself up from sunlight, water, and a small diversity of chemical compounds, does all this over evolutionary time. The biosphere does achieve persistent measuring of displacements from equilibrium from which work can be extracted and does discover “devices” to couple to those energy sources such that work can be extracted.
And since the biosphere does this, and the biosphere is part of the universe, then the universe does it. This coming into existence of self-constructing ecosystems must, somehow, be physics. Thus, it is important that we have no theories for these issues in current physics. The stark fact that a biosphere builds up this astounding complexity and diversity suggests that our current physics is missing something fundamental. A biosphere becomes complex, the universe becomes complex. I will argue that the very diversity and complexity of a biosphere begets its further diversification and complexification. I strongly suspect that the same is true of the universe as a whole. The universe’s very diversity and complexity begets its further diversification and complexification.
After exploring Maxwell’s demon, I will ask a physicist’s question, What is work? Physicists have an answer  work is force acting through distance  given by a single number, or scalar, representing the sum of the force acting through the distance. But it will turn out that in any specific case of work, the specific process is organized in some specific way. Work is more than force acting through distance; it is, in fact, the constrained release of energy, the release of energy into a small number of degrees of freedom. It is the constraints themselves  with, as Phil Anderson points out, a kind of rigidity  that largely constitute the organization of the process. But  and here will be the hook  in many cases it takes work to construct the constraints themselves. So we will come to a terribly important circle, work is the constrained release of energy, but it often takes work to construct the constraints.
A conceptual cluster lies at the heart of the mystery. The cluster concerns the progressive emergence of organization in the evolution of the physical universe and of a biosphere. That emerging organization concerns the appearance in the evolving universe of entities measuring relevant rather than nonrelevant properties of nonequilibrium systems, by which they identify sources of energy that can perform work. Then physical entities appear that construct constraints on and couplings to the release of the identified source of energy whereby the energy is actually released and work comes to be performed. Such work often comes to be used to construct further detectors of energy sources and entities that harbor constraints on the release of energy, which when released constitutes work that constructs still further sources of energy and constraints on its release. It should be clear that we have at present no theories about these matters, nor even a clear concept of the subject matter of such theories.
The heart of the mystery concerns a proper understanding of “organization” and “propagating, diversifying organization.” Most profoundly, the mystery concerns the historical appearance since the big bang of connected structures of matter, energy, and processes by which an increasing diversity of kinds of matter, sources of energy, and types of processes come into existence in a biosphere, or in the universe itself. This is what lies directly before us but which we have not been able to see. A biosphere does all the above. Ours has for four billion years of awesome, ill-understood creativity. Doubt it? Open your eyes and look around you.
The universe, since the big bang, was and remains out of equilibrium, or vastly nonequilibrium. It was a profound insight in the development of equilibrium thermodynamics to recognize that the energy present in the thermal motions of an equilibrium gas system could not be extracted to do work. But we might ask a similar question of the nearly featureless, profound nonequilibrium of the early universe. How, in the absence of specific structures and processes, could the nonequilibrium universe couple that enormous energy to the specific generation of anything at all? Part of the answer lies in the concept of broken symmetries. Consider a pole standing vertically on a horizontal plane. In due course, it will fall over under the influence of gravity. Prior to falling, its range of possible directions to fall is the full circle. After it falls, it points in some specific direction. By falling, the pole has broken the circular symmetry of the system and come to a specific orientation. Thus part of the answer to the emergence of specific structures lies in the expansion and cooling of the universe, with the associated sequences of symmetry breakings that split the four fundamental forces, yielded a quark-gluon soup that cooled into other elementary particles, then atoms, simple molecules, self-gravitating masses, galaxies, giant molecular clouds, and second-generation stars.
As symmetries broke, the variety of matter and process increased. As the variety increased, the pairwise diversity of matter and processes increased roughly as the square of the diversity. Hence, it became more probable that specific pairs of spontaneous and nonspontaneous processes might become linked in a variety of ways, capturing the energy resources of the spontaneous processes that could then flow in constrained ways into the nonspontaneous processes to yield novel consequences. Among those consequences are the construction of new structures able to measure sources of energy. Among the other consequences are the generation of novel and specific nonequilibrium energy sources and of structures and constraints that might couple to those novel specific sources of energy. The couplings and constraints, in turn, channel the release of energy in specific ways that constitutes the work that is done to construct still further novel energy sources, measuring structures, couplings, and constraints. This, in a nutshell, is the universe diversifying, constructing structures and processes, propagating and elaborating wondrous organization.
In chapter I introduced the chemical adjacent possible and will return to it in later chapters. In terms of molecular diversity and other types of diversity, the universe and the biosphere keep advancing into a persistent adjacent possible. New kinds of molecules with new properties themselves and in couplings with other kinds of molecules persistently arise on planet Earth, and presumably in the giant cold molecular clouds that are the birthplaces of stars in most spiral galaxies. The new species of molecules aord the novel exergonic and endergonic reactions, novel constraints, and novel sources of energy that are part of the creativity outside our collective window.
Yet we hardly know how to say what this propagation and elaboration of organization and process is, nor have we a clue about whether there may be general laws that govern such self-constructing nonequilibrium processes. Such a law could be my hoped-for fourth law of thermodynamics for open self-constructing systems.
We have begun with autonomous agents. But we are here driven beyond bio-spheres. What are the general conditions that allow such self-constructing nonequilibrium processes to flourish? Are biospheres the only examples? What of the evolution of the geology of a planet, a solar system, a galaxy, the universe as a whole? Are there ways of thinking about the emergence of structures that measure and discover sources of energy in nonequilibrium systems, together with the emergence of structures and processes that couple to sources of energy, do work to construct constraints, and propagate the constrained release of the discovered energy such that more diverse structures, constraints, and processes can arise, de novo, in the adjacent possible of the evolving universe?
Is the universe highly diverse, and is our biosphere diverse, because there is some general law or tendency for such nonequilibrium self-constructing systems to diversify? I confess I suspect so. In an intuitive nutshell, in a nonequilibrium setting, the greater the diversity of structures, potential reactions, or other transformations among structures, measurement processes and devices, coupling devices, and constraints that already exist in a ramified web of propagating structures, reactions, work, measurement, constraint and coupling constructions, the easier it is for the total system to generate new kinds of molecules or other structures, processes, measurement devices, couplings, and constraints such that a biosphere or the universe can expand into the newness of its adjacent possible. But those new structures, processes, measuring devices, couplings, and constraints in turn increase the total diversity, hence, enable yet further expansion into the adjacent possible, creating perpetual autocatalytic novelty on timescales that must be vastly longer than the current age of the universe.
The universe, in short, is breaking symmetries all the time by generating such novelties, creating distinctive molecules or other forms which had never existed before. Indeed, there may be a general law for biospheres and perhaps even the universe as a whole along the following lines. A candidate fourth law: As an average trend, biospheres and the universe create novelty and diversity as fast as they can manage to do so without destroying the accumulated propagating organization that is the basis and nexus from which further novelty is discovered and incorporated into the propagating organization.
Autonomous agents themselves, self-reproducing systems carrying out one or more work cycles linking exergonic and endergonic processes in a cyclic fashion that propagate the union of catalysis, constraint construction, and process organization that constitute such autonomous agents are but the most miraculously diversifying examples of this universal process in our unfolding, ever-changing universe.
Maxwell’s Demon
Arguably James Clerk Maxwell was the greatest scientist of the nineteenth century, notwithstanding giants such as Carnot, Boltzmann, and Darwin. While his most radical work is captured in the Maxwell equations for electromagnetic fields, which introduced the fundamental concept of fields into physics, Maxwell concerned himself deeply with the puzzle Carnot had raised in what is now called the second law of thermodynamics.
Consider again a thermodynamically isolated system. That is, consider some box containing a gas, isolated from any change in its energy or mass arriving from the outside. There are N gas particles in the box, and as noted earlier, we can consider the positions and momenta of all N particles. Each position and each momentum can be decomposed into three numbers defining position and motion in the three spatial directions. Hence, the entire state of the N particles of gas can be defined by N numbers, plus a specification of the interior boundaries of the box.
As described above, all the possible states of this N system of particles can be divided into very small volumes of states, which we will call microstates. Again, as noted in chapter , a macrostate is a collection of microstates. In particular, the equilibrium macrostate is a collection of microstates having the property that the gas particles are nearly uniformly distributed in the box, with a characteristic equilibrium distribution of velocities that Maxwell himself worked out. This equilibrium macrostate has the further important properties that () vastly many microstates are in the equilibrium macrostate; () a few macroscopic features  temperature, pressure, and volume  suce to specify the equilibrium macrostate.
In terms of microstates and macrostates, as we saw, the second law can be reformulated in its famous statistical mechanics incarnation. The second law becomes the statement that, at equilibrium, the system will flow from any initial macrostate such that it spends most of its time in the equilibrium macrostate. This statement of the second law does not preclude the extremely improbable case in which the N particles just happen to flow to one corner of the box. Thus, the second law is a statistical law in statistical mechanics.
But now Maxwell enters and invents a “wee creature,” later dubbed Maxwell’s demon. (I confess that I find the use of the term “demon” here more than slightly interesting. Maxwell’s demon is almost an autonomous agent. While the demon is not defined as I have done, you will soon see that he seems to be able to make decisions and to act on the physical world. I suspect it is more than a mere coincidence that Maxwell and we seem forced to use this kind of intentional language. In fact, an odd feature of physics is that experimenters, who are outside the “system,” are always busy intentionally setting up experiments and preparing quantum systems in desired states. Surely, in a full theory the experimenters themselves, each an autonomous agent, would be part of the theory? And if not, why not? In chapter I return to this theme, for it relates to our incapacity to finitely prestate the configuration space of a biosphere.)
Maxwell asks us to consider the very same box with N particles in it. But he imagines the box to be divided into two chambers by a wall with a window in it. In the window is a flap valve. When the flap valve is open, gas particles can pass from the left to the right box via the window, or from the right to the left box via the window.
Now, smiles Maxwell, suppose the initial state of the gas in the box is in the equilibrium macrostate. No macroscopic work can be done by the equilibrium system. That was Carnot’s central point. There is plenty of energy in the random motions of the gas particles, but there is no means to extract mechanical work from it, say, to drive a piston. Next, says Maxwell, warming to his point, “Imagine that my wee friend operates the flap valve such that, whenever a fast gas particle approaches the window from inside the left box toward the right box, he opens the flap and lets the faster than average, hence hotter, gas particle through. And suppose my demon also operates the flap value to let the slower than average, hence cooler, gas particles pass from the right to the left box. Well, soon the left box will be cool and the right box will be hot. And now,” concludes Maxwell with a broad smile, “we can use the macroscopic temperature dierence between the left and right boxes to extract mechanical work, say, by driving a piston.”
There you have it. Maxwell posed a severe question for statistical mechanics and the second law. It appeared that the actions of the demon might circumvent the second law.
Maxwell’s demon has set a puzzle that is still not fully resolved. An important step in “saving” the second law was taken by Leo Szilard, who also conceived of the nuclear chain reaction one day in London and helped set in motion the development of the atomic bomb and atomic energy. Szilard carried out a calculation linking, for the first time, the concept of entropy and a new concept of information. The “entropy” of a system is a measure of its disorder. Recall that we can define the volumes of dierent macrostates by the numbers of microstates each macrostate contains. For convenience, take the logarithm of the number of microstates in each macrostate. In addition, each macrostate also has a probability of being “occupied” by the system. Multiply the logarithm of the number of microstates per macrostate by the probability that the system is in that macrostate. Now add up all these quantities for all the macrostates. The total is the entropy of the system.
Statistically, of course, the entropy of a system either increases over time or is constant. At equilibrium it is constant. If the system is released from an initially improbable macrostate, its initial entropy for the first period of time is low since most macrostates are not occupied. However, over time it will tend to spread out over all possibilities, and the sum of the probabilities of occupancy times macrostate volumes will increase to the equilibrium value.
Szilard took a first step in thinking about what Shannon later called information. Roughly Szilard realized that when the demon lets a faster or a slower gas particle pass specifically into the left or right box, respectively, then the total entropy of the system is decreasing a little bit. But in turn Szilard estimated the amount of work that must be done by the demon to discriminate that the gas particle is faster or slower than average. It turns out that the work that must be done, hence the energy utilized, equals the work that can later be extracted from the system after the fast and slow particles are separated into the two boxes. Since the work done by the demon equals the work that later can be extracted from the system, no net work can be extracted from the equilibrium system, and the second law is saved.
The link to information due to Shannon comes next. Shannon was concerned with transmitting signals down wires. He brilliantly thought of the minimal signal as a yes or no answer, hence representable as the binary or , now called a “bit.” Shannon considered the entropy of a source sending a prospective signal as the set of possible messages that might be sent, where each message was to be weighted by the probability of actually being sent. He thought of receiving a message as reducing the entropy, or uncertainty, about which message was actually sent, given the initial set of possible messages. Thus, Shannon wound up reinventing the same mathematics that covers entropy. Here there is an ensemble of messages, and each can be thought of as occupying a volume in a space of possible messages. Each message is sent with some probability from the source. So Shannon took the logarithm of the volume in message space occupied by a message and multiplied it by the probability that that message was sent from the source. If the fraction of the total volume of message space occupied by a given message is “p,” then the logarithm of this volume is “logp” and the probability of that volume is “p.” Thus, the logarithm of a probability of a message multiplied by that probability itself is “plogp.” The sum of these “plogp” terms for the total set of messages at the source is the entropy of the source. Reception of a signal reduces the receiver’s uncertainty about what is being sent from the source, hence is a negative entropy. Shannon’s information measure is, thus, just the negative of the normal entropy measure.
The link established by Szilard between information and Maxwell’s demon is, roughly, that the discrimination by the demon that a given gas molecule is faster or slower than average and whether it is coming from the left or right box (hence, whether he should open or close the flap valve) constitutes a measurement that extracts information about the gas system, hence, lowers the uncertainty about the gas system, hence, lowers the entropy of the gas system.
Importantly, there is an implied observer in discussions about entropy. Thus, a physicist might typically say that the entropy of a system is due to “our coarse graining” of the system into (arbitrarily) chosen macrostates. If “we” had more information about the microscopic states of the system, our more refined coarse graining would reduce the entropy of the system from our point of view. Indeed, there has been some genuine confusion about the role of the observer and his more or less arbitrary choice of coarse graining in the concept of entropy.
One resolution to this confusion has been suggested by Rolf Sinclair and Wojciech Zurek, who have returned to the demon problem with a wonderful set of concepts. When the demon has at it with the flap valve, he is, in fact, performing measurements on the gas system. As he performs the measurements, he “knows” more about the detailed state of the system. Now just what might it mean to know about the gas system? One useful sense of “know” is that the demon has some compact description of the state of the gas system. Indeed, the compact description of the equilibrium state is about as compact as you can get: A few macroscopic variables  temperature, pressure, volume  suce.
One modern sense of a compact description of something is a computer program. We are to think of the computer program as a calculating engine. We give it initial input data. It has some program, typically written as a sequence of binary numbers, and , and the program operates on the input data, also a string of binary symbols, and churns out an answer. Then the concept of a compact description becomes the concept of the shortness of the symbol string giving the input data and the shortness of the program. In order to maximize compression, we must get all redundancy out of both the input symbol string and the symbol string representing the program.
Sinclair and Zurek have independently carried out work that shows the following: Initially, as the demon operates, his knowledge about the system increases, hence, the entropy of the gas system decreases. But at the same time, as the demon’s information about the system increases, the length of the most compact description of the system increases as well. In fact, the length of the most compact description increases, on average, exactly as fast as does the decrease in the entropy of the gas system.
But as the length of the most compact description increases, bit by actual bit, its information content increases, bit by bit. Thus, for each bit in reduction of the entropy of the gas system achieved by our measurements, the information content of the most compact description increases, on average, exactly as rapidly. Or, as Zurek says, in the modern interpretation, the sum of the entropy of the gas system plus the observer’s knowledge about that system is a constant for an equilibrium gas system.
Well, we could still cheat and extract work from our measured gas system using the information about its microstate achieved by all the measurements. But Sinclair notes that, in the long run, the cheat will not work. We have had to record the information about the gas system somewhere, say, in the registers on a silicon chip. At some point in a closed system, the chip will be filled up with bits in registers. To keep measuring the equilibrium system, we will have to erase the chip. And Sinclair did the calculation that mirrors Szilard’s. To erase a memory-stored bit has a minimal energy cost that exactly balances the work we could get from the gas system by using the stored information about the system. The second law, again in the statistical sense, holds. No macroscopic work can be done by an equilibrium system. Measurement does not pay in an equilibrium setting.
Why this long discourse? Because it does pay to measure the gas system if the gas system is not at equilibrium. Think of a simple example: The gas particles in the left box are actually hotter than the gas particles in the right box. Thus, pressure in the left box is higher than in the right box. If the flap valve is opened, gas will tend to flow from the left to the right box until equilibrium is established. Note that a very simple, compact description has captured these features of the nonequilibrium system, and work can be extracted as the gas system flows to equilibrium.
More generally, Zurek’s point is that as measurements are performed on a nonequilibrium gas system, the length of the most compact description increases more slowly than the knowledge thus gained reduces the entropy of the system. It pays to measure the nonequilibrium system in the sense that those measurements specify the displacements from equilibrium that constitute energy sources that can be utilized to extract work.
So the demon is indeed a place in physics where matter, energy, information, and indeed, work, come together.
Let’s consider just how work might actually be extracted in the classical Maxwell demon situation with an ideal gas in two boxes separated by a partition with the window and flap valve. As a simple example, consider again the tiny windmill mentioned above, consisting of a fan and a vane perpendicular to the fan. Let the windmill be located very near the window with the flap valve inside the total gas system. If the flap valve is opened, a wind will pass transiently from the left to the right box. The windmill’s vane will measure the direction of the wind and actually orient the windmill fan blades perpendicular to the wind. The wind will cause the fan to turn, thus the turning fan extracts mechanical work from the system until equilibrium is reached.
But now we need to pause and reflect, for the story of the demon is both tantalizing and incomplete. Consider again our tiny windmill. What feature of the total gas system was measured and detected such that work could be extracted? Roughly, the wind from the left to the right box.
But not all measurements of the two-box system would have resulted in information that was useful, in the sense that work could have been extracted by the actual box in its actual configuration. For example, the box with the flap valve separates the left and right boxes; suppose that there is an identical number of gas molecules in the two equal-sized boxes and that the gas in the left box is hotter than the gas in the right box. Further, suppose the demon measures the number and instantaneous locations of all the gas particles in the left and right boxes. The fact that the particles in the left box are hotter than those in the right box, hence are moving faster than those in the right box, would not be revealed by a measurement of the instantaneous numbers and locations of all the gas particles in the left and right boxes. To measure faster motion, the demon must measure positions at two time moments or some other feature, such as the recoil of the box’s walls from the momentum transferred by the hotter versus cooler gas particles in the left and right boxes as they bounce o the wall. So, just how does the demon decide (Figure .) or come to measure the relevant properties such that an energy source is successfully identified such that work can be extracted?
We have, in fact, no answer as yet.
But this is an essential issue. Only certain features of a nonequilibrium system will, upon measurement, reveal a displacement from equilibrium that can actually be used to extract work. Other features, if measured, are useless with respect to revealing a displacement from equilibrium that can be used to extract work by any given specific system.
It is important to stress that we have here a sense of “useful” outside the context of autonomous agents. Useful measurements detect features of displacements from equilibrium that reveal energy sources from which work can be extracted. Only some measurements are actually useful in this sense in a biosphere, a geosphere, or a galaxy. These useful measurements participate together with the coming into existence of devices that extract work used to build further measurement and work extraction structures, in the gradual buildup of the diversity of structures and processes of a biosphere, a geosphere, a galaxy, or a universe. This buildup is part of why the universe is complex.
I believe that we can ultimately create a statistical theory of the probability of the generation of specific novel processes, structures, and energy sources; propagation of measurements; detection of useful sources of energy; and couplings of structures and processes to the energy sources to extract work and progressively build up still further new structures, energy sources, and processes  all as a function of the current diversity of structures, transformation processes, and measuring and coupling entities. Such statistical theories should be constructable, for example, for a giant cold molecular galactic cloud or early prebiotic planet or, most fundamentally, the expanding universe as a whole. We need a theory in which symmetry breaking begets further symmetry breaking in a progressive construction of diversifying structures and processes. Chapter , with its discussion of the origin of self-reproducing molecular systems as a phase transition to supracritical behavior in catalyzed chemical reaction graphs as a function of molecular diversity and the ratio of reactions to molecular species, is a partial prototype for such a statistical theory. A further partial prototype is present in chapter , with its discussion of autonomous agents as self-reproducing physical systems that do successfully measure displacements from equilibrium and do successfully evolve to couple exergonic and endergonic reactions to achieve completed work cycles. The vast and richly coupled network of coupled exergonic and endergonic reactions in the global ecosystem is proof positive of such propagating construction in the physical universe. In chapter I will discuss a quantum analogue to such a theory, in which complex quantum systems that couple tend to “decohere” irreversibly to classical behavior and thereby progressively build up complex classical structures.
It is also important to unpack the sense, three paragraphs above, of “actually” and “any specific system.” Consider a single gas particle in a box. Measure its location, left or right of any arbitrary surface transecting the box. Here “arbitrary” means that we can choose to perform any such measurement we wish by placing the partition arbitrarily in the box. If we know the particle is to the left of a given arbitrary partition, we can in principle extract work by allowing the particle to pass through a window in the partition and do work on a fan as it passes to the right box. Hence, it seems that in principle any such arbitrary measurement can detect a source of energy that can be used to extract work.
But the conclusion is false that any arbitrary measurement of our single-gas-molecule system can detect a displacement from equilibrium from which work can be extracted. The “in principle” just above includes the idea that, having made an arbitrary choice of placement of the partition and a measurement of which side of the partition the particle is in and, hence, having detected by that arbitrary measurement the displacement from equilibrium that is a source of energy, we can afterward decide on a construction procedure that will utilize the information about the displacement from equilibrium to extract work from the measured, nonequilibrium system. In short, we can place the windmill in the system after we have measured the location of the gas particle. We measure first, then place the windmill in the compartment that does not have the particle of gas, such that that particle, upon passing through the flap valve, will cause the windmill to turn slightly.
But what if we already have constructed the system that is to extract the work, as in the tiny windmill case, and already mounted the windmill at a specific location inside the box? Thereafter we perform an arbitrary measurement by placing the partition in the box and then locate the gas particle. We may have placed the partition in the box such that the windmill is on the same side of the partition that has the gas molecule, rather than placing the partition such that the prepositioned windmill is in the empty side. No net work can be extracted. The gas molecule will repeatedly bounce o the windmill fan from all angles. No net rotation of the fan can occur.
Thus, in a concrete context, when we can no longer alter the work-extracting structure, such as the location of the windmill, but perform the measurement after the work-extracting system is in place, then only certain measurements of the nonequilibrium system will detect sources of energy that can couple to the work-extracting structure such that work is extracted. Other measurements of the extant nonequilibrium system may be utterly useless in the sense that no sources of energy that can couple to the work-extracting system are detected.
We see the hints here of something new. Only certain features of a given nonequilibrium system, if measured, will result in detection of sources of energy that might become coupled to specific other processes that, by doing work, propagate macroscopic changes in the universe. Moreover, the tiny windmill is an example of a device that not only detects the wind from the left to the right box, but also orients the fan perpendicular to that wind and has couplings and constraints embodied in its structure such that mechanical work is actually extracted.
Fine, but we built the tiny windmill. How do such coupling structures that link identified sources of energy to the carrying out of work come to exist in the universe on their own? There is not the slightest doubt, for example, that such entities have come into existence in our biosphere as autonomous agents have coevolved over the eons. Thus, a host of new questions are raised. In the beginning, presumably, the universe was simple, homogeneous, featureless, almost isotropic. Now it is vastly complex. In the beginning, the early Earth had a paucity of complex molecules, chemical reactions, linked structures and processes. Now it is vastly complex. 
The universe as a whole has witnessed the coming into existence of novel structures and processes; so too has the biosphere. Where no dierence existed, dierences have come into existence. In a general sense, the persistent emergence of dierent structures and processes is the persistent breaking of the symmetry of the universe. What feeds this apparent propagating diversity? One aspect may be the following. Consider again the case of the box with the flap valve and something simpler than a fan, say a small mica flake suspended in the cooler of the left and right boxes. If the flap valve “be opened,” a wind from the hotter to the cooler box is transiently present. This is a simple displacement from equilibrium, and a simple device, the mica flake, will be made to quake, hence, extract mechanical work. 
Now consider an antiferromagnetic material. Such material has magnetic dipoles that, when adjacent, prefer to point in opposite directions. The north pole of one prefers to be adjacent to the south poles of its neighbors. If arranged along a straight line, an antiferromagnetic material has two equivalent lowest-energy “ground” states, NSNSNSNSN versus SNSNSNSNS. Now consider a subtle displacement from one of these lowest-energy states, say NNNSNSSSN. Here, rather than alternating N and S poles being next to one another, runs of NNN and SSS occur. The energy of the total system would be lowered if the dipoles flipped orientation to come closer to one or the other of the ground energy states. Therefore, at a suciently low temperature such that the system can flow to and remain at a ground state, the NNNSNSSSN antiferromagnet is displaced from its lowest-energy equilibrium state, and in principle, work could be extracted from this system as it relaxes to one of the two lowest-energy states. But notice now that, compared to detecting the direction of the wind by the mica flake, a rather complex and subtle measurement must be made by any measuring device that is to detect the subtle displacement from equilibrium and that any device that is to use that displacement to extract work must be correspondingly subtle. Roughly speaking, a measuring device must be of similar complexity to the antiferromagnet. Indeed, a second antiferromagnet could serve as a measuring device if it were near its own ground state and brought into proximity to the first antiferromagnet. The runs of SSS and NNN in the first antiferromagnet, brought close to a second one with ground state runs of SNS and NSN could cause the first antiferromagnet to flip closer to its ground states. Hence, the measuring-detecting-extracting device must be more structurally and functionally complex than a mere mica flake considered as a thin planar crystal.
The linked exergonic and endergonic organic chemistry reactions present in the molecular autonomous agents that we call cells exemplify just this structural and functional subtlety. The electric charge distribution on two complex organic molecules brought into proximity, coupled with the modes of translational, vibrational, and rotational motions, constitute the subtle means to measure displacements from equilibrium, couple to those displacements, and achieve linked catalyzed exergonic and endergonic reactions. As the molecular diversity of the biosphere increases, more such molecular species displaced from equilibrium come into existence, more such molecular species able to detect such displacements from equilibrium come into existence, more such coupled catalyzed exergonic and endergonic reactions come into existence.
In general, it would begin to appear that as a higher diversity of entities come into existence  entities that are then necessarily more complex  their modes of being in nonequilibrium conditions increase in diversity and subtlety. In turn, the very existence of sets of these increasingly diverse and complex entities gives them an increased number of ways, and so an increased probability, to couple with one another such that one may measure a displacement from equilibrium of the other; hence, these entities happen upon a source of energy that can be and is extracted to do work. In turn, that work may drive nonspontaneous processes to create still more complex molecular species or other entities in the adjacent possible.
In short, there appears to be some positive relationship between the diversity and complexity of structures or processes and the diversity and complexity of the features of a nonequilibrium system, which can be detected and measured by the detecting structure to identify a source of energy, then couple to the source of energy and actually extract work. If there is a relation such that diverse and complex features of nonequilibrium systems useful as sources of energy can best be detected by equally diverse and complex structures, then there appears to be some generalized “autocatalytic” set of processes in the universe since the big bang, and in a biosphere, by which nonequilibrium systems of increasing complexity and diversity arise, provide sources of energy of increasing subtlety and complexity, and in turn are detected and extracted by the increasingly complex structures that arise.
Of course, to hint the above is to hint an initial answer. At least in our bio-sphere, the cumulative coevolution of autonomous agents has, in the past four billion years, achieved precisely such a diversification. Cells and organisms have achieved astonishingly ramified and subtle detectors that measure sources of energy, plus coupling devices, that extract work and use it to build rough copies of themselves. Thus, metabolism in cells is a coupled web of chemical reactions among simple, complex, and very complex organic molecules, ranging from carbon dioxide to proteins comprised of thousands of amino acids. The catalytic sites of enzymes possess high stereospecificity  that is, shape specificity  for the transition state of the substrate(s) of the reaction. Such reactions may release energy or may couple the release of energy to the endergonic synthesis of other molecular species. Cells are replete with equally stunning receptor complexes decorating their surfaces. Binding a ligand to a receptor may trigger a complicated sequence of reactions leading to the synthesis of hundreds of dierent molecular species. But the high specificity of molecular interactions in a cell are precise examples of the coming into existence of richly nuanced, structurally and procedurally complex molecular processes that measure and detect sources of energy, and couple those sources to the carrying out of further chemical, electrical, or mechanical work.
A coevolving biosphere achieves exactly the emergence of such self-constructing diversifying organization. Whether galaxies, planetary, stellar, or other systems do as well is an open question. Again, one senses the possibility of a statistical theory of the propagation and self-elaboration of such linked structure transformational systems.
Work
Let’s turn to the concept of “work.”
I have detailed evidence that work is a puzzling concept. I am deeply proud that Phil Anderson, one of the world’s best physicists, is a close friend. One day over an Indian dinner in Santa Fe, thinking of the issues above and of more to come, I said, “Phil, the concept of work is rather puzzling.” Phil cracked o a bit of chapati, scooped some chutney onto it, paused, and said, “Yes.”
Thank God. I’m not a physicist, so I was glad to get through that hurdle.
I shall proceed in steps. First, let’s just consider the physicist’s definition of work as the integral of force acting through distance. The physicist has in mind something like Newton’s laws, where F = MA. And we understand distance, plain old nonrelativistic distance. So the work done is given by just adding up little increments of the force acting on a mass and accelerating it through a distance.
But already there is a bit of a puzzle. In any specific case of work done, some direction of application of force is specified in three-dimensional space, some actual direction of motion of the mass is specified in three-dimensional space, and some actual coupling mechanism is in place such that the force does act on the mass and get it to accelerate in that direction. How does the “specification” of a direction come to be? How does the organization of the specific case of work come about?
Now in normal physics, say, college-level physics, all these specifications occur at the beginning of the problem, in the statement of the initial and boundary conditions. The billiard balls are in such and such positions on the billiard table, the cue is moved with such and such velocity and strikes a given ball in such and such a position with such and such velocity. Now, given Newton’s calculus, let us compute the forward trajectory of the balls on the table. So the puzzle of where the initial and boundary conditions come from, and the specific coupling of cue to ball, are “hidden” in the initial and boundary conditions of “the problem” and in how Newton taught us to calculate. In short, the problem of the organization of the process in any specific case of work is hidden from view in the initial and boundary conditions of the usual statement of the physical problem. In eect, this choice is the choice of the “relevant” degrees of freedom, which is equivalent to the choice of the boundary conditions versus the dynamical variables of the system.
But an evolving biosphere is all about the coming into existence in the universe of the complex, diversifying ever-changing initial and boundary conditions that constitute coevolving autonomous agents, with their changing organization of capacities to measure and detect energy sources, and couple those detected energy sources to systems that sometimes extract work. We will return in a subsequent chapter to ask if it makes sense to try to finitely prestate the initial and boundary conditions of a biosphere. I will claim that it does not. I will claim that we cannot finitely prespecify the configuration space of a biosphere, hence, we cannot finitely prespecify the initial and boundary conditions of a biosphere.
If so, then we cannot hide the issue of the organization of work processes in a statement of the initial and boundary conditions of the biosphere. We must grapple with the emergence and propagation of organization itself on its own terms. If so, perhaps there is something amiss with the way Newton taught us to do science in his spectacular career.
Let’s take a second look at work. Consider an isolated thermodynamic system. At equilibrium the system can do no work. But let the system be partitioned into two or more domains, say, by a membrane. Ah, then one part of the system can do work on the other part. For example, if the average pressure in one part is higher than in another part, the first part can bulge the membrane into the second part.
Where did the membrane come from? How does the system come to be partitioned? Is this just another initial or boundary condition hiding from view the question: Where did this organization of stu and process come from? Meanwhile, note that the concept of work appears to require that the universe be partitioned. Regions of the universe must be distinguished (by what or whom?) such that work manages to happen.
Now I come to a definition I like, due to Atkins in his book on the second law. Atkins defines work as “the constrained release of energy.” Work is, says Atkins, a “thing.”
Think about the cylinder and piston in the idealized Carnot cycle, with the hot, compressed working gas in the chamber. What are the constraints? The cylinder and the piston, the position of the piston in the cylinder, the grease between the piston and cylinder are constraints. These roughly suce, together with the hot gas compressed in the cylinder head, for work to happen as the hot gas expands and pushes on the piston.
Where did these constraints come from? In actual fact, in the current case some human, or some machine made by a human, did work to construct the cylinder, the piston, assemble the piston into the cylinder with working gas and grease in place. Then more work was done to compress and heat the gas by pushing on the piston from the outside.
So we appear to come to an interesting circle. It sometimes takes work to construct constraints, and it takes constraints to get work.
Does it always take work to construct constraints? No, as we will soon see. Does it often take work to construct constraints? Yes. In those cases, the work done to construct constraints is, in fact, another coupling of spontaneous and nonspontaneous processes. But this is just what we are suggesting must occur in autonomous agents. In the universe as a whole, exploding from the big bang into this vast diversity, are many of the constraints on the release of energy that have formed due to a linking of spontaneous and nonspontaneous processes? Yes. What might this be about? I’ll say it again. The universe is full of sources of energy. Nonequilibrium processes and structures of increasing diversity and complexity arise that constitute sources of energy and that measure, detect, and capture those sources of energy, build new structures that constitute constraints on the release of energy, and hence drive nonspontaneous processes to create more such diversifying and novel processes, structures, and energy sources.
I find it delightful that we hardly have the concepts to state these issues; surely we have as yet no coherent theory for this burgeoning of process and structure. Whatever it is, a biosphere does it. It was quite barren in Nebraska, wherever Nebraska was, four billion years ago. Not now.
Propagating Work
By way of whimsy, consider Figures .a and .b. Figure .a exhibits a cannon, clearly marked “cannon,” firing a cannonball, clearly marked “cannonball,” that hits the ground some distance away, creating a hole, clearly marked “hole.” In addition to creating the hole, the cannonball, now embedded in the bottom of the hole, has created hot dirt, marked “hot dirt.”
In Figure .b I exhibit a device  a Rube Goldberg device, in fact  of which I am extremely proud. The same cannon as in .a now fires the same cannonball, which, however, hits a paddle on a sturdy paddle wheel I constructed. Once struck by the cannonball, the paddle wheel is set to spinning. Prior to my firing the cannonball, I contrived to tie one end of a red rope around the axle of the paddle wheel and a modest size bucket to the other end of the rope. Thereafter, I dropped the bucket down the well. The water-filled bucket has now rested, silent and waiting, until the cannonball strikes the paddle wheel, whereupon the wheel spins, the red rope winds up, pulling the water-filled bucket up the well, up against the axle, which tilts the bucket over  you will have to imagine this part  and pours the water into a long funnel that slopes down from the wellhead toward my bean field. When the water from the bucket arrives at the bottom of the water pipe, it pushes against a flap valve, thereby opening the valve and watering my bean field. You can see why I might be proud of my machine.
What is the dierence between .a and .b? The point of the cannon and cannonball in the two figures is to emphasize that there is the same total input of energy into the two cases. The explosion of gunpowder is evidently the same, as is the flight of the cannonball. Obviously, in Figure .a, most of the energy carried by the cannonball is dissipated as heat, random molecular motions induced in the particles of dirt. Indeed, I might have sent the cannonball bouncing along a large steel plate rather than hitting mere dirt. In the case of the plate, no hole would have formed, and hot steel would have been the consequence.
In Figure .b, my Rube Goldberg device achieves a rudimentary  or sophisticated, depending upon pride of inventorship  propagation of macroscopic consequences in the universe. Note the linking of spontaneous and nonspontaneous processes  the arc of the cannonball imparting energy that winds the wheel and lifts the water-filled bucket. Note also the constraints everywhere present that coordinate the flow of energy into the specific, if slightly comical, unfolding of events.
In fact, my fine Rube Goldberg device does not quite demonstrate all I might wish it to show, for it does not demonstrate the use of the release of energy to actually construct constraints. However, an ingenious modification of my device, of which I am also deeply proud, demonstrates constraint construction. Let us modify the device such that the cannonball, after hitting the paddle wheel and setting it spinning, is deflected downward onto the ground and digs a long shallow groove in the dirt, with high sides due to the displaced dirt. Let this groove lead to the bean field and guide the water spilled from the bucket such that it flows to water the bean field. The digging of the groove in the dirt by the cannonball constitutes the construction of constraints on the release of energy, for the water flowing down the gravitational potential to the bean field is just such a constrained release of energy.
My Rube Goldberg device propagates work; it succeeds in creating a sequence of coordinated macroscopic changes in the physical universe. I do not know a formal definition of “propagating work,” so, in the absence of anything better, I will point at what I mean by Figure .b.
We have some clues in place now. Work is the constrained release of energy. Often constraints themselves are the consequence of work. I have tentatively defined an autonomous agent as a self-reproducing system that carries out at least one work cycle. In turn, this led us to note that an autonomous agent is necessarily a nonequilibrium device, therefore, that it stores energy. To think about work cycles, we have been driven to ask about Maxwell’s demon, measurement, when and why measurement pays, thence to what features of a nonequilibrium system are measured such that they constitute a source of energy, thence to how couplings arise that capture the energy source, thence to work and constraints, and now to propagating work due to the occurrence of linked sets of constraints and flows of matter and energy.
A next step is to realize that the only well-known autonomous agents, namely real cells such as yeast, bacteria, your cells and mine, do actually carry out linked processes in which spontaneous and nonspontaneous processes are coupled to build constraints on the release of energy. The energy, once released, constitutes work that propagates to carry out more work, building more constraints on the release of energy, which when released constitutes work that propagates further.
Figure . is a schematic representation of a cell. The figure shows a typical bilipid membrane, small organic molecules of dierent species, A, B, C, D, E, F, G, a transmembrane channel, and so forth. Now, in fact, your cell typically does thermodynamic work to build up lipids from smaller molecular species. Typically, the energy is supplied by breakdown of ATP to ADP or similar exergonic reactions in metabolism. But lipids have the capacity to fall to a low energy structure, which is precisely a bilipid layer. As noted in chapter , lipids are molecules with a hydrophobic tail and a hydrophilic head. The hydrophilic head, as the name implies, likes water. Consequently, in an aqueous environment lipids will tend to form bilipid membranes with the hydrophilic heads facing the aqueous medium and the hydrophobic tails buried next to one another, away from the water. In fact, if you take some cholesterol, or another lipid or lipidlike molecule, and dissolve it in water, bilayer membrane vesicles form spontaneously that are called liposomes. So, your cells do thermodynamic work to make lipids, which spontaneously form a low-energy structure, the membrane.
But the membrane constitutes constraints. Watch. A and B are small organic molecular species and are capable of three hypothetical reactions. A and B can undergo a two substrate–two product reaction to form C and D. A and B can ligate to form a single product, E. Or A and B can undergo a dierent two substrate–two product reaction to form F and G. Naturally, each of these three reaction pathways from A and B passes along its own reaction coordinates through its own dierent “transition state.” Because each of the three transition states has a higher energy than does A and B or the products C and D or E or F and G, the transition state energy is a potential energy barrier, slowing the reaction from A and B down any of the three reaction pathways.
Let A and B dissolve in the bilipid membrane from the aqueous interior of the “cell.” Once this happens, immersion of A and B in the membrane environment alters the vibrational, rotational, and translational motions, or “degrees of freedom,” of A and B. But, in turn, these alterations in the motions of A and B alter the heights of the transition state energies along each of the three reaction pathways from A and B to C and D or to E or to F and G.
But the alteration in potential energy heights along the three dierent reaction pathways from A and B is precisely the alteration of the constraints on these reactions. The barrier heights, together with the even higher energy barriers that provide the walls of the reaction coordinates along which the reaction proceeds, constitute the constraints. So, in fact, the cell has actually done thermodynamic work to construct constraints on the release of chemical energy stored in A and B, that might be released to form C and D or E or F and G.
Moreover, the cell does thermodynamic work, utilizing ATP degradation to ADP, to link amino acids together into a protein enzyme. The enzyme diuses to the A-and-B-laden region of the membrane and binds stereospecifically to the transition state leading from A and B to the products C and D. By binding the transition state complex of this reaction pathway, the enzyme lowers the potential barrier for the A + B ÷ C + D reaction, and the chemical energy stored in A + B is released to form C + D.
Thus the cell does work, both to construct constraints and to modify those constraints, by raising or lowering potential barriers such that chemical energy is released. More, the released energy can, and often does, propagate to do work constructing more constraints. Thus, the product D may itself diuse to a transmembrane channel and bind to the channel, giving up some energy stored in its structure by an internal rotation to a lower energy state, and thereby both bind the channel and add energy to the channel to open the channel such that calcium ions can enter the cell. A spontaneous and a nonspontaneous process are coupled. Work propagates in cells and often does so by the construction of constraints on the release of energy, which when released constitutes work that propagates to construct more constraints on the release of energy.
Records
Let’s turn to the concept of a “record.” As we saw, Zurek has led us to the point, in thinking about Maxwell’s demon, at which a record of measurements might be kept and used later to extract work. In the case of a nonequilibrium system, in principle, measurements of a system might pay in the sense that more work could be extracted from the system  which now becomes a provider of energy  than need be used to record and later erase the measurement.
Interestingly, the “erasure cost” suggests that autonomous agents must be finitely displaced from equilibrium to aord the finite erasure cost and still reproduce. In addition, of course, rapid reproduction requires finite displacement from equilibrium.
We have many colloquial notions of a record. I want to try a tentative technical definition: Records are correlated macroscopic states that identify sources of energy that can be tapped to extract work.
Thus, we are to think of records as recording “measurements” that identify the source(s) of energy in the measured system, which may then be tapped to do work. My example of the wind through the window in Maxwell’s two-chambered gas system is a case in point. We have good grounds from Zurek’s work to believe that the complexity of the record is related to the reduction in entropy of the measured system.
Notice some interesting features of records. First, a useless feature of a nonequilibrium system with respect to extraction of work may be recorded. Second, errors may be made in the record of a useful feature of a nonequilibrium system from which work can be extracted. Third, the record may go out of date, so that work can no longer be extracted by reference to the record. Fourth, the record may be erased and may be updated. All the above features arise in a coevolving microbial community. Indeed, all sorts of signaling pathways in cells record and report energy sources and coordinate cellular activities within and between cells in a community. Mutation, recombination, and selection are means to update the recording devices with respect to changing sources of energy, opportunity, and danger. Again we see that cells in a community have the embodied know-how to get on with making a living.
We are struggling with a circle of concepts involving work, constraint, constraint construction, propagating work, measurements, couplings, energy, records, matter, processes, events, information, and organization. It has been said by many that we do not understand the linking of matter, energy, and information. The circle above points at something we must trouble ourselves to understand, and I suspect that the triad of matter, energy, and information is insucient. Rather, the missing “something” concerns organization. While we have, it seems, adequate concepts of matter, energy, entropy, and information, we lack a coherent concept of organization, its emergence, and self-constructing propagation and self-elaboration.
If we do not yet understand organization fully, we can at least think about what happens in autonomous agents such as real cells. A real cell, a real molecular autonomous agent, does in fact carry out self-reproduction. In addition, it carries out one or more real work cycles, linking spontaneous and nonspontaneous processes. It does, in fact, measure, detect, and record sources of energy and does do work to construct constraints on the release of energy, which when released in the constrained way, propagates to do more work, often constructing further constraints on the release of energy or doing work by driving further nonspontaneous processes. Cells do achieve propagating work.
The work propagating in a cell achieves a “closure” in a set of propagating work tasks such that the cell literally constructs a rough copy of itself. In a later chapter I will return to discussing “tasks,” which turn out on a Darwinian analysis to be a subset of the causal consequences of the release of energy at a point and time in the system. For the moment, I want to focus on the concept of a closure in a set of propagating “work tasks.”
We know what it means to cook dinner, eat dinner, and clean up afterward. A coordinated set of activities is carried out that completes the events concerning preparing, eating, and cleaning up after dinner. The notion of completing a set of tasks is not mystical. So we can straightforwardly state that a cell completes a set of propagating work tasks such that it builds a copy of itself by linking spontaneous and nonspontaneous processes in constrained ways.
Thus, a molecular autonomous agent achieves two dierent closures. First, it achieves a “catalytic” closure; all the reactions that must be catalyzed are catalyzed by molecular members of the system. Second, it achieves a closure in a set of propagating work tasks by which it completes the construction of a rough copy of itself. Cells achieve this work-task closure, nor is there anything nonobjective about this truth.
Notice that the closure in catalytic and work tasks cannot be defined “locally.” No single reaction, no single linking of spontaneous and nonspontaneous processes typically suces to specify the closures we are describing. These closures are typically collective properties of the entire autonomous agent in its environment. In fact, cells achieve closure in some wider range of tasks by which they propagate their organization. Thus, cells carry out measurements and record them all the time. The bacterium swimming upstream in a glucose gradient was my initial candidate example of an autonomous agent. The bacterium does so by molecular “sensors” that measure glucose, a molecular motor with a stator and a rotor that can rotate in either direction, and a flagellum that can rotate in two directions, causing “swimming” in one direction and “tumbling” in the other. The cell achieves swimming “upstream” by continuing to swim if the glucose concentration is rising and tumbling then swimming in a random direction if not.
Autonomous agents achieve catalytic and propagating work-task closures by which they build copies of themselves. The myriad sensors, receptors, ligands, enzymes, and linked reactions of metabolism are the structure and dynamic of the reproducing cellular autonomous agent that constitutes the measurement, detection, recording, and search for useful energy sources to link into its ongoing construction of itself. The propagating closure of events and organization that is a cell or colony of cells, an autonomous agent, or a collection of autonomous agents is not matter alone, energy alone, entropy alone, nor the negation of entropy, Shannon’s information, alone. The propagating closure that is an autonomous agent appears to be a new physical concept that we have not known how to see before.
What we can here see is the natural embodiment of organization. We have, I suggest, no coherent concept of organization. We have tended to think that the concept of entropy, of order and disorder in statistical arrangements of states of aairs, is the proper and central concept of organization. But I claim that entropy is not yet adequate. Nowhere does entropy cover the topics we have discussed, the closure of catalysis and propagating work tasks creating the complete whole that is an autonomous agent coevolving in a biosphere. This closure of tasks, measurements, records, and linkages that propagates macroscopic work seems to constitute at least an ostensive definition, a definition by example, of “organization.”
Although my discussion above about organization is still preliminary, the basic points seem correct. A coevolving mixed microbial community that existed some three billion years ago, diversifying and coevolving via Darwinian mutation, recombination, and natural selection, did, in fact, measure and detect and create an increasing variety of energy sources, did, in fact, couple those detected energy sources into work cycles and other activities, and did, in fact, build a biosphere. Self-constructing organization did and does propagate. Our globe is covered by this propagating organization  life and its consequences.
Indeed, it seems important to wonder which conditions in a nonequilibrium universe would allow such propagating organization to proliferate. A biosphere does it, of course. One can imagine a watery planet with small sail boats, sails, and tillers trimmed to tack forever on a left tack, forever circling the everywhere ocean. Here the sails and tiller match the windmill and its vane, orienting the fan to capture the transient wind and extract mechanical work. Intuitively, it seems unlikely that such a planet of nonliving complex entities could have arisen spontaneously since the big bang. Just as intuitively, all we have discussed seems sucient for the ongoing diversification of propagating organization: the Darwinian processes of natural selection and random variation, the coevolutionary construction of vastly complex autonomous-agent cell systems that continually evolve ever-novel measurements of novel sources of energy, recordings of those energy sources, couplings to those sources, constraint construction, and the linking of exergonic and endergonic reactions that builds the diversifying biosphere.
The biosphere is the most rambunctiously complex, integrated, diversifying, milling, buzzing, busyness in the universe that we know. Perhaps there are other biospheres, and they too hum in persistent diversification. Autonomous agents appear to be a sucient condition for application of this concept of organization, and a biosphere comprised of coevolving autonomous agents appears to be a sucient condition for propagating self-constructing organization. It remains an open question whether other structures and processes in the universe that may not be autonomous agents  say, lifeless galaxies, stars, the giant molecular clouds in galaxies, or lifeless planets  can generate and propagate diversifying organization as radically well as do biospheres.
I close this chapter by asking whether there is a way to “mathematize” the concept of an autonomous agent and, through it, the concept of propagating organization. The answer is, perhaps, category theory. I am honored to note, in memorium, that my friend and colleague Robert Rosen first explored some of these issues and some others of those touched upon here in his book Life Itself.
Category theory is a branch of mathematics concerning mappings. Consider a “domain” and a “range.” A mapping takes points in the domain to points in the range. The mappings might be :, or :many, or many:. For example, in a : mapping, each point in the domain maps to a single corresponding point in the range. The domain and range can be discrete sets or continuous.
An interesting feature of categories is that a category can have the property that the mapping from the domain to the range is specified by the category itself in a recursive way; the elements of the range determine the mapping from the domain to the range. This recursive specification comes close to an autocatalytic set. We need merely think of a set of molecular species in the domain and a set of molecular species in the range; the mapping from domain to range is just the set of reactions that transform the initial “substrate molecules” in the domain to the “product molecules” in the range. Now, an autocatalytic set has the property that certain product molecules in the range, namely the products that are also catalysts, “choose” the reactions that are catalyzed from the substrates to the products, hence, choose the specific mapping from the domain to the range. Thus, an autocatalytic set can be thought of as this kind of recursive category.
The category theory image is at least a start with respect to catalytic closure. Perhaps some enhanced category theory that includes closures of work tasks, measurements, and records, as well as catalysis, is part of what an adequate formalization of “autonomous agent” may be. It is too early to say.
On the other hand, I am not persuaded that category theory will suce. In category theory it seems necessary to specify ahead of time all the possible domains and ranges and mappings under consideration. I will suggest in a later chapter when we consider the evolution of novelties that there is no finite prespecification for the work tasks, measurements, records, and catalytic tasks that might constitute autonomous agents. In short, I will argue that we cannot prestate the configuration space of a biosphere. Whether an incapacity to prestate the configuration space of a biosphere genuinely precludes the use of category theory to mathematize the concepts of autonomous agents and propagating organization is an open question.
We have arrived at this: An autonomous agent, or a collection of them in an environment, is a nonequilibrium system that propagates some new union of matter, energy, constraint construction, measurement, record, information, and work. It is a new organization of process and events. The collective behaviors of coevolving autonomous agents have, over the past four billion years, constructed a biosphere. If life is common, the elaboration of biospheres in the universe is rife. The propagating union of work cum record cum measurement cum constraint construction, the propagation of organization unfolding and diversifying, exhibits the very creativity of the universe. We are entitled to ask whether there may be general laws governing such nonequilibrium self-constructive processes in biospheres and the universe as a whole. I return to candidate general laws in chapters and .









Chapter 3
Autonomous Agents
Some wellspring of creation, lithe in the scattered sunlight of an early planet, whispered something to the gods, who whispered back, and the mystery came alive. Agency was spawned. With it, the nature of the universe changed, for some new union of matter, energy, information, and something more could reach out and manipulate the world on its own behalf. Selfish? Yes. But how does matter, energy, information, and something else miraculous become selfish? From that miracle grew a biosphere = and, we must surmise, from that grow other biospheres, scattered seeds and gardens across the cosmos.
Pregnant in the birth of the universe was the birth of life. Agency may be coextensive with life. Life certainly burgeons nowhere without agency. We all act on our own behalf. In the Kantian form: What must something be such that it can act on its own behalf?
I will hazard again my tentative answer, baldly now, then return to it: An autonomous agent must be an autocatalytic system able to reproduce and able to perform one or more thermodynamic work cycles.
The thrashing E. coli swimming upstream in a glucose gradient is an autocatalytic system able to reproduce. In its swimming, it is carrying out one or more thermodynamic work cycles. Can I deduce this tentative definition from some more primary categories? I do not know how. At the beginning, I jumped = more realistically, I struggled = for weeks searching for a constellation of properties that seemed promising, in order to articulate something I sensed but could not yet say. It has taken four more years to understand more of what I still can only partially say in these investigations.
Definitional Jumps and Circles
What of definitional jumps in science? 
So a pause to look at such jumps, to new clusters of concepts that, whole cloth, change how we carve up the world. Consider Isaac Newton and his famous F = MA, force is equal to mass times acceleration. It all seems sensible. If a log lies on an iced pond and I push it, it accelerates. If I push harder, it accelerates faster. If there are two logs, one on top of the other, and I push, the two accelerate less rapidly than if there were one log.
“I make no hypotheses,” stated Newton. Yet Poincaré, two centuries later, argued that Newton’s brilliant move was definitional. The three terms, F, M, and A = force, mass, and acceleration = argued Poincaré, admit no independent definitions. Acceleration is independently definable by the metric concepts of distance, motion, time, the rate of change of position with time = velocity, and the rate change of velocity with time = acceleration. But force and mass are, said Poincaré, joined at the hip, codefined, one in terms of the other. Mass is that which resists acceleration by force. Force is that which induces acceleration when applied to a mass. 
The equation F = MA is a definitional circle, according to Poincaré. Many physicists disagree with Poincaré. I tend to agree, but then I am not a physicist, so take care.
On the other hand, the great twentieth-century philosopher Ludwig Witt-gen-stein said something similar in his majestic Philosophical Investigations. Witt-genstein came to his revolutionary investigations painfully, ultimately rejecting his own earlier triumph in the Tractatus. Indeed, part of why I have so blatantly borrowed Wittgenstein’s title, without my presumption to similar intellectual stature, is that there is a parallel between Wittgenstein’s abandonment of the Tractatus and growing awareness of knowing as living a language game, and a central theme of this Investigations, that there may be a limit to the way Newton taught us to do science and a need to reformulate what we do when we and other agents get on with living a life. As we will see, in both cases, it appears that something profound is going on in the universe that is not finitely prestatable. Life and language games seem persistently open to radical innovations that cannot be deduced from previous categories and concepts. I will only be able to discuss these issues more fully after we have encountered autonomous agents and their unfolding mysteries.
In his early Tractatus, Wittgenstein had brought to conclusion the mandate of logical atomism from Russell. Logical atomism sought a firm epistemological foundation for all knowledge in terms of privileged “atomic statements” about “sense data.” The idea, flowing from Hume to Berkeley to Kant then back to British empiricism, was the following: One might be mistaken in saying that a chair is in the room, but one could hardly be mistaken in reporting bits and pieces of one’s own awareness. For example, “I am having the experience of a brown color”; “I am aware of the note A-flat.” These statements were thought to record sense data and to be less susceptible to error than statements about the “external world” of chairs, rocks, and legal systems. Logical atomism sought to reconstruct statements about the external world from logical combinations of atomic statements about sense data. The Tractatus sought to bring that program to fruition   .   .   .    and nearly succeeded.
It was Wittgenstein himself who, twenty years later, junked the entire enterprise. Philosophical Investigations was his later-life revolution. His revolution has done much to destroy the concept of a privileged level of description and paved the way to an understanding that concepts at any level typically are formed in codefi-nitional circles. Newton was just ahead of his time.
You see, even in the case of the physical chair, the idea that we can reconstruct statements about chairs as equivalent to combinations of statements about sense data fails. The failure is deep and will have unfolding resonances with the mysteries of autonomous agents. The program to replace statements about physical objects with sets of statements about sense data requires “logical equivalence.” Logical equivalence means that wherever a statement about a chair occurs at a “higher level” of description, it must be possible to specify a list of statements about sense data whose truth are jointly necessary and suYcient for the statement about the chair to be true. For example, the statement, “There is a Windsor rocker in the living room,” must be implied by, “I seem to be seeing a brown surface with a given shape,” “I feel a hard surface,” and also, “When I push the top of the shape, I observe an oscillatory motion of the brown surface.”
The trouble is, it appears to be impossible to finitely prespecify a set of statements about sense data whose truth is logically equivalent to statements about chairs. What if the observer were colorblind, or blind, or deaf, or not in the room but might enter the room wearing hobnailed boots, fall on the chair, and break it? Could we finitely specify the list, “If I were to enter the room, I would have the following sense data; and if one who is red-green colorblind were to enter the room he or she would have the following sense data; and if the rocker were to be on a soft rug, the sounds that would be heard by one who is A-flat tone deaf would   .   .   .   . To achieve this end, we would have to be able to finitely prespecify something about a set of statements concerning atomic sense data statements whose truth would be necessary and suYcient to the truth of a statement about the Windsor chair in the living room.
The problem, briefly, is that there appears to be no finitely prestatable set of conditions about sense data statements whose truth is logically equivalent to any statement about a real physical chair in a living room.
Wittgenstein invented the concept of a “language game,” a codefined cluster of concepts that carve up the world in some new way. Consider, he said, legal language, and try translating it to ordinary statements about human agents without using legal concepts. So consider, “The jury found Henderson guilty of murder.” We understand this statement but do so in the context of law, evidence, legal responsibility, trials, guilt and innocence, jury systems, bribing jury members, appeal processes, and so forth. Now try to translate the statement into a set of statements about ordinary human actions, “A group of twelve people were seated behind a wooden enclosure for several days. People talked about someone having died of poison. One day, the twelve people left the room and went to another room and talked about what had happened. Then the twelve people came back and one man stood up and uttered the words, ‘We find Henderson guilty of murder.’”
There is no finitely prespecifiable list of statements about ordinary human actions whose truth would be necessary and suYcient for the truth of the statement that the jury found Henderson guilty of murder.
Another example concerns the United Kingdom going to war with Germany. There is no finitely prespecifiable set of ways this must happen. Thus, the queen, one day after tea, might betake herself to Parliament and cry, “We are at war with Germany!” Or the prime minister might in Parliament say, “Members, by the authority of my oYce I declare that we are at war with Germany!” Or ten thousand irate football fans from Leeds might shoulder picks, take to barges, funnel in fury up the Rhine, and attack football fans in Koblenz. Or   .   .   .   . In short, there is no prestatable set of necessary and suYcient conditions about the actions of individual humans for the United Kingdom to manage to go to war with Germany. (And may neither nation again find a way to make war on the other in the future.)
Wittgenstein’s point is that one cannot, in general, reduce statements at a higher level to a finitely specified set of necessary and suYcient statements at a lower level. Instead, the concepts at the higher level are codefined. We understand “guilty of murder” within the legal language game and thus in terms of a codefining cluster of concepts concerning the features noted above = law, legal responsibility, evidence, trial, jury.
Useful new concepts arise in codefining clusters. It is fine that F = MA is circular, Poincaré might say, for the codefining circle is at the center of a wider web of concepts, many of which have reference to the world; hence, the web of concepts touches, articulates, discriminates, and categorizes the world.
So too did Darwin jump to a new definitional circle with his concept of natural selection, heritable variation, and fitness. Many have worried that natural selection and fitness, which is defined as an increased expected number of oVspring, are a definitional circle. Like F = MA, the definitional circle is virtuous.
So too I jump to the tentative definition, “An autonomous agent is a system able to reproduce itself and carry out one or more thermodynamic work cycles.” Actually, at this stage my own tentative definition is not circular because “reproduce itself” and “work cycle” are definable independently. But as we delve further into the concept of an autonomous agent in succeeding chapters, cyclic definitions arise concerning “work,” “propagating work,” “constraints,” “propagating organization,” “task.” I hope that the circle is virtuous and brings us toward a new understanding of “organization” itself.
In short, unpacking this definition will lead us into odd territory. Part of the oddness is the question of just what is the proper mathematical form to describe an autonomous agent. Is it a number, hence, a scalar? A list of numbers, hence, a vector? A tensor? I think not. An autonomous agent is a relational concept. In a later chapter I will suggest a spare mathematical form for an agent derived from category theory. This attempt is better than nothing, but I am not persuaded that eVort is satisfactory, for the mathematical mappings of category theory are themselves finitely prestatable and a biosphere, I both fear and celebrate, is not. Somethings new are needed.
Autonomous Agents
Well, let’s have at it. I begin with the cornerstone of thermodynamics, the Carnot cycle.
Sadi Carnot was a French engineer writing in the 1830s. The French had recently lost the Napoleonic Wars, Waterloo had come and gone, a certain famous statue to Wellington had been erected in London. Carnot, like others at the time, realized that part of the success achieved by the English had to do with early industrial economic power. The Brits had large numbers of steam pumps that were able to clear water from coal and iron mines, allowing miners to work under bad but relatively dry conditions and extract coal and iron more eVectively than could their French counterparts. The coal and iron in turn were worked into the machinery of the Industrial Revolution and cannons and also, notably, more steam pumps that could keep the mines in working condition. I find it fascinating that the British system was an autocatalytic technology, iron and coal fueled the manufacture of pumps that abetted the mining of iron and coal.
Carnot set about understanding the fundamentals of the extraction of mechanical work from thermal energy sources. The result of his eVort was an analysis of an idealized device to extract mechanical work from heat, the Carnot cycle. Carnot titled his work “An Investigation on the Motive Force of Heat.”
A second point of fascination is that Carnot carried out his crucial analysis just as steam was becoming established as a source of mechanical work. It is almost certainly not a coincidence that the impulse to investigate the central nature of autonomous agents arises just as we are on the threshold of creating such molecular systems. Science, technology, and art tumble into the adjacent possible in roughly equal and yoked pace.
Figure 3.1 shows the essentials of Carnot’s idealized machine. There are two heat reservoirs, one hotter than the other, T1 > T2. Between the two heat reservoirs is a cylinder with a piston inside. The space between the top of the piston and the head of the cylinder is filled with an idealized “working gas,” which can be compressed and can expand. As a real, and certainly an idealized, gas is compressed, the gas becomes hotter; as the gas expands, it becomes cooler.
I will modify the Carnot machine in one central way, which does not alter but rather makes explicit an important feature of the actual working of the Carnot machine. I will attach a red handle to the cylinder, as shown in Figure 3.1. The Carnot cycle begins with the piston pressed up near the top of the cylinder, the working gas is compressed and hot, indeed, it is as hot as the high temperature T1. You will operate the machine. You pull on the red handle, sliding the cylinder (frictionlessly) into contact with the high-temperature reservoir, T1. You then let go of the red handle and allow the working gas in the cylinder to expand, thereby pushing the piston downward away from the head of the cylinder, in the first part of the power stroke of the Carnot engine.
As the power stroke initiates, the working gas expands and starts to cool. However, thanks to the fact that the cylinder is now in contact with the hot thermal reservoir, heat flows into the cylinder from T1 and maintains the working gas almost at the constant temperature T1. Indeed, if the Carnot engine is operated slowly enough, the temperature remains constant. Such slow operation is said to be reversible. If the engine is operated more rapidly, hence irreversibly, the temperature is held nearly constant during this part of the power stroke, thus this section of the power stroke is called the “isothermal expansion portion” of the Carnot work cycle.
It is not only convenient but central to understanding a Carnot engine to plot the state of the system in a Cartesian coordinate system in which the x-axis corresponds to the volume of the working gas, while the y-axis corresponds to the pressure of the gas (Figure 3.2). The work cycle began with the piston near the top of the cylinder, the working gas hot and compressed. As the isothermal expansion phase of the power stroke happens, the pressure falls slightly, while the volume increases appreciably. The corresponding segment of the work cycle connects the starting position in Figure 3.2, position 1, to position 2 by a line segment representing the simultaneous values of volume and pressure during the isothermal expansion part of the power stroke.
You initiate the second part of the power stroke by pushing on the handle and moving the cylinder out of contact with the hot T1 reservoir to a position between the two heat reservoirs, touching neither. You immediately let go of the handle. The working gas continues to expand, pushing downward on the piston and moving it away from the head of the cylinder. However, because the cylinder is out of contact with T1 and the working gas is expanding, the working gas gets noticeably cooler, so pressure drops appreciably while volume increases slightly. This part of the power stroke is called “adiabatic expansion.” In Figure 3.2, the adiabatic expansion step carries the system from step 2 to step 3, the end of the power stroke, a point where the pressure is at the lowest point, and the volume of the working gas is at the highest point of the work cycle.
Now in order to return the Carnot engine to its initial state, 1 (in Figure 3.2), such that the working gas can again expand and do mechanical work on the piston, work must be done on the engine to bring the piston back up to its position near the head of the cylinder and to recompress and reheat the working gas so that its temperature and pressure values, or state, correspond to state 1. If the work done on the Carnot engine simply retraced the exact pathway from step 3 to step 2 to step 1, at least as much work would have to be done on the Carnot engine as the engine released in the power stroke in going from 1 to 2 to 3. If so, no net work would be carried out by the Carnot engine on the external world.
Instead of retracing the power stroke pathway, the Carnot engine, and all heat engines, use a simple trick. You will do it. At step 3, the end of the power stroke, you push on the handle, pushing the cylinder into contact with the low-temperature reservoir, T2. Indeed, you have arranged things such that at the end of the power stroke the working gas is itself at this lower temperature, T2.
With the cylinder in contact with T2, you now run around to the base of the cylinder, where a stout handle is attached to the piston and extends beyond the cylinder’s base. You push on the handle, pushing the piston upward in the cylinder, thereby compressing the working gas. As you do this work on the piston, the compressing gas tends to heat up. But thanks to contact with the low-temperature reservoir, the heat generated by compression in the working gas diVuses into the cool T2 reservoir, holding the working gas only slightly warmer than T2. Thus volume decreases appreciably, while pressure increases slightly.
The point of this trick is that it requires less work to compress a gas that remains cool than one that heats up. Because the working gas is held at nearly a constant temperature T2, this part of the compression stroke is called “isothermal compression,” and it carries the system in its volume-pressure state space from position 3 to position 4 in Figure 3.2.
At the end of the isothermal compression stroke, you do your part again. You pull on the handle, pulling the cylinder out of contact with the cool T2 reservoir to a position between T2 and T1, touching neither. Then you return to push on the handle connected to the piston, further compressing the working gas. Due to the compression of the working gas and the fact that it is not in contact with the cool T1 reservoir, the working gas heats up, so the pressure increases appreciably while the volume decreases slightly, as the gas is compressed until the initial state of hot compressed gas, step 1, is achieved. The work cycle is now complete. The connected set of four lines in Figure 3.2, from step 1 to 2 to 3 to 4 to 1, depicts the sequence of pressure volume states of the working gas around the work cycle.
I have emphasized the role of you and the red handle in carrying us through the work cycle. In a real engine, of course, the role of the red handle is carried out by various gears, rods, escapements, and other mechanical devices that serve an essential role: The handle and you, or the gears, rods, and escapements, literally organize the flow of the recurrent process. I will return to this organization of the flow of process in a machine or an autonomous agent. The Carnot cycle is involved with the organized release of thermal energy in achieving recurrent mechanical work. The organization of work is essential = and will be central = to thinking about what occurs in an autonomous agent. Indeed, part of what we need is a way of characterizing the organization of real processes in the nonequilibrium world. I do not think we have, as yet, an adequate concept of organization.
The first question I want to raise about the Carnot cycle is this: Why is it a “cycle”? There is a clear sensible answer. The Carnot cycle operates in a cycle, as does a steam engine, gasoline engine, or electric motor, precisely because at the completion of one cycle the total system is returned to the same initial state as at the start of the cycle. Because of this, the organization of the process, achieved by the actual gears, rods, and escapements that coordinate the relative motion of the parts of the engine, has returned to the initial configuration from which, with no further ado, the system can again perform a work cycle. Thus in the case of the Carnot engine, the system performs mechanical work on the piston in a work cycle that, in net, transfers heat from the hot reservoir to the cold reservoir. At the end of the cycle, the Carnot engine returns to the initial state with the piston raised and filled with hot compressed gas at the temperature of the hot reservoir. The Carnot engine is all set as a total organization to receive another input of heat energy and perform another work cycle.
Suppose that there were no cycle? For example, a cannon fires a cannonball that hits a standing steel beam that is knocked over and hits a lever arm tossing a ball on its opposite end into the air which then falls to the ground and stops. To get the contraption to do it again would require that somehow the cannon be reloaded, the steel beam be reset on end, the lever arm to be reset with a ball on its other end. Where is all this organization of processes and events to come from? I will return to these issues in the next chapter, but notice for now that the cyclic organization of processes in the Carnot, the steam, the gas, and the electric engines achieve the requisite organization precisely because the system works as a cyclic process. 
A second issue concerns a well-known feature of the Carnot engine that is very much worth comment here. If the sequence of steps is run in the reverse directions, so that the engine is run from state 1 to 4 to 3 to 2 to 1, the Carnot engine is not performing as a pump at all. It is, instead, performing as a refrigerator. Run in the reverse direction, the Carnot engine uses mechanical work to pump heat from the cool reservoir, T2, to the hot reservoir, T1, making T2 cooler.
Now, heat does not spontaneously flow from cooler to hotter objects, making the cooler objects even cooler. So two points leap to attention here. First, the same device, the Carnot engine, can be a pump or be a refrigerator, depending upon the order of the operations. In fact, I am cheating a bit, for the organization of gears and escapements would diVer in achieving the sequence of states 1, 2, 3, 4, 1 versus 1, 4, 3, 2, 1. But essentially the same machine can perform two very diVerent functions, or tasks, pumping in one case, cooling in the other.
The third point, of course, concerns spontaneous processes and nonspontaneous processes. It took more than fifty years from Carnot’s work to really begin to understand thermodynamics = the first law, conservation of energy; the famous and mysterious second law and its handmaiden, entropy; the third law concerning a zero temperature at which molecular motions stop = and for the invention of statistical mechanics to connect thermodynamics and Newtonian mechanics.
Some processes occur spontaneously, some conceivable processes do not. One of the most obvious cases is that if a hot gas is in contact with a cold gas, the two will in due course come to be the same temperature. Heat spontaneously “diVuses” from the hot to the cold object, cooling the former, warming the latter. In statistical mechanics we think of “hot” as corresponding to atoms moving rapidly, hence, with high kinetic energy. When these high-kinetic-energy atoms interact with slower-moving sets of atoms, the collisions transfer kinetic energy to the slower-moving atoms, speeding them up and slowing down the faster-moving atoms. Eventually, the atoms in the two sets come to have the same statistical distribution of motions, hence kinetic energy and hence temperature, where “temperature” is now understood to correspond to the average kinetic energy of the particles in the system.
The apparently mysterious second law of thermodynamics states that the entropy of a system is either constant or increases. The modern understanding of entropy can be stated roughly with the help of the concept of a 6N-dimensional phase space. 
Consider an isolated closed thermodynamic system, say, an ideal gas in a thermos bottle. Let there be N gas particles in the bottle. Now, each particle is in motion in real three-dimensional space; therefore, we can pick an arbitrary three-dimensional coordinate system, with length, width, and height (x, y, and z). We can note the current position of any particular particle in the bottle at any moment on each of the three positional coordinates. In addition to having a position, each particle may be in motion, it may have a velocity and an associated momentum in some direction in the bottle. Using Newton’s vectorial composition of forces rules, we can decompose the motion of the real particle into its motions in the x direction, the y direction, and the z direction. The momentum in each of these directions is just the mass of the particle times its velocity in that direction. Newton’s vector composition rule says that we can recover the motion of the initial particle by constructing the obvious parallelogram that adds the x, y, and z velocity or momentum vectors back together.
So for each particle we can represent its position and momentum in three spatial directions by 6 numbers. We have N particles in the bottle, so we can represent the current positions and momenta of all N particles at any instant in time by 6N numbers. DiVerent combinations of positions and velocities now correspond to diVerent sets of 6N numbers. And, as the N particles in the bottle collide and exchange momenta, bouncing oV in new combinations of directions with new combinations of velocities according to Newton’s three laws of motion, the 6N numbers representing the system at each moment change in time through some succession of 6N numbers. If we think of all the possible values of the positions and velocities of the N particles in the bottle, that set of possible values is the 6N-dimensional phase space of our system. The system starts at some single combination of 6N numbers, hence a single state in the phase space. Over time, as positions and momenta change, the 6N numbers change and the system flows along a trajectory in phase space.
Now here is the heart of the second law: Some of the positions in the 6N-dimensional phase space correspond to states in which all the particles are more or less uniformly spread throughout the bottle and are moving with more or less the same velocities. Other positions in the 6N-dimensional phase space correspond to unusual situations, in which all the particles are located near the top of the bottle, are along the walls of the bottle, are moving in the same direction in the bottle, and so forth.
Consider mathematically breaking up the 6N-dimensional phase space into a very large number of tiny 6N-dimensional “cubes” that together add up to the entire 6N-dimensional phase space. If the cubes are small enough, then each cube corresponds to a quite similar set of states. One cube might correspond to all the particles flowing downward in the bottle, another cube might correspond to a near uniform distribution of positions and momenta.
It is easy to see intuitively that there are many more combinations of positions and momenta that correspond to nearly uniform positions of the particles and their motions scattered in all possible directions than there are combinations of positions and momenta that correspond to all the particles being located in a specific small region of the bottle. In order to quantify this intuition, statistical mechanics counts the numbers of small 6N-dimensional cubes corresponding to each such “macroscopic” state of the gas. Vastly many more small cubes correspond to the “macrostate” in which particles are nearly uniformly distributed and are moving in all the possible directions with velocities bunched around an average velocity = hence kinetic energy = than for any other macrostate, such as the macrostate corresponding to all the particles being located near the top of the bottle.
We are almost home free. We need one more premise = the famous “ergodic hypothesis.” This hypothesis asserts that the trajectory of states leading from the initial state in a long stringlike “walk” will, over time, spend as much time in any small 6N cube as in any other cube. In short, the ergodic hypothesis asserts = indeed, assumes = that the system will wander around its phase space such that after a long time it will have spent as large a fraction of its time in any one tiny cube as any other cube.
But now we are home free. Since vastly many more small cubes correspond to the nearly uniform distribution of particles, moving in all possible directions but bunched around an average velocity, it follows from the ergodic hypothesis that the system will have spent most of its time in this “equilibrium” macrostate.
The second law, in its modern understanding, is simply the statement that an isolated thermodynamic system will tend to flow away from improbable macrostates = corresponding to very few of our tiny 6N-dimensional cubes = and flow into and spend most of its time in the equilibrium macrostate for no better reason than that that macrostate corresponds to vastly many small 6N cubes in the entire 6N-dimensional phase space. The increase of entropy in the second law is nothing but the tendency of systems to flow from less probable to more probable macrostates.
The physical concept of entropy of a macrostate is understood, since Ludwig Boltzmann in the last century, to be proportional to the logarithm of the number of small 6N-dimensional cubes that correspond to that macrostate. The increase of entropy in spontaneous processes is then the tendency to flow from macrostates comprised of a small numbers of 6N-dimensional cubes, or “microstates,” to macrostates comprised of a very many microstates.
Our next step in thinking about autonomous agents requires us to consider again the concept of a “catalytic task space” and the character of autocatalytic sets in the context of catalytic task space. In the first chapter I described the basic framework, due to Alan Perelson and George Oster, of an abstract shape space, where each point would represent a molecular shape. Shape space has at least the three spatial dimensions of length, height, and width, but in addition it has properties reflecting the features of clusters of atoms that contribute to an eVective molecular shape, that is, to those features that collectively might be “recognized” by another molecule that bound the shape in question. Such additional molecular features may include electric charge, dipole moment, hydrophobicity, or other features. At present, it is a reasonable guess that shape space is between five and seven dimensional. If true, this would not mean that there are five familiar features, three spatial and two others, that constitute the dimensions of shape space. Rather, some odd combination of several physical properties = partially charge, partially dipole moment, or partially hydrophobicity and partially dipole moment = might be the dimensions that matter.
In any case, we are to consider a bounded shape space with maximum and minimum values for each axis. A shape is a point in shape space. Thus, a molecular feature on a virus antigen, an epitope, is a point in shape space. An antibody might bind that epitope and a family of similar shapes filling a ball in shape space. As remarked above, very diVerent molecules can have eVectively the same shape, so endorphin and morphine both bind the same endorphin receptor. A finite number of balls will “cover” shape space, and the immune repertoire of perhaps a hundred million antibodies may well cover shape space.
Catalytic task space, you recall, simply applied the concept of shape space to catalysis. A point in catalytic task space now represents a catalytic task. A given chemical reaction constitutes a catalytic task. As in shape space, similar reactions constitute similar catalytic tasks. As in shape space, diVerent reactions can constitute essentially the same catalytic task. An enzyme covers some ball in catalytic task space, comprising the set of reactions it can catalyze. And as noted before, according to transition state theory a catalytic task corresponds to a catalyst binding the distorted, hence high-energy, molecular configuration corresponding to the transition state of a reaction with high aYnity and binding the substrate and product states with, in general, lower aYnity.
In terms of catalytic task space, what is a collectively autocatalytic set? Consider a simple case. Two peptides, A and B, form a collectively autocatalytic set if A catalyzes the formation of B from two of B’s fragments, while B catalyzes A from two of A’s fragments. Then consider two balls in catalytic task space, the first ball, covered by A, constitutes the catalytic task in which two fragments of B are ligated to form B. The second ball, covered by B, constitutes the catalytic task in task space in which two fragments of A are ligated to form A.
The first feature of a collectively autocatalytic set is what I call “catalytic closure.” Every reaction that must find a catalyst, does find a catalyst. The formation of A requires B, and the formation of B requires A. It is important to notice that this closure in catalytic task space is not “local”; there is no single reaction in this collectively autocatalytic set that by itself constitutes the closure in question. In a clear sense, the catalytic closure is a property of the whole system.
A second feature to notice is that A and B as catalysts do not by themselves constitute the closure in question; A and B might catalyze a variety of reactions. In particular, if B is presented with the two “proper” fragments of A, call them A’ and A”, then B will ligate A’ and A’’ to form A. But if B were presented with other substrates, say Q and R, then B might catalyze a reaction transforming Q and R into two other molecular species, S and T. Similarly, A, as a catalyst, will ligate two proper fragments of B, B’ and B’’ to form B. But A, if confronted with two other substrates, say, F and G, might catalyze their ligation to form a single third molecule, H.
While the set A, B, A’, A”, B’, B’’ is collectively autocatalytic, forming more A and B from a substrate pool of A’, A”, B’, and B”, it is not the case that the set A, B, Q, R, F, and G is collectively autocatalytic, for the products of the reactions catalyzed by A and B, namely S, T, and H, are not themselves the catalysts A and B.
In short, the closure of catalytic tasks requires specification of the catalytic tasks themselves plus the specific substrates whose products, here A and B, constitute the very catalysts that carry out the catalytic tasks in question.
The closure of an autocatalytic set and set of catalytic tasks has a kind of dualism. From the point of view of the molecules involved, the specific catalytic tasks constitute the avenues of release of chemical energy by which the molecular system reproduces itself. The tasks coordinate the flow of atoms among the molecules whereby the set reforms itself. From the point of view of the tasks, the molecular species manage to carry out the tasks repeatedly, with no further molecular species being necessary to carry out the tasks. The molecules carry out the tasks, the tasks coordinate, or organize, the processes among the molecules.
The coordination aVorded by the catalytic tasks that are jointly present and fulfilled is highlighted if we recall that, in general, two molecular species, say, A’ and A”, might undergo a variety of diVerent reactions that form, in addition to A, perhaps E, L, M, P, and other molecular species. The specific catalytic task that carries A’ and A’’ to A in the presence of a catalyst, B, speeds that specific reaction in comparison to the alternative reactions forming E, L, M, and P. Thus, the closure of the catalytic tasks, substrates and catalysts, A, B, A’, A”, B’, B”, achieves a coordination, or organization, of the flow of matter and energy into the autocatalytic system.
The organization achieved by the closure of catalytic tasks is similar to the organization achieved by the gears and escapements together with the rest of the idealized Carnot engine. The flow of process is marshaled into an organized whole. In the case of the autocatalytic set, the set reproduces itself. It also seems worth stressing that this closure in catalytic task space is a new concept with real physical meaning. It is a matter of objective fact whether or not a physical reaction system achieves catalytic closure; the hypothetical AB system above, and any free-living cell, achieves catalytic closure.
A final preliminary will bring us to our attempted definition of an autonomous agent. This preliminary is based on the distinction, noted above, between spontaneous and nonspontaneous chemical reactions. At equilibrium, the net rate of formation or destruction of each molecular species is zero, aside from small fluctuations that damp out. Thus, if two molecular species, X and Y, interconvert, the equilibrium is attained at that ratio of X and Y concentrations at which Y converts to X as fast as X converts to Y. If the reaction is displaced in one direction, say there is a higher X concentration than the equilibrium ratio, then the spontaneous, or exergonic, reaction proceeds in the direction toward equilibrium that reduces the excess of X concentration (Figure 3.3).
All spontaneous chemical reactions, if coupled to no other source of energy, are exergonic. On the other hand, if some other free energy source is coupled to the reaction, the reaction can be driven “beyond equilibrium” by using some of the energy source. Reactions that are driven beyond equilibrium by addition of free energy are called endergonic. Thus X might convert to Y, and this reaction might be coupled to another source of free energy, such that the steady state concentration of Y is much higher than the normal equilibrium X:Y ratio (Figure 3.3).
In the Carnot cycle, completion of the work cycle involved the cylinder piston system doing exergonic work on the external world during the power stroke, then the outside world doing work on the cylinder piston system when you pushed on the piston to recompress the working gas. The Carnot cycle links mechanical and thermal energy sources into a work cycle. A chemical reaction network with a work cycle will have to link spontaneous, exergonic and nonspontaneous, endergonic reactions into the chemical analogue of a work cycle. Like the cyclic Carnot engine, the chemical analogue will have to work in a cycle of states, like the 1, 2, 3, 4, 1 cycle of the Carnot cycle. Further, in order for the cycle to operate at a finite rate, hence irreversibly, the autonomous agent must be an open thermodynamic system driven by outside sources of matter or energy = hence “food” = and the continual driving of the system by such “food” holds the system away from equilibrium.
In this light, think again of the Ghadiri autocatalytic system, the 32-amino-acid sequence A that ligates two fragments A’, a 15-amino-acid fragment, and A”, a 17-amino-acid fragment, into A. This reaction is purely exergonic. The reaction proceeds from the substrate fragments A’ and A’’ to form the product molecule A and approaches the equilibrium ratio of substrates to product. Ghadiri’s autocatalytic system is wonderful, but merely exergonic. It does not achieve a work cycle. In general, autocatalytic and collectively autocatalytic systems can be purely exergonic. In any such case, no work cycle is achieved.
Now we can return to my jumped-to definition: An autonomous agent is a reproducing system that carries out at least one thermodynamic work cycle. That bacterium, sculling up the glucose gradient, flagellum flailing in work cycles, is busy as hell doing “it,” reproducing and carrying out one or more work cycles. So too are all free-living cells and organisms. We do, in blunt fact, link spontaneous and nonspontaneous processes in richly webbed pathways of interaction that achieve reproduction and the persistent work cycles by which we act on the world. Beavers do build dams; yet beavers are “just” physical systems.
But Reza Ghadiri’s example of an autocatalytic peptide doesn’t make the grade, nor does Gunter von Kiedrowski’s autocatalytic hexamer DNA or collectively autocatalytic set of two DNA hexamers. All these systems are merely exergonic. No work cycle is performed.
Now that we have stated our proposed definition of an autonomous agent, it is not too hard to imagine a chemical realization. In Figure 3.4 I show a hypothetical molecular autonomous agent. Given visualization of a first case, I expect that we will be constructing molecular autonomous agents within a few years.
Figure 3.4, our first example of a candidate molecular autonomous agent, is “constructed” to link with two further molecular systems, the exergonic auto-catalytic system developed by Gunter von Kiedrowski based on ligation of two DNA trimers by their complementary hexamer. Here, the hexamer is simplified to 3’CCCGGG5’, and the two complementary trimers are 5’GGG3’ + 5’CCC3’. Left to its own devices, this reaction is exergonic and, in the presence of excess trimers compared to the equilibrium ratio of hexamer to trimers, will flow exergonically toward equilibrium by synthesizing the hexamer. Because the hexamer is itself the catalyst for the reaction, the synthesis of hexamer is autocatalytic.
The first additional system consists in pyrophosphate, PP, a high-energy dimer of monophosphate that breaks down to form two monophosphates, P + P. Like any reaction, the reaction converting PP to P + P has an equilibrium, hence an equilibrium ratio of PP and P. In the presence of excess PP compared to equilibrium, the reaction flows toward equilibrium by the spontaneous cleavage of PP to yield P + P.
My purpose in invoking the exergonic conversion of PP to P + P is to utilize the loss of free energy in this exergonic reaction to drive the DNA trimer-hexamer reaction beyond its own equilibrium, leading thereby to an excess synthesis of the 3’CCCGGG5’ hexamer when compared to its equilibrium concentration. Thus, the excess synthesis of the hexamer, which would not occur spontaneously, is driven endergonically by being coupled to the exergonic breakdown of PP to P + P (Figure 3.4). In short, the exergonic breakdown of PP to P + P supplies the free energy to drive the excess buildup of 3’CCCGGG5’ concentration beyond its own equilibrium with respect to its trimer substrates, 5’GGG3’ and 5’CCC3’.
The excess synthesis of 3’CCCGGG5’ constitutes excess reproduction of the hexamer autocatalytic reaction product beyond that which would occur without the coupling to the additional PP free energy source. Thus, the system is reproducing “better” with the coupling to PP than without the coupling.
Another point to note is that the coupling of the breakdown of PP to P + P with the excess synthesis of the DNA hexamer compared to the equilibrium concentration of the DNA hexamer means that energy is stored within the system. This is true because the excess concentration of the hexamer DNA, compared to its equilibrium, could in principle be released by degradation of the hexamer to the two trimer substrates, releasing that stored free energy as this reaction couple flowed toward its own equilibrium ratio of hexamer and trimers. Thus, the coupling to the PP to P + P reaction means that the autonomous agent stores energy internally. Later in evolution, such internally stored energy can be used to drive reactions that correct errors, as in DNA repair in contemporary cells. I am glad to thank Phil Anderson and, indirectly, John Hopfield for this point.
Once the pyrophosphate, PP, is cleaved to form P + P, as this reaction flows toward its own equilibrium ratio of PP to P, that free energy is used up. In order to have a renewed internal supply of the free energy needed to synthesize excess hexamer, it is convenient to resynthesize pyrophosphate from the two monophosphates, P + P. I’ll return below to the meaning of “convenient,” for in a general sense, the convenience reflects the organization of processes that sustains an agent, and that organization is not convenient, it is essential.
Resynthesis of PP from P + P requires the addition of free energy. This is true because we used the exergonic breakdown of PP to P + P to drive the excess synthesis of 3’CCCGGG5’. Now we need to add energy to resynthesize PP from P + P. To do so, I invoke an additional source of free energy in the form of an electron, e, which absorbs a photon, hv; is driven endergonically to an excited state, e*, and falls back exergonically to its low-energy state, e, in a reaction that is coupled to the synthesis of PP from P + P.
The point of this third reaction-couple is clear: PP is resynthesized from P + P so that PP can continue to drive the excess synthesis of the DNA hexamer, 3’CCCGGG5’. Overall, the total system of linked reactions is exergonic = there is an overall loss of free energy that is ultimately supplied by the incoming photon, hv, plus the 2 substrates, 5’GGG3’, and 5’CCC3’. Thus, we are not cheating the second law.
Let’s return to the Carnot cycle, where I had you pushing and pulling on the handle and on the piston itself during the work cycle. We noted that in a real engine you would not be busy pushing and pulling. Your role in organizing the processes would be taken by gears, escapements, rods, connectors, bearings, and other bits of machinery.
I now invoke the analogue of the gears, rods, and connectors in the form of hypothetical molecular couplings that control the reactions I have already invoked. Specifically, I will assume that the hexamer, 3’CCCGGG5’, is the catalyst that couples ligation of the two trimers, 5’GGG3’ + 5’CCC3’, to the exergonic breakdown of PP to P + P. My second assumption is that monophosphate, P, binds to the hexamer and facilitates the reaction. Thus, I am assuming that P is an allosteric enhancer of the reaction. “Allosteric” means that P binds to a site on the enzyme, here the hexamer, other than the hexamer’s own binding site for the substrates. Allosteric enhancers and inhibitors are common in biological systems. 
Here, P might bind to the sugar-phosphate backbone of the DNA hexamer. This coupling implies that as PP breaks down to form P + P, the monophosphate, P, will feed back to further activate the hexamer enzyme, making the catalysis of hexamer formation even more rapid. Just such a positive feedback of a reaction product on the enzyme forming it occurs in the famous glycolytic pathway that is the core of metabolism in your cells. In fact, under appropriate experimental conditions, this positive feedback coupling can cause the glycolytic pathway to undergo sustained temporal oscillations in the concentrations of the glycolytic metabolites.
Finally, I will invoke a few more couplings. I assume that one of the trimers, 5’CCC3’, is the catalyst that couples the exergonic loss of free energy from the activated electron, e* to e, with the resynthesis of PP from P + P. And I invoke an allosteric inhibition of this catalysis by PP itself. Thus, when PP is in high concentration, it tends to inhibit its own resynthesis. But when PP concentration falls, the inhibition on PP resynthesis is removed, and PP is resynthesized. The whole molecular contraption, our first hypothetical autonomous agent, is shown in Figure 3.4.
One of the first things to note about our hypothetical autonomous agent is that it constitutes a previously unstudied class of chemical reaction networks. The behavior of exergonic autocatalytic and cross-catalytic systems is beginning to be studied. The behavior of linked exergonic and endergonic reaction networks is the very stuV of intermediate metabolism and energy’s biochemical transduction, studied for years by biochemists. But, to date, no one has begun to study linked reaction networks in which autocatalysis is coupled to linked exergonic and energonic reactions. So we are entering an entirely new domain.
Thus, our molecular autonomous agent constitutes a system with two essential features of living systems, self-reproduction and metabolism. However, my insistence that an autonomous agent carries out a work cycle refines the generally understood concept of a metabolism to include the requirement that the metabolism carries out a work cycle.
The second feature to note is that our autonomous agent is, necessarily, a nonequilibrium system. Free energy, here in the form of the photon, hv, and the trimer substrates is taken in and used to drive the linked synthesis of PP and excess DNA hexamer. There is no agency at equilibrium. The excess synthesis of DNA hexamer constitutes excess replication of the hexamer by virtue of the coupling of the trimer-hexamer synthesis to the PP  P + P cycle of reactions, which, as noted next, constitute a “chemical engine.”
The third feature to note is the work cycle performed by the agent. The simplest way of seeing the work cycle here is in the behavior of the PP  P + P reaction. In the Carnot cycle, the working gas cycles from compressed and hot to less compressed and cool, back to compressed and hot. In our hypothetical autonomous agent, there is a macroscopic cycle of matter from PP to P + P via the reaction- forming DNA hexamer and back around to PP via the reaction with the high-energy electron. The macroscopic cycling of matter around this cycle is the engine at work. (I am grateful to Peter Wills for this clarification of the concept of a chemical motor.) In addition, depending upon the details of the kinetic constants, our autonomous agent may literally show an oscillatory concentration cycle in which PP concentration begins high and falls as P + P is formed, then the high PP concentration is reformed by use of the photon-energized exergonic e*  e reaction. 
Thus, the PP P + P reaction embedded in the autonomous agent constitutes a chemical engine in which there is a macroscopic net flux of matter around the PP  P + P cycle, which is operating displaced from equilibrium as it is driven by addition of energy from the photon, hv, and addition of the two DNA trimers, and as energy is drained oV to drive excess synthesis of the DNA hexamer.
The fourth thing to note about the autonomous agent is that, like the Carnot engine, the steam engine, the gas engine, and the electric engine, the autonomous agent works in a cycle. At the end of the cycle the system is poised to cycle again. A repeating organization of process is achieved. And next, just as the Carnot engine run backward is a refrigerator and not a pump, if the reactions of the autonomous agent were run backward the PP  P + P engine would run in the reverse direction. This is because all reaction couples would be displaced from equilibrium the opposite way and the analogue of throwing the gears in reverse, namely reversing in sign the positive and negative activator and inhibitor couplings to the two proper enzymes, would convert the excess energy stored in the above equilibrium concentration of hexamer into production of the two trimers and the resynthesis of PP from P + P. Were the release of the photon, hv, a readily reversible step, the excess of PP would drive emission of a photon by the excited electron, thus returning the electron to the initial unexcited state.
In short, if the autonomous agent is run backward, the autonomous agent melts down into its foodstuV. Run backward, the system is not an autonomous agent, for it does not reproduce itself and perform a work cycle. Run backward, the system is a flashlight!
Does the autonomous agent work? The answer is yes. My colleagues Andrew Daley, Andrew Girvin, Peter Wills, and Daniel Yamins and I have simulated the system of diVerential equations that correspond to the dynamics of this autonomous-agent molecular reaction network. The diVerential equations represent the way the concentration of each chemical species in the autonomous agent changes over time as a function of its own and other chemical concentrations. In general in such mathematical models, a number of unchanging constants representing kinetic constants and other parameters enter into the diVerential equations. In the present case, the diVerential equation system has thirteen such parameters. 
The model autonomous agent system is displaced from equilibrium by the persistent addition of the two DNA trimers, 5’GGG3’ and 5’CCC3’, the removal of the DNA hexamer, and the persistent shining of photons, hv, from the outside. The chemical reaction network occurs under “chemostat” conditions. This means that all molecular constituents of the system are treated mathematically as if they were in a real well-stirred container to which the trimers and photons are added at a constant rate. In addition, the hexamer molecular components are removed from the system at an adjustable rate that holds their internal concentrations constant whatever the rate of reproduction of hexamer may be.
The autonomous agent system reproduces more eYciently with the couplings of the DNA trimer-hexamer system to the PP and electron cycles than in the purely exergonic case in which the DNA trimer-hexamer system operates alone. We measured eYciency thermodynamically as the conversion of available free energy coming into the system from the photon source into the excess hexamer with respect to the undriven steady-state rate of reaction concentration of the hexamer.
Figure 3.5 shows the results of our simulations. In these simulations of the chemical reaction network, there are, as noted, thirteen kinetic constants. We carried out computer selection experiments not only comparing the autonomous agent to a nude exergonic DNA trimer-hexamer system, but also computationally mutating the kinetic constants by small amounts and computationally evolving autonomous agents to reproduce with higher thermodynamic eYciency.
Our results demonstrate first and most important that autonomous agents operating displaced from equilibrium and utilizing a work cycle can be more eYcient at using the available free energy coming into the total system in reproducing hexamer DNA than in the absence of the coupling of the trimer-hexamer DNA system to the PP and electron-photon work cycle system. Thus, the autonomous agent as a whole, including its work cycle, reproduces DNA hexamer more rapidly than would the trimer-hexamer exergonic system alone. In short, and also important, being an autonomous agent coupling an autocatalytic system with a work cycle is of selective advantage compared to being a merely exergonic autocatalytic system.
Second, just as in the glycolytic positive-feedback case, our autonomous agent model, for appropriate values of the kinetic constants, can undergo sustained temporal oscillations of PP and other concentrations. The oscillation of PP from high concentration to low concentration then back to high concentration during the work cycle is analogous to the expansion and recompression oscillation of the working gas in the Carnot engine’s work cycle.
Third, a mountainous fitness landscape exists in the mathematical parameter space of the thirteen kinetic constants, in which some values of the kinetic constants lead to higher eYciency of reproduction than others. Darwin’s natural selection could, in principle, operate if there were heritable variation in the kinetic constants.
The main conclusion to draw from our simulation is that autonomous agents coupling one or more autocatalytic and work cycles are a perfectly reasonable, if novel, form of nonequilibrium, open chemical reaction network. There is no hocus pocus here. In the near future we will almost certainly construct such autonomous-agent molecular reaction networks and study their dynamics and evolutionary behavior. A general biology is, in fact, around the corner.
The hypothetical molecular autonomous agent that we have considered has been discussed, for simplicity, as if the problem of retaining the reactants in a confined region of space could be ignored. In fact, this assumption is an idealization. Were our autonomous agent in a dilute solution, the rates of reaction would be very slow. Actual creation of a functioning molecular autonomous agent will require that the reacting molecular species be confined to a small volume or a surface or in some other fashion.
Candidates for isolation to small volumes include micelles and liposomes. Both macromolecular aggregated structures are comprised of “amphipathic molecules,” that is, molecules with hydrophobic and hydrophilic regions such as lipids. Micelles are single-layered structures which, in an aqueous medium have hydrophilic regions directed outward, but are able to enclose an aqueous core in which the other molecular species of an autonomous agent might reside. In an aqueous medium, liposomes form double-layered membranes, homologous to cell membranes, with hydrophilic heads in the aqueous medium and hydrophobic tails abutted. In an aqueous medium, both micelles and liposomes can form and even reproduce by budding. A full-fledged molecular autonomous agent would have to synthesize the lipid or similar molecular constituents of its bounding surface and coordinate budding with dispersion of autocatalytic and work cycle partners to daughter vesicles.
An alternative to isolation of the autocatalytic and work cycle molecular species within a bounding volume is the confinement of such reacting species to a surface. Such confinement has the further advantage of altering diVusive search by reactants from a three- to a two-dimensional search process. The latter can shift the corresponding chemical equilibrium toward synthesis of larger polymers from their smaller substates. Here one can imagine confinement of reactants and products to clay surfaces or confinement of complex organic reactants and products to the surfaces of the abundant dust particles in giant molecular clouds in galaxies.
I will have much more to say in subsequent chapters about the properties of molecular autonomous agents. In particular, in order to understand agents we will have to carry out a critique of the physicist’s concept of “work,” as in a work cycle, for the best understanding of “work” appears to be that work is the constrained release of energy. Yet the very constraints on the release of energy that are essential to the doing of work themselves constitute the analogues of the gears, rods, connectors, and escapements of an ordinary machine. Most important, it typically takes work itself to construct the constraints on the release of energy that then constitutes work. In our first example of an autonomous agent, Figure 3.4, these constraints are present in the invoked couplings of catalysts and allosteric eVectors to the reactions of which the autonomous agent is comprised. I have a hunch = a deep hunch verging on conviction = that the coherent organization of the construction of sets of constraints on the release of energy which constitutes the work by which agents build further constraints on the release of energy that in due course literally build a second copy of the agent itself, is a new concept, the proper formulation of which will be a proper concept of “organization.”
In the meantime, if I am right, what did Schrödinger miss? He was right about his microcode = the microcode will reemerge as a subset of the constraints on the release of energy by which an autonomous agent builds a rough copy of itself. Namely, the microcode is the very structure of DNA, which serves as constraints on the enzymes that then transcribe and translate the code. But Schrödinger missed stating the requirement for an agent to be nonequilibrium. On the other hand, displacement from equilibrium is a necessary condition for a microcode to do anything at all. So perhaps displacement from equilibrium was implicit in his theme. More important, I think, is that he missed the concept that an agent is a union of an autocatalytic system that does one or more work cycles. This union is a new kind of dynamical system.
Now that we have seen an autonomous agent, I find myself wondering whether autonomous agents may constitute a proper definition of life itself. I make no attempt to defend my own strong intuition that the answer is yes. I suspect that the concept of an autonomous agent as an autocatalytic system carrying out one or more work cycles defines life. If so, here is the center, the elusive core of life, that examination of the molecular chunks of cells does not reveal. Most of the remainder of this book is devoted to examining the unexpected unfoldings of this tentative definition of autonomous agents and, perhaps, life. But I certainly will not insist upon my intuition. It suYces at this stage to note that all free-living systems we know = single-cell bacteria, single-cell eukaryotic cells, and multicelled organisms = fulfill my definition of autonomous agent.
If Figure 3.4 shows us a first case of a molecular autonomous agent, how broad a family of systems does the concept of an autonomous agent embrace? I confess I do not know. Clearly, there is nothing in the concept of a reproducing system that carries out at least one thermodynamic work cycle that limits such a system to DNA, RNA, and proteins. As we have seen, Julius Rebek has already created self-reproducing organic molecules well outside the familiar classes of biopolymers. If no such reproducing molecular system yet enfolds a thermodynamic work cycle, that is not to say that we shall long be stalled in creating such systems. It seems plausible that wide classes of chemical reaction networks can fulfill the criteria I have traced above. But must autonomous agents be “molecular” in the familiar sense? Could mutually gravitating systems such as galaxies fulfill the criteria? What of systems made largely of photons, self-reproducing spectra in a lasing cavity fed by a gain medium? What of geomorphology? I do not know. Perhaps it suYces at this stage to have begun an enquiry, an investigation, rather than to have completed it.
Natural Games
I turn, in the final section of this chapter, to yet another puzzle concerning what I call a natural game. A natural game is a way of making a living in an environment. That is, autonomous agents are able to act on their own behalf and regularly do so in order to make a living in an environment. The bacterium swimming upstream in a glucose gradient is making a living in its environment. So, in fact, are all free-living entities in the biosphere.
Well, it seems straightforward enough; we all know more or less what it is to make a living. For example, I am currently writing Investigations as part of my own hopefully not-too-solipsistic eVorts to make my own living as a scientist.
But natural games are not quite so straightforward. I begin by mentioning again the rather surprising no-free-lunch theorem proved by Bill Macready and David Wolpert as postdoctoral fellows at the Santa Fe Institute a few years ago. Recall that Bill and David were wondering whether there might be some search algorithm for adapting on a fitness landscape that was inherently better than all other algorithms. For example, John Holland, another Santa Fe Institute colleague, is justly well-known for inventing his “genetic algorithm” to optimize hard computational problems. The genetic algorithm, which has been rather widely used in academic and industrial settings, is based on analogy with biological adaptation driven by mutation, recombination, and selection.
In eVect, Bill and David were wondering whether biological systems in this biosphere happen to have stumbled on the best possible optimization procedure. Importantly, the answer appears to be no. Macready and Wolpert considered a mathematically well-formulated set of “all possible fitness landscapes” and showed that, averaged over all landscapes, no search algorithm outperforms any other algorithm. No free lunch.
In short, given an arbitrary fitness landscape, only some search algorithms do well on that landscape. The search procedure must be tuned to the fitness landscapes being searched if the search procedure is to be more eVective than average among search procedures.
But this poses the important problem raised in chapter 1. Most organisms are sexual, hence adapt using both mutation and recombination as part of their search procedures in making natural livings. But my own and other research demonstrates that recombination is essentially useless on very rugged fitness landscapes. For example, Mark Feldman and Aviv Bergman at Stanford have shown that if genes that evolve on rugged landscapes increase the frequency of recombination in model populations of organisms, they will not be selected to increase, hence establish, recombination. Yet most organisms are sexual and pay the twofold loss in fitness in requiring two parents rather than one. If so, presumably our biosphere is rife with the kinds of smooth correlated landscapes for which recombination is a good search procedure.
Then how is it that in our biosphere we should find a family of landscapes that happen to be well searched by recombination? Either such smooth landscapes are built into the physical nature of things or evolution has itself somehow brought forth the very kinds of landscapes that are well searched by mutation and recombination. Restated, assuming that mutation and recombination are, in fact, good search procedures for the kinds of fitness landscapes inhabited by we mere mortals as we were hanging around and adaptively hill climbing for the past four billion years, I ask again: Whence these wonderful fitness landscapes that are so well suited to be climbed by mutation and recombination?
Let’s try another tack. Assume for the sake of discussion that I am right about my formulation of molecular autonomous agents. When life = and I argue, autonomous agents = began, their diversity was low. There are now some hundred million species, representing perhaps a thousandth of the total diversity that has wandered our globe. The rest have gone extinct. Natural games, ways of making a living, have obviously coevolved with the autonomous agents, the species, making those livings. So, as I imagined Darwin telling us in chapter 1, “The winning natural games are the games the winning species play.”
Well, of course, the winning natural games are the games the winners play. But what natural games are these? The reasonable answer leaps to mind. The winning games must be those that are readily searched out by the very adaptive search procedures used by the coevolving autonomous agents themselves.
In short, a biosphere is a self-consistent coevolutionary construction of autonomous agents and ways of making a living that are themselves self-consistently well searched by the search procedures the autonomous agents are using. In colloquial terms, from our experience in economic systems, jobs come into existence with jobholders. If no one can learn or exploit a given kind of job, that sort of job will not be widely populated and will not become diVerentiated into a family of similar jobs.
In the biosphere, modes of making a living that are well-searched by mutation and recombination will be populated by many sibling species making their livings by playing slightly diVerent natural games. Those natural games, therefore, proliferate. Ways of making a living that cannot be explored successfully by mutation and recombination will not aVord new niches for many sibling species, so those natural games will not proliferate.
We are literally making our world together, we critters. If we couldn’t make livings at it given our search procedures of mutation, recombination, and selection, we wouldn’t be making our livings doing what we are doing. These comments are only the start of understanding, and I do not profess to hold much of that understanding. But I can begin to point. A biosphere is a self-consistent coevolutionary construction of autonomous agents making livings, the natural games that constitute those livings, and the search mechanisms that allow such modes of living to be persistently mastered by adaptive natural selection.
Most broadly, I believe a general biology awaits founding. And I believe that autonomous agents will prove central to that eVort. The next feature of autonomous agents that I will note in closing this chapter will be central to any general biology. Precisely because an autonomous agent links exergonic and endergonic reactions in work cycles, the breakdown of high-energy sources here can be used to build up structure and organization there. Indeed, the coevolution of autonomous agents naturally leads to a linked web of exergonic and endergonic reactions within and between the autonomous agents. Breakdown of this stuV here is linked to the excess build up of that stuV there. By these linkages, sunlight spattered carelessly on this swirl of stuV ninety-three million miles from our average star cumulates into the wondrous structure of the giant redwoods, tall on the western slopes of the United States and Canada. Precisely because autonomous agents carry out work cycles, they = we = literally build a biosphere.
And the central factors underlying that buildup of organization are the same factors that apply in an economy = that merely human extension of biospheres. The central factors, in fact, center on “advantages of trade.” We can see this keystone concept by supposing that you and I are the only members of a tiny economy. You begin life with an endowment of a thousand pears and a hundred apples. I begin life with an endowment of a hundred pears and a thousand apples. Suppose your happiness, or “utility,” would increase if you had fewer rather than more pears and more rather than fewer apples. Alas, you have more pears than apples. I, in turn, happen to have desires such that I would be happier with rather more pears than apples. Alas, I have more apples than pears.
You and I have advantages of trade. We can both be happier if we swap some of my apples for some of your pears. It is essential to understand that, indeed, both of us can be better oV by trading. Advantages of trade are the fundamental factor driving trade itself in an economy. In an actual simple economic model, advantages of trade are studied in an “Edgeworth box.” Edgeworth invented a two-dimensional box representation of values, or “worths,” plotted along the edge of his box (Figure 3.6). In the Edgeworth box, I am represented at the bottom-left corner, you are represented at the top-right corner. A family of equal happiness, or “isoutility” curves, show your “isohappiness” trade-oVs of apples and pears at any total abundance to you of apples and pears. You are, in general, happier the more total apples and pears you have. Your happiness landscape increases from low to high like a cone-shaped mountain whose peak is located over my head. On that peak, you have all the apples and pears in the system.
My isohappiness trade-oV curves begin low at the lower-left corner and mount to a peak over your head in the upper-right corner, when I would have all the apples and pears.
The curvature of my isohappiness curves and your isohappiness curves are bent such that they are convex from my and your points of view. Therefore, if the initial economy starts with you having most of the pears and I most of the apples, as shown as a point toward the lower-right of the Edgeworth box in Figure 3.6, then that initial point of the economy lies on the intersection of a specific isohappiness curve for you and an isohappiness curve for me.
And now we can see advantages of trade. Any point that lies inside the region bounded by our two isohappiness curves is, therefore, higher on your happiness landscape and also higher on my happiness landscape. Thus, anywhere inside the region bounded by our two isohappiness curves, we are both happier. We have advantages of trade within this area bounded by our two isohappiness curves.
A few more points from Economics 100. Consider the family of your isohappiness curves and the family of my isohappiness curves. Pick one of your isohappiness curves. There will be exactly one of my isohappiness curves that just touches your isohappiness curve at a single position, thus one point of tangency. Therefore, for each of your isohappiness curves, there is a unique point of tangency with one of my isohappiness curves. Therefore we can draw a line connecting those points of tangency. In particular, we can draw a line of those tangencies across the two isohappiness curves, yours and mine, that meet at the initial apple-pear distributions to you and me at the outset, before trading, and define the region where we have advantages of trade.
The line of tangency is called the “contract curve.” Along the contract curve, there is no way to exchange apples and pears that increases both our happiness. If you are happier, I am less happy. The contract curve is said to be “Pareto-eYcient.” There is no way to make you happier without making me less happy, and vice versa. In contrast, if we have not yet attained the contract curve, there are further advantages of trade that we can attain. The economic concept of “price” in this context is just the ratio of exchange between you and me, apples for pears. Evidently, if we attain one of the points on the contract curve, that corresponds to some exchange ratio and is the price of apples for pears.
Now, nothing in a one-shot exchange economy picks any particular point on the contract curve. We tussle along the contract curve, each trying to get all the advantages of the trade. But what if we could take our happiness, now call it utility or wealth, and reinvest it in making orchards that grew apples and pears? In an economy with reinvestment, what happens if we can take our advantages of trade and reinvest any excess so that we can create more apples and pears than we had to start with?
Then let me draw an analogy for bacterial species or other autonomous agents. Let happiness, or the economist’s utility, become “rate of reproduction,” hence, fitness. Let increased happiness become “increased rate of reproduction,” hence, increased fitness. Let the advantages of trade map into mutualistic interactions in which you and I, two species of autonomous agents, help one another reproduce more rapidly. Case in point: Legume root systems with microrhizzae and symbiotic fungi, in which the root and its plant capture sunlight and water and carbon dioxide and supply sugars to the fungi, while the fungi capture nitrogen from the air and fix it into amino acids and supply amino acids to the plant. Plant and fungi feed one another.
Two mutualists, A and B, can have advantages of trade. Molecules created at metabolic cost in A and secreted can help B reproduce faster. Molecules created at metabolic cost in B and secreted can help A reproduce faster. If the help is larger than the metabolic cost in both directions, both win by helping the other. Indeed, you can quickly intuit that, since both A and B will reproduce exponentially, there might be a fixed ratio of the abundance of A and abundance of B species such that each helps the other optimally. If so, then the enhancement in the growth of A and B by their mutual interaction must be the same, otherwise, either A or B would soon be exponentially more abundant than the other, and the mutual help society would fall apart.
Peter Schuster and Peter Stadler of the University of Vienna and I at the Santa Fe Institute several years ago created a simple model of two replicating RNA species, A and B, that did help one another in just these ways, and it confirmed that in the appropriate mutual help regime, the A + B mixed community outgrew A alone or B alone. Further, the growth was such that the ratio of A and B remained fixed. Therefore, the exchange of A’s product molecules and B’s product molecules also remained fixed at a specific point on the contract curve. That point corresponds to price. So in at least some simple models, when autonomous agents form a mutualism, A and B helping one another, they have found a means to create advantages of trade, and they can find and remain on a fixed point on the contract curve that establishes an exchange ratio = the price.
And note with the plant root and the fungi, thermodynamic work has been done by the plant to synthesize the sugars from sunlight, water, and carbon dioxide, and thermodynamic work has been done by the fungi to fix nitrogen from the air into amino acids. In a real biosphere, the linking of exergonic to endergonic reactions by which thermodynamic work is done to build up complex organization is, in fact, inextricably linked with the emergence of new advantages of trade = new, enhanced ways to make livings in new niches. In the present case, the exchange of sugar and amino acids helps both plant and fungi reproduce more rapidly.
So, as noted earlier, the fact that autonomous agents do link exergonic and endergonic reactions is central to the creation of advantages of trade and hence, new niches, new mutualistic opportunities. They lead to the vast web of an ecosystem trapping sunlight; gobbling some water, nitrogen, carbon dioxide, and a few other simple molecular species; and literally building up the vast profusion of Darwin’s tangled bank. Ultimately, we should be able to build a theory that accounts for the distribution of advantages of trade, the distribution of residence times of energy stored in diVerent forms in an ecosystem, as well as the statistical patterns of linking of exergonic and endergonic reactions in a biosphere as it builds itself and persistently explores novel ways of making a living, the novel niches that permit the success of Darwin’s minor variations creating novel species for those niches.
The curious thing about evolution is that everyone thinks he understands it? Not me. Not yet. Yet I hope there may be general principles governing the self-consistent construction of any biosphere. In later chapters I will hazard a hunch or two about such general laws, but we are only at the beginning of a general biology.









Chapter 10
A Coconstructing Cosmos?
rom biospheres to the cosmos? Yes, because they may share general themes. The major enquiry of Investigations has concerned autonomous agents and their coconstruction of biospheres and econospheres whose configuration spaces cannot be finitely prestated. These themes find echoes in thinking about the cosmos as a whole. But abundant caution: I am not a physicist, the problems are profound, and we risk nonsense.
Whatever the risk, two facts are true. First, since the big bang our universe has become enormously complex. Second, we do not have a theory for why the universe is complex. Equally unarguably, the biosphere has increased in molecular diversity over the past four billion years, just as the standing diversity of species has increased. And equally unarguably, the econosphere has become more complex over the past few million years of hominid evolution. We know this with confidence. If we lack a theory, it is not because the staggering facts of increasing diversity and complexity that stare us in the face do not deserve a theory to account for them.
But we have seen hints of such a theory in the coconstruction of biospheres and econospheres by the self-consistent search of autonomous agents for ways to make a living, the resulting exapting novel ways of making livings, the fact that new adjacent niches for yet further new species grow in diversity faster than the species whose generation creates those new adjacent possible niches, and the search mechanisms to master those modes of being. We have seen a glimmer of something like a fourth law, a tendency for self-constructing biospheres to enlarge their workspace, the dimensionality of their adjacent possible, perhaps as fast, on average, as is possible  glimmers only, not yet well-founded theory nor well-established fact. But glimmers often precede later science.
Consider again how the chemical diversity of the biosphere has become more diverse in the past four billion years, urged into its adjacent possible by the genuine chemical potential from the chemical actual into the adjacent possible, where the actual substrates exist and the adjacent possible products do not yet exist. Each time the molecular diversity of the biosphere expands, the set of adjacent possible reactions expands even faster. Recall our simple calculation that for modestly complex organic molecules, any pair of molecules could undergo at least one two substrate–two product reaction. But then the diversity of possible reactions is the square of the diversity of chemicals in the system. As the diversity of molecular species increases, there are always proportionally more novel reactions into the adjacent possible. If we take the formation of a chemical species that has never existed in the biosphere, or perhaps the universe, as a breaking symmetry, then the more such symmetries are broken, the more ways come into existence by which yet further symmetries may be broken.
And the chemical case makes clear the linking of the flows of matter and energy in this sprawling chemical diversity explosion. Many such reactions will link exergonic and endergonic processes. As this occurs, energy is pumped from the exergonic partner into the products requiring endergonic synthesis. These products  the chemical diversity in the bark of a redwood tree, for example  take their place in the chemical actual, poising the biosphere, and thus the universe, for its next plunge into the chemical adjacent possible.
Consider again equilibrium statistical mechanics. At its core, statistical mechanics relies on the same kind of statistical argument as does the flipping of a fair coin , times. We all understand that distributions of roughly , heads and , tails are far more probable macrostates than distributions with all heads or all tails. Now consider the general argument I have made that as molecular diversity increases, the diversity of reactions increases even faster, and that there is a genuine chemical potential from the actual into the adjacent possible. And consider again the general argument made just above that the greater the diversity of molecular species and reactions, the more likely the coupling of exergonic and endergonic reaction pairs driving the endergonic synthesis of new adjacent possible molecules that poise the system to advance again into the next adjacent possible. While the detailed statistical form of these chemical reaction graphs are not yet known, they too smell of “law.” As in the case of fair coin flips and equilibrium statistical mechanics, it is as if here again the mathematical structure compels the consequent behavior of matter and energy. In the case of the nonergodic and nonequilibrium chemical flux into the adjacent possible, the universe is busy diversifying itself into myriad complexity.
The universe is enormously complex, and we don’t really yet know why. May there be new ways of thinking of the cosmos itself? If a mere glimmer can be acceptable as potentially useful early science, then the burden of this chapter is to suggest perhaps, yes.
It is not obvious, in fact, that the universe should be complex. One can imagine universes governed by general relativity that burst briefly into big bang being, then recollapse in a rapid big crunch within parts of a second or a century. Alternatively, one can imagine universes governed by general relativity that burst into big bang being and expanded forever with no further complexity than hydrogen and helium and smaller particles in an open and ever-expanding dark, cold vastness.
Here we are, poised, it seems (but see below) between a universe that will expand forever and a universe that will eventually ease into gentle contraction, then rush to a big crunch.
Our fundamental theories in physics, and just one level up, biology, remain un-united. Einstein’s austere general relativity, our theory of space, time, and geometry on the macroscale, floats untethered to quantum mechanics, our theory of the microscale, seventy-five years after quantum mechanics emerged in Schrödinger’s equation form for wave mechanics. Theoretically apart, general relativity and quantum mechanics are both verified to eleven decimal places by appropriate tests. But it remains true that general relativity and quantum mechanics remain fitfully fit, fitfully un-united. And Darwin’s view of persistent coevolution remains by and large unconnected with our fundamental physics, even though the evolution of the biosphere is manifestly a physical process in the universe. Physicists cannot escape this problem by saying, “Oh, that’s biology.”
The Complexity of the Universe
Why the universe is complex rather than simple is, in fact, beginning to emerge as a legitimate and deep question. In the past several years, I have had the pleasure to come to know Lee Smolin, whose career is devoted to quantum gravity and cosmology. Most of what I shall write in this chapter reflects my conversations and work with Lee and his colleagues, who have been wonderfully welcoming to this biologist. Sometimes outsiders can make serious contributions. Sometimes outsiders just make damned fools of themselves.
Caveat lector, but I will continue.
In Smolin’s book, The Life of the Cosmos, he raises directly the question of why the universe is complex. Current particle physics has united three of the four fundamental forces  the electromagnetic, weak, and strong forces called the “standard model.” With general relativity, which deals with the remaining force, gravity; this provides a consistent framework. Particle physics plus general relativity have altogether some twenty “constants” of nature, which are parameters of the standard model and general relativity, such as the value of Planck’s constant, h; the fine structure constant, that is, the ratio of the electron rest mass to proton rest mass; the gravitational constant, g; and so forth. Smolin puts approximate maximum and minimum bounds on these twenty constants and asks a straightforward question: In a twenty-dimensional parameter space ranging over the plausible values of these twenty constants, what volume of that parameter space is consistent with values of the constants that would yield a complex universe with stars, chemistry, and potentially, life?
Smolin’s rough answer is that the volume of parameter space for the constants of nature that would yield a complex universe are something like raised to the minus th power. That is, a tiny fraction of the possible combinations of the values of the constants are consistent with the existence of chemistry and stars, as well as life. For the universe to be complex, the constants must be sharply tuned.
Smolin’s argument could be o by many orders of magnitude without destroying his central point: The fact that our universe is complex, based on our current theories of the standard model and general relativity, is surprising, even astonishingly surprising.
Many physicists have remarked upon this fine tuning of the constants.
There have been several responses to this issue, some raised prior to Smolin’s work. One is based on a view of multiple universes and the “weak anthropic principle.” This principle states that there exist multiple universes, but only those universes that were complex would sport life forms with the wit to wonder why their universe was complex. So the very fact that we humans are here to wonder about this issue merely means that we happen to be in one of the complex universes among vastly many universes. The argument is at least coherent. But it’s hard to be thrilled by this answer.
The “strong anthropic principle” goes further  indeed, too far  and posits that, for mysterious reasons, the universe is contrived such that life must arise to observe it and wonder at it. Few think the strong anthropic principle counts as science in any guise.
Smolin points out that there are two possible answers to the puzzle of the complexity of the universe. Either we will find a parameter-free description  a kind of supertheory  that yields something like our complex universe with its constants, or some historical process must pick those constants. Smolin proposes the possibility of “cosmic natural selection.” Here, daughter universes are born of black holes. Universes with more black holes will have more daughter universes. Given minor heritable variation in the constants of the laws of the daughter universes, cosmic natural selection will select for universes whose constants support the formation of a near-maximum number of black holes. He then argues that on very crude calculations most alterations in the known constants would be expected to lower the number of black holes. Lee points out that his theory is testable, for example, by deducing that our constants correspond to near-maximum black hole production, and that his theory has not been ruled out yet.
I confess I am fond of and admire Lee Smolin a great deal, but I don’t like his hypothesis. Why? Well, preferably, one would like a theory that had the consequence that any universe would be complex like ours and roughly poised between expansion and contraction. We have no such theory at present, of course. The remainder of this chapter discusses ideas and a research program that just might point in this direction.
As a start, we can begin with the most current view of the large-scale structure and dynamics of the universe. The most recent evidence suggests that on a large enough scale the universe is flat, the matter distribution is isotropic, and  a recent surprise  the universe may be expanding at an accelerating rate. This latest result, if it holds true, contravenes the accepted view of the past several decades that the rate of expansion of the universe has been gradually slowing since the big bang. The hypothesis that the universe is exactly poised between persistent expansion and eventual collapse has held that the rate of expansion of the universe will gradually slow, but never stop.
One way to explain a persistent accelerating expansion of a flat universe is to reintroduce Einstein’s “cosmological constant” into the field equations of general relativity. A positive cosmological constant expresses itself as a repulsive force between masses that increases with the distance between those masses. Some physicists think that a positive cosmological constant must be associated with some new source of energy in free space. The source of such an energy is currently unknown.
Quantum Mechanics and Classicity
Before turning to the huge diculties of quantum gravity, we should review the fundamental mystery of quantum mechanics. Most readers are familiar with the famous two-slit experiment, which exhibits the fundamental oddness of quantum interference. Feynman, in his famous three-volume lectures on physics, gives the mystery as simply as possible: We begin with a gun shooting bullets. The bullets pass through one of two holes in a metal plate and fly further on, landing on a flat layer of sand in a box. Bullets passing through either hole may be deflected slightly by hitting the walls of the hole. Thus, in the sandbox behind the metal plate, we would expect, and actually would find, two mounds of bullets. Each mound would be centered on the line of flight of the bullet from the gun through the corresponding hole to the sandbox, with a “Gaussian” or normal bell-shaped distribution of bullet densities falling away from the peak of each mound.
When we use monochromatic light rather than bullets, we note the following: If the light hits the sandbox, changed into a photon-counter surface, we find that the size of the energetic impact is the same each time a photon hits the surface. Photons of a given wavelength have a fixed energy. A photon either is recorded at a point on the surface or not. Whenever one is recorded, the full parcel of energy has been detected at the surface. Now if only one hole is open, one gets the Gaussian mound result. Most photons pass through the hole unscathed and arrive in a straight line at the photon-counter surface. A Gaussian distribution peaked at that center is present because some photons are deflected slightly by the edges of the hole.
But if two holes are open, then one gets the famous interference pattern of light and dark interfering circles spreading from the centers on the photon-counter surface that were the peaks of the mounds seen when hole or hole was open. Of course, as Feynman points out, there is no way to account for this oddness in classical physics.
Quantum mechanics was built to account for the phenomenon. The Schrödinger equation is a wave equation. The wave that propagates from the photon gun is an undulating spherically spreading wave of probability “amplitude.” The amplitude at any point in space and time is the square root of the probability that the photon will be found located at that point. To obtain the actual probability, the amplitude must be squared.
A central feature of Schrödinger’s equation is its linearity. If two waves are propagating, the sum and dierences of those waves are also propagating. It is the essential linearity of quantum mechanics that makes the next puzzle, the link from quantum to classical worlds, so dicult. For a central puzzle of quantum mechanics becomes the relation between this odd quantum world of possible events, where the possibilities can propagate, but never become actual, and the classical world of actual events.
A variety of approaches to the liaison between the quantum and classical realms exist. The first is the “Copenhagen interpretation,” which speaks of the “measurement event,” when the quantum object interacts with a macroscopic classical object, the measuring device, and a single one of the propagating possibilities becomes actual in the measurement event, thereby “collapsing” the wave function. A second approach is the Everett multiworld hypothesis, which asserts that every time a quantum choice happens, the universe splits into two parallel universes. No one seems too happy with the Everett interpretation. And few seem very sure what the Copenhagen interpretation’s collapse of the wave function might really mean.
Meanwhile, there are two other long-standing approaches to the link between the quantum and classical worlds. The first is Feynman’s famous sum over all possible trajectories, or histories, approach. In quantum mechanics, we are to imagine a given possible pathway of the photon from the photon gun through the screen with the two slits to the photon-counting surface. For each pathway, there is a well-defined procedure to assign an “action.” This action can be thought of as having an amplitude and a phase, and the phase rotates through a full circle, pi, many times along the pathway. According to the Feynman scheme, classical trajectories correspond to quantum pathways possessing minimal action.
Consider, says Feynman, all the pathways that start at the photon gun and end up at the same point on the photon-counting surface. Nearly parallel, nearly straight-line pathways, have nearly the same action. So when those pathways interact, they have nearly the same phase, and their interaction yields constructive interference, which tends to build up amplitude. Thus, pathways that are near the classical pathway interact constructively to build up amplitude. By contrast, quirky crooked pathways between the photon gun and the same point on the counter screen have very dierent actions, hence very dierent phases, and interact destructively, so their amplitudes tend to cancel. The classical pathway, therefore, is simultaneously the most probable pathway over the sum of histories of all possible pathways, and the pathway that requires the least action.
The result is beautiful, but has two problems. First, Feynman assumes a continuous background space and time in his theory. Quantum gravity, as we will see, cannot make that assumption in the first place. Rather space, or geometry, is a discrete, self-constructing object on its own. Thus, achieving a smooth space and time is supposed to be a consequence of an adequate theory of quantum gravity. If Feynman’s sum over histories must assume a smooth background space and time, then it cannot as such be taken as primitive in quantum gravity. Second, granting a continuous background space and time, Feynman’s sum over all histories still only gives a maximum of the amplitude for the photon to travel the classical pathway, it never gives an actual photon arriving at the counting surface. No more than any other does Feynman overcome the fundamental linearity of quantum mechanics. We still have to collapse the wave function. Despite these problems, Feynman’s results are brilliant, and at least we see a link between the classical and quantum worlds, if not yet actual photons striking counters.
But there is an alternative approach to the link between the quantum and the classical worlds. This possible approach is based on the well-established phenomenon of “decoherence.” Decoherence arises when a quantum-coherent Schrödinger wave is propagating and the quantum system interacts with another quantum system having many coupled variables, or degrees of freedom. The consequence can be that the Schrödinger wave function of the first quantum system becomes entangled in very complex ways with the other complex quantum system, which may be thought of as the environment. Rather like water waves swirling into tiny granular nooks and crannies along a rugged fractal beach, the initial coherent Schrödinger equation representing the initial quantum system swirls into tiny and highly diverse patterns of interaction with the quantum system representing the environment. The consequence of this intermixing is decoherence.
To understand the core of decoherence, one must understand that the exhibition of interference phenomena, the hallmark of quantum mechanics noted in the double-slit photon experiment, requires that literally all the propagating possible pathways in Feynman’s sum over histories that are to arrive at each point on the photon-counter surface, do in fact arrive at that point. If some fail to arrive, the sum over all histories fails. In eect, if some of the phase information, the core of constructive and destructive interference, has been lost in the maze of interactions of the quantum system with its environment, then that phase information cannot come to be reassembled to give rise to quantum interference.
Decoherence is accepted by most physicists. For example, in attempts to build quantum computers that can carry out more than one calculation simultaneously due to the linear features of quantum mechanics, actual decoherence is currently a technical hurdle in obtaining complex quantum calculations.
Decoherence, then, aords a way that phase information can be lost, thereby collapsing the wave function in a nonmysterious fashion. Thus, some physicists hope that decoherence provides a natural link between the quantum and classical realms. Notable among these physicists are James Hartle and Murray Gell-Mann, whose views can be found in Gell-Mann’s The Quark and the Jaguar. In essence, Hartle and Gell-Mann ask us to consider “the quantum state of the universe” and all possible quantum histories of the universe from its initial state. Some of these histories of the universe may happen to decohere. Hartle and Gell-Mann argue that the decoherent histories of the universe, where true probabilities can be assigned, rather than mere amplitudes, correspond to the classical realm. Others have argued that decoherence itself can be insucient for classical behavior.
It is striking that there appear to be two such separate accounts of the relation between the quantum and classical worlds, Feynman’s sum over histories in a smooth background space-time and decoherence. For an outsider, it is hard to believe that both can be correct unless there is some way to derive one from the other. I will explore one such possibility below. In particular, I will explore the possibility that decoherence of quantum geometries is primary and might yield a smooth space-time in which Feynman’s account is secondarily correct.
An Outsider’s Doubts
I turn next to an outsider’s grounds for doubts about some of the core propositions of quantum mechanics. Roland Omnes, in The Interpretation of Quantum Mechanics, is at pains to argue that decoherence is the plausible route to classicity. In his discussion, two major points leap to attention. The first concerns the concept of an elementary predicate in quantum mechanics. Quantum mechanics is stated in the framework of Hilbert spaces, which are finite or infinite-dimensional complex spaces, that is, spaces comprised of finite or infinite vectors of complex numbers. In eect, an elementary predicate is a measurement about an “observable” that returns a value drawn from some set of possible values. And so the first striking point is Omnes’ claim that all possible observables can be stated in Hilbert space. The second striking point is Omnes’ claim that some observables cannot be observed.
The first point is striking because it is not at all clear that all possible observables can be finitely stated in Hilbert space. My issue here is precisely the same as my issue with whether or not the configuration space of the biosphere is finitely prestatable. As I argued above, there does not seem to be a finite prestatement of all possible causal consequences of parts of organisms that may turn out to be useful adaptations in our or any biosphere, which arise by exaptation and are incorporated in the ongoing unfolding exploration of the adjacent possible by a biosphere.
In quantum mechanics, an observable corresponds to a mathematical operator that “projects out” the subspace of Hilbert space corresponding to the desired observable in a classical measurement context that allows detection of the presence or absence of the observable. But the biosphere is part of the physical universe, and the exapted wings of Gertrude the flying squirrel are manifestly observables, albeit classical observables. If we cannot finitely prestate the observable, “Gertrude’s wings,” then we cannot finitely prestate an operator on Hilbert space to detect the presence or absence of Gertrude’s wings. In short, there seems to be no way to prespecify either the quantum or classical variables that will become relevant to the physical evolution of the universe.
It turns out that the above issues may bear on the problem of time in general relativity, as Lee Smolin realized from our conversations and as I return to shortly.
Now, the second point. Omnes follows up on it. An observable requires a measuring device. There are some conceivable observables for which the measuring device would be so massive that it would, of itself, cause the formation of a black hole. Thus, no information resulting from the measurement could be communicated to the outside world beyond the black hole.
A strange situation; even if we could finitely prestate all possible observables, only some observables can manage to get themselves observed in the physical universe.
What shall we make of conceivable observables that cannot, in principle, be observed? More important, it seems to this outsider, is the following: If observation happens by coupling a quantum system to some other system, quantum or classical, whereby decoherence occurs and, in turn, classicity arises because loss of phase information precludes later reassembly of all the phase information to yield quantum interference, then there appears to be a relation between an observable being observed and the very decoherence by which something actual arises from the quantum amplitude haze.
If that is correct, then only those observables that can get themselves observed can, in principle, become actual. More, it begins to seem imperative to consider the specific possible pairs of quantum systems that can couple and decohere, for only thereby can such pairs become classical via decoherence. This begins to suggest preferred histories of the universe concerning such comeasuring pairs of quantum systems. Preferentially, those comeasuring pairs of quantum systems that decohere and become classical will tend to accumulate, due to the irreversibility of classicity. Thereafter quantum-classical pairs of systems that cause decoherence of the quantum system will preferentially accumulate into classicity.
If comeasuring yields classicity, and classicity is irreversible, the classical universe begins to appear to coconstruct itself. In particular, it is generally accepted that bigger systems, that is, systems with more coupled degrees of freedom, decohere more rapidly when they interact than smaller systems. If so, this begins to refine the suggestion of preferred histories of the universe concerning comeasuring pairs of quantum systems toward a preference for the emergence of classical diversity and complexity: If quantum systems with more coupled degrees of freedom irreversibly decohere more rapidly into classical behavior when they interact than smaller, simpler systems, then the kinetics of decoherence should persistently favor the irreversible accumulation of bigger, more complex quantum systems, rather than of smaller, simpler, quantum systems.
Chemistry should be an example. Molecules are quantum objects, yet flow into the chemical adjacent possible. The adjacent possible explodes ever more rapidly as molecular diversity, and hence molecular complexity, increases. Reactions of complex molecules are precise examples of the couplings of quantum systems whereby decoherence can happen. Decoherence presumably happens more rapidly among complex reacting molecules than among very simple molecules or the same total number of mere atoms, nucleons, and electrons in the same total volume. This hypothesis ought to be open to experimental test. If confirmed, the flow of possible quantum events into the chemical adjacent possible should, in part, be made irreversible by the decoherence of complex molecular species as they couple and react with one another.
If the general property obtains that complex quantum entities can couple to and interact with other complex quantum entities in more ways than can simple systems and that the number of ways of coupling explodes faster than the diversity of entities, and thus faster than the complexity of those quantum objects, then decoherence should tend to lead to favored pathways toward the accumulation of complex classical entities and processes. I return to these themes below.
The Problem of Time in General Relativity
To my delight, I soon found myself coauthor on a paper with Lee Smolin concerning the problem of time in general relativity. Lee had done the majority of the work, but had taken very seriously my concern that one cannot finitely prestate the configuration space of a biosphere.
In general relativity, space-time replaces space plus time. A history becomes a “world-line” in space-time. But that world-line is a geometrical object in spacetime. Time itself seems to disappear in general relativity, to be replaced by the geometrical world-line object in space-time.
But argued Lee, with my name appended, general relativity assumes that one can prestate the configuration space of a universe. In that prestated configuration space, a world-line is, indeed, merely a geometrical object. What if one cannot prestate the configuration space of the universe? If so, one cannot get started on Einstein’s enterprise, even if general relativity is otherwise correct. As concrete examples, Lee pointed out that four-dimensional manifolds are not classifiable.
How might one do physics without prestating the configuration space of the universe? Lee postulated use of spin networks, as described below, with the universe constructing itself from some initial spin network. In this picture, time and its passage is real. If there can be a framework in which time enters naturally, and possibly there is a natural flow of time, or an arrow of time preferentially from past to future, then, among other possible consequences, we may be able to break the matter-antimatter symmetry, for antimatter can be stated as the corresponding matter flowing backward in time. Break the symmetry of time in fundamental physics and you may buy for free the breaking of the symmetry between matter and antimatter. If time flows preferentially from past to future, matter dominates antimatter. That would be convenient since matter does dominate antimatter, and no one knows just why.
We will head in this direction.
Spin Networks
For the sixty years following and the emergence of matrix mechanics and the Schrödinger formulation of quantum mechanics, scant progress was made on quantum gravity. Now, in the past decade or so, there are two alternative approaches, string theory and spin networks. Of the two, string theory has captured the greatest attention. I discuss it briefly below.
Spin networks were invented by Roger Penrose three decades ago as a framework to think about a quantized geometry. Quite astonishingly, spin networks appear to have emerged from a direct attempt to quantize general relativity by Carlo Rovelli and Lee Smolin. In outline, part of the tension between quantum mechanics and general relativity lies in the very linearity of quantum mechanics and the deep nonlinearity of general relativity.
Building on work of Astekar and his colleagues, Rovelli and Smolin proceeded directly from general relativity along somewhat familiar pathways of canonical quantization. In outline, general relativity is based on a metric tensor concerning space-time. The metric tensor is a x symmetric tensor. It turns out that this tensor yields seven constraint equations. The solutions of six of the seven have turned out to be spin networks. The solution of the seventh equation would yield the Hamiltonian function, hence the temporal unfolding, of spin networks in a space x time quantum gravity.
Spin network theories can be constructed in dierent dimensions. The two most familiar are for two spatial and one temporal or three spatial and one temporal dimension. We will concern ourselves with three plus one spin networks for concreteness. The minimal objects in a spin network are discrete combinatorial objects that constitute first a tetrahedron, with four vertices and four triangular faces. A tetrahedron represents a primitive discrete unit of geometry, or space. Integer-valued labels are present on the edges and vertices of these tetrahedra. The labels on the edges represent spin states. The labels on the vertices represent “intertwinors” and concern how edges entering a vertex are connected to one another into and out of the vertex.
Analytic work has associated an area with a face of a tetrahedron and a volume with its volume. There is, at present, no way to represent the length of an edge connecting vertices. On the other hand, one can think of the integer values on the edges around a face of a tetrahedron as associated with the area of the tetrahedron, such that larger integers correspond to larger areas.
A geometry is built up by minimal moves, called “Pachner moves,” in which a given tetrahedron can give rise to daughter tetrahedra o each face. In addition, several tetrahedra can collapse to a single tetrahedron.
Thus we may picture an initial spin network, say, a single tetrahedron. In analogy with chemistry and combinatorial objects, the founder set of a chemical reaction graph, and the adjacent possible in the chemical reaction graph, we may consider the single initial tetrahedron as a founder set, gamma . Consider next all possible adjacent spin networks constructible in any single Pachner move. Let these first adjacent possible spin networks lie in an adjacent ring, gamma . In turn, consider all the spin networks constructible for the first time from the founder set in two Pachner moves, hence constructible for the first time in one Pachner move from the gamma- set of spin networks. Let this new set be the gamma- set of spin networks.
By iteration, we can construct a graph connecting the founder spin network with its -Pachner move “descendants,” -Pachner move descendints,   .   .   .   N-Pachner move descendents.
Each spin network in each gamma ring represents a specific geometry, subject to the constraint that two spin network tetrahedra that share one triangular face must assign the same spin labels to the common edges, hence, the same area to the common face.
Changes in the values of spins on the edges that change the areas and volumes of the tetrahedra can be thought of as deforming the geometry so that it warps in dierent ways. However, it should be stressed that there is no continuous background space or space-time in this discrete picture. Geometry is nothing but a spin network, and a change in geometry is nothing but a change in the tetrahedral structure of the spin network by adding or deleting tetrahedra or by changing the spin values on the edges of tetrahedra.
Within quantum mechanics, there is an appropriate way to consider the discrete analogue of Schrödinger’s equation, namely a means over time of evolving amplitudes from an initial distribution. In particular, the appropriate means of evolving amplitudes concern what are called “fundamental amplitudes,” which specify initial and final values of the integer values on edges before and after Pachner moves.
Consider a given graph linking spin networks from an initial tetrahedron in gamma , outward as in a mandala, to all daughter networks in gamma , gamma ,   .   .   .   gamma N, where N can grow large without limit.
The Emergence of a Large-Scale Classical Limit?
I now describe one approach to thinking about quantum gravity and the emergence of a smooth large-scale geometry based on this mandala and on Feynman’s idea of a sum over all histories. Endow the spin networks throughout with the same fundamental amplitudes, thus, the same law propagating amplitudes applies everywhere in the spin network mandala. Begin with all amplitude concentrated in the initial spin network tetrahedron in gamma . In this vision, a unit of time elapsing is associated with a Pachner move, such as a move from gamma to a point in gamma . With analogy to Feynman’s sum over all possible histories, consider the set of all pathways that begin at the initial tetrahedron in gamma and end on a given specific spin network N time steps later, for N = . That final spin network might lie in the gamma- ring, the gamma- ring, the gamma- ring, or any ring out to the gamma-N ring.
Here is a hopeful intuition that may prove true. If we consider the family of all histories beginning on gamma and ending in a specific spin network in the gamma N = ring, those pathways must be very similar and few in number. By contrast, if we consider all pathways length that begin on the gamma- tetrahedron and end, steps later, on a specific spin network in the gamma- ring after wandering all over the spin network mandala graph, there may be many such pathways, and they can be very dissimilar. Now, during the amplitude propagation along any pathway, an action can be associated with each Pachner move, hence, we can, with Feynman, think about the constructive or destructive interference among the family of pathways steps long that begin on the gamma- tetrahedron and end on any specific spin network. Then the hopeful intuition is that those pathways that begin on gamma and end on a spin network member of the gamma N = ring in Pachner moves will have very nearly the same action, hence, show strong constructive interference. By contrast, those pathways that begin on the gamma- tetrahedron and end, Pachner moves later, on a specific spin network in the gamma- ring will have very dierent actions, hence, show strongly destructive interference.
If the constructive interference among the few pathways to ring N overwhelms any residual constructive interference in the inner rings  such as ring , due to the larger number of pathways from gamma to gamma   then the hopeful concept is that amplitude will tend to accumulate in the gamma-N ring. Then (goes the hope shared with Smolin) the neighboring spin networks in the gamma-N shell constitute nearly the same geometry and nearly the same action in the sum of histories reaching them, which begins to suggest that a smooth large-scale geometry might emerge.
For this line of theory to succeed, it is not actually necessary that amplitude preferentially accumulate in the outermost, gamma-N, ring. Rather it is necessary as N increases that there be some ring, M, where M is less than N but increases monotonically with N, such that a suciently large number of alternative pathways with suciently similar phase end on members of the M ring that constructive interference is maximum for members of the M ring. Further, it is necessary that as N increases and M increases, amplitude continue to accumulate on the Mth ring.
In short, the concept is that, via constructive and destructive interference as amplitudes propagate in the mandala, some large-scale smooth geometry will pile up amplitude, hence probability, and a smooth classical geometry will emerge. Here is at least one image of how a large-scale smooth geometry might emerge from spin networks and constructive interference.
At least three major caveats are required. First, no calculation has yet been carried out for such a model, so such a theory may not work. Second, Feynman’s sum over histories assumes a classical continuous space and time. It may be entirely invalid to attempt to use a sum over histories argument in this quantum geometry setting. Third, assuming we can use Feynman’s sum over histories, we still have possible quantum geometries, not an actual geometry.
Self-Selection of the Laws and Constants of Nature?
Recall the puzzle, nay, the deep mystery, about what processes, if any, might have “chosen” the twenty constants in the standard model such that the universe happens, improbably, to be complex. To answer this deep mystery we have, at present, the anthropic principle, Lee Smolin’s concept of cosmic natural selection for black hole density, and the hope to find the ultimate parameter-free theory that would not require multiple universes or a historical process.
With caveats, I now briefly describe a way that may be useful to begin to think about the emergence of the constants such that any universe would have a given set of constants.
Tuning the constants corresponds to tuning the laws of physics. Is there a way to imagine a self-tuning of a universe to pick the appropriate values of its constants, to tune its own laws? I think the answer may be yes. And if the following is wrong in detail, the pattern of thought may prove useful.
In the spin network mandala picture, a J symbol, present throughout the spin networks in the mandala, generates an analogue of Schrödinger’s equation, hence, the means to propagate amplitudes in the graph of spin networks. Thus, a change in a J symbol would correspond to changing the laws of physics about how amplitudes propagate.
Importantly, the fundamental amplitudes are an ordered listing of integers, hence, there is a family of all possible fundamental amplitudes. Since each fundamental amplitude can be thought of as the “law” about propagating amplitudes among spin networks, Louis Crane pointed out that there is an infinite family of all possible laws to propagate amplitude among spin networks.
Thus, imagine an infinite stack of our spin network mandalas, in which each manadala is a graph from gamma , the tetrahedron, outward to gamma N, for N allowed to be arbitrarily large, of spin networks reachable in N steps by Pachner moves. The mandala members of the infinite stack of mandalas dier from one another only in the fundamental amplitudes, hence laws, that apply to each mandala. (I concede it may be necessary to have a means to encode in each manadala the given fundamental amplitudes that apply to that manadala.)
Now consider how amplitudes propagate in each mandala from an initial state with all the amplitudes concentrated in the gamma- tetrahedron. And consider any two mandalas whose fundamental amplitudes are minimally dierent. For some such adjacent mandalas with adjacent laws, the small change in the law may lead to a large change in how amplitudes propagate in the mandalas. For other pairs with minimal changes in the fundamental amplitudes or law, the way the amplitude propagates throughout the mandala may be very slight. Assuming this is true, one intuitively imagines that the total system is spontaneously drawn to those tuned values of the fundamental amplitude laws, where small changes in the laws make minimal changes in how amplitudes propagate.
A simple possible mechanism might accomplish this. Imagine a sum of histories from an initial gamma- tetrahedron in a mandala with some given fundamental amplitude laws (thereby the initial and boundary conditions are specified), where the pathways in that set of histories pass up and down the stack of mandalas such that the fundamental amplitude laws change, as does the spin network, and then consider the bundle of all such histories that end on a given spin network in a given gamma ring with given, perhaps new, fundamental amplitude laws. In eect, this conceptual move allows there to be quantum uncertainty not only with respect to spin networks along histories, but also quantum uncertainty with respect to the law by which amplitude propagates.
Then one can imagine a sum over all histories that, by constructive interference alone, picks those pathways, hence fundamental amplitude laws, that minimize the change in the ways amplitudes propagate. Such pathways would have similar phase, hence, accumulate amplitude by constructive interference. Then, by mere constructive interference, one can hope that such a process would pick out not only the history, but also tune the law to the well-chosen fundamental amplitudes laws that maximized constructive interference. Hopefully, that constructive interference would pick out smooth large-scale geometries like classical flat or near flat space. In such a large-scale classical-like space and time, Feynman’s familiar sum over histories that minimizes a least action along classical trajectories would emerge as a consequence.
Smolin and I discuss this possibility in a second paper. I find the idea attractive as a research program because it oers a way in which a known process, constructive interference, modified to act over a space of geometries and laws simultaneously, chooses the law. It is, of course, rather radical to suppose that there is quantum uncertainty in the law, but it does not seem obviously impossible.
On an even grander scale, particle physicists build the standard model from an abstract algebra called SU() x SU() x U(). One can imagine a similar research program that by constructive interference alone picks out the particles, constants, and laws of the standard model. Presumably, particles governed by suciently “nearby” laws would be able to interact, hence undergo constructive or destructive interference, thus picking the particles and the laws simultaneously.
There is a further interesting feature, for we appear to have in our mandala, or mandalas, a new arrow of time. Allow that at any step, any Pachner move can happen. Some moves add tetrahedra. A equal number delete tetrahedra. Yet the number of spin networks in ring N + is larger than the number of spin networks in ring N. Statistically, there are more ways to advance into ring N + than to retreat from ring N into ring N - . Other things equal, amplitude should tend to propagate outward from the gamma- tetrahedron. There is an analogy in chemical reaction graphs to the adjacent possible and the real chemical potential across the frontier from the actual to the adjacent possible.
But if so, time enters asymmetrically due to the graph structure of the spin network mandala. Then, statistically, time tends to flow in one direction, from simpler toward more complex spin networks into the ever-expanding adjacent possible.
A Brief Comment on String Theory
String theory has gained very substantial attention as a potential “theory of everything,” namely, a theory that might link all four forces and all the particles of the standard model into a single coherent framework. I do not write with even modest expertise on the subject. Nevertheless, it is possible that the concept of the law selecting itself via maximum constructive interference in a sum over all possible histories in a space of both spin networks and laws might possibly have relevance to string theory. The description of string theory that I give draws heavily on Brian Greene’s The Elegant Universe.
As is known qualitatively by many outside the confines of the physics community, string theory began by giving up the picture of fundamental particles as zero-dimensional, point particles. In its initial version, in the place of point particles, string theory posited one-dimensional strings that might be open, with two ends, or closed loops, with no free ends. Among the fundamental ideas of string theory is the idea that the dierent particles and the dierent forces can all be thought of as dierent modes of vibration of such strings. Because strings have finite length, string theory can hope to overcome the infinities that emerge when attempts are made to marry point particle quantum theories with general relativity in a continuous space-time. In eect, the finite length of the strings prevents consideration of space becoming infinitely curved at a point. Thus, string theory can dream of uniting quantum mechanics and general relativity, and it has, in fact, produced the entity carrying the gravitational force, the graviton, in a natural way.
Current string theory has gone beyond single-dimensional strings, and now considers two-or-higher-dimensional entities called M-branes. The rough present state of the art has shown that there are at least five one-dimensional string theories and M-brane theory. All of these theories appear to be linked as cousins of one another via various dualities among the theories.
String theories posit either eleven-or-fewer-dimensional space and time, with three of the spatial dimensions unfurled and large scale, corresponding to our familiar three-dimensional space. The remaining dimensions are imagined as curled up on the Planck length scale in what are called “Calabi-Yau” spaces, or more generally, compactified moduli. Compactification of an eleven-dimensional space and time can be thought of as a large-scale three-dimensional space and time, but with the additional dimensions curled up at each point in the large-scale three-dimensional space.
Calabi-Yau spaces can have dierent topologies. Consider as an analogy a long thin tube with two ends and a one-hole torus, like a donut. These two are topologically dierent. As a consequence, closed one-dimensional string loops can “live” on these surfaces in dierent ways. Thus, if you think of a string as a closed loop, that loop might live on the long tube in two ways, either wrapped around the tube one or more times or not wrapped around the tube, but lying on the tube’s surface like a rubber band lying on a surface. By contrast, consider the torus. The closed string might wrap around the torus in either of two ways, through the hole or around the torus. In addition, the string loop might live on the surface of the torus without wrapping either dimension. Each of these dierent ways of being on the tube or torus and the corresponding modes of vibration constitute dierent particles and forces. Calabi-Yau spaces are more complex than the tube or torus, but the basic consequences are the same. Dierent Calabi-Yau spaces, or more generally, dierent compactified moduli, with dierent kinds of holes around which strings can wrap zero, one, or more times correspond to dierent laws of physics with dierent particles and forces.
Physicists have shown, furthermore, that one Calabi-Yau space can smoothly deform into another with a “gentle” tearing of space and time. Hence, the laws, forces, and particles can deform into one another in a space of laws, forces, and particles. Within current string theory, it appears that it is still not certain that there exists a Calabi-Yau space whose string or M-brane inhabitants would actually correspond to the known particles and forces, but hopes are high.
However, even if there is a Calabi-Yau space whose strings and M-branes do correspond to our known particles and forces, string theorists have the diculty that it is not clear how the current universe happens to choose the correct Calabi-Yau space. The familiar ideas on this subject include the existence of a multiverse and the weak anthropic principle. For example, one could imagine Lee Smolin’s arguments for choices of Calabi-Yau spaces that lead to fecund universes with a near maximum of black holes, which are the birthplaces of still further universes.
The parallel between spin networks with dierent fundamental amplitude laws and the family of string and M-brane theories that can deform into one another is that in both theories we confront a family of theories having the property that dierent members of the family correspond to dierent particles, forces, and laws. In both cases, physicists do not at present have a theory to account for how, in this embarrassment of riches, our universe happens to pick the correct laws. I therefore make the suggestion that the same pattern of reasoning that I described above, a sum over histories of trajectories that vary both in configurations and in the laws, which maximizes constructive interference, might prove a useful approach. In the string theory context, one would consider a hyperspace of Calabi-Yau spaces, in which neighboring Calabi-Yau spaces would propagate amplitudes from the same initial condition in dierent ways. Presumably, somewhere in the hyperspace of Calabi-Yau spaces, small changes in Calabi-Yau spaces would yield small changes in how amplitudes propagate. For other locations in the hyperspace of Calabi-Yau spaces, small changes in the Calabi-Yau space would yield large dierences in how amplitudes propagate. In the hyperspace of Calabi-Yau spaces, where one Calabi-Yau space can deform into its neighbors, it should be possible to construct a sum over all histories of trajectories between an initial and final state in the same or dierent Calabi-Yau space, then seek such sums over histories that maximize constructive interference. The hope is that maximizing constructive interferences would pick out the Calabi-Yau space corresponding to our particles and forces. Presumably, this would occur in the region of the hyperspace of Calabi-Yau spaces, where small changes in the Calabi-Yau space yield the smallest changes in how amplitudes propagate. In short, maximization of constructive interference may be a useful principle to consider to understand how the universe chooses its laws.
String theorists recognize the need to confront further major problems. Most notably, string theory posits a background space-time in which strings and M-branes vibrate. But if string theory is to be the theory of everything, including space and time, then space and time cannot be assumed as a backdrop. Thus, a virtue of spin networks is that it aords the hope of a quantized geometry from the outset. On the other hand, particles and the three nongravitational forces have yet to be incorporated into a spin network picture.
A Decoherence Spin Network Approach to Quantum Gravity
However the universe picks its presumably quantum laws, somehow the classical realm emerges. I noted above that current theory sees two approaches to linking the quantum and classical realms. The first is based on Feynman’s sum over histories, but as a perturbative theory assumes a continuous background space-time and does not get rid of the linear superposition of possibilities that is the core of quantum mechanics and interference.
What of the second approach, decoherence? The reality of decoherence is established. If one is to take decoherence seriously, and also to consider geometry constructing itself, then presumably decoherence can apply to geometry as it constructs itself. What would it mean to apply decoherence to quantum gravity itself, to the vacuum, to geometry itself?
Well, to an outsider, the following seems possible. If we are to conceive of an initial spin network, say a tetrahedron, and all possible daughter spin networks, as well as all their possible daughter spin networks, propagating amplitudes on the mandala, then at any moment N steps away from moment , more than one geometry is possible  namely all those reachable in N Pachner moves.
We seem to confront the same problem we confront with quantum systems coupling to quantum systems, such as electrons coupling to organic molecules, or to classical systems, such as rocks. These quantum systems can decohere. Can quantum geometries become coupled with one another or dierent parts of one quantum geometry become coupled, so to speak, and decohere?
Why not try the idea?
I now discuss one possible approach to this issue. The approach posits a quantum of action, h, to the generation of a tetrahedron, hence a Planck energy and thus a Planck mass to a tetrahedron, and decoherence setting in at a sucient mass and size scale.
By use of an equation suggested by Zurek relating the decoherence timescale, Td, to the relaxation timescale, Tr, of the system, in which increasing mass and area increase the rate of decoherence in proportion to their product, it can be qualitatively shown (via suciently rough arguments) that geometry may well be thought of as decohering, and doing so on a length scale of about cm, which is smaller than the Compton radius of the electron and even smaller than the radius of a nucleus.
Now, there are some interesting features of this rough calculation. First, if we begin with an initial tetrahedron of geometry, it can have four daughter tetrahedra. In turn, each daughter tetrahedron can have two or more daughter tetrahedra, hence, the initial spin network can grow exponentially in the number of tetrahedra before decoherence sets in. This is a clue that a purely quantum account might be given of an initial exponential expansion of a universe starting with a single tetrahedron. Thus, it might be possible to do without the “inflationary hypothesis” of exponential expansion of a classical space in the early moments after the big bang.
Second, an initial exponential expansion of geometry might overcome, as the inflationary hypothesis does, the particle-horizon problem in cosmology, in which we confront the puzzle of why parts of the universe that have been out of apparent causal contact since the big bang can be so similar. If the initial expansion is exponential, then slows to linear, as in the inflationary hypothesis or perhaps in this purely quantum approach, then the particle-horizon problem may disappear.
Third, a purely quantum exponential expansion over many orders of magnitude should presumably yield a flat power spectrum over many size scales for quantum fluctuations in the earliest small fraction of a second of the life of the universe prior to the end of this exponential expansion when decoherence of geometry occurs.
Fourth, we must consider when geometries decohere whether there may be geometries that are the slowest to decohere. If dierent parts of a single spin network geometry can become coupled, it is natural to assume that flat parts might decohere more slowly than distorted parts of that geometry. Intuitively, phase information can get lost more readily when two lumpy parts of a geometry couple than when two flat parts of a geometry couple. Of course, an explicit model exploring this is badly needed and entirely missing, but in its absence, let’s make the assumption. Given that, then an initial exponential explosion of flat and warped geometry occurs until decoherence sets in on a length scale of something like cm. At this point, flat geometry “wins” because it decoheres most slowly. Hence, as soon as decoherence of geometry sets in, space tends to be flat in the absence of matter.
But even after decoherence sets in, geometry is busy all the time trying to build geometry exponentially and everywhere, while simultaneously decohering. Now an interesting feature of the Td/Tr equation alluded to above is that whatever the exponential rate of expansion of geometry may be per Planck time unit, the exponential rate of decoherence, Td, which grows as the mass times the size scale squared of the geometry, increases, until eventually the exponential rate of formation and exponential rate of decoherence of geometry must balance. The exponential expansion of the universe is over. However, linear expansion by construction of geometry can continue. The fastest linear construction of geometry from any tetrahedron would be at the speed of light.
When the rate of geometry formation and decoherence balance, geometry keeps building tetrahedra as fast as possible everywhere, but flat geometry, by hypothesis, decoheres most slowly. In the limit, perhaps flat geometries do not decohere at all. Then, the geometry of the universe tends to be flat in the absence of matter, as Einstein requires in general relativity. And, once again, the flatness after exponential expansion may overcome a need for the inflationary scenario and solve the particle-horizon problem.
It may be of interest that the assumption of an action, h, in the generation of each tetrahedron implies an expanding total energy in geometry itself, the vacuum itself, as geometry constructs itself. Indeed, one expects that the assumption of an action, h, per tetrahedron would lead to a uniform energy density, a constant scalar quantity even as geometry grows. Such an energy could be related to the cosmological constant.
It may also be of interest that string theory posits “extra dimensions” that “curl up” on themselves to yield four-dimensional space-time. Could the decoherence of geometry aord a parallel way that extra dimensions can curl up? And could the ever-generating possible geometries, as they generate exponentially even as they decohere, yield sucient extra degrees of freedom to correspond to the modes of oscillation of strings or M-branes in six or seven extra dimensions?
It may be interesting that the energy content of geometry could be enormous compared to that of familiar particles of the same size scale. That might allow the familiar particles with rest mass to borrow a tiny bit of the vacuum energy for their mass. Such a possibility could hint that matter, energy, and geometry might be able to interconvert. Perhaps dierent particles would be dierent kinds of topological “knots” in the spin network structure of geometry with interconvertible particles being nearby knot topologies.
We are obviously far from anything like a coherent theory that implements any of the intuitions above. They remain at best mere suggestions for a research program.
Coconstructing Complexity?
I began this chapter wondering why the universe is complex. In place of the anthropic principle or Lee Smolin’s cosmic selection, I have suggested one possible approach to the choices of the constants of nature by maximizing constructive interference over a sum of all histories through a space of both configurations and laws. Even if that program were to succeed, it does not necessarily yield a complex universe, let alone one poised roughly between expansion and contraction.
Might we see ways to understand why the universe is complex? Perhaps, but merely perhaps. I return to the thoughts earlier in this chapter that decoherence requires coupling systems and the loss of phase information. If, in general, complex and high-diversity quantum systems with many coupled degrees of freedom lose phase information when they interact more rapidly than an equal number of simple, low-diversity quantum systems with the same total number of interacting parts, then the comeasuring of entangled quantum systems should tend toward higher complexity, diversity, and classicity. In short, complexity and diversity would beget classicity irreversibly. In turn, this would lead to a preferred tendency toward a lock-in of complexity and diversity. There is a sense in which classical objects are like the constraints on the release of energy that permits work to be done. Classical objects, interacting with quantum objects, lead to decoherence and more classicity. Complex pairs of quantum objects that decohere readily, or classical objects and those quantum objects that are caused to decohere readily when interacting with the classical object, form preferred pairs that tend to decohere, hence become frozen into classicity. We begin to have an image of preferred pairs of quantum systems coupling and decohering, hence, an image of a complex and diverse universe constructing itself as it nonergodically invades the adjacent possible, rather as a biosphere constructs itself. And if more complexity and diversity means more comeasurement and faster decoherence of a wider variety of complex quantum systems, in analogy with the concept that extracting work from increasingly subtle nonequilibrium systems requires increasingly subtle measuring and coupling devices, the universe as a whole may persistently break symmetries as new entities come into existence, and hence expand its diversity, complexity, and classicity as fast as possible.
Loose arguments? Yes. Testable? Here and there. Wrong? Probably. Deeply wrong? Maybe not. Does this get the universe to the edge of expansion versus contraction or to a flat universe expanding forever more rapidly? I would love it to be so. Indeed, I would love a view in which matter, energy, and geometry can all interconvert. After all, if geometry, the vacuum, has energy, such interconversion does not seem impossible. Do the considerations of this chapter require detailed models and supporting calculations to be taken as more than the merest suggestions? Absolutely. This chapter, like much of Investigations, is protoscience. But science grows from serious protoscience, and I take Investigations to be serious protoscience.
We enter a new millennium. There will be time for new science to grow.









Chapter 1
Prolegomenon to a General Biology
ecturing in Dublin, one of the twentieth century’s most famous physicists set the stage of contemporary biology during the war-heavy year of 1944. Given Erwin Schrödinger’s towering reputation as the discoverer of the Schrödinger equation, the fundamental formulation of quantum mechanics, his public lectures and subsequent book were bound to draw high attention. But no one, not even Schrödinger himself, was likely to have foreseen the consequences. Schrödinger’s What Is Life? is credited with inspiring a generation of physicists and biologists to seek the fundamental character of living systems. Schrödinger brought quantum mechanics, chemistry, and the still poorly formulated concept of “information” into biology. He is the progenitor of our understanding of DNA and the genetic code. Yet as brilliant as was Schrödinger’s insight, I believe he missed the center. Investigations seeks that center and finds, in fact, a mystery.
In my previous two books, I laid out some of the growing reasons to think that evolution was even richer than Darwin supposed. Modern evolutionary theory, based on Darwin’s concept of descent with heritable variations that are sifted by natural selection to retain the adaptive changes, has come to view selection as the sole source of order in biological organisms. But the snowflake’s delicate sixfold symmetry tells us that order can arise without the benefit of natural selection. Origins of Order and At Home in the Universe give good grounds to think that much of the order in organisms, from the origin of life itself to the stunning order in the development of a newborn child from a fertilized egg, does not reflect selection alone. Instead, much of the order in organisms, I believe, is self-organized and spontaneous. Self-organization mingles with natural selection in barely understood ways to yield the magnificence of our teeming biosphere. We must, therefore, expand evolutionary theory.
Yet we need something far more important than a broadened evolutionary theory. Despite any valid insights in my own two books, and despite the fine work of many others, including the brilliance manifest in the past three decades of molecular biology, the core of life itself remains shrouded from view. We know chunks of molecular machinery, metabolic pathways, means of membrane biosynthesis = we know many of the parts and many of the processes. But what makes a cell alive is still not clear to us. The center is still mysterious.
And so I began my notebook “Investigations” in December of 1994, a full half century after Schrödinger’s What Is Life?, as an intellectual enterprise unlike any I had undertaken before. Rather bravely and thinking with some presumptuousness of Wittgenstein’s famous Philosophical Investigations, which had shattered the philosophical tradition of logical atomism in which he had richly participated, I betook myself to my oYce at home in Santa Fe and grandly intoned through my fingers onto the computer’s disc, “Investigations,” on December 4, 1994. I sensed my long search would uncover issues that were then only dimly visible to me. I hoped the unfolding, ongoing notebook would allow me to find the themes and link them into something that was vast and new but at the time inarticulate.
Two years later, in September of 1996, I published a modestly well-organized version of Investigations as a Santa Fe Institute preprint, launched it onto the web, and put it aside for the time being. I found I had indeed been led into arenas that I had in no way expected, led by a swirl of ever new questions. I put the notebooks aside, but a year later I returned to the swirl, taking up again a struggle to see something that, I think, is right in front of us = always the hardest thing to see. This book is the fruit of these eVorts. And this first chapter is but an introduction, in brief, to the themes that will be explained more fully in the following chapters. I would ask the reader to be patient with unfamiliar terms and concepts.
My first eVorts had begun with twin questions. First, in addition to the known laws of thermodynamics, could there possibly be a fourth law of thermodynamics for open thermodynamic systems, some law that governs biospheres anywhere in the cosmos or the cosmos itself? Second, living entities = bacteria, plants, and animals = manipulate the world on their own behalf: the bacterium swimming upstream in a glucose gradient that is easily said to be going to get “dinner”; the paramecium, cilia beating like a Roman warship’s oars, hot after the bacterium; we humans earning our livings. Call the bacterium, paramecium, and us humans “autonomous agents,” able to act on our own behalf in an environment.
My second and core question became, What must a physical system be to be an autonomous agent? Make no mistake, we autonomous agents mutually construct our biosphere, even as we coevolve in it. Why and how this is so is a central subject of all that follows.
From the outset, there were, and remain, reasons for deep skepticism about the enterprise of Investigations. First, there are very strong arguments to say that there can be no general law for open thermodynamic systems. The core argument is simple to state. Any computer program is an algorithm that, given data, produces some sequence of output, finite or infinite. Computer programs can always be written in the form of a binary symbol string of 1 and 0 symbols. All possible binary symbol strings are possible computer programs. Hence, there is a countable, or denumerable, infinity of computer programs. A theorem states that for most computer programs, there is no compact description of the printout of the program. Rather, we must just unleash the program and watch it print what it prints. In short, there is no shorter description of the output of the program than that which can be obtained by running the program itself. If by the concept of a “law” we mean a compact description, ahead of time, of what the computer program will print then for any such program, there can be no law that allows us to predict what the program will actually do ahead of the actual running of the program.
The next step is simple. Any such program can be realized on a universal Turing machine such as the familiar computer. But that computer is an open nonequilibrium thermodynamic system, its openness visibly realized by the plug and power line that connects the computer to the electric power grid. Therefore, and I think this conclusion is cogent, there can be no general law for all possible nonequilibrium thermodynamic systems.
So why was I conjuring the possibility of a general law for open thermodynamic systems? Clearly, no such general law can hold for all open thermodynamic systems.
But hold a moment. It is we humans who conceived and built the intricate assembly of chips and logic gates that constitute a computer, typically we humans who program it, and we humans who contrived the entire power grid that supplies the electric power to run the computer itself. This assemblage of late-twentieth-century technology did not assemble itself. We built it.
On the other hand, no one designed and built the biosphere. The biosphere got itself constructed by the emergence and persistent coevolution of autonomous agents. If there cannot be general laws for all open thermodynamic systems, might there be general laws for thermodynamically open but self-constructing systems such as biospheres? I believe that the answer is yes. Indeed, among those candidate laws to be discussed in this book is a candidate fourth law of thermodynamics for such self-constructing systems.
To roughly state the candidate law, I suspect that biospheres maximize the average secular construction of the diversity of autonomous agents and the ways those agents can make a living to propagate further. In other words, on average, bio-spheres persistently increase the diversity of what can happen next. In eVect, as we shall see later, biospheres may maximize the average sustained growth of their own “dimensionality.”
Thus, the enterprise of Investigations soon began to center on the character of the autonomous agents whose coevolution constructs a biosphere. I was gradually led to a labyrinth of issues concerning the core features of autonomous agents able to manipulate the world on their own behalf. It may be that those core features capture a proper definition of life and that definition diVers from the one Schrödinger found.
To state my hypothesis abruptly and without preamble, I think an autonomous agent is a self-reproducing system able to perform at least one thermodynamic work cycle. It will require most of this book to unfold the implications of this tentative definition.
Following an eVort to understand what an autonomous agent might be = which, as just noted, involves the concept of work cycles = I was led to the concepts of work itself, constraints, and work as the constrained release of energy. In turn, this led to the fact that work itself is often used to construct constraints on the release of energy that then constitutes further work. So we confront a virtuous cycle: Work constructs constraints, yet constraints on the release of energy are required for work to be done. Here is the heart of a new concept of “organization” that is not covered by our concepts of matter alone, energy alone, entropy alone, or information alone. In turn, this led me to wonder about the relation between the emergence of constraints in the universe and in a biosphere, and the diversification of patterns of the constrained release of energy that alone constitute work and the use of that work to build still further constraints on the release of energy. How do biospheres construct themselves or how does the universe construct itself?
The considerations above led to the role of Maxwell’s demon, one of the major places in physics where matter, energy, work, and information come together. The central point of the demon is that by making measurements on a system, the information gained can be used to extract work. I made a new distinction between measurements the demon might make that reveal features of nonequilibrium systems that can be used to extract work, and measurements he might make of the nonequilibrium system that cannot be used to extract work. How does the demon know what features to measure? And, in turn, how does work actually come to be extracted by devices that measure and detect displacements from equilibrium from which work can, in principle, be obtained? An example of such a device is a windmill pivoting to face the wind, then extracting work by the wind turning its vanes. Other examples are the rhodopsin molecule of a bacterium responding to a photon of light or a chloroplast using the constrained release of the energy of light to construct high-energy sugar molecules. How do such devices come into existence in the unfolding universe and in our biosphere? How does the vast web of constraint construction and constrained energy release used to construct yet more constraints happen into existence in the biosphere? In the universe itself? The answers appear not to be present in contemporary physics, chemistry, or biology. But a coevolving biosphere accomplishes just this coconstruction of propagating organization.
Thus, in due course, I struggled with the concept of organization itself, concluding that our concepts of entropy and its negative, Shannon’s information theory (which was developed initially to quantify telephonic traYc and had been greatly extended since then) entirely miss the central issues. What is happening in a biosphere is that autonomous agents are coconstructing and propagating organizations of work, of constraint construction, and of task completion that continue to propagate and proliferate diversifying organization.
This statement is just plain true. Look out your window, burrow down a foot or so, and try to establish what all the microscopic life is busy doing and building and has done for billions of years, let alone the macroscopic ecosystem of plants, herbivores, and carnivores that is slipping, sliding, hiding, hunting, bursting with flowers and leaves outside your window. So, I think, we lack a concept of propagating organization.
Then too there is the mystery of the emergence of novel functionalities in evolution where none existed before: hearing, sight, flight, language. Whence this novelty? I was led to doubt that we could prestate the novelty. I came to doubt that we could finitely prestate all possible adaptations that might arise in a biosphere. In turn, I was led to doubt that we can prestate the “configuration space” of a biosphere.
But how strange a conclusion. In statistical mechanics, with its famous liter box of gas as an isolated thermodynamic system, we can prestate the configuration space of all possible positions and momenta of the gas particles in the box. Then Ludwig Boltzmann and Willard Gibbs taught us how to calculate macroscopic properties such as pressure and temperature as equilibrium averages over the configuration space. State the laws and the initial and boundary conditions, then calculate; Newton taught us how to do science this way. What if we cannot prestate the configuration space of a biosphere and calculate with Newton’s “method of fluxions,” the calculus, from initial and boundary conditions and laws? Whether we can calculate or not does not slow down the persistent evolution of novelty in the biosphere. But a biosphere is just another physical system. So what in the world is going on? Literally, what in the world is going on?
We have much to investigate. At the end, I think we will know more than at the outset. But Investigations is at best a mere beginning.
It is well to return to Schrödinger’s brilliant insights and his attempt at a central definition of life as a well-grounded starting place. Schrödinger ‘s What Is Life? provided a surprising answer to his enquiry about the central character of life by posing a core question: What is the source of the astonishing order in organisms? The standard = and Schrödinger argued, incorrect = answer, lay in statistical physics. If an ink drop is placed in still water in a petri dish, it will diVuse to a uniform equilibrium distribution. That uniform distribution is an average over an enormous number of atoms or molecules and is not due to the behavior of individual molecules. Any local fluctuations in ink concentration soon dissipate back to equilibrium.
Could statistical averaging be the source of order in organisms? Schrödinger based his argument on the emerging field of experimental genetics and the recent data on X-ray induction of heritable genetic mutations. Calculating the “target size” of such mutations, Schrödinger realized that a gene could comprise at most a few hundred or thousand atoms.
The sizes of statistical fluctuations familiar from statistical physics scale as the square root of the number of particles, N. Consider tossing a fair coin 10,000 times. The result will be about 50 percent heads, 50 percent tails, with a fluctuation of about 100, which is the square root of 10,000. Thus, a typical fluctuation from 50:50 heads and tails is 100/10,000 or 1 percent. Let the number of coin flips be 100 million, then the fluctuations are its square root, or 10,000. Dividing, 10,000/100,000,000 yields a typical deviation of .01 percent from 50:50.
Schrödinger reached the correct conclusion: If genes are constituted by as few as several hundred atoms, the familiar statistical fluctuations predicted by statistical mechanics would be so large that heritability would be essentially impossible. Spontaneous mutations would happen at a frequency vastly larger than observed. The source of order must lie elsewhere.
Quantum mechanics, argued Schrödinger, comes to the rescue of life. Quantum mechanics ensures that solids have rigidly ordered molecular structures. A crystal is the simplest case. But crystals are structurally dull. The atoms are arranged in a regular lattice in three dimensions. If you know the positions of all the atoms in a minimal-unit crystal, you know where all the other atoms are in the entire crystal. This overstates the case, for there can be complex defects, but the point is clear. Crystals have very regular structures, so the diVerent parts of the crystal, in some sense, all “say” the same thing. As shown below, Schrödinger translated the idea of “saying” into the idea of “encoding.” With that leap, a regular crystal cannot encode much “information.” All the information is contained in the unit cell.
If solids have the order required but periodic solids such as crystals are too regular, then Schrödinger puts his bet on aperiodic solids. The stuV of the gene, he bets, is some form of aperiodic crystal. The form of the aperiodicity will contain some kind of microscopic code that somehow controls the development of the organism. The quantum character of the aperiodic solid will mean that small discrete changes, or mutations, will occur. Natural selection, operating on these small discrete changes, will select out favorable mutations, as Darwin hoped.
Fifty years later, I find Schrödinger’s argument fascinating and brilliant. At once he envisioned what became, by 1953, the elucidation of the structure of DNA’s aperiodic double helix by James Watson and Francis Crick, with the famously understated comment in their original paper that its structure suggests its mode of replication and its mode of encoding genetic information.
Fifty years later we know very much more. We know the human genome harbors some 80,000 to 100,000 “structural genes,” each encoding the RNA that, after being transcribed from the DNA, is translated according to the genetic code to a linear sequence of amino acids, thereby constituting a protein. From Schrödinger to the establishment of the code required only about twenty years.
Beyond the brilliance of the core of molecular genetics, we understand much concerning developmental biology. Humans have about 260 diVerent cell types: liver, nerve, muscle. Each is a diVerent pattern of expression of the 80,000 or 100,000 genes. Since the work of François Jacob and Jacques Monod thirty-five years ago, biologists have understood that the protein transcribed from one gene might turn other genes on or oV. Some vast network of regulatory interactions among genes and their products provides the mechanism that marshals the genome into the dance of development.
We have come close to Schrödinger’s dream. But have we come close to answering his question, What is life? The answer almost surely is no. I am unable to say, all at once, why I believe this, but I can begin to hint at an explanation. Investigations is a search for an answer. I am not entirely convinced of what lies within this book; the material is too new and far too surprising to warrant conviction. Yet the pathways I have stumbled along, glimpsing what may be a terra nova, do seem to me to be worth serious presentation and serious consideration.
Quite to my astonishment, the story that will unfold here suggests a novel answer to the question, What is life? I had not expected even the outlines of an answer, and I am astonished because I have been led in such unexpected directions. One direction suggests that an answer to this question may demand a fundamental alteration in how we have done science since Newton. Life is doing something far richer than we may have dreamed, literally something incalculable. What is the place of law if, as hinted above, the variables and configuration space cannot be prespecified for a biosphere, or perhaps a universe? Yet, I think, there are laws. And if these musings be true, we must rethink science itself.
Perhaps I can point again at the outset to the central question of an autonomous agent. Consider a bacterium swimming upstream in a glucose gradient, its flagellar motor rotating. If we naively ask, “What is it doing?” we unhesitatingly answer something like, “It’s going to get dinner.” That is, without attributing consciousness or conscious purpose, we view the bacterium as acting on its own behalf in an environment. The bacterium is swimming upstream in order to obtain the glucose it needs. Presumably we have in mind something like the Darwinian criteria to unpack the phrase, “on its own behalf.” Bacteria that do obtain glucose or its equivalent may survive with higher probability than those incapable of the flagellar motor trick, hence, be selected by natural selection.
An autonomous agent is a physical system, such as a bacterium, that can act on its own behalf in an environment. All free-living cells and organisms are clearly autonomous agents. The quite familiar, utterly astonishing feature of autonomous agents = E. coli, paramecia, yeast cells, algae, sponges, flat worms, annelids, all of us = is that we do, everyday, manipulate the universe around us. We swim, scramble, twist, build, hide, snuZe, pounce.
Yet the bacterium, the yeast cell, and we all are just physical systems. Physicists, biologists, and philosophers no longer look for a mysterious élan vital, some ethereal vital force that animates matter. Which leads immediately to the central, and confusing, question: What must a physical system be such that it can act on its own behalf in an environment? What must a physical system be such that it constitutes an autonomous agent? I will leap ahead to state now my tentative answer: A molecular autonomous agent is a self-reproducing molecular system able to carry out one or more thermodynamic work cycles.
All free-living cells are, by this definition, autonomous agents. To take a simple example, our bacterium with its flagellar motor rotating and swimming upstream for dinner is, in point of plain fact, a self-reproducing molecular system that is carrying out one or more thermodynamic work cycles. So is the paramecium chasing the bacterium, hoping for its own dinner. So is the dinoflagellate hunting the paramecium sneaking up on the bacterium. So are the flower and flatworm. So are you and I.
It will take a while to fully explore this definition. Unpacking its implications reveals much that I did not remotely anticipate. An early insight is that an autonomous agent must be displaced from thermodynamic equilibrium. Work cycles cannot occur at equilibrium. Thus, the concept of an agent is, inherently, a nonequilibrium concept. So too at the outset it is clear that this new concept of an autonomous agent is not contained in Schrödinger’s answer. Schrödinger’s brilliant leap to aperiodic solids encoding the organism that unleashed mid-twentieth-century biology appears to be but a glimmer of a far larger story.
Footprints of Destiny: The Birth of Astrobiology
The telltale beginnings of that larger story are beginning to be formulated. The U.S. National Aeronautics and Space Agency has had a long program in “exobiology,” the search for life elsewhere in the universe. Among its well-known interests are SETI, a search for extraterrestrial life, and the Mars probes. Over the past three decades, a sustained eVort has included a wealth of experiments aiming at discovering the abiotic origins of the organic molecules that are the building blocks of known living systems.
In the summer of 1997, NASA was busy attempting to formulate what it came to call “astrobiology,” an attempt to understand the origin, evolution, and characteristics of life anywhere in the universe. Astrobiology does not yet exist = it is a field in the birthing process. Whatever the area comes to be called as it matures, it seems likely to be a field of spectacular success and deep importance in the coming century. A hint of the potential impact of astrobiology came in August 1997 with the tentative but excited reports of a Martian meteorite found in Antarctica that, NASA scientists announced, might have evidence of early Martian microbial life. The White House organized the single-day “Space Conference,” to which I was pleased to be invited. Perhaps thirty-five scientists and scholars gathered in the Old Executive OYce Building for a meeting led by Vice President Gore. The vice president began the meeting with a rather unexpected question to the group: If it should prove true that the Martian rock actually harbored fossilized microbial life, what would be the least interesting result? 
The room was silent, for a moment. Then Stephen Jay Gould gave the answer many of us must have been considering: “Martian life turns out to be essentially identical to Earth life, same DNA, RNA, proteins, code.” Were it so, then we would all envision life flitting from planet to planet in our solar system. It turns out that a minimum transit time for a fleck of Martian soil kicked into space to make it to earth is about fifteen thousand years. Spores can survive that long under desiccating conditions.
“And what,” continued the vice president, “would be the most interesting result?” Ah, said many of us, in diVerent voices around the room: Martian life is radically diVerent from Earth life.
If radically diVerent, then.   .   .   .   
If radically diVerent, then life must not be improbable.
If radically diVerent, then life may be abundant among the myriad stars and solar systems, on far planets hinted at by our current astronomy.
If radically diVerent and abundant, then we are not alone.
If radically diVerent and abundant, then we inhabit a universe rife with the creativity to create life.
If radically diVerent, then = thought I of my just published second book = we are at home in the universe.
If radically diVerent, then we are on the threshold of a new biology, a “general biology” freed from the confines of our known example of Earth life.
If radically diVerent, then a new science seeking the origins, evolution, characteristics, and laws that may govern biospheres anywhere.
A general biology awaits us. Call it astrobiology if you wish. We confront the vast new task of understanding what properties and laws, if any, may characterize bio-spheres anywhere in the universe. I find the prospect stunning. I will argue that the concept of an autonomous agent will be central to the enterprise of a general biology.
A personally delightful moment arose during that meeting. The vice president, it appeared, had read At Home in the Universe, or parts of it. In At Home, and also in this book, I explore a theory I believe has deep merit, one that asserts that, in complex chemical reaction systems, self-reproducing molecular systems form with high probability.
The vice president looked across the table at me and asked, “Dr. KauVman, don’t you have a theory that in complex chemical reaction systems life arises more or less spontaneously?”
“Yes.”
“Well, isn’t that just sensible?”
I was, of course, rather thrilled, but somewhat embarrassed. “The theory has been tested computationally, but there are no molecular experiments to support it,” I answered.
“But isn’t it just sensible?” the vice president persisted.
I couldn’t help my response, “Mr. Vice President, I have waited a long time for such confirmation. With your permission, sir, I will use it to bludgeon my enemies.”
I’m glad to say there was warm laughter around the table. Would that scientific proof were so easily obtained. Much remains to be done to test my theory.
Many of us, including Mr. Gore, while maintaining skepticism about the Mars rock itself, spoke at that meeting about the spiritual impact of the discovery of life elsewhere in the universe. The general consensus was that such a discovery, linked to the sense of membership in a creative universe, would alter how we see ourselves and our place under all, all the suns. I find it a gentle, thrilling, quiet, and transforming vision.
Molecular Diversity
We are surprisingly well poised to begin an investigation of a general biology, for such a study will surely involve the understanding of the collective behaviors of very complex chemical reaction networks. After all, all known life on earth is based on the complex webs of chemical reactions = DNA, RNA, proteins, metabolism, linked cycles of construction and destruction = that form the life cycles of cells. In the past decade we have crossed a threshold that will rival the computer revolution. We have learned to construct enormously diverse “libraries” of diVerent DNA, RNA, proteins, and other organic molecules. Armed with such high-diversity libraries, we are in a position to begin to study the properties of complex chemical reaction networks.
To begin to understand the molecular diversity revolution, consider a crude estimate of the total organic molecular diversity of the biosphere. There are perhaps a hundred million species. Humans have about a hundred thousand structural genes, encoding that many diVerent proteins. If all the genes within a species were identical, and all the genes in diVerent species were at least slightly diVerent, the biosphere would harbor about ten trillion diVerent proteins. Within a few orders of magnitude, ten trillion will serve as an estimate of the organic molecular diversity of the natural biosphere. But the current technology of molecular diversity that generates libraries of more or less random DNA, RNA, or proteins now routinely produces a diversity of a hundred trillion molecular species in a single test tube.
In our hubris, we rival the biosphere.
The field of molecular diversity was born to help solve the problem of drug discovery. The core concept is simple. Consider a human hormone such as estrogen. Estrogen acts by binding to a specific receptor protein; think of the estrogen as a “key” and the receptor as a “lock.” Now generate sixty-four million diVerent small proteins, called peptides, say, six amino acids in length. (Since there are twenty types of amino acids, the number of possible hexamers is 20ﬂ, hence, sixty-four million.) The sixty-four million hexamer peptides are candidate second keys, any one of which might be able to fit into the same estrogen receptor lock into which estrogen fits. If so, any such second key may be similar to the first key, estrogen, and hence is a candidate drug to mimic or modulate estrogen.
To find such an estrogen mimic, take many identical copies of the estrogen receptor, afix them to the bottom of a petri plate, and expose them simultaneously to all sixty-four million hexamers. Wash oV all the peptides that do not stick to the estrogen receptor, then recover those hexamers that do stick to the estrogen receptor. Any such peptide is a second key that binds the estrogen receptor locks and, hence, is a candidate estrogen mimic.
The procedure works, and works brilliantly. By 1990, George Smith at the University of Missouri used a specific kind of virus, a filamentous phage that infects bacteria. The phage is a strand of RNA that encodes proteins. Among these proteins is the coat protein that packages the head of the phage as part of an infective phage particle. George cloned random DNA sequences encoding random hexamer peptides into one end of the phage coat protein gene. Each phage then carried a diVerent, random DNA sequence in its coat protein gene, hence made a coat protein with a random six amino acid sequence at one end. The initial resulting “phage display” libraries had about twenty million of the sixty-four million diVerent possible hexamer peptides.
Rather than using the estrogen receptor and seeking a peptide estrogen mimic that binds the estrogen receptor, George Smith used a monoclonal antibody molecule as the analogue of the receptor and sought a hexamer peptide that could bind the monoclonal antibody. Monoclonal antibody technology allows the generation of a large number of identical antibody molecules, hence George could use these as identical mock receptors. George found that, among the twenty million diVerent phage, about one in a million would stick to his specific monoclonal antibody molecules. In fact, George found nineteen diVerent hexamers binding to his monoclonal antibody. Moreover, the nineteen diVerent hexamers diVered from one another, on average, in three of the six amino acid positions. All had high aYnity for his monoclonal antibody target. 
These results have been of very deep importance. Phage display is now a central part of drug discovery in many pharmaceutical and biotechnology companies. The discovery of “drug leads” is being transformed from a diYcult to a routine task. Not only is work being pursued using peptides but also using RNA and DNA sequences. Molecular diversity has now spread to the generation of high-diversity libraries of small organic molecules, an approach called “combinatorial chemistry.” The promise is of high medical importance. As we understand better the genetic diversity of the human population, we can hope to create well-crafted molecules with increased eYcacy as drugs, vaccines, enzymes, and novel molecular structures. When the capacity to craft such molecules is married, as it will be in the coming decades, to increased understanding of the genetic and cellular signaling pathways by which ontogeny is controlled, we will enter an era of “postgenomic” medicine. By learning to control gene regulation and cell signaling, we will begin to control cell proliferation, cell diVerentiation, and tissue regeneration to treat pathologies such as cancer, autoimmune diseases, and degenerative diseases.
But George Smith’s experiments are also of immediate interest, and in surprising ways that will bear on our later discussion of autonomous agents.
George’s experiments have begun to verify the concept of a “shape space” put forth by George Oster and Alan Perelson of the University of California, Berkeley, and Los Alamos National Laboratory more than a decade earlier. In turn, shape space suggests “catalytic task space.” We will need both to understand autonomous agents.
Oster and Perelson had been concerned about accounting for the fact that humans can make about a hundred million diVerent antibody molecules. Why, they wondered. They conceived of an abstract shape space with perhaps seven or eight “dimensions.” Three of these dimensions would correspond to the three spatial dimensions, length, height, and width of a molecular binding site. Other dimensions might correspond to physical properties of the binding sites of molecules, such as charge, dipole moment, and hydrophobicity.
A point in shape space would represent a molecular shape. An antibody binds its shape complement, key and lock. But the precision with which an antibody can recognize its shape complement is finite. Some jiggle room is allowed. So an antibody molecule “covers” a kind of “ball” of complementary shapes in shape space. And then comes the sweet argument. If an antibody covers a ball, an actual volume, in shape space, then a finite number of balls will suYce to cover all of shape space. A reasonable analogy is that a finite number of Ping-Pong balls will fill up a bedroom.
But how big of a Ping-Pong ball in shape space is covered by one antibody? Oster and Perelson reasoned that in order for an immune system to protect an organism against disease, its antibody repertoire should cover a reasonable fraction of shape space. Newts, with about ten thousand diVerent antibody molecules, have the minimal known antibody diversity. Perelson and Oster guessed that the newt repertoire must cover a substantial fraction, say about 1/e = where e is the natural base for logarithms = or 37 percent of shape space. Dividing 37 percent by 10,000 gives the fractional volume of shape space covered by one antibody molecule. It follows that 100,000,000 such balls, thrown at random into shape space and allowed to overlap one another, will saturate shape space. So, 100 million antibody molecules is all we need to recognize virtually any shape of the size scale of molecular binding sites.
And therefore the concept of shape space carries surprising implications. Not surprisingly, similar molecules can have similar shapes. More surprisingly, very diVerent molecules can have the same shape. Examples include endorphin and morphine. Endorphin is a peptide hormone. When endorphin binds the endorphin brain receptor, a euphoric state is induced. Morphine, a completely diVerent kind of organic molecule, binds the endorphin receptor as well, with well-known consequences. Still more surprising, a finite number of diVerent molecules, about a hundred million, can constitute a universal shape library. Thus, while there are vastly many diVerent proteins, the number of eVectively diVerent shapes may only be on the order of a hundred million.
If one molecule binding to a second molecule can be thought of as carrying out a “binding task,” then about a hundred million diVerent molecules may constitute a universal toolbox for all molecular binding tasks. So if we can now create libraries with 100 trillion diVerent proteins, a millionfold in excess of the universal library, we are in a position to begin to study molecular binding in earnest.
But there may also be a universal enzymatic toolbox. Enzymes catalyze, or speed up, chemical reactions. Consider a substrate molecule undergoing a reaction to a product molecule. Physical chemists think of the substrate and product molecules as lying in two potential “energy wells,” like a ball at the bottom of one of two adjacent bowls. A chemical reaction requires “lifting” the substrate energetically to the top of the barrier between the bowls. Physically, the substrate’s bonds are maximally strained and deformed at the top of this potential barrier. The deformed molecule is called the “transition state.” According to transition state theory, an enzyme works by binding to and stabilizing the transition state molecule, thereby lowering the potential barrier of the reaction. Since the probability that a molecule acquires enough energy to hop to the top of the potential barrier is exponentially less as the barrier height increases, the stabilization of the transition state by the enzyme can speed up the reaction by many orders of magnitude.
Think of a catalytic task space, in which a point represents a catalytic task, where a catalytic task is the binding of a transition state of a reaction. Just as similar molecules can have similar shapes, so too can similar reactions have similar transition states, hence, such reactions constitute similar catalytic tasks. Just as diVerent molecules can have the same shape, so too can diVerent reactions have similar transition states, hence constitute the “same” catalytic task. Just as an antibody can bind to and cover a ball of similar shapes, an enzyme can bind to and cover a ball of similar catalytic tasks. Just as a finite number of balls can cover shape space, a finite number of balls can cover catalytic task space.
In short, a universal enzymatic toolbox is possible. Clues that such a toolbox is experimentally feasible come from many recent developments, including the discovery that antibody molecules, evolved to bind molecular features called epitopes, can actually act as catalysts.
Catalytic antibodies are obtained exactly as one might expect, given the concept of a catalytic task space. One would like an antibody molecule that binds the transition state of a reaction. But transition states are ephemeral. Since they last only fractions of a second, one cannot immunize with a transition state itself. Instead, one immunizes with a stable analogue of the transition shape; that is, one immunizes with a second molecule that represents the “same” catalytic task as does the transition state itself. Antibody molecules binding to this transition state analogue are tested. Typically, about one in ten antibody molecules can function as at least a weak catalyst for the corresponding reaction.
These results even allow a crude estimate of the probability that a randomly chosen antibody molecule will catalyze a randomly chosen reaction. About one antibody in a hundred thousand can bind a randomly chosen epitope. About one in ten antibodies that bind the transition state analogue act as catalysts. By this crude calculation, about one in a million antibody molecules can catalyze a given reaction.
This rough calculation is probably too high by several orders of magnitude, even for antibody molecules. Recent experiments begin to address the probability that a randomly chosen peptide or DNA or RNA sequence will catalyze a randomly chosen reaction. The answer for DNA or RNA appears to be about one in a billion to one in a trillion. If we now make libraries of a hundred trillion random DNA, RNA, and protein molecules, we may already have in hand universal enzymatic toolboxes. Virtually any reaction, on the proper molecular scale of reasonable substrates and products, probably has one or more catalysts in such a universal toolbox.
In short, among the radical implications of molecular diversity is that we already possess hundreds of millions of diVerent molecular functions = binding, catalytic, structural, and otherwise.
In our hubris, we rival the biosphere.
In our humility, we can begin to formulate a general biology and begin to investigate the collective behaviors of hugely diverse molecular libraries. Among these collective behaviors must be life itself.
Life as an Emergent Collective Behavior of Complex Chemical Networks
In the summer of 1996, Philip Anderson, a Nobel laureate in physics, and I accompanied Dr. Henry MacDonald, incoming director of NASA, Ames, to NASA headquarters. Our purpose was to discuss a new linked experimental and theoretical approach to the origin-of-life problem with NASA Administrator Dan Golden and his colleague, Dr. Wesley Huntress. I was excited and delighted.
As long ago as 1971, I had published my own first foray into the origin-of-life problem as a young assistant professor in the Department of Theoretical Biology at the University of Chicago. I had wondered if life must be based on template replicating nucleic acids such as DNA or RNA double helices and found myself doubting that standard assumption. Life, at its core, depends upon autocatalysis, that is, reproduction. Most catalysis in cells is carried out by protein enzymes. Might there be general laws supporting the possibility that systems of catalytic polymers such as proteins might be self-reproducing? Proteins are, as noted, linear sequences of twenty kinds of standard amino acids. Consider, then, a first copy of a protein that has the capacity to catalyze a reaction by which two fragments of a potential second copy of that same protein might be ligated to make the second copy of the whole protein. Such a protein, A, say, thirty-two amino acids long, might act on two fragments, say, fifteen amino acids and seventeen amino acids in length, and ligate the two to make a second copy of the thirty-two amino acid sequence.
But if one could imagine a molecule, A, catalyzing its own formation from its own fragments, could one not imagine two proteins, A and B, having the property that A catalyzes the formation of B by ligating B’s fragments into a second copy of B, while B catalyzes the formation of A by catalyzing the ligation of A’s fragments into a second copy of A? Such a little reaction system would be collectively autocatalytic. Neither A alone, nor B alone, would catalyze its own formation. Rather the AB system would jointly catalyze its reproduction from A and B fragments. But if A and B might achieve collective autocatalysis, might one envision a system with tens or hundreds of proteins, or peptides, that were collectively autocatalytic?
Might collective autocatalysis of proteins or similar polymers be the basic source of self-reproduction in molecular systems? Or must life be based on template replication, as envisioned by Watson and Crick, or as envisioned even earlier by Schrödinger in his aperiodic solid with its microcode? In view of the potential for a general biology, what, in fact, are the alternative bases for self-reproducing molecular systems here and anywhere in the cosmos? Which of these alternatives is more probable, here and anywhere?
By 1971 I had asked and found a preliminary answer to the following question: In a complex mixture of diVerent proteins, where the proteins might be able to serve as candidates to ligate one another into still larger amino acid sequences, what are the chances that such a system will contain one or more collectively autocatalytic sets of molecules? In the next chapter I will discuss the current state of theory and experiment on this issue. The best current guess is that, as the molecular diversity of a reaction system increases, a critical threshold is reached at which collectively autocatalytic, self-reproducing chemical reaction networks emerge spontaneously.
If this view is correct, and the kinetic conditions for rapid reactions can be sustained, perhaps by enclosure of such a reproducing system in a bounding membrane vesicle, also synthesized by the system, the emergence of self-reproducing molecular systems may be highly probable. No small conclusion this: Life abundant, emergent, expected. Life spattered across megaparsecs, galaxies, galactic clusters. We as members of a creative, mysteriously unfolding universe. Moreover, the hypothesis is richly testable and, as described in the next chapter, is now under the early stages of testing.
One way or another, we will discover a second life = crouched under a Mars rock, frozen in time; limpid in some pool on Titan, in some test tube in Nebraska in the next few decades. We will discover a second life, one way or another.
What monumental transformations await us, proudly postmodern, mingled with peoples on this very globe still wedded to archetypes thousands of years old.
The Strange Thing About the Theory of Evolution
We do not understand evolution. We live it with moss, fruit, fin, and quill fellows. We see it since Darwin. We have insights of forms and their formation, won from eVorts since Aristotle codified the embryological investigations that over twenty-five centuries ago began with the study of deformed fetuses in sacrificial animals.
But we do not understand evolution.
“The strange thing about the theory of evolution,” said one of the Huxleys (although I cannot find which one), “is that everyone thinks he understands it.” How very well stated in that British fashion Americans can admire but not emulate. (“Two peoples separated by a common language,” as Churchill dryly put it.)
The strange thing about the theory of evolution is that everyone thinks he understands it. How very true. It seems, of course, so simple. Finches hop around the Galapagos, occasionally migrating from island to island. Small and large beaks serve for diVerent seeds. Beaks fitting seeds feed the young. Well-wrought beaks are selected. Mutations are the feedstock of heritable variation in a population. Populations evolve by mutation, mating, recombination, and selection to give the well-marked varieties that are, for Darwin, new species. Phylogenies bushy in the biosphere. “We’re here, we’re here,” cry all for their typical four-million-year-stay along the four-billion-year pageant.
“We’re here!”
But how?
How, in many senses. First, Darwin’s theory of evolution is a theory of descent with modification. It does not yet explain the genesis of forms, but the trimmings of the forms, once they are generated. “Rather like achieving an apple tree by trimming oV all the branches,” said a late-nineteenth-century skeptic.
How, in the most fundamental sense: Whence life in the first place? Darwin starts with life already here. Whence life is the stuV of all later questions about whence the forms to sift.
How, in still a diVerent sense. Darwin assumed gradualism. Most variation would be minor. Selection would sift these insensible alterations, a bit more lift, a little less drag, until the wing flew faultless in the high-hoped sky, a falcon’s knot-winged, claw-latching dive to dine.
But whence the gradualism itself? It is not God given, but true, that organisms are hardly aVected by most mutations. Most mutations do have little eVect, some have major eVects. In Drosophila, many mutants make small modifications in bristle number, color, shape. A few change wings to legs, eyes to antennae, heads to genitalia. Suppose that all mutations were of dramatic eVect. Suppose, to take the limiting philosophical case, that all mutations were what geneticists call “lethals.” Since, indeed, some mutations are lethals, one can, a priori, imagine creatures in which all mutations were lethal prior to having oVspring. Might be fine creatures, too, in the absence of any mutations, these evolutionary descendants of, well, of what? And progenitors of whom? No pathway to or from these luckless ones.
Thus, evolution must somehow be crafting the very capacity of creatures to evolve. Evolution nurtures herself! But not yet in Darwin’s theory, nor yet in ours.
Take another case = sex. Yes, it captures our attention, and the attention of most members of most species. Most species are sexual. But why bother? Asexuals, budding quietly wherever they bud, require only a single parent. We plumaged ones require two, a twofold loss in fitness.
Why sex? The typical answer, to which I adhere, is that sexual mating gives the opportunity for genetic recombination. In genetic recombination, the double chromosome complement sets, maternal and paternal homologues, pair up, break and recombine to yield oVspring chromosomes the left half of which derives from one parental chromosome, the right half of which derives from the other parental chromosome.
Recombination is said to be a useful “search procedure” in an evolving population. Consider, a geneticist would say, two genes, each with two versions, or alleles: A and a for the first gene, B and b for the second gene. Suppose A confers a selective advantage compared to a, and B confers an advantage with respect to b. In the absence of sex, mating, and recombination, a rabbit with A and b would have to wait for a mutation to convert b to B. That might take a long time. But, with mating and recombination, a rabbit with A on the left end of a maternal chromosome, and B on the right end of the homologous paternal chromosome might experience recombination. A and B would now be on a single chromosome, hence be passed on to the oVspring. Recombination, therefore, can be a lot faster than waiting for mutation to assemble the good, AB chromosome.
But it is not so obvious that recombination is a good idea after all. At the molecular level, the recombination procedure is rather like taking an airplane and a motorcycle, breaking both in half, and using spare bolts to attach the back half of the airplane to the front half of the motorcycle. The resulting contraption seems useless for any purpose. 
In short, the very usefulness of recombination depends upon the gradualness that Darwin assumed. In later chapters I will discuss the concept of a “fitness landscape.” The basic idea is simple. Consider a set of all possible frogs, each with a diVerent genotype. Locate each frog in a high-dimensional “genotype space,” each next to all genotypes that diVer from it by a single mutation. Imagine that you can measure the fitness of each frog. Graph the fitness of each frog as a height above that position in genotype space. The resulting heights form a fitness landscape over the genotype space, much as the Alps form a mountainous landscape over part of Europe.
In the fitness landscape, image, mutation, recombination, and selection can conspire to pull evolving populations upward toward the peaks of high fitness. But not always. It is relatively easy to show that recombination is only a useful search procedure on smooth fitness landscapes. The smoothness of a fitness landscape can be defined mathematically by a correlation function giving the similarity of fitnesses, or heights, at two points on the landscape separated by a mutational distance. In the Alps, most nearby points are of similar heights, except for cliVs, but points fifty kilometers apart can be of very diVerent heights. Fifty kilometers is beyond the correlation length of the Alps.
There is good evidence that recombination is only a useful search strategy on smooth, highly correlated landscapes, where the high peaks all cluster near one another. Recombination, half airplane–half motorcycle, is a means to look “between” two positions in a high-dimensional space. Then if both points are in the region of high peaks, looking between those two points is likely to uncover further new points of high fitness, or points on the slopes of even higher peaks. Thereafter, further mutation, recombination, and selection can bring the adapting population to successively higher peaks in the high-peaked region of the genotype space. If landscapes are very rugged and the high peaks do not cluster into smallish regions, recombination turns out to be a useless search strategy.
But most organisms are sexual. If organisms are sexual because recombination is a good search strategy, but recombination is only useful as a search strategy on certain classes of fitness landscapes, where did those fitness landscapes come from? No one knows.
The strange thing about evolution is that everyone thinks he understands it.
Somehow, evolution has brought forth the kind of smooth landscapes upon which recombination itself is a successful search strategy.
More generally, two young scientists, then at the Santa Fe Institute, proved a rather unsettling theorem. Bill Macready and David Wolpert called it the “no-free-lunch theorem.” They asked an innocent question. Are there some search procedures that are “good” search procedures, no matter what the problem is? To formalize this, Bill and David considered a mathematical convenience = a set of all possible fitness landscapes. To be simple and concrete, consider a large three-dimensional room. Divide the room into very small cubic volumes, perhaps a millimeter on a side. Let the number of these small volumes in the room be large, say a trillion. Now consider all possible ways of assigning integers between one and a trillion, to these small volumes. Any such assignment can be thought of as a fitness landscape, with the integer representing the fitness of that position in the room.
Next, formalize a search procedure as a process that somehow samples M distinct volumes among the trillion in the room. A search procedure specifies how to take the M samples. An example is a random search, choosing the M boxes at random. A second procedure starts at a box and samples its neighbors, climbing uphill via neighboring boxes toward higher integers. Still another procedure picks a box, samples neighbors and picks those with lower integers, then continues.
The no-free-lunch theorem says that, averaged over all possible fitness landscape, no search procedure outperforms any other search procedure. What? Averaged over all possible fitness landscapes, you would do as well trying to find a large integer by searching randomly from an initial box for your M samples as you would climbing sensibly uphill from your initial box.
The theorem is correct. In the absence of any knowledge, or constraint, on the fitness landscape, on average, any search procedure is as good as any other.
But life uses mutation, recombination, and selection. These search procedures seem to be working quite well. Your typical bat or butterfly has managed to get itself evolved and seems a rather impressive entity. The no-free-lunch theorem brings into high relief the puzzle. If mutation, recombination, and selection only work well on certain kinds of fitness landscapes, yet most organisms are sexual, and hence use recombination, and all organisms use mutation as a search mechanism, where did these well-wrought fitness landscapes come from, such that evolution manages to produce the fancy stuV around us?
Here, I think, is how. Think of an organism’s niche as a way of making a living. Call a way of making a living a “natural game.” Then, of course, natural games evolve with the organisms making those livings during the past four billion years. What, then, are the “winning games”? Naturally, the winning games are the games the winning organisms play. One can almost see Darwin nod. But what games are those? What games are the games the winners play?
Ways of making a living, natural games, that are well searched out and well mastered by the evolutionary search strategies of organisms, namely, mutation and recombination, will be precisely the niches, or ways of making a living, that a diversifying and speciating population of organisms will manage to master. The ways of making a living presenting fitness landscapes that can be well searched by the procedures that organisms have in hand will be the very ways of making a living that readily come into existence. If there were a way of making a living that could not be well explored and exploited by organisms as they speciate, that way of making a living would not become populated. Good jobs, like successful jobholders, prosper.
So organisms, niches, and search procedures jointly and self-consistently coconstruct one another! We make the world in which we make a living such that we can, and have, more or less mastered that evolving world as we make it. The same is true, I will argue, for an econosphere. A web of economic activities, firms, tasks, jobs, workers, skills, and learning, self-consistently came into existence in the last forty thousand years of human evolution.
The strange thing about the theory of evolution is that everyone thinks he understands it. But we do not. A biosphere, or an econosphere, self-consistently coconstructs itself according to principles we do not yet fathom.
Laws for a Biosphere
But there must be principles. Think of the Magna Carta, that cultural enterprise founded on a green meadow in England when John I was confronted by his nobles. British common law has evolved by precedent and determinations to a tangled web of more-or-less wisdom. When a judge makes a new determination, sets a new precedent, ripples of new interpretation pass to near and occasionally far reaches of the law. Were it the case that every new precedent altered the interpretation of all old judgments, the common law could not have coevolved into its rich tapestry. Conversely, if new precedents never sent out ripples, the common law could hardly evolve at all.
There must be principles of coevolutionary assembly for biospheres, economic systems, legal systems. Coevolutionary assembly must involve coevolving organizations flexible enough to change but firm enough to resist change. Edmund Burke was basically right. Might there be something deep here? Some hint of a law of coevolutionary assembly?
Perhaps. I begin with the simple example oVered by Per Bak and his colleagues some years ago = Bak’s “sand pile” and “self-organized criticality.” The experiment requires a table and some sand. Drop the sand slowly on the table. The sand gradually piles up, fills the tabletop, piles to the rest angle of sand, then sand avalanches begin to fall to the floor.
Keep adding sand slowly to the sand pile and plot the size distribution of sand avalanches. You will obtain many small avalanches and progressively fewer large avalanches. In fact, you will achieve a characteristic size distribution called a “power law.” Power law distributions are easily seen if one plots the logarithm of the number of avalanches at a given size on the y-axis, and the logarithm of the size of the avalanche on the x-axis. In the sand pile case, a straight line sloping downward to the right is obtained. The slope is the power law relation between the size and number of avalanches.
Bak and his friends called their sand pile “self-organized critical.” Here, “critical” means that avalanches occur on all length scales, “self-organized” means that the system tunes itself to this critical state.
Many of us have now explored the application of Bak’s ideas in models of coevolution that I will discuss shortly. With caveats that other explanations may account for the data, the general result is that something may occur that is like a theory of coevolutionary assembly that yields a self-organized critical biosphere with a power law distribution of small and large avalanches of extinction and speciation events. As we shall see, the best data now suggest that precisely such a power law distribution of extinction and speciation events has occurred over the past 650 million years of the Phanerozoic. In addition, the same body of theory predicts that most species go extinct soon after their formation, while some live a long time. The predicted species lifetime distribution is a power law. So too are the data. 
Similar phenomena may occur in an econosphere. Small and large avalanches of extinction and speciation events occur in our technologies. A colleague, Brian Arthur, is fond of pointing out that when the car came in, the horse, buggy, buggy whip, saddlery, smithy, and Pony Express went out of business. The car paved the way for an oil and gas industry, paved roads, motels, fast-food restaurants, and suburbia. The Austrian economist Joseph Schumpeter wrote about this kind of turbulence in capitalist economies. These Schumpeterian gales of creative destruction appear to occur in small and large avalanches. Perhaps the avalanches arise in power laws. And, like species, most firms die young; some make it to old age = Storre, in Sweden, is over nine hundred years old. The distribution of firm lifetimes is again a power law.
Here are hints = common law, ecosystems, economic systems = that general principles govern the coevolutionary coconstruction of lives and livings, organisms and natural games, firms and economic opportunities. Perhaps such a law governs any biosphere anywhere in the cosmos.
I shall suggest other candidate laws for any biosphere in the course of Investigations. As autonomous agents coconstruct a biosphere, each must manage to categorize and act upon its world in its own behalf. What principles might govern that categorization and action, one might begin to wonder. I suspect that autonomous agents coevolve such that each makes the maximum diversity of reliable discriminations upon which it can act reliably as it swims, scrambles, pokes, twists, and pounces. This simple view leads to a working hypothesis: Communities of agents will coevolve to an “edge of chaos” between overrigid and overfluid behavior. The working hypothesis is richly testable today using, for example, microbial communities.
Moreover, autonomous agents forever push their way into novelty = molecular, morphological, behavioral, organizational. I will formalize this push into novelty as the mathematical concept of an “adjacent possible,” persistently explored in a universe that can never, in the vastly many lifetimes of the universe, have made all possible protein sequences even once, bacterial species even once, or legal systems even once. Our universe is vastly nonrepeating; or, as the physicists say, the universe is vastly nonergodic. Perhaps there are laws that govern this nonergodic flow. I will suggest that a biosphere gates its way into the adjacent possible at just that rate at which its inhabitants can just manage to make a living, just poised so that selection sifts out useless variations slightly faster than those variations arise. We ourselves, in our biosphere, econosphere, and technosphere, gate our rate of discovery. There may be hints here too of a general law for any biosphere, a hoped-for new law for self-constructing systems of autonomous agents. Biospheres, on average, may enter their adjacent possible as rapidly as they can sustain; so too may econospheres. Then the hoped-for fourth law of thermodynamics for such self-constructing systems will be that they tend to maximize their dimensionality, the number of types of events that can happen next.
And astonishingly, we need stories. If, as I will suggest, we cannot prestate the configuration space, variables, laws, initial and boundary conditions of a biosphere, if we cannot foretell a biosphere, we can, nevertheless, tell the stories as it unfolds. Biospheres demand their Shakespeares as well as their Newtons. We will have to rethink what science is itself. And C. P. Snow’s “two cultures,” the humanities and science may find an unexpected, inevitable union.
Investigations leads us to new views of the biosphere as a coconstructing system. In the final chapter, I step beyond the central concern with autonomous agents to consider the universe itself. Again, there are hints of coconstruction = of the laws themselves, of the complexity of the universe, of geometry itself. The epilogue concludes with limits to reductionism in its strong form and an invocation to a constructivist science.









In recent years, the Secret Constitution has come to assert itself in the opinions, particularly the dissenting opinions, of the Supreme Court. If we are to understand the impact of our implicit postbellum commitment to the ideas of nationhood, democracy, and equality, we cannot limit ourselves to the jurisprudence of the nine justices who happen to sit on the Court in Washington. The Secret Constitution has, in fact, a much deeper grounding in American political and legal culture, and it has come to express itself in diverse arenas. It spontaneously percolates through civil society. It shapes the process of constitutional amendment; indeed, virtually every constitutional amendment enacted since the Civil War expresses, in one way or another, the values of the Secret Constitution. This is true as well of the two leading proposed constitutional amendments that have gained a large political following in the last decade: the proposal to protect the flag against “desecration” and the movement to protect victims of crime. The values of the Secret Constitution have also found their way into subconstitutional federal legislation based, as a technical matter, on the Interstate Commerce Clause, granting Congress authority to regulate commerce “among the states.”1 The earlier defeat in the Supreme Court of the Civil Rights Act of 1866 meant that Congress had to find other means of bringing to bear the same set of values in the pursuit of equal treatment in public facilities and in the workplace. In order to see the resurgence of the three great ideas of the Secret Constitution—nationhood, democracy, and equality—we have to look afield, away from the courts, to these diverse areas that give birth to legal trends and define the bedrock of the American Constitution.2


Constitutional Amendments

Of all the arenas in which the Secret Constitution has come to the fore, none is more impressive than the process of constitutional amendment. All of the amendments adopted and ratified over the last 135 years reveal the traces of a shared understanding, an unconscious plan, of what American government should be like. This is a remarkable thesis, for the general tendency is to assume that the amendments consist in a hodgepodge of special responses to unrelated problems.
The dominant theme is the spread of the franchise and the fine-tuning of the system of democratic representation. But there are other strains from the Secret Constitution as well. As we work our way through the amendments, from the Thirteenth to the Twenty-Seventh, we shall also see a countervailing principle at work. Democracy stresses the responsibility of the people for their self-governance. The offsetting principle is that the government must be strong, well financed, and act with a sense of compassion for the weak and defenseless. Our postbellum commitment to democracy is well known. Less well appreciated is the deep American sense of concern for those who are not able to fend for themselves. The final implication, then, of the Secret Constitution is the commitment of government to the dignity and self-esteem of all its citizens.
If we think of the Civil War as a moral drama, we cannot but perceive a government at work that is committed to the dignity of all. The drama can be narrowly understood as an enormous sacrifice of human life to liberate people held in the most demeaning condition imaginable. The war snuffed out one life, one being created in the image of God, for every seven slaves freed. There might have been a less costly way of solving the problem. Simply waiting and negotiating, we might have seen the market itself render the keeping of slaves too costly an enterprise. Industrialization spreading South might have made “free labor” a more appealing alternative for those who profited from the system of slave labor. The end of plantation capitalism might have come as safely as the demise of communism in Europe. But these possible scenarios are beside the point. The sacrifice did occur. And we thought it was necessary, as Lincoln preached, to cleanse us of our “offences” and to give the nation a “new birth of freedom.” We could not have survived this drama with anything but a sense that government was capable of a great moral undertaking. Government was no longer instituted simply to keep the peace, deliver the mail, and protect us from foreign enemies but also to ensure that we not descend into the kind of evil that seared the soul of the first American Republic. The period of the Civil War witnessed legislative measures that had never been seen before in the United States—the beginning of a national banking system, the issuance of a national currency, a homestead act that distributed 160 acres to each settler, and land grants for building universities. We incorporated this new understanding of government into the Thirteenth Amendment, which declared boldly that the particular kind of evil that had led to war would never again exist in the United States. To prevent this reoccurrence, the federal government would have to be strong and vigilant. It would have to observe the transactions that occurred in the marketplace to ensure that they did not approach the danger zone of “involuntary servitude.” The war itself and this consequent postbellum policy of necessary vigilance laid the foundation for the later expressions of compassion for the weak and defenseless.
From the Thirteenth to the Fifteenth Amendment, however, from 1865 to 1870, we can sense a sharp decline in the moral energy of government. Section 1 of the Fourteenth Amendment contains, of course, the invocations of “privileges and immunities,” “due process,” and “equal protection” that have engaged the Supreme Court and its academic commentators. But implicit in this 1868 amendment is the resurgence of the states’ responsibility for the events that occur within their borders. And Sections 2, 3, and 4 of the amendment contain time-specific provisions designed to penalize the disloyal states and rebel soldiers and officials. These vengeful provisions have caused much mischief, as we have seen, by providing fodder today for those who prefer denying the franchise to convicted felons.3 Still, the equal protection clause was a breakthrough and supplied the anchor for a cardinal principle of the postbellum legal order. And the due process clause would prove to be the umbrella that would enable the Supreme Court, in the last half-century, to develop a jurisprudence of human rights that applies to the entire country.
The framing of the Fifteenth Amendment suffered from the loss of moral ambition. Congress could have drafted the amendment simply to require the franchise for all persons above the age of 21. But that would have required a clear rationale for the democratic franchise, a clear principle telling us who should vote and why. At the most, we had a vague commitment to the new idea of democracy for the entire nation of Americans. The women’s suffrage movement had begun but it had little support. And it was not at all clear that emancipated slaves would receive the vote. Democrats were naturally fearful that the newly enfranchised blacks would vote for the party that promoted their liberation. Republicans in Congress pressed both for the vote for former slaves and for the disenfranchisement of disloyal members of the Confederacy. A new coalition, they hoped, would break the power of the landed élite and bring about a social revolution in the South. President Johnson himself identified with the class of small white farmers in Tennessee, who felt threatened by the potential rise of black political power in the South.
These political considerations played themselves out against ambivalent sentiments about who constituted the “people” in “government of the people, by the people, for the people.” Yet, we should not underappreciate the radical step of granting the franchise to emancipated slaves on the same terms as it was available to the rest of the population. This transformation of a slave population was unique in the history of revolutionary wars. The concept of popular democracy was beginning to take root. We should not forget that despite pretensions of a democratic founding in 1787, the idea that more than a dominant élite should vote was as foreign to the mind of the late eighteenth century as were the terms “American nation” and “equality.” Rule by the demos or the nation was, like equality, still unfolding as a way of life. It had no guiding theory—no rationale and no historical model. It was not at all obvious that the uneducated, propertyless masses should govern the country.
The entire constitutional structure drafted in 1787 needed revamping but, without a compelling theory to guide them, the political powers in Congress settled for the modest demand in the Fifteenth Amendment that the states not deny the franchise “on account of race, color, or previous condition of servitude.” It is hard to imagine a lesser demand on the states, consistent with the policy of treating the emancipated slaves as members of the nation with equal political rights.
The ensuing amendments also pursue the principles latent in the Secret Constitution. The Sixteenth Amendment, ratified after a lapse of forty-five years, recognized the legitimacy of the income tax. The government had already experimented with the income tax during the Civil War, and enacted another tax in the 1890s. The Supreme Court initially upheld the imposition of an income tax,4 but then in 1895, the Court vetoed, five votes to four, the new aspirations of the federal government.5 The rationale for the Court’s intervention was an obscure provision on “direct” and “indirect” taxes in the Constitution of 1787 that had gotten in the way of the new vision of government.6
The Seventeenth Amendment brings us back to the process of developing a democratic system of government. Henceforth, senators would have to be elected not by state legislatures but directly by the people. The tone of the amendment remains deferential to the states’ control of the electoral process, even for national office. The text does not tell us that all people over the age of twenty-one should be entitled to vote but leaves it up to each state to decide who shall be able to vote “for the most numerous branch of the state legislature.” Whatever that standard happens to be will prevail as well for elections to the United States Senate.
The Eighteenth Amendment is the most significant of the lot, for once again we witness in action a government solicitous of the welfare of its people. The structure of this amendment is exactly the same as the Thirteenth. As the latter declares that a certain form of private relationship of subordination shall not exist in the United States, the Eighteenth Amendment tells us, analogously, that another private relationship shall not occur: “the manufacture, sale, or transportation of intoxicating liquors within . . . the United States . . . is hereby prohibited.” This much misunderstood amendment, ratified in 1919, expressed a collective concern for the dignity and welfare of all those whose lives were destroyed by drink. Of course, we know that it did not work, but the sentiment expressed was a noble one. It reflects a politics of mutual responsibility in a single nation, a concern for those who could easily get lost in the rough and tumble of capitalist America.
We encounter this noble motive at work and see its failure in our current policy toward the sale and use of narcotics. We deploy vast sums and personnel in an effort to halt the spread of drug usage, although it is hard to see any tangible payoff from our investment. The reason is simple. It is not easy for government to interdict the pleasures of those who can satisfy them through purely private transactions. The level of vigilance required exceeds the capacity of government in a society that also seeks to protect privacy and civil liberties.
In the case of liquor, in particular, Prohibition had the effect of making consumption tantalizing and exciting. The speak-easy, the drink on the sly, the home brew—all these brought extra pleasure to those who imbibed. The effect of Prohibition was much the same as in the case of flag burning. The law’s forbidding the act makes it more thrilling. The effect is just the opposite of that intended.
Therein lies a message for the politics of governmental intervention. There are times when we must rely on civil society to achieve our goals—sometimes with a slight nudge from government. Witness the turnaround that has occurred in the United States with regard to cigarette smoking. The government posted health warnings on cigarette packs, required airlines and governmental buildings to ban smoking, but did not try to follow the model of Prohibition or the drug laws. The policy of deferring to voluntary initiative has been more effective. A revolution in attitudes toward smoking has occurred, largely because people were free, in effect, to decide for themselves in their homes, offices, and other spheres of influence. They did not need the coercive force of government behind them.
For many, the limitations on governmental power represent a trivial and self-evident proposition. But those who believe in the power of government, as I do, should pay heed. And conservatives, who are generally skeptical of the power of government, would do well to ponder the analogies between Prohibition and the drive for prayer in the schools or the criminalization of flag burning. Of course, there are some areas, such as the protection of the victims of crime, where only the government can act. Of that problem there will be more to say later.
Allow me to take the Twenty-First Amendment out of order. After a decade of Prohibition, the country realized in 1933 that the government simply could not act upon its noble motives. The Constitution had to be amended once more, this time to countermand the Eighteenth Amendment. Some states, for example, Mississippi, retained Prohibition for many more years. As a colleague from ostensibly dry Mississippi once jibed, “Prohibition is better than no liquor at all.” The country as a whole finally decided, however, that a little liquor was more desirable than the costs to freedom in trying to achieve Prohibition.
The rest of the amendments, beginning with the Nineteenth, are all directed to the process of spreading the franchise and refining the mechanism of democratic representation. The Nineteenth (1920), the Twenty-Fourth (1964), and the Twenty-Sixth Amendments (1971) all serve the purpose of extending the franchise. The drafting style follows the Fifteenth Amendment by specifying the criterion on account of which the states may not limit or abridge the right to vote. By using this negative formulation, the first of the series finally extends suffrage to women, the second to those who have not paid a poll tax or any other tax required to vote, and the third, to all men and women over the age of 18. Also in this group is the Twenty-Third Amendment, which extends the right to vote for the president and vice president to citizens otherwise qualified in the District of Columbia.
These amendments bespeak the philosophical principles of the Secret Constitution. A clear commitment to a universal right to vote finally takes hold. The franchise attaches not to those with qualifications, education, wealth, age, or even the supposed superiority that, according to the attitudes of 1920, men enjoyed in practical affairs. The franchise belongs to all Americans and even to resident noncitizens who are capable of knowing, in the minimal theory of democratic voting, when “the shoe pinches.”7 Lincoln’s vision of government “by all the people” was becoming the law of the land.
Also, elections for the presidency begin to take on the quality of a national referendum in place of a compilation of preferences by the individual states. People started voting and expressing themselves as the voice of the nation. Thus, it came to be obvious that citizens of the country who did not reside in the states (namely, those in the federal district) must also have the right to vote for national offices. The Constitution nominally retained the electoral college as a way of giving lip service to the states, but it is clear that the popular vote expresses the will of the nation. This became clear in the presidential election of 2000, discussed in detail in the Afterword. On the basis of the results certified on November 26, Governor George W. Bush acquired a one vote majority in the electoral college. Vice President Gore’s persistent legal challenge to the certified result depended, in part, on the sense of legitimacy he acquired from winning the confidence of the nation in the popular vote.
The remaining constitutional amendments fine-tune the workings of Congress and the presidency. The Twentieth shortens the lameduck period between the November election and the change of leadership in the following year. Previously the inauguration was prescribed for the beginning of March, but the amendment moved up the date to January 3 for Congress and January 20 for the presidency. Although this amendment appears simply to address matters of the calendar, it came into play recently in the dispute about whether an outgoing lameduck House of Representatives could, in the period between election and going out of office, constitutionally impeach President Clinton. Bruce Ackerman shocked the Capital by testifying before the House that the newly seated Senate could not constitutionally try the president on an impeachment passed by the outgoing House.8 The amendment also authorizes Congress to prescribe a mode of succession to the presidency between elections.
The Twenty-Second Amendment (1951) limits the term of office of the president to two four-year terms plus a maximum of two years inherited from a predecessor unable to complete his term. And the Twenty-Fifth (1967) regulates in detail the problem of transition when the president is still alive but incapable of executing the office. The last amendment, the Twenty-Seventh, prohibits congressionally legislated pay raises from taking effect until another national election has taken place, and a new Congress is sworn in. This last revision of the national charter also testifies to the theme of improving the workings of popular democracy: the people must be consulted before their elected representatives should be allowed to raise their own salaries. The curious twist in this last addition to the Constitution is that although it was finally ratified by three-fourths of the states in 1993, it was originally proposed by James Madison two hundred years earlier. Its formal roots lie in the original Constitution of 1787.
The amendments to the original Constitution all bespeak the same pattern of realizing the implicit postbellum commitment to nationhood, democracy, and equality. The realization of these values in the amendments bespeaks the resurgence of the Secret Constitution.


Compassion for Victims

The structure of our basic rights favors those who act—those who speak, assemble, worship, carry guns, keep their homes private, or stretch their liberties to the point that the state charges them with criminal offenses. The attention paid to the rights of criminal defendants in the Bill of Rights is extraordinary. The Fourth, Fifth, Sixth, and Eighth Amendments address the rights of suspects, defendants, and those convicted of crime. Noticeably absent in this catalogue of rights is due regard for those who suffer from the constitutionally protected actions of others. Our liberties entail costs, but for some reason the human beings who bear these costs are left outside of the constitutional equation. The victims have no rights. They are mentioned nowhere.
Indifference toward the victim began to change with the Thirteenth Amendment. For the first time, the people who must bear the cross of involuntary servitude became the focus of attention. They would no longer suffer in the United States. The federal government had the duty to protect them. The government also asserted its duty to protect the weak in the Prohibition Amendment, but, alas, the duty to help others is not always easily realized. Yet, the idea that the government should protect the weak, that it should tender compassion for victims, became a mainstay of the Secret Constitution.
Of course, no one is constitutionally protected in the action of committing a crime. The rights attach to those suspected of crime. The purpose of the amendments is to insure both that innocent persons will not be convicted but just as critically to protect the dignity of every suspect as he or she falls under the investigative and prosecuting power of the state. For example, the privilege against self-incrimination goes beyond the protection of the innocent to speak to the dignity of the suspect who may remain silent. Similarly, the protection of the home and private papers often deters the efficiency of law enforcement, but only for the sake of promoting personal privacy. So long as we recognize that the constitutional provisions are interlaced with dignity concerns, then we cannot properly disregard the claims of victims to be treated in the same way. The victims’ rights movement focuses, therefore, on increasing the participation of victims in various stages of the process. Participation itself helps enhance the dignity of the victim by allowing him or her to be heard and to feel respected as a citizen.
The most common problem faced by victims is that they are not allowed to attend the trials of those who have allegedly assaulted or raped them or killed members of their families. The trial of Timothy McVeigh for bombing the Murrah Federal Building in Oklahoma City in 1995 and killing 168 people provides dramatic proof of indifference to discrimination against the interests of victims. First, federal Judge Richard Matsch changed the venue of the trial from Oklahoma City to Denver, which of course made it much more difficult for the murdered victims’ families to attend the trial. The nominal reason for the change of venue was that McVeigh was more likely to receive an unbiased jury in a city several hundred miles away. The likelihood of finding potential jurors, in Denver or anywhere else in the United States, unaffected by the intensive media coverage of the bombing was thought to be minimal. The other factor influencing the judge’s decision to relocate the trial in Denver was the politely undiscussed fact that he owned a ranch outside of Denver. It suited his personal interests to be close to home.
If the change of venue was not bad enough, Judge Matsch also banned the victims who braved the journey from sitting in the courtroom during the trial. Many courts require witnesses to wait outside if they are likely to be called later in the trial, but in this case the defense prevailed on the judge to bar the victims’ families on the ground that their very presence might induce an emotional response in the jury. This decision, we might say, represented the nadir of compassion for victims in the United States. Finally, Congress intervened to guarantee victims who have suffered direct physical, emotional, or financial harm the right to observe the trial by closed circuit television.9
A more compassionate approach to victims’ rights became evident in the famous O. J. Simpson case, which held the country’s rapt attention for more than a year in 1996 and 1997. In the pretrial skirmishes, the defense objected to the families of the two victims, Nicole Brown Simpson and Ron Goldman, remaining in the courtroom if they might later be called as witnesses. Marcia Clark won the argument in the name of the Brown and Goldman families, actually with some help from a book I had just published on victims’ rights. Whether his words did the trick or not, the author could not help but enjoy hearing them enter into the deliberations. As Clark read them in the debate: “The minimal task of the criminal trial is to stand by victims, to restore their dignity, to find a way for them to think of themselves, once again, as men and women equal to all others.”10 Judge Ito made the right decision to let the families stay in court. If they were later called as witnesses, the defense could adequately protect itself by cross-examining the witnesses about testimony previously heard.
European courts are also wary of allowing potential witnesses to hear the testimony of other witnesses before they testify (they put less faith in cross-examination), but they take strong measures to protect the interests of victims at trial. The typical pattern is to allow the victim to join the proceedings either as a civil plaintiff suing simultaneously for tort damages or as a coprosecutor arguing and presenting the case alongside the state prosecutor. American reformers want to improve the position of the victim at trial, but none of them dares go so far as to suggest reforms comparable to accepted practice on the Continent.
The American movement favoring compassion for victims of crime has found expression in a variety of low-visibility measures. The constitutional amendment, sponsored by Senators Jon Kyl of Arizona and Diane Feinstein of California, sought to introduce the following rights:

To be notified of the proceedings
To attend all public proceedings
To be heard at certain crucial stages in the process
To be notified of the offender’s release or escape
To consideration for a trial free from unreasonable delay
To an order of restitution
To have the safety of the victim considered in determining a release from custody
To be notified of these rights and to have standing to enforce them

So far as it goes, the proposed amendment makes sense. It expresses the spirit of compassion rooted in the Secret Constitution. It expresses the same sentiments that led to other initiatives to protect the weak and defenseless. Although each of the constitutional efforts to intervene on behalf of the powerless has a different impulse and a different agenda, they all spring from a root concern for those who are not strong enough to act for themselves. This is the common thread that begins in the Thirteenth Amendment, peaks, perhaps wrongly, in Prohibition, and issues today into the movement “to stand by victims, to restore their dignity, to find a way for them to think of themselves, once again, as men and women equal to all others.”
The opposition to victims’ rights stems from both prosecutors and defense counsel. The former do not want victims complicating the trial. They are surely opposed to my proposal that victims be able to veto plea bargains and insist on going to trial to vindicate their charges.11 Prosecutors generally like to have victims around at the sentencing phase. The suffering and rage of the victims, when expressed in court, tends to spike the punishment. Defense counsel are opposed for other reasons. They are afraid that empowering victims will distract from the rights of criminal defendants, but this is not necessarily the case.12 The victim’s interest is primarily in participating in the trial. He or she may communicate a desire for conviction but that parochial sentiment of interest will be readily discounted by the commonsense responses of the jury. The fact is that it is possible to strengthen the participatory rights of victims without unduly complicating the procedure or compromising the traditional rights of the defense.


Civil Society

The central question in any movement of compassion is whether the government is the best agency of reform. There are obviously some areas where we must rely on the government or on no one. Only the federal government could have waged the Civil War and emancipated the powerless. Only the federal government could secure the franchise to those who had no power on the local level. Only the federal courts can secure equal protection of the laws when the states decide to disfavor some of their citizens. But in other areas of life, the government can further its ends by staying its hand.
The U.S. government has sought to maintain the religious sensibility that brought forth the Declaration of Independence but was abandoned in the secular Constitution of 1787. Americans have become and remained one of the most religious nations on earth, and largely because the state has evolved toward a rigorous policy of symbolic support for religion, at the same time insisting that the religious culture either thrive or die on its own. The symbolic gestures include printing “IN GOD WE TRUST” on our money, celebrating two Christian holidays as national holidays, and using the Bible in oath-taking ceremonies. These are significant public gestures in a society that rigorously forbids the state’s spending money to support religious education. Amusingly, the Court even quotes the Great Maxim from the Secret Constitution—all men are created equal—to support the separation of Church and State.13 These postures seem to be the mirror opposite of European practices, where the state readily provides subsidies for religious schools, but would not consider using religious symbols on its money or even using the Bible in court to administer the oath to “tell the truth, the whole truth, and nothing but the truth.” Whether these differences in practice are determinative or not, it is clear that the United States has remained a more deeply religious country than Germany, France, or even Italy. For religious faith to remain strong, it might be better for the state to keep its distance.
The same could be said of devotion to the nation. The state must engage in some elementary gestures of national pride. It must define and disseminate a flag, a national anthem, and celebrate holidays such as the Fourth of July, Veterans’ Day, and the birthdays of great national leaders. Nations that fail to do these things have trouble melding their people into a single culture of national identity. A good example is Israel, which has yet to find a holiday that Jews and Arabs can celebrate together. We live in a time of national disintegration—witness Czechoslovakia, the Soviet Union, and the near-misses in Canada—and, therefore, the state is properly advised to cultivate a common identity and a sense of shared history and destiny.
Since the Civil War, the United States has hardly lacked a strong sense of national patriotism. But the state has had to do little to further it. In the 1890s, the Pledge of Allegiance, our secular prayer to the flag, spontaneously spread across the country and became a standard part of the socialization process for all American children. There was little national hesitation about our wars of national aggrandizement against militarily weak opponents in Cuba and Panama. And the country joined enthusiastically in sending our doughboys overseas, in President Wilson’s words, “to make the world safe for democracy.” The generation that fought and won World War II is still with us, infusing in both blacks and whites a strong sense of a national mission well executed. The war in Vietnam was undoubtedly a setback for the spirit of patriotism. A whole generation—my friends and students—became skeptical about the use of military power. Yet, to my surprise and somewhat to my chagrin,14 a new cohort took up the sentiments of their grandparents and enthusiastically supported the questionable goals of the government in the Gulf War. As we were bombing Iraq, the country erupted again in a spontaneous display of unity and patriotic enthusiasm. Yellow ribbons appeared everywhere. It reminded one of the pledge that burst out a hundred years earlier, a paean to the flag in school houses around the country.
Civil society is a powerful medium, and when the public takes up the cause either of religion or of patriotism, its strength overshadows the feeble efforts of government to manipulate its opinions. Yet, in both fields—religion and patriotism—we face a constant challenge from those who are unsatisfied with the successes of civil society. They want government to join the action. Nowhere is this more evident than in the politics of schooling. We worry constantly, perhaps with good reason, that the young in America are growing up with the wrong values. They supposedly suffer from all the mistakes of their elders who promote violence on television and have permitted the country to be flooded with guns, which, as everyone knows, enable teenagers who go on rampages to gain a few hours of prime time news coverage. One wonders, however, whether it is an effective response for government to require, as suggested in one Republican initiative, schools to post the Ten Commandments on schoolhouse walls. This drive toward governmental intervention in the field of value formation has been nowhere more evident—and questionable—than the recently revived push for a constitutional amendment to protect the flag against protestors who want to burn it.
The commitment to the flag has surely been one of the stable and recognized provisions of our sub rosa constitution. We do well to cultivate reverence toward the flag, which coupled with national rituals like the pledge, instills sentiments of national loyalty in our children. Although patriotic sentiments toward the flag antedate the Civil War, we begin to find, in the early twentieth century, a duty of reverence toward the Stars and Stripes formulated as a legal issue. In 1907, the Supreme Court upheld the conviction for flag desecration of a beer manufacturer who printed the flag on his cans. Appropriating the flag for commercial purposes was considered disrespectful.15
Our attitudes toward the flag were then so obeisant that we adopted religious language to describe acts of disrespect toward Old Glory. It would be difficult to say that piece of cloth on which the stars and stripes were printed was ever “consecrated” so that it could be “desecrated.” These terms imply the ritual use of an object exclusively for worshiping God. Despite the inappropriate use of religious language, the Supreme Court upheld this crime as a sensible expression of government’s instinct to protect the symbols of the nation.
But then the commitment to national pride ran into a contrary trend in American thought that had been in the process of emergence for over a century. The impulse to protect the flag against desecration confronted the rising devotion to the cardinal American value of free speech. Since World War I and the dissenting opinion of Justices Holmes and Brandeis,16 the American recognition of the primacy of free speech has been on an upward trajectory. The Supreme Court, including its most conservative justices, has consistently favored the primacy of speech over the interests of victims injured or offended by the rough and ready rumble of the “marketplace of ideas.”17
The collision was inevitable. Two American ideas—protecting the flag and celebrating freedom of speech—would eventually come into focus as contradictory ways of being American. It was a close battle, but in two sharply divided votes of the 1990s, the Supreme Court decided that freedom of expression must prevail.18 But this was hardly a defeat for the politics of national sentiment. Those who loved the flag still had recourse to civil society.19 The proponents of patriotic rituals, such as honoring the flag, could learn from the history of religious sensibility in the United States. The government cannot coerce religious observance without, as John Locke argued in his first Letter Concerning Toleration (1689), corrupting the act of faith into an empty gesture of external compliance. The opposite effect occurs when the government seeks to punish those who burn the flag. The punitive sanction enhances the communicative sting of flag burning. The simple act of destroying a piece of cloth becomes a major event watched closely by the police and the media. The subsequent trial of the flag burner gives him or her a platform for broadcasting the political views expressed in the illegal act. At one time, burning the flag was something like wearing a jacket in the courthouse blazoned with the words “Fuck the Draft.”20 But when flag burning becomes an acceptable and potentially routine event, it draws no more attention than the use of four-letter words at cocktail parties.
There is no doubt that free speech has its victims, and in most European societies and in Canada, the courts rush in to protect the victims against being offended. A good example is the way every major jurisdiction outside the United States treats Holocaust denial. Someone publishes a book saying that Auschwitz never happened, that it is a lie propagated by the Jews. This is a punishable act in Germany, France, Israel, the Netherlands, Canada—just about everywhere where people believe that the government must intervene in order to protect those who might be disturbed and offended by the obscene lie. By intervening and putting the Holocaust denier on trial, of course, they only broadcast the lie to a larger audience, and they convert the mad dissident into a martyr in his own circle.
The Supreme Court has remained remarkably unaffected by the academic swing toward support for hate speech legislation. In the R.A.V. case, for example, the Court struck down a municipal ordinance that punished the display of a symbol that one knows or has reason to know “arouses anger, alarm or resentment in others on the basis of race, color, creed, religion or gender.”21 Academic critics of the decision stress the value of regulating speech that has the effect, it is argued, of silencing minorities.22 The overriding value, they claim, is the equality of those affected by hate speech. Only by restricting intimidating speech, the argument goes, can all potential participants in the democratic dialogue feel free to speak and to make their opinions known. In the courts, however, the ancien principles still reign. The primary value is not equality but freedom.
But the government’s staying its hand does not mean that hate speech goes unsanctioned. Civil society has it own spontaneous means of chastising those who veer too far from the acceptable range of discourse. The best remedy against the “Auschwitz lie,” as the Germans call it, is to ignore it. Deborah Lipstadt, in her book Denying the Holocaust, wrote that we should not publicly debate unacceptable as well as obviously false claims, and thus she advanced a remedy as powerful as governmental censorship. When civil society turns a deaf ear, crazy ideas lose their edge. The remedy disturbed one historian labeled a “denier” so much that in late 1999 he unsuccessfully sued Lipstadt for libel, primarily to force her to confront his claims.23
In other areas, where racist and sexist speech wounds, the spontaneous order of American society has been uncannily effective in changing patterns of speech. Consider the careful choice of words in this book. I do not write “Negro” or “colored,” as people were wont to do not long ago. “Black” and “African American” have become the norm, and it all happened without government’s uttering a sound. When governmental officials try to tell people how to talk, they look slightly ridiculous. Witness the French trying to outlaw the use of the word “cheeseburger” and other insidious harbingers of American culture. However strong the value of preserving the French language in all its purity, the task is not one for government. At a certain point we have to trust the unplanned, powerful forces of civil society.


Human Dignity

But civil society is not always to be trusted. Witness the drive toward a constitutional amendment to protect the flag against physical desecration. The amendment actually passed the House of Representatives in the summer of 1999, but it is not expected to command the necessary two-thirds vote in the Senate. When speech induces a sense of victimization in minorities and women, many academics in the United States and even more lawmakers abroad reach for the arsenal of legal remedies to show their compassion for victims. Two basic strategies present themselves. One technique trades heavily on the values of the Secret Constitution and the other, characteristic of German thought, relies heavily on the Kantian concept of human dignity. The general principle of equal treatment, as we have elaborated it, lends itself to the argument for limiting freedom of speech. The claim is that obscenity degrades women and, thus, fails to treat them equally with the men who are interested in consuming the obscene material. Similarly, hate speech systematically degrades its targets and, therefore, treats them as unworthy of equal status in society. These are good arguments that draw on a long tradition of concern in the theory of equality for protecting the weak and defenseless.
The alternative mode of compassionate jurisprudence relies on the concept of human dignity, elaborated in Article 1 of the German Basic Law of 1949. The term “human dignity” is not defined in the Basic Law and, therefore, the courts must rely on the basic Kantian principles that human dignity expresses the ultimate personhood of each individual. In my view, although we have never expressed a principle of human dignity in American constitutional law, the same principle underlies our commitment to the Great Maxim. Our notion of equality-in-creation derives from the view that we are all of ultimate value, an idea that can be expressed either by going back to the biblical idea of creation in the image of God or taking the secular alternative of human dignity beyond all price, as articulated in Kant’s moral theory.24
To see how the notion of human dignity operates in practice, let us take a look at the well-known Peep Show case decided in 1981 by the Federal Administrative Court [Bundesverwaltungsgericht] in Germany.25 The operators of a peep show were denied a business permit because their show supposedly violated the morals of the community. Their show displayed a naked woman on a circulating round stage, viewed by men in private booths equipped with one-way windows. The women could not see the men who were gawking at their genitalia and the men could not see each other. The Federal Administrative Court upheld the denial of the license on the ground that the show violated the “human dignity” of the women who chose to participate. That participation was voluntary was irrelevant, for the state had an absolute duty under Article 1 to “protect human dignity” whether the victims wanted the help or not.
The court’s rationale for the decision traded heavily on the Kantian principle that no one should ever use another person exclusively as a means to an end.26 The judges had no objection to strip-tease performances, which they regarded as a variation on dancing in front of an interactive public. But the one-way nature of the viewing in this case disturbed the court:
By contrast with a strip tease, the women in the peep show are subjected to a humiliating objectifying role, brought about by a number of factors: the automatic way in which the viewers pay for the opening of the “peep” window, in which the viewing of the naked woman resembles buying a product from a vending machine, the one-way windows that leave the women, without eye contact, as the isolated objects of salacious desire and the voyeurs relegated to their secret cabins.27

One has to think twice before rejecting this argument. This is not simple prudery. The fact is that the entire enterprise does degrade the participating women into mere objects, and though one could imagine a woman enjoying doing a strip-tease to an appreciative bunch of unruly sailors, the anonymity of private sexual gratification could leave one with a sense of humanity abandoned. Yet, there is obviously another point of view. The self-exposure of the woman on the rotating stage is not that much different from doing a strip-tease before a television camera. The audience is invisible; each viewer is in his little cubicle, called a living room. The danger in the argument of human dignity is that it carries the risk of dogmatism. In the face of the conviction that the peep show violates the dignity of the women who choose to participate, there is little one can say.
At least one German feminist favors the American approach of treating the problem in the Peep Show case as one of equality rather than human dignity.28 The participation of the woman may seem voluntary on the surface. But the mandate of equal justice for men and women requires that we inquire whether in light of the existing power structure, the participation of the women is really voluntary. Appearances deceive. The argument of dignity begins and ends with the question whether the work reduces women to the status of objects. The perspective of equality, by contrast, encourages a broader political inquiry into the relations between women and men in the arenas of sex and money. The feminist assumption, apparently, is that in a state of true equality, no one would agree to engage in this kind of self-humiliation for pay. To be sure, however, that the work is so degrading, we must make implicit judgments about the kinds of activities that allow our sense of humanity to flourish. We are invariably drawn back to the Kantian theory of human dignity.
Whether we approach the problem of sexual exploitation as a problem of dignity or of equality, we can see the politics of compassion at work. The society as a whole undertakes to protect the self-worth of those who fall prey to superior forces. We have made the transition from governmental intervention to prevent slavery to a collective responsibility for the welfare of each. Perhaps Americans would not interfere with the appearance of autonomy in the peep show. But we took aggressive measures during Prohibition to protect individuals against the self-degradation of alcoholism, and we intervene today in a mammoth and seemingly unproductive campaign to protect people against drug abuse.
The paradox of the American approach toward equality is that though we trail European societies in our concern about economic equality and wealth discrimination, we lead the world in other areas of egalitarian thinking. The Secret Constitution has emerged, with vigor, in our collective effort to curtail sexual harassment and discrimination against women in the work place. The movement has occurred at the level of federal law, particularly in the interpretation of Title VII of the 1964 Civil Rights Act.29 The public often forgets that the expansion of sexual harassment law is grounded in the simple commitment to overcome gender inequality in the workplace. The law has moved so quickly in this arena that most men and women no longer know when and how they can approach a coworker and make a compliment or request a date. President Clinton even paid a ransom of $850,000 to avoid an appeal in a sexual harassment dispute in which the law and the lower court judgment seemed clearly on his side.30 Whatever the merits of this body of law, there is little doubt that Americans stand responsible for exporting this vision of sexual equality on the job and even for the creation of a new vocabulary of sexuelle Belästigung and harcèlement sexuel necessary to discuss the problem.
The redress of sexual harassment should be understood, in part, as an expression of the egalitarian aspirations of the Secret Constitution. Yet, as a symptom of the times, sexual harassment also represents a new vision of government; it has developed against the background of growing skepticism about whether things really are what they seem.
Equality for Believers 
and Nonbelievers

The values of the second constitution continue to collide with those of the first. The egalitarian approach toward freedom of religion dictates a leveling of two conflicting clauses in the First Amendment on freedom of religion. One clause prescribes “establishment of religion”; the other mandates “the free exercise of religion.” For the past thirty years or so, the tendency has been to read these two clauses together to prohibit both the state financing of religious activities and the state’s favoring one religion by granting to believers special exemptions from the laws applicable to everyone.31 The opposition claims that religious reasons warrant exceptional treatment, say, for refusing to work on one’s personal Sabbath,32 for using hallucinatory drugs,33 or for keeping one’s children out of school in violation of truancy laws.34 Again the conflict is between equality and freedom. Equality requires that all be treated alike—no exceptions for those motivated by fear of God. The faithful object and insist on the teaching found in Matthew 22:21: “Render therefore, unto Caesar the things which are Caesar’s; and unto God, the things that are God’s.”35 The constitutional right to “freedom of religion,” they argue, requires special exemptions for those who dissent, as a matter of conscience, from the laws applicable to others.
While the judicial proponents of freedom continue to hold the upper hand on free speech, the reigning approach to freedom of religion underscores the even-handedness of the law—the same rules should apply to religious and nonreligious alike. In 1990, in Oregon v. Smith, the majority of the Court held that this egalitarian approach to religion should govern the cases of some Native Americans who claimed the right to use peyote in their religious services. Their good-faith claim for exceptional treatment did not prevail in the face of the general prohibition against peyote as a drug perceived to be dangerous.36 In order to reach this conclusion, the Court had to push aside a line of precedents recognizing a policy of deference to any who refused, as a matter of religious conscience, to comply with the laws of the state.37
Congress responded to Smith’s egalitarian treatment of religion by enacting the Religious Freedom Restoration Act of 1993.38 The purpose was to restore the earlier jurisprudence of the Court and “to provide a claim or defense to persons whose religious exercise is substantially burdened by government.”39 The supposed ground for Congress’s overruling a constitutional decision of the Supreme Court was Section 5 of the Fourteenth Amendment.40 The proponents of the statute thus relied upon a provision of the second constitution to defend a conception of freedom rooted in the First Amendment and the first Constitution. When the case reached the Supreme Court, six justices found that Congress had exceeded its authority under the Fourteenth Amendment.41 The spirit of the decision dovetails well with the Court’s decision in 1883 to overturn the first civil rights acts as an excessive claim of congressional authority.
The decision reflects a general tendency of the Supreme Court to suppress the independent significance of the second constitution. If the postbellum constitutional order were taken seriously, as an independent source of constitutional law, its legislative provisions would be construed as liberally as the grants of legislative authority under the “interstate commerce” clause and the other provisions of Article I defining the power of Congress in the old Constitution. Yet, the Court’s attitude toward legislative authority under the Fourteenth Amendment begins on the assumption of fear. Congress should be able to implement the “due process” and “equal protection” clauses but not engage in imaginative interpretations of what these clauses should mean in practice. In defense of the current Supreme Court, however, we should note the extraordinary claim that Congress should have the authority—wherever it might be located—explicitly to overrule a constitutional decision of the Supreme Court. Recognizing congressional authority for this purpose would destabilize the structure of judicial review, as it has evolved since the early nineteenth century, and therefore the conservative inclination of the Court has much to commend it.
One cannot but be impressed by the “postmodern” style of the Court’s resolution of this constitutional crisis about freedom of religion. The Supreme Court relies on egalitarian thinking—a value drawn from the second constitution—to develop an approach to the conflicting clauses on religion in the First Amendment. Congress seeks to return to an interpretation of religious liberty attributed to the first Constitution, but grounds its authority in the Fourteenth Amendment, the cornerstone of the second constitution. The Court parries in the name of equality by cabining and curtailing the legislative authority that could be used to further the egalitarian values of the Fourteenth Amendment.









Revolutions are never easy. The people who inhabit the new regime are the same as those who dominated the old detested order. They cannot be expected to change quickly. The judges who interpret the new law are basically the same as those who interpreted the old law. Even if the law changes, even if there is a nominally new constitution, the process of reading the new document will gravitate toward the old. The regime changes, but the people are, after all, the same.
The ancient Israelites would spend forty years wandering in the desert before the passing of time would generate a new people, unaffected by the mentality of the “fleshpots of Egypt.” Modern political conditions rarely offer this luxury. The Soviets dreamed of creating a “new man” who would regard the communist system as the natural backdrop for cooperation. History never gave them the chance. But Germans could engineer a radical transformation after the fall of the Berlin Wall and the unification of the country. The West Germans absorbed the former German Democratic Republic and then restaffed the courts and the law faculties with new personnel, drawn overwhelmingly from Western ranks.
For Americans in the postbellum period, the obstacles to revolutionary change were daunting. Emancipating the slaves was one thing, changing attitudes toward blacks was quite another. Americans of the 1860s were essentially the same people who had tolerated the institution of slavery; their judges were of the same background and schooling as those who had declared in the Dred Scott decision that persons of African descent, whether born free or born in bondage, could never become citizens of the United States.
As part of its reconstructing the former Confederacy, the victorious North tried to cleanse the formerly rebellious governments of their “treasonous” followers. The Fourteenth Amendment, which the rebellious states were expected to ratify as the price for reinstating their right to representation in Congress, included a clause disqualifying from public office, in either the states or the federal government, anyone who had taken an oath to uphold the Constitution and thereafter “engaged in insurrection or rebellion against the same.”2 This provision could conceivably have rid the South of those who supported the war for Southern independence, but it could not liberate the North from its judges and politicians who were ambivalent about the equality of all citizens. The membership of the Supreme Court changed entirely between the time of the Dred Scott decision in 1857 and the first major constitutional decision of the postbellum period in 1872. Yet, the judges who came onto the court still carried with them the values and confusions of their antebellum youth. They could not easily imbibe an entirely new spirit of nationhood and a strong commitment to equality. Their justice did not express the vision of the victor but rather the reluctant judgment from within that the vanquished, too, had arguments on their side.
Securing a nominal legal change in the form of the black-letter rules of constitutional revisions was not so difficult. The Thirteenth Amendment was ratified as soon as the war was over, and the Fourteenth and Fifteenth followed within five years. By 1870, the language of revolutionary change was in place. The only question was whether the words on paper would bring about a fundamental change in American self-government.
The three promises of Gettysburg—nationhood, equality, and democracy—should have become the guiding values for interpreting the amendments that would govern postbellum America. These amendments had the form of a new constitution. They set forth the basic principles of government and each of them granted authority to Congress to realize the amendment with appropriate legislation. The amendments needed only the backdrop of the three branches of government then in operation. It would not have overtaxed the legal imagination simply to incorporate the existing structure of the federal government into the new constitutional order.
Had the United States been able to begin anew, with judges educated in the values and vision of Gettysburg, with a new generation unaffected by old habits of thought, Lincoln’s prophecy at Gettysburg might have prevailed. The commitment to “a single nation” of black and white would have provided the foundation for a jurisprudence of equality in the courts. The federal government would have become the watchdog of private relationships that approached too close to the forbidden line, defined in the Thirteenth Amendment as “slavery” or “previous condition of servitude.” The “self-evident truths” of the Declaration of Independence—the inalienable rights to life, liberty, and the pursuit of happiness—could have generated the foundation of a new constitutional order. Yet, this was not to be the fate of postbellum America.
Part of the problem is the way we came to think of the great sacrifice that occurred on the battlefields of Gettysburg, Antietam, Vicksburg—all the places where Americans rushed to give their lives for the sake of vague principles. If we did not have the great articulation of the war’s aim that Lincoln gave us at Gettysburg, the entire enterprise would have reeked of the absurd. “I am fighting for my rights,” a Confederate soldier might have said—not too sure what those “rights” were. On the other side, in blue rather than gray, he might have said, “I am fighting for the Union” with the nagging sense that dying for a governmental structure was slightly ridiculous.
The Gettysburg Address was pregnant with the sentiment that the war expressed the fraternity of Americans. The bond was expressed not only toward the slaves who were liberated but also toward the two hundred thousand black men who fought side by side, though in separate battalions, with white men to liberate those still under domination.3 The national tie—the “bonds of affection”4 —is expressed as well toward the Confederate men in arms who, in Lincoln’s view, never ceased to be part of the American nation. This was a war between brothers. It was necessary to settle the inevitable family quarrel about the kind of nation the United States would become.
As American history took its course in the decades that followed the “war for the nation,” we managed to betray the inner meaning of the great sacrifice that Lincoln sought to consecrate at Gettysburg. We absorbed the war into the preexisting political and legal vocabulary. We could have celebrated a new vocabulary of politics—a vocabulary we shared with Europeans who were then moving toward nation-states of internal solidarity. And, yet, we ignored the appeal of the new for the sake of the old. We drove the solidarity of Gettysburg underground. We converted the ideas that should have become our new activist national charter into our passive Secret Constitution.
The issues that concerned postbellum America were not the ideas of solidarity and reconciliation that Lincoln managed to articulate both at Gettysburg and in his second inaugural address. With the assassination in April 1865 of the man who had preached a new order of ideas, the United States became a country obsessed with power. The great issues of the postbellum period breathed the tensions of institutional conflict.
The party of Lincoln became the radicals in Congress, and Lincoln’s successor, Andrew Johnson, himself from Tennessee with roots in the yeomanry of the former Confederacy, was less eager than Congress to effectuate a cleansing of the governments that had supported the rebellion. He was opposed to the Fourteenth Amendment, which would have subjected the states to continuing federal scrutiny, and he was at odds with Lincoln’s secretary of war, Edwin Stanton, who concurred in the effort to seek radical reconstruction of the South. Fearing that Johnson would fire Stanton, Congress passed a statute requiring congressional approval to remove a member of the presidential cabinet. Johnson resisted; he fired his secretary of war. In retaliation, the House began impeachment proceedings. After a fierce trial that Johnson himself did not attend, the president survived, by one senatorial vote short of the required two-thirds majority. Johnson was humbled and offered less resistance thereafter to congressional policies, including the enactment of the Fourteenth Amendment.
Behind the Sturm und Drang of the nation’s first impeachment trial was a struggle for power between the Congress and the presidency. Would the constitutional structure that emerged from the war more closely resemble the European style of parliamentary democracy, with the executive cabined by congressional directives? Or would the presidency remain an independent third force of government? Wars have a way of throwing open basic questions of this sort, and by unleashing aggression within a society, a Civil War inevitably invites a redefinition of governmental power. Thus, a whole new set of issues came onto the agenda of constitutional discussion.
Among the most important of these was the proper relationship between the federal government and the states. This is the question of “federalism” that still preoccupies American constitutional lawyers. There is no doubt that the federal government came out of the war more powerful than ever. It had experimented with an income tax and, therefore, could look forward to more effective funding. It had coordinated the armies of the states and now it would undertake to guide the redevelopment and integration of the South in a society governed by a new set of values. The question now was whether under a new governmental structure with Washington at its head, the individual states could nourish the principle that they were the residual source of governmental power as set forth in the Tenth Amendment, “The powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.”
In 1791, when the Bill of Rights was ratified, it made sense for the Tenth Amendment to affirm that all federal power derived from the states and from the people. The Constitution represented a pact among preexisting states. But the states that entered the Union between the founding of the nation and the end of the Civil War, all twenty-three of them, could hardly be thought of as enjoying the same history of a prior state of independence as the original thirteen.5 The new states, with the exception perhaps of Texas, came into being by federal fiat. They were born, in almost all cases, of territories already possessed by the United States. They were created as administrative units and then recognized as states. To think of them as being the residual source of powers delegated to the governments that created them is the kind of self-deception that only lawyers can devise.
The new states admitted by 1865 should have enjoyed only the autonomy that the federal government allowed them to have. Yet, the great myth of American constitutional theory—that the new states were just like the original thirteen—prevailed. Perhaps this sleight-of-hand was necessary to maintain equality among the states. It would not do to regard the original thirteen as constituting one country superior to a second country constituted by states thereafter recognized. Yet, it would have made sense, after the Civil War, to recognize that the Tenth Amendment had lost its relevance to a United States that embodied a nation of equal Americans.
This is not to say that for the purpose of administrative efficiency, it would not make sense to divide functions between the federal and state governments. This kind of efficient allocation of functions would make sense against a conception of the nation as the foundation of governmental power. Perhaps this concern for efficiency is all that lawyers mean when they talk about the problems of states’ rights and a limited federal government. Yet, the discussion remains haunted by the myth that the states admitted after the founding retroactively granted authority to the federal government that created them.
An institution emerged to articulate and preserve this myth of autonomous states enjoying residual powers under the Tenth Amendment, and that institution was the Supreme Court. The Court had assumed the power to declare federal and state laws unconstitutional ever since Chief Justice John Marshall so interpreted our basic charter in 1803.6 In the fifty-five years leading up to the Civil War, the Court used this power sparingly.7 In the postbellum institutional shakeup, however, the Court would become more aggressive in exercising its power to overrule decisions by other agencies of government. It would articulate the ideas—it would, as we now say, give the “spin” to our basic concepts—that would define the fate of nationhood, equality, and democracy in postslavery America.
How the Court accomplished these acts of reinterpretation constitutes a major chapter in the intellectual history of the United States. It is the history of the way in which we took the words of the postbellum legal order, betrayed their inner sense, and assimilated the new legal order into the original Constitution of 1787. Blending the new language into our old habits nullified the vision of a new legal order. The principles that should have inspired postbellum America became our Secret Constitution, remaining latent for decades before they would reappear to shape the contours of American law. The story may be disheartening but it must be told. To explore the process of reinterpretation, I will focus on two leading Supreme Court decisions of the time, the first Slaughterhouse decision, and the Civil Rights Cases.


The Plight of the 
New Orleans Butchers

In 1869, four years after the war was over, the Louisiana legislature passed a statute that brought home the persistence of a dispute about economic freedom that reached back to the earliest stages of modern European and English legal history. The great virtue of the case was to remind the legal community that many issues of freedom had nothing at all to do with the war of solidarity to preserve the nation and emancipate the slaves.
At the time, about one thousand people in New Orleans were engaged in the business of receiving shipments of livestock from boats coming down the Mississippi, slaughtering the animals and packing the meat for distribution. The 1869 Act claimed to concentrate the management of the livestock and meat packing trade into selected areas. It provided that animals could be unloaded and slaughtered exclusively on the properties owned by two of the many enterprises engaged in the trade. All the butchers in the area had the right to use these facilities, but they had to pay a prescribed fee to the patented monopoly. The ostensible reason for consolidating these activities was “to protect the health of the city of New Orleans.”8 The Act was entitled: “An act to protect the health of the city of New Orleans, to locate the stock-landings and slaughter-houses, and to incorporate the Crescent City Live-Stock Landing and Slaughter-House Company.” The Act named seventeen people who were entitled to exercise the privileges of the incorporated company, and, further, it imposed fines for every violation of the patent. The excluded local butchers were enraged. They thought as landowners they were entitled to use their land to house and slaughter animals as the market required. They wanted nothing more complicated than to pursue their trade as they saw fit on their own land.
On the assumption that the legislature had acted in good faith, that there was no graft involved in vesting this authority in the Crescent City Slaughter-House Company, the controversy seemed to be an easy one—at least by contemporary standards of public regulation. This was a reasonable exercise of the state’s “police power,” its general authority to promote the common good. The single slaughterhouse was in the nature of a public utility—much like a telephone or electric company that has received a franchise from the government to provide service to a particular area. In describing the case, Charles Black dismissed the controversy as trivial.9 The complaint by the butchers should not even have generated a serious constitutional question.
At the time, however, the dispute claimed attention as posing fundamental issues. The dispute reached the Supreme Court within seven years of Appomattox. The passage of the Reconstruction Amendments was still fresh in the minds of everyone. The age overflowed with vision—but not in the Supreme Court.
The argument was close, but in the end the advocates of state power won in the Supreme Court the battle they could not win on the killing fields. Five justices voted to uphold the 1869 Act granting a monopoly to the Crescent City Company. All three of the articulated dissents empathized with the independent butchers’ economic freedom to carry on their trade without paying tolls to those favored by the Louisiana legislature. Justice Stephen Field honestly expressed the intuition that motivated the search for legal arguments for the dissent: “No one will deny the abstract justice which lies in the position of the [independent butchers].”
The reader will forgive me, I hope, for dwelling on these 1872 opinions of justices whose names we barely remember. The confrontation was so deep and so wrenching for the history of the Constitution that these conflicts have taken on epic proportions. Speaking for the majority favoring the autonomy of state power there was Justice Samuel Miller, appointed to the Court by Lincoln in 1862, and on the other side, we encounter three passionate opinions expressing sympathy for the plight of the independent butchers. I shall focus here on the conflict between Justices Miller and Field.
The “abstract justice” mentioned by the dissenting Justice Field derives from the weight of history. In the early stages of capitalism, independent entrepreneurs found themselves embedded in a feudal system of overlords and toll collectors. The lawyers for the butchers eloquently expressed the historical associations in prerevolutionary France:
The peasant could not cross a river without paying to some nobleman a toll, nor take the produce which he raised to market until he had bought leave to do so; nor consume what remained of his grain till he had sent it to the lord’s mill to be ground, nor full his cloths on his own works, nor sharpen his tools at his own grindstone, nor make wine, oil, or cider at his own press.10 

The plight of the craftsman is expressed equally poignantly: “the prying eye of the government followed the butcher to the shambles and the baker to the oven.”11 
Reading this passionate language today, we can grasp the way so many people felt about the principles of “abstract justice” favoring the butchers. The struggle for the right to work and to retain the fruits of one’s labor was one of the passions of the nineteenth century. The same sense of justice that inspired Marx worked its way, in the same middle decades of the century, into the disputes of the butchers against the City of New Orleans.
The problem was to capture in concrete legal terms the abstract wrong committed against the butchers. The lexicon of American jurisprudence was freshly stocked with high-sounding language in the Thirteenth and Fourteenth Amendments. Were these restrictions on the butchering trade an “involuntary servitude” as prohibited by the Thirteenth Amendment, or were they a violation of the “privileges and immunities” of citizenship, either state or federal, or an infringement against the state’s duty to accord all persons subject to its power both due process of law and the equal protection of the laws?
Before they reached this rich stock of possible constitutional arguments, the lawyers for the butchers tried a simple tack: The Louisiana statute infringed the common law of England, the basic principles of which had become the bedrock of American law. One of these principles was that monopolies were per se invalid. The leading jurist of the seventeenth century, Sir Edward Coke, articulated this principle in a case in which the Crown had granted an exclusive franchise to a London merchant to buy and sell playing cards of a certain type. When a competitor was sued, he claimed that he was free to engage in his chosen trade; celebrating the principles of free enterprise, the court declared the monopoly invalid.12 
This case would have been persuasive precedent for the butchers but for two hurdles that counsel had to negotiate. The first was to brand the New Orleans slaughtering franchise a “monopoly.” That proved to be problematic. The dissenting judges had no trouble concluding that requiring the butchers to use, for a fee, a single slaughterhouse was as “much a monopoly as though the act had granted to the company the exclusive privilege of buying and selling the animals themselves.”13 But the majority, led by Justice Miller, balked. The Court was willing to accept the label of “monopoly” but denied “the assertion that the butchers are [thereby] deprived of the right to labor in their occupation.”14 
If the analogy with common law monopolies had held, the second problem would then have consisted of transplanting the English practice of invalidating statutes simply because they violated, as Edward Coke said in another leading case, “common right or reason.”15 There was no evidence that courts in the United States would or could invalidate statutes simply because they violated the “common law.” The Supreme Court never took this attack on the Louisiana statute seriously. It interpreted Coke’s decision in the Case of Monopolies to be about whether the king could grant a monopoly. Coke supposedly took the side of the Commons against the king, but left open the question whether parliament could grant monopolies. The impermissibility of the statute is dismissed with the rhetorical question: “Whoever doubted the authority of Parliament to change or modify the common law?”16 The notion of legislative power to regulate the economy prevailed. The elected representatives of the people enjoyed wide-ranging discretion in the legislature to enact measures that had at least the nominal purpose of promoting the public good.
To find a way of striking down the Louisiana statute, the New Orleans butchers would have to invoke a constitutional prohibition that would override the presumed competence of the legislature. The specific clause would have to capture the sense of “abstract justice” favoring the butchers, the sentiment of right and wrong that, in the opinion of Justice Field, no one could deny.
In exploring the lawyers’ and the Court’s arguments, our primary concern should be the fate of the ideas proposed at Gettysburg as the foundation of the postbellum legal order. Our task is to ponder the fate of the ideals of nationhood, equality, and democracy, to understand how the second founding of the United States imploded and merged, at least nominally, with the first Constitution and the Bill of Rights.


Nationhood and Citizenship

As much as Lincoln sought to evoke a consciousness of American nationhood, this idea did not readily resonate in the minds of lawyers. The word “nation” was not used in the postbellum amendments. I doubt if it even occurred to counsel for the butchers to come into court and argue that independent tradesmen had a right, granted to them by the American nation, to practice their trade without the duty to pay tolls and use specific facilities. Their rights derived, if from anyplace, from universal principles governing the free market and dignity of working people. Yet, this very argument—that the nation was the source of rights acquired under the Thirteenth and Fourteenth Amendments—would show itself, remarkably, in a majestic dissenting opinion in 1883.17 
The idea of the American nation may have been in the air in the 1870s, but it was not part of the stock of concepts that the Court would draw on directly to domesticate its abstract sense of justice. The concept of an American nation was part of the American creed, but it had yet to become a fixed feature of American law. It enjoyed a fate comparable to the inalienable right to the “pursuit of happiness” as articulated in the Declaration of Independence. The latter is sometimes mentioned in legal opinions,18 but it never became the rationale for decision making in the courts. It remains an article of faith, as does the commitment to think of the American people as a single nation.
The faith in the American nation, along with the inalienable right to happiness, constitute affirmations of the American civic religion. They belong side by side with the frequent invocations, on the currency of the affirmation of faith: “IN GOD WE TRUST.” These are the background assumptions by which we live. The same is true of the sense of nationhood. In 1892, the secular prayer to the flag and the nation—the Pledge of Allegiance—would spontaneously sweep the country.19 It stood for the idea that the United States was “one nation indivisible”—a residue of “the war between brothers” that occurred thirty years before. However important these ideas may be in American civic religion, however much they dominate the thinking of Americans in the civil society that exists side by side with government, they might not be suitable as legal doctrines for deciding court cases.
Nationhood rings of romance. It appeals not to the analytic mind but to the sentimental heart. As between thought and emotion, lawyers have a bias for the linear creations of mind. The appeals of nationhood are left to poets. Lawyers opt for its analytic counterpart: citizenship. As used in the Fourteenth Amendment, citizenship is a purely formal idea, dependent solely on one’s place of birth. In the debates about the rights of New Orleans butchers before the Supreme Court, the notion of citizenship and its privileges became the stakeholder for any residual yearnings to express the rights of the nation.
Perhaps, as Charles Black and other scholars have argued, the privileges and immunities of national citizens capture whatever relevance the nation has to constitutional law. The position is defensible, though in my view, there remain important differences between the romantic extralegal idea of nationhood and the formal legal concept of citizenship. But let us leave these differences aside and imagine that if nationhood is to play a role in constitutional law, it must become domesticated under the rubric of citizenship.
The original Constitution recognized both state and U.S. citizenship. Only citizens—not merely residents—of different states could bring their cases to the federal courts.20 More important, the 1787 pact sought to equalize the legal status of citizens across the country by guaranteeing that “the Citizens of each State shall be entitled to all Privileges and Immunities of Citizens in the several States.”21 National citizenship, either for a specified period of time or by birth, was necessary to run for national office.22 Yet, the charter of 1787 said nothing about how one becomes a citizen either of a state or of the national polity. The matter was left entirely to state law, as it is today in the European Union. In antebellum America as in the European Union today, citizenship in the larger entity requires that you first pass the local hurdles set for local citizenship. Leaving the matter of citizenship to the states meant that slave states could deny citizenship to blacks or to anyone they chose. This proved to be disastrous in the Dred Scott decision, where first Missouri and then the Supreme Court held that the bloodline of Africans forever excluded them from citizenship.23 
The first item of business in the Fourteenth Amendment was to establish who, as a formal matter, belonged to the American polity. To find a simple definition, the Constitution adapted the traditional English rule that it is not blood but place of birth that matters: “All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.” Applying the traditional rule of jus soli to everyone born on American soil—except for the children of diplomats and other people “not subject to the jurisdiction” of the country—had the radical effect of eliminating family and racial history from the definition of the bond between citizen and government in the United States.
This part is simple and direct. Complications begin to arise as soon as we note the difference between U.S. and state citizenship. It would have been much simpler to have a single conception of national citizenship, the same idea that one finds in virtually every other country in the world. If the Reconstruction Amendments had really been an entirely new constitution, the courts could have ignored the concept of state citizenship altogether. Alas, the Fourteenth Amendment itself mentions it: Every national citizen becomes a citizen of the state in which he resides. And to make things more complicated, each form of citizenship carries its own privileges and immunities. The original body of the Constitution prescribes that every state must respect the privileges and immunities of citizens of other states;24 the Fourteenth Amendment extends the same duty of recognition to the privileges and immunities of national citizenship.
The problem that confronted the Supreme Court in the Slaughterhouse case, therefore, was twofold: first, how to interpret the relationship between two kinds of citizenship and second, how to fit the “abstract justice” favoring the butchers’ claim into the confines of the privileges and immunities of either form of citizenship.
Dissenting Justice Field constructed an ingenious interpretation of the Fourteenth Amendment that had the effect of promoting the butchers’ cause. The first step in the argument was to find a principle of equality embedded in the 1787 clause prohibiting discrimination against citizens of sister states. Although the original Constitution does not mention the word “equality,” the “privileges and immunities” clause can be read as a mandate of equal treatment regardless of the state of origin—at least as to citizens. Now, let us suppose that Louisiana enacted a statute prohibiting out-of-state butchers from using the Crescent City Slaughter-House Company. This kind of preference for one set of butchers over another would have been clearly unconstitutional, as the case law in this area readily reveals.25 It follows that if Louisiana cannot arbitrarily disfavor citizens of other states, it would seem odd that they could do the same thing to a group of their own butchers. Prior to the postbellum constitutional amendments, there were a limited number of clauses that made the states accountable for wrongs committed against their own citizens. The most notable were the prohibitions against ex post facto laws, bills of attainder, and laws impairing the obligation of contracts.26 But these provisions hardly provided a foothold for attacking the special privileges accorded to the butchers of the Crescent City Company.
At this point in the reasoning process, Justice Field made his striking claim: the very purpose of U.S. citizenship was to fill this gap left by the other clauses in the Constitution. It made no sense for the federal courts to guarantee better protection for butchers out of state than for those within the state. To bring about parity between these two classes—the protected citizens of other states and the unprotected citizens of one’s own state—the concept of U.S. citizenship should protect people against the actions of their own states.
The intellectual problem was similar to the situation that occurred in international law after World War II. The legal order among the nations protected citizens of foreign states against atrocities committed by the Germans, but it did not protect Jews living in Germany against their own government. This was a remarkable omission in the structure of international law. To correct it, the architects of the Nuremberg tribunal generated the idea of crimes against humanity. Today, in disputes from Rwanda to Kosovo, we take it for granted that states have duties, under international law, toward their own citizens. The Slaughterhouse Cases struggled to achieve the same breakthrough in the relationship between individual states and their own citizens.
The conceptual hurdle in 1872 was the same as in 1945. In order for a state to have duties toward its own citizens, the citizens must be considered as members of some entity higher than the state to be held accountable. In other words, the citizen and the state must both be considered as subjects of a higher legal order. Nuremberg located German Jews within the higher legal order called humanity. The victims of German terror were to be protected simply because they were human beings. Justice Field thought, correctly in my view, that the notion of United States citizenship was akin to being the member of a legal order higher than the states, a legal order to which the states themselves owed a duty to treat citizens of their own state no worse than the citizens of other states in the United States.
There is little doubt that Justice Field’s analysis, though rejected in the Slaughterhouse decision, eventually became the guiding principle for interpreting the Fourteenth Amendment. The proper home for this analysis turned out not to be the dual concepts of the citizenship clauses but rather the due process and equal protection provisions in the neighboring clauses of the same amendment. Both of these latter provisions, it will be remembered, are directed to the protection of “any persons” (due process) or “any persons within the jurisdiction” (equal protection). The drafting of the Fourteenth Amendment thus anticipated the theory underlying the Nuremberg principle of a crime against humanity. Under the Nuremberg standard, the international order imposed a duty on nation-states to treat their own citizens decently. In the postbellum legal order, the same result derived from federal constitutional principles.
But this gets us slightly ahead of the story. The question remains why and how the majority of the court rejected Justice Field’s ingenious construction of harmony between the two levels of citizenship. Keep in mind what the stakes were. There was no question that the states were subject to a higher legal order. The only question was whether that higher order would be the order established by the federal government or the order implicit in the idea of humanity. Would the controlling feature of the butchers living in Louisiana be their membership in the polity called the United States or their status as “persons” entitled to due process and the equal protection of the laws?
Field’s argument carried four votes. The other five members of the court recoiled at the thought that the states owed duties to a higher legal order called the United States. U.S. citizenship did not have the effect of leveling the distinction between local citizenship and being the citizen of another state. To read the Reconstruction Amendments in this way would “fetter and degrade the State governments by subjecting them to the control of Congress.”27 The primary issue, as understood by the majority, was whether the states would retain their own special authority over their own citizens, an authority that was expressed in the “police power” to legislate for the common good. The implication was that states could readjust private rights and obligations among their own citizens if doing so served the overall advantage of the state’s residents. Granting a special franchise to the Crescent City Slaughter-House Company was simply an illustration of a general authority to help some citizens and hurt others—all within the state. What no state could do, however, was to seek to promote the interests of its citizens over the citizens of other states.
This, we should note, carried forth the struggle of the Civil War by other means. The special solicitude shown to “the relations of the State and Federal governments to each other and of both these governments to the people” harks back to the rhetoric of the 1830s about the asserted autonomy of the new states to decide whether they would go one way or the other on the issue of slavery. It is almost as though the Civil War had accomplished only one objective, namely settling the issue of secession, while doing nothing to define the nation of the United States or to establish a principle of equality among all its citizens.
Nonetheless, writing for the majority, Justice Miller constructed a plausible theory of what it should mean to be a citizen of the United States. The picture presented is something like the posture of a supplicant toward a distant protector. The citizen should be able to address representatives of the U.S. government in person, make claims against the higher power, and receive its protection as a citizen abroad or on the high seas. None of this is particularly radical, and it fails, to be sure, to incorporate the commitments to nationhood and equality bequeathed by the Civil War.
On these larger issues, the opinion of the Court proves to be a great historical disappointment. The Miller opinion’s perception of our unity as a nation comes across in this remarkable sentence:

And quoting from the language of Chief Justice Taney in another case, it is said “that for all the great purposes for which the Federal government was established, we are one people, with one common country, we are all citizens of the United States. . . .”28 
The date of this other opinion is not mentioned, but Chief Justice Taney, it will be recalled, was the author of the Dred Scott opinion, which did indeed affirm that we were one [white] people and that persons descended from slaves could never become a part of it. To cite Taney on the issue of American nationhood is a bit like invoking Al Capone on the rule of law.


Equality

And equality—that glaring omission from our original Constitution? How did the Fourteenth Amendment’s attempt to rectify the sins of 1787 fare in the grip of the antebellum intuitions that drove the Miller court? The five majority justices could have applied the “equal protection” clause and achieved the same result that Justice Field had engineered under his construction of the dual tracks of citizenship: the butchers rendered dependent on the Crescent City Company were subject, they could easily have concluded, to impermissible discrimination. That would not have been a particularly radical result, and it would have established an enduring commitment to equality under the postbellum constitution. But no, the Court turned away from the larger issue of principle for the sake of overcoming a narrow historical injustice. The “evil to be remedied by this [equal protection] clause,” the Court writes, was “the existence of laws in the States where the newly emancipated Negroes resided, which discriminated with gross injustice and hardship against them as a class.”29 In other words, the only point of the new commitment to equality should be simply to eliminate the institution of slavery and its concomitant legal institutions. But if that was the only purpose of the Reconstruction Amendments, the Thirteenth had already done the job. There was no need for the Fourteenth Amendment and its commitment to the larger principle of equality among all “persons in the jurisdiction.”
Susan B. Anthony had already begun her campaign for women’s suffrage, but as of the date of the Slaughterhouse opinion there was little sympathy for moving the spectrum of equality up one notch to include women as a class worthy of protection. Immediately after resolving the Slaughterhouse dispute, the Court turned to the petition of Myra Bradwell to be admitted to practice law in Illinois.30 There was no dispute about whether she was qualified. She was a citizen of the United States and of Illinois, and she had the training and character to make a fine lawyer, but there was one problem: She was a woman. This was sufficient for the state to bar her admission, and the Supreme Court, with only one justice dissenting, thought this was an acceptable exercise of state power. After the Slaughterhouse decision, it was a minor stretch for Justice Miller to conclude that practicing law did not fall within the ambit of “privileges and immunities” of citizens. The amazing feature of the Court’s decision in this case is that it did not even occur to the judges to justify the discrimination against women as compatible with “equal protection of the laws.” The opinion is totally silent on the issue of equality. This was the temper of the times. In 1874, another woman, Virginia Minor, argued to the Supreme Court that Missouri’s denying her the right to vote violated the Fourteenth Amendment. The Court resolved the matter by unanimous vote.31 It did not even mention the possibility that the discrimination violated equal protection of the laws.
Apparently, it lay beyond the imagination of the justices in the 1870s that someday equal protection would be extended to protect all those created in God’s image. It would protect not only racial minorities but also women, children born out of wedlock, aliens, and all groups that suffered the stigma of arbitrary social and legal exclusion. They ignored the “abstract justice” that screamed at them from the bold language of the new constitutional structure. Rather, they read the language to narrow it, to confine it to historical circumstances, in effect, to defeat the vision of a new, more just society. Supreme Court justices are an inherently conservative lot, but they are rarely as reactionary as these justices of the postbellum era. The Reconstruction Court did as much as possible to convert the vision of a new order into our Secret Constitution.
Yet, the values of nationhood and equality would not remain forever hidden, camouflaged in the deep structure of constitutional thought. They would begin to reassert themselves both in the political arena and in the courts. The debate in the Slaughterhouse case had failed to take seriously the issues either of nationhood or of equality. The dissent never got to the question of equality because they were satisfied that the Louisiana statute violated the “privileges and immunities” of United States citizenship. The majority never reached that point because, as far as they were concerned, the Fourteenth Amendment had the limited function of eliminating statutory discrimination against African Americans. The Court’s view that the purpose of “equal protection of the laws” was solely to protect blacks from apartheid-like legislation was so clearly narrow-minded that it could not hold for long. Fourteen years later, the Court would extend the principle of equal protection to Chinese launderers in San Francisco subject to discriminatory enforcement of zoning regulations.32 This was the first step toward a sensible jurisprudence of equality.
The historical associations of the Slaughterhouse dispute lend themselves to multiple perspectives. For the advocates of the butchers’ economic rights, the critical perspective was the long history of emancipating craftsmen and laborers from the feudal bondage that subjected them to a network of service and financial obligations. For the dissenting judges, the challenge posed by the case was the creation of a single national polity in which the states were obligated to treat insiders as well as they treated outsiders. And for the majority, the issue was the one that should have been resolved by the Civil War: the struggle for power between the states and the federal government. Unfortunately, that struggle would continue to haunt the court for decades of contentious litigation.


Apartheid in the Theater

It is tempting to read the Slaughterhouse case as a decision by the Court to turn its back on the struggle for racial equality in the United States. In fact, as we should keep in mind, the case had nothing to do directly with discrimination against former slaves. The decision does, however, signal a great concern for the autonomy of the states, for the revival of states’ rights against the federal government. This could have generated a jurisprudence of deference to the states in their exercise of police power, even if executive and legislative decisions had the effect of discriminating against former slaves. In subsequent decisions, however, the Court established the basic principle that in the field of criminal justice at least, the states could not treat blacks as an inferior class. In one 1880 decision, the Court upheld a federal penalty against a Virginia state officer who disqualified blacks from jury service.33 And another decision in the same year reversed a state court conviction of an African American tried by a West Virginia jury on which blacks were not permitted to serve.34 With respect to African Americans’ exercising the basic rights of citizenship, particularly in the field of criminal justice, the Court would be vigilant.
The more contentious issues arose in defining the way the emancipated slaves could move and function as supposedly free citizens in American society. The most fundamental rights of former slaves could not be taken for granted. The first Civil Rights Act, enacted in 1866 on the basis of the Thirteenth Amendment’s commitment to suppress slavery and involuntary servitude, established elementary civil rights for former slaves: the right to sue in the courts, to be witnesses, to have the same legal remedies, and to be subject to the same penal and tax obligations as other citizens. The act provided criminal penalties against any official who subjected any person to one of these basic legal inequalities on grounds of race, color, or status as an alien.35 
The difficult question was whether Congress could properly legislate under the Thirteenth Amendment to protect former slaves against informal but rigid forms of customary discrimination, for example, the denial of service in restaurants, the refusal to rent rooms in hotels, and the segregation of theaters. The Civil Rights Act of 1875, Section 1, provided that all persons should enjoy equal access to “inns, public conveyances on land or water, theaters, and other places of public amusement” regardless of race, color, or previous condition of servitude.36 Section 2 attached a fine and a prison term of up to thirty days for committing the misdemeanor of denying someone access to these facilities for the prohibited reasons. On the basis of these provisions, the federal government indicted various suspected violators around the country—New York, San Francisco, Tennessee—for having denied access to theaters and other public facilities. Significantly, all of these prosecutions were brought in areas that had been loyal to the Union in the war. The defendants appealed their jury convictions on the ground that the Civil Rights Act exceeded the authority of Congress. Their appeals were consolidated on appeal to the Supreme Court.37 
Eight justices decided that the Congress’s effort to prevent segregation and apartheid in public life overstepped their authority under both the Thirteenth and Fourteenth Amendments. Accordingly, the Court reversed the convictions and set free the defendants who enforced the color line in public accommodations. The Court reasoned about the Reconstruction Amendments in the same sterile and truncated way we have already witnessed in the Slaughterhouse Case. This discrimination in access to public transportation, inns, and theaters did not constitute an “involuntary servitude,” for, as the Court had the temerity to suggest, these interactions in public were in the realm of “social rights of men and races in the community.”38 The purpose of the Thirteenth Amendment was merely “to declare and vindicate those fundamental rights which appertain to the essence of citizenship.”39 Of course, this was obvious discrimination on the basis of race. Why should it not qualify as the denial of “equal protection of the laws” under the Fourteenth Amendment? The Court focused on the wording of the amendment: No state shall deny to any person within its jurisdiction the equal protection of the laws. Only the states could violate the amendment. And the particular persons who enforced the color bar at trains, inns, and theaters were not agents of the state. Their actions did not constitute legislation by any government or executive action by any official wearing a badge of state authority. And, therefore, the state was not responsible for these private persons denying “social rights” to black citizens. The conclusion: If the wrongdoing was purely social or private, then the federal government could not punish it under legislation designed to enforce the Fourteenth Amendment.
This cramped and faithless reading of the Constitution has become obvious to us over time, but it was apparent in 1883 as well. The lone dissent by Justice John Marshall Harlan records, with allusion and insight, the betrayal of what should have been the postbellum constitutional order. Harlan pinpoints the intellectual moves that led the court astray. On the issue of state action, Harlan recognizes the spectrum of possible positions ranging from purely private actions to the actions taken as the policy of the state. To grasp the subtleties of the problem, think of the following points on a spectrum of actions ranging from purely private action at home to the purely public functions of state officials:
1. Actions taken at home, in the family, with friends.
2. Actions taken in public by employees of private companies that serve the public, for example, a store clerk refuses to sell goods to a black person.
3. Actions taken in public by employees of an organization entrusted with a public function, for example, ushers at the opera or conductors in railroad cars refuse to seat blacks.
4. Actions by a privately owned utility that has a state franchise to provide service in a particular area, for example, Bell Telephone refuses to sell service to former slaves.
5. Actions taken by local officials on their own, in defiance of governmental policy, for example, a local judge refuses to include blacks on the jury list.
6. Official policies of the government, discriminatory legislation, executive decisions not to hire blacks.

Except for purely private actions at home and official policies at the other extreme, the other points on this spectrum represent a mix of private decision making and government policies. In fitting the Fourteenth Amendment to the reality of these diverse combinations, the Court could have insisted on stage six as the threshold of behavior included within the scope of the amendment, thus limiting the supervisory power of the federal courts to the official action of state officials. But it was clear from the outset that this would make little sense. Discriminatory application of sound laws could not escape federal scrutiny simply because state officials acted beyond the scope of their authority. Limiting “state action” and official policies of the state would encourage officials to act beyond their legal competence. Thus, stage five came to be included within the ambit of state responsibility.
The fatal mistake in 1883 was concluding that everything below stage five could properly be classified as private or “social.” Justice Harlan’s dissent stresses that stages two, three, and four are also actions in the public domain that implicate the state in various ways—as enforcer, as beneficiary of the surrogate private enterprise, or by direct or indirect funding (e.g., tax incentives). Reading the Fourteenth Amendment with a view to what it was intended to accomplish would have yielded a more generous understanding of “state action.” The range of constitutionally relevant action would have included at least actions fulfilling the public functions of providing transportation, accommodations for travelers, education, and culture. And if the Court had so interpreted the notion of state action, it would have had no difficulty sustaining both the Civil Rights Act of 1875 and the convictions brought against the violators of the provision requiring equal access to theaters and other facilities open to the public.
Furthermore, as Justice Harlan pointed out, the Court had read the new rights established by the Reconstruction Amendments as though they were just like other restrictions imposed on state governments, for example, the prohibitions against the states enacting bills of attainder, impairing the obligations of contract, or granting titles of nobility.40 Therefore, the Court could engage in close analysis of the specific prohibition against state authority and assess whether it was really the “state” that was responsible for the wrong committed against those who were shut out of facilities supposedly open to the public.
The Court ignored, in Harlan’s clearheaded view of the case, the critical feature of the Reconstruction Amendments, namely that each of them grants Congress authority to effectuate the amendment with “appropriate legislation.” This was the first time in our history that constitutional amendments carried with them an expansion of Congressional authority.41 Accordingly, it was up to Congress to decide how best to implement the general commitments explicit in the Thirteenth and Fourteenth Amendments. Congress had acquired a general police power in this area comparable to the state legislative power upheld in the Slaughterhouse Case.
Harlan’s most devastating argument was that the courts had long assumed that Congress enjoyed a general legislative power to regulate the conditions of slavery. The constitutional text of 1787 had stipulated a right of slave owners to recover slaves who had escaped into free territory.42 On that basis, Congress enacted the Fugitive Slave Law of 1793, which in a manner similar to the Civil Rights Act under attack had imposed a federal penalty on those who refused to cooperate in the return of runaway slaves.43 If Congress could elaborate on a constitutional clause securing slavery, surely they enjoyed an analogous power, reasoned Justice Harlan, under an express grant of legislative authority in the Reconstruction Amendments to eliminate slavery and secure equal protection of the laws.
Justice Harlan’s position eventually triumphed—but not until our own time. After a long process of litigation, addressed primarily to the constitutionality of New Deal welfare legislation, the courts expanded the authority of Congress to legislate on all matters affecting “interstate commerce.”44 This became the basis for the Civil Rights Act of 1964, which finally enacted the broad-gauged protection against discrimination that the Court had declared beyond the competence of Congress in 1883. Grounding congressional competence to counteract discrimination in its power to regulate interstate commerce smacked of legal convolution. The better ground would have been precisely the original claim of authority asserted by Congress in the Civil Rights Act of 1875.
Justice Harlan’s fidelity to Lincoln’s vision of the postbellum constitutional order becomes clear in his appeal to the concept of nationhood. Of all the opinions surveyed in leading cases decided in the aftermath of the Civil War, Harlan’s is the only one that comes close to conceptualizing the United States as a nation acting as a single unit. When the term appears in the other opinions, it is always as the adjective “national.” Yet, Harlan’s opinion is studded with references that replicate the usage that we heard in the Gettysburg Address and then found in selected poetry and philosophy written at the time. The nation is not just a government. It is an organic entity, a source of authority. As Harlan repeats nearly thirty times in the course of his opinion, the “nation has liberated”45 the slaves, “the nation has established universal freedom in this country,”46 and blacks, denied citizenship in the Dred Scott decision, acquired their equal citizenship “in virtue of an affirmative grant from the nation.”47 
Reasoning like Orestes Brownson or Frances Lieber, Justice Harlan distinguished clearly between the nation and the federal or national government. The nation is not a constituted government. It is rather the source of authority that legitimates government. This conception of nationhood, synonymous with the spirit of Gettysburg, is evident in expressions stressing the logical priority of the nation’s will. For example, Harland writes that to insure that “the purposes of the nation might not be doubted or defeated . . . the Fourteenth Amendment was proposed for adoption.”48 Equally poignant are passages that treat the rights and privileges of the Constitution as “derived from the nation”49 or that stress “what the nation through Congress has sought to accomplish.”50 
John Marshall Harlan’s entire philosophy, expressing the heart of the Secret Constitution in dissent, is summed up in this sentence:
Exemption from race discrimination in respect of the civil rights which are fundamental in citizenship in a republican government, is, as we have seen, a new right, created by the nation, with express power in Congress, by legislation, to enforce the constitutional provision from which it is derived.51 

It is clear in this passage that the nation, as distinct from government, creates rights, grants citizenship; it has objectives that it seeks to accomplish, but it must act through the prescribed processes of the law. The nation acts initially in the process of constitutional amendment, and then, by means of delegated authority, through the Congress. The nation has expressed its will by precisely these means in the Reconstruction Amendments, which delegated Congress authority to engage in the kind of legislation under attack in the Civil Rights Cases. The logic of the argument traces the genesis of the nation-state. First the nation comes into being as a prelegal organic unity, and then the nation expresses itself in a governmental structure.
One might properly inquire how the idea of the nation’s expressing its will differs from “We the People” acting in concert for the sake of a better government. The differences are admittedly subtle. Perhaps the accent in Justice Harlan’s mind was on the historical bond implied in the war that held the nation together. Yet, it is no accident that the expression “We the People” is absent in the rhetoric of his dissenting opinion. The problem he addressed was not one that the people could decide for themselves. The question “Who constitutes the nation?” does not lend itself to democratic resolution. The question of nationhood logically precedes both government and the popular will. For the nation to express itself as “government of the people,” it must first come into being.
The nation does not constitute itself by popular vote or by a decision of government. The nation comes alive, as Lincoln viewed our history, as a bond forged in an historical struggle. The bond was first cast in 1774 with the first stirring of independence or, at the latest, in July 1776. The inclusion of emancipated slaves within the nation came as the only consequence of the Brothers’ War that could make sense of the national search for redemption.
Remarkably, the eight justices who signed the Court’s opinion invalidating the Civil Rights Act of 1875 used the vocabulary neither of peoplehood nor of nationhood. They had no conception of the American nation—or at least not one relevant to their legal analysis. Of course, they refer to the national government, a phrase in which “national” is synonymous with “federal” or “central.” Yet, they use the term “nation” in reference to France!52 I suppose that in the minds of the majority of justices, the United States constituted not a nation but a people still living under the Constitution they had designed and ratified in the 1780s.
No one chose to create an American nation consisting of North and South, white and black, native and immigrant, and there were undoubtedly many people displeased by the idea. Yet, this was the situation in which we found ourselves in 1863. Lincoln had conceived of rooting our history in the identity generated by the struggle for independence. History had forged a unique nation of people of diverse origins. Justice Harlan understood what the nation had become and what it could do to further its own internal harmony. His magisterial dissent leaves us with a historical record of what constitutional thought in the postbellum period could have been.
Instead of integrating our nationhood and the commitment to equality into constitutional discourse, the Civil Rights Cases completed the process of driving Lincoln’s vision into the deep structure of our constitutional thought. The Court generated a surface discourse to camouflage the Secret Constitution. It bequeathed to us a narrow conception of state action that we are still struggling to overcome. And, more to the point, by undermining federal authority to remove the incidents and marks of slavery, the Court facilitated segregation in American society. It would be a mere dozen or so years until the Supreme Court upheld the idea that public facilities, including schools, might be “separate but equal”—thus institutionalizing apartheid for generations.53 At the same time that the courts drove the postbellum legal order underground, concerted action by the children of slave owners organized to frustrate the purposes of the Fifteenth Amendment. Various measures, including poll taxes, literacy tests, and organized violence, were used to prevent African Americans from realizing their right to vote. The Democratic Party gained the loyalty of white Southern voters and remained in power for more than half a century, largely on the basis of segregationist principles.54 
Yet, there is an important difference between the courts’ betraying the Thirteenth and Fourteenth Amendments and the people’s frustrating the purposes of the Fifteenth Amendment. With regard to the first two of the Reconstruction Amendments, the courts gutted the great aspirations of the new constitutional order and led many professorial observers to teach that our Constitution really was what the segregationist courts said it was. This tendency to take the Courts at face value derived largely from academic skepticism about the possibility of a higher law prevailing over the uses of judicial power in our understanding of what the Constitution really required.
The Constitution became what the courts do in fact. Legalism prevailed. The legal philosophy of the Confederacy triumphed, both in substance and in style.55 The ideals of Gettysburg became, for the lawyers in the second half of the nineteenth century, a matter of history. For the nation as a whole, however, the values of Gettysburg—nationhood, equality, and democracy—retained their promise, and these principles would eventually return to the field of litigated law.
At least the commitment to democracy had begun to make inroads in the official documents of the lawyers. The language of the Fifteenth Amendment, the first federal measure directly securing a right to vote, betokened the beginnings of popular democracy. No state could deprive African-American men of the right to vote—at least in theory. Missing was not the constitutional language but the will to enforce it. The campaign to overcome impediments to black voting would take several generations, including additional amendments and legislation abolishing poll taxes and literacy tests. As the Secret Constitution would again reassert itself in American politics, we would also take the promise of the Fifteenth Amendment seriously.
As a sequel to World War II, when black and white had again fought side by side, although still in segregated units, the will would again arise to fight for equality in a single nation. It would take a campaign of restaurant sit-ins and bus boycotts finally to correct the great error of the Civil Rights Cases. In 1964, four-score-years-and-one after the initial defeat in the Supreme Court, the country could once again say that equal access to theaters and public accommodations was the law of the land.
If we look at the legacy of the Slaughterhouse Case and the Civil Rights Cases together, we should note two additional casualties to the vision of a new postbellum legal order. In the first case, counsel raised the issue of economic discrimination, which had never received due attention from the Supreme Court. We turn in the next chapter to the legacy of that failure in ongoing economic discrimination in education. As race came center stage in the truncated arena of “equal protection,” the Supreme Court would ignore the tragedies of the states’ toleration of wealth and class discrimination. As we shall see, other countries have confronted the problem of wealth discrimination as an aspect of their commitment to equality. It will eventually be incumbent on the Supreme Court to do the same.
The second major casualty was the concept of “involuntary servitude” as invoked in the Thirteenth Amendment. Counsel tried, but they could not persuade the Supreme Court to think of the burdens imposed on the New Orleans butchers and on African Americans subject to public segregation as variations of the servitudes prohibited by the Thirteenth Amendment. That concept had the potential of inducing a new role for government in the relationships between private parties. If servitudes should be understood as relationships of domination, then an open-ended approach to the concept would have generated a watchdog role for the federal government in inspecting and supervising private relationships of potential exploitation and domination. The Crescent City Company’s domination of the independent butchers, who had to pay tribute to practice the slaughtering trade, should have been a paradigm of impermissible domination. And the other paradigm of coerced servitude would have been the domination of blacks by whites in a segregated society.
Had these two decisions gone the other way, a triadic relationship with government would have emerged. The triangle would have consisted in the potentially dominant private party, the potentially subservient private party, and the government as the guarantor of relationships of equality and nondomination. It is not clear which branch of the federal government would have benefited most from a triadic relationship with private parties. Congress would have exercised its authority to legislate under the Thirteenth Amendment. The executive would have established commissions to keep tabs on relationships that came to public attention. Although the judiciary probably would have prospered as well, the Supreme Court of the 1870s and 1880s did not want to see the federal government become the watchdog of economic and semipublic racial relationships. Our history took a different course, one that required us to confront, in ways that we hardly expected, the moral difficulties of understanding equality under law.









The genius of the Gettysburg Address is that it took the words of the Declaration of Independence and found in them a crystallization of a meaning suitable for the refounding of American democracy. In 1776, the idea that “all men are created equal—for all purposes” had no precedent in the declarations of political leaders. Even the great French Declaration of the Rights of Man, issued thirteen years after the French Revolution, preached a more limited version of equality—“All men are born and remain equal under the law.”1 In its original context, the famous five words “all men are created equal” had a limited function. They undermined the pretension of King George III to rule under the divine right of kings. If all men were of equal stature under God, then no one could claim to have been anointed as ruler by supernatural authority. At the same time, however, the famous maxim could also be understood as referring to “men” as collective entities: “all peoples have equal status.” It was not particularly novel to argue that all nations, all states, had an equal claim to govern themselves. The principle of national self-determination, urged so adamantly in the twentieth century, derives from the same source: every nation is entitled to preserve its own culture, cultivate its language, and express itself as a subject of the international community. International law is based on the idea that nations, anchored in the form of states, enter into legal relationships. The states in which nations are embodied enjoy legal personalities. They incur debts and, significantly, these debts are not extinguished by revolutionary changes of government. The forms of the state come and go, and the nation endures through it all. It is no wonder, therefore, that the Declaration of Independence would assert that the American people were equally entitled, with all other nations, to determine their form of government.
These two senses of the famous “all men are created equal” capture the ambiguous quality of the American revolt against the British. It was both a revolutionary and an anticolonial war of independence. The revolutionary spirit was captured in the categorical rejection of monarchy. The anticolonial thrust appears in the assertion of the Americans’ equal claim to rule by “consent of the governed.”
More far-reaching than both of these original meanings, however, is the individualist interpretation: All human beings are of equal dignity. They are created equal and remain equal in the eyes of their Creator. There can be no foundation, therefore, for the claim that whites are superior to blacks or that men should count more than women. Of course, many framers of the Declaration were slave owners and most, if not all of them, were patriarchal heads of households. Yet, they bequeathed to the world a rhetorical phrase that was pregnant with meaning deeper than many of them may have intended. This deeper meaning lay, embedded in the text, ready to come alive for the first time as their Declaration became the sacred text of the American abolitionist movement.
Legal texts often bear one meaning on their surface and a higher meaning that requires faith and personal investment beyond the surface meaning. A good example is the commandment in the Decalogue prohibiting homicide. Allow me a short digression on the commandment against killing to illustrate the phenomenon of a text that carries one meaning on its surface and a more radical meaning beneath.
The Hebrew expression in the Sixth Commandment, lo tirtsach, is generally read: Thou shall not commit murder. The term “murder” implies a prohibition only against unjustified killing, implying the permissibility of killing in self-defense. Yet, a survey of the sources in Jewish law reveal that the term also bears the interpretation found in many Christian translations: Thou shall not kill. “Thou shalt not murder” is a rule that we can expect people to follow, but “Thou shalt not kill” hardly lends itself to the same strict enforcement. The morality of not killing becomes an aspiration, a challenge for people to realize in their struggle with imperfection. Whether they can renounce self-defense, as the Mennonites appear to have done, is a matter of personal moral realization. Whether they can extend the prohibition against killing to all living creatures, as some exemplary spiritual leaders have done, depends on their moral evolution. Those who eat meat are not wrongdoers or sinners. They simply have not yet reached the highest point of aspiration. One should respect the Buddha, for respecting all forms of life by not killing, but those who fall short of the Buddha are not subject to blame.
The same contrast can be drawn between the equality of all nations and the equality of all human beings. The equality of nations has become a postulate of the international legal order. There may be debate about which groups of people constitute nations entitled to self-determination and representation in the international community, but the principle seems to be accepted by all. For the community of nations, so recognized, equality—let us, say, with regard to voting rights in the General Assembly of the United Nations—becomes a norm readily enforced.
Not so for the equality of all human beings. First, it is not at all clear what we mean by equality, why we should recognize it in all human beings, and what we should do to realize equality in practice. Even Lincoln did not favor the equality of blacks for all purposes, including social and marital relationships. And even if we think that all children are equal in the sight of God, we might understandably bequeath our property to our own kin. How much equality and the form that it should take remain a matter of constant debate.
As in the case of “not killing,” in the field of granting equality, there is always more that one can do. The minimum is recognizing an equal “right to life, liberty and the pursuit of happiness.” This requires, to be sure, the abolition of slavery. But there arises then the question of equality in the exercise of basic legal rights, like owning property, serving on a jury, and testifying as a witness in court. Some of these basic legal rights of equality did not accrue to women until well into this century. At a further frontier is political equality, namely the right to express opinions, to vote, and to hold office. Further up the scale of equality, we encounter equality of opportunity in economic competition: Every individual should have the right to compete on an equal footing, with equal education and the basic resources required for the market.
At this point in the spectrum, we begin to make the transition from equality of opportunity to equality of outcomes. Everyone should arguably have an equal claim to the world’s resources. The manna of life, in Bruce Ackerman’s apt metaphor, should be distributed equally.2 The accidents of birth prevent us all from having equal talents, but perhaps those born with lesser talents should receive some form of compensation for their deprivation. All other outcomes, as John Rawls argues, would be “arbitrary from a moral point of view.”3 A similar form of compensation might be urged for those who fall short in the unfolding of their lives. Some have bad luck in romance, fail at their creative efforts, suffer the accidental loss of a child. An extreme egalitarian might see an injustice, requiring compensation, in these differential life paths.
We might refer to this layered set of possibilities as the spectrum of equality. As in abstaining from killing, one can cross the initial stage of this spectrum and remain unsure about how far to ascend on the scale. To whatever height one ascends on the spectrum of equality, there should be a strong connection between that perch and the reason for recognizing human equality in the first place. Once again, the analogy with the commandment against killing (or murder) proves instructive. However much one becomes convinced that killing is wrong, one needs a reason for that degree of conviction. In order to renounce self-defense you need a reason, something to the effect that violence only breeds more violence. Or, if you wish to emulate the model of Albert Schweitzer, you must say something like: All living things are the creatures of God, they all deserve to live. This is not to say that your reason must be demonstrably correct, but you need a reason for your commitment for it to make any sense at all.
The abolitionists, too, must have had reasons for believing in equality in a way that both Northern and Southern fellow citizens rejected. Abraham Lincoln, too, followed an inner logic in cultivating the deeper meaning of the Declaration of Independence. And today we must also have grounds for taking human equality seriously as a basic ideal of social and political justice.
Providing these reasons turns out not to be so easy. As a descriptive claim, the thesis “all men are created equal” is obviously false. People differ in every conceivable respect—size, strength, intelligence, musical talent, beauty. But being equal is not equivalent to being the same, identical, or similar. Equality is a curious relationship, and its model is arithmetic relations. Two sides of an equation are stipulated as equal, but this may not be apparent to the untrained eye. For example: 17 x 17 = 289. The two sides of the equation are not identical in notational form but equivalent in numeric value. The suggestion is that all our differences are like notational form. My DNA, my biography, my talents, are certainly not the same as yours, but these differences become superficial in light of the deeper equivalence of moral value. What gives us this deep equality of value?
Some philosophers have tried to analyze human equality by searching for some single factor by virtue of which we are equal. We might all be equal because we can use language and say things like, “I am as good as you are.”4 Utilitarians claim that we are equal because we feel pleasure and pain.5 John Locke argued that we are all equal because we are all the property of God.6 Or as contemporary secular thinkers claim, we are all equal because, in principle, we can act both rationally and reasonably.7 All these arguments suffer from the same objection. Suppose someone could not speak, would he not be equal to other human beings? Suppose she could not feel pleasure or pain, would that put her outside the human community? If he were not rational, would he not be one of us? None of these criteria alone could be an adequate test of equality unless it was accompanied by a theory that explained why that factor, and that factor alone, was sufficient to generate the strong sense of human equality. Of little value, as well, is Locke’s influential argument that we are the property of God. Animals also belong to the same Creator but that does make them equal to humans.
Modern philosophical approaches toward equality all suffer from the same flaw. They are strongly committed, vaguely, to some position on the spectrum, but they offer no reason why they are so intensely committed to this value that has become so powerful in the English-speaking West. Human equality seems to be an unquestioned postulate—one of those truths that we hold to be “self-evident.” And those things that are obvious apparently require no grounding in reasons. In the contemporary liberal culture, equality is one of those values that has become so deeply held that it is neither questioned nor justified.
Given the long history of popular belief in the intrinsic superiority of certain classes of people—men, whites, Christians, Americans—the philosophical belief in equality stands as a critique of commonly held beliefs. It is clear that the popular culture still harbors many biases about some people being intrinsically better, entitled to greater privileges, than others. Yet, the long-range popular trend favors overcoming our biases in favor of a belief in the equality of all humanity. The American Revolution took the first step by abolishing the privileges of the nobly born. The 1787 Constitution prohibits both the states and the federal government from granting “titles of nobility.”8 There was this much equality in the founding, but anchoring the “peculiar institution” of slavery in the Constitution was the great “offence” against equality that could be expiated only on the killing fields of Gettysburg and Antietam.
The postbellum history of the United States has carried the egalitarian message of Gettysburg into the liberation of ever more marginal groups. After the emancipation of blacks, the movement for women’s suffrage gained strength and finally triumphed in 1920, and then in unclear succession came the contemporary efforts toward the equal treatment of homosexuals, “illegitimate” children, the handicapped, and even undocumented aliens.9 The thrust toward inclusion of more and more groups within the inner circle of the equally privileged has been one of the central themes of American life. Yet, even the victory of the Civil War is not yet complete. The badges and vestiges of slavery still haunt the land. The quest for redemption from the original sin of slavery continues in our own time.
Our sensibilities are conditioned by our history. But, however difficult the struggle, we have a history of which we can be proud. We Americans were the first to conceptualize the great maxim of equality and to label it a self-evident truth. No other legal system, so far as I can tell, relies explicitly on the principle that all human beings are created in the image of God. Yet, all modern legal systems and international documents of human rights today subscribe to the principle of equality before the law. Typical of the American influence is the 1789 French Declaration of the Rights of Man, which provides in the second part of Article 6: “The law must be the same for everyone, regardless whether it serves to protect or to punish.”10
Equality before the law is the most limited claim of human equality. This form of equality applies only to fellow nationals and residents subject to the same legal order. More ambitious are the arguments of the philosophers such as Ackerman and Rawls who claim that equality is the first principle of social justice. At the outer reaches of principle, we find the great maxim invoked in the Gettysburg Address: All human beings are equal in the sight of God.
Let us limit our thinking, for the time being, to the most modest claim—that all individuals, black and white, men and women, gay and straight, born in wedlock and out of wedlock, should be treated equally under the law. We did not recognize this principle in the 1787 Constitution. It came into our positive law—the law actually applied by the courts—in 1868 with the Fourteenth Amendment. But what is the grounding for this transformation in our attitudes toward equality under law? Did we need the more radical faith in equality in the sight of God to discover the imperative of treating everyone equally under the law? Is equality under law limited to Americans? If so, why does the Fourteenth Amendment literally protect all “persons” against the American states that deprive them of equal protection of the laws? These are the difficult issues to which we now turn.


The Nation as the Crucible 
of Equality

Gettysburg forged a link between the nation and egalitarian thinking that we sometimes forget. The connection between the limited nation and unbounded equality has paradoxical overtones. The nation is dedicated to the proposition that all men are created equal. The thrust toward equality has universalist implications. Neither Lincoln in 1863 nor the founders in 1776 argued that only “Americans” were created equal. The claim was that all people—in principle, all human beings on the planet—are born with equal dignity. Yet, this universalistic thinking thins our commitment to equality to a point of fragility.
Equality flourishes in an environment of mutual sympathy and reciprocal identification. The love for each and the needs of each come to the fore in the affective bonds of family, friendship, tribe, and, by extension, in the reciprocal attachments of nationhood. The limited political sphere of the nation facilitates the recognition of others as human beings sharing a common history. If blacks and whites, Northerners and Southerners, eventually men and women, could respect each other as Americans participating in the same national drama, they would lay a foundation for affirming their mutual equality. They need not be brothers and not exactly friends, but they could at last recognize each other as compatriots with a common language, a single history, and a shared future.
The source for this association between bonds of affection and equality lies outside the Judeo-Christian tradition, notably in the philosophy of the ancient Greeks. The fullest development comes in Aristotle’s Politics and in the Nicomachean Ethics. The idea of universal human equality was foreign to Aristotle, but he did believe in the mutual recognition of equality within the bonds of friendship and other close associations. Indeed, wishing well for the other as an end in himself is an essential component of philia or friendship understood broadly, and this sentiment, Aristotle believed, provides the necessary foundation for all virtuous behavior.11
Equality appears as a central theme in the virtue of justice as well as friendship. The just person is one who pays due regard to his own interests as well as to those of others. He is able to maintain the proper balance between his own interests and those of others. This is an aspect of distributive justice that generally requires each person to receive a due or proportionate share of the good to be distributed. Aristotle describes this proportion as an expression of geometric equality. Similarly, when one person wrongs another, some correction is necessary. This species of justice is also based on equality, understood arithmetically. The wrongdoer and the victim should both be restored to the state they were in prior to the wrong. This might be done by compelling the wrongdoer to pay compensation from the gains that he has received in order to make up the loss to the victim.
These virtues of friendship and justice require cultivation, for they contribute to the flourishing of the virtuous individual. Adapted to the nationalist argument for equality among all Americans, Aristotle’s argument about friendship would go something like this: we should treat all members of the American polity as equal, with equal concern for their lives, precisely as we would treat friends. By so doing, we as a nation will flourish and we as individuals will flourish from our taking the ends of our compatriots as seriously as we would those of friends.
Each nation must seek equality for the sake of its own flourishing. The sense of common destiny is nowhere better expressed than in the Jewish expression: Kol Jehudim eruvim ze bze [All Jews are responsible for each other]. In the rhetoric of American nationalism, the metaphor of the chosen people, of the substitution of Americans for Jews, recurs as a familiar trope. The sense of organic closeness is implied. The responsibility of the American nation should run to all members of the nation, defined in the Fourteenth Amendment as all those naturalized or born on the soil of the United States and subject to its legal jurisdiction.
Nationalism becomes a virtue if it avoids hatred of outsiders as it encourages mutual respect among insiders. This, indeed, was Lincoln’s ambition in seeking reconciliation in the Gettysburg Address and in his second inaugural address. Accepting his idea of a “new nation dedicated to the proposition that all men are created equal” would have enabled Americans to negotiate the postbellum period without self-seeking and rancor. But this was not, as we saw, the way it happened, particularly after the tragic turn at Ford’s Theatre.
Andrew Johnson’s plan for Reconstruction was plagued by controversies about whether the previously disloyal were still full members of the nation and whether blacks, once emancipated, should ascend a step higher and receive the franchise on equal terms with whites. Lincoln imagined grounding the equality between black and white, Northern and Southern, in a shared sense of nationhood. With the rancorous infighting that dominated Congress in the period 1865 to 1870, the relevance of nationhood began to recede. More important were the ideological issues of loyalty, personal desert, and political self-interest. The question of the black franchise became associated with the fears of Democrats that a coalition of freedmen and Republicans would dominate the postbellum South.
But this should not surprise us. Politics merely occupies the surface of our lives. The give-and-take of daily conflict can lead us easily to forget both our shared purposes and our enduring principles. The Civil War had ushered in a commitment to the equality of all members of the nation. Whatever the struggle for adoption may have been, the language of egalitarian principle came into force. By 1868, we had in place a clause in the Fourteenth Amendment that was unique in American constitutional history: no state could “deprive any person of the equal protection of the laws.” What this clause would imply in practice, no one quite knew. We did know, however, that the legal idea of equality carried no historical gloss. The Constitution had already spoken of “privileges and immunities”12 and the Bill of Rights, of securing “life, liberty, and property” against deprivation “without due process of law.”13 But the Constitution had never before contained the notion of equality of persons before the law.
The remarkable feature of this ideal-bearing language is that it protects all persons within the power of the state—all those whom the state can touch with its legal power. This was hardly a self-evident way for the provision to be drafted. Given the nationalist background of our sentiments of equality, one could readily have formulated the clause: “No state shall deny to any American citizen within its jurisdiction the equal protection of the laws.” That is, because we were bound together foremost as fellow Americans, one would expect a commitment first to the equal treatment of all Americans. The Weimar Constitution in Germany found this to be a perfectly natural way of formulating the commitment to equality: All Germans are equal before the Law.14 It was not until the postwar Basic Law came to be in 1949 that West Germany recognized that a commitment to equality had to be universal. The provision now reads: All human beings are equal before the Law.15 The striking fact is that Americans came to this principle of universalization as early as 1868.
As the distinguished German constitutional law scholar and philosopher of the Weimar period Gerhard Leibholz pointed out, the Western theory of equality has united two distinct strains of thought.16 The first is the Aristotelian principle, which grounds the virtue of equal treatment in the affective bonds of friendship or, by extrapolation, in the ties of nationhood. The Civil War enabled Americans of different cultural strains, some with power, others without, to see themselves as compatriots of a single nation. Their mutual recognition as partners in a common struggle generated a sense that at least they—the Americans—were created equal.
The second great principle in Leibholz’s egalitarian synthesis stressed the universality of all humans in the love of God. This universalization derives from the biblical faith that all persons are created in the image of God.17 The first is limited and circumscribed by the bonds of affective identification. The second breaks the bonds of the nation and extends to persons unknown and unimagined. We will allow ourselves a slight detour to explore these religious ideas and to understand their impact on the theory of equality as it developed under the Fourteenth Amendment.


The Religious Basis 
of Equality

The abolitionist movement began on the heels of the Second Great Awakening of the first three decades of the century. The country overflowed with the religious pursuit of self-perfection, talk of the millennium—the thousand years of peace before the Second Coming of the Lord—and of the hand of God in human affairs. The American revivalists adopted the Jewish idea that our purpose on earth is to complete and perfect God’s creation. As historian William G. McLoughlin sums up the fervor of the times: “The new consensus also included the belief that Americans are a peculiar race, chosen by God to perfect the world.”18
Many of the preachers of the Awakening supported the abolitionist cause but many others did not. Faith in God and the higher law of revelation enables some people to confront the injustice they see around them; it enables others to retreat and to find solace in their personal quest for salvation. Religious beliefs also supported the cause of those who believed in slavery. Lincoln summed up the ambivalent role of religious faith in the Brothers’ War: “Both [sides] read the same Bible, and pray to the same God; and each invokes His aid against the other.”19
Religious faith hardly lays out a straight path leading to the affirmation of human equality. Yet, it is hardly an accident that many of the great abolitionists such as William Lloyd Garrison and Theodore Parker were ministers whose faith fired their dedicated opposition to the great sin of one man’s owning another. These men carried with them an intimate knowledge of the Bible, yet they did not require a consensus of biblical interpretation to support their political commitments. Frederick Douglass argued that slavery was a sin because by “subjecting one man to the arbitrary control of another, it contravenes the first command of the Decalogue. . . .”20 He was appealing to the basic principles of monotheism. But sophisticated biblical exegesis was unnecessary for those who shared the root intuition that slavery was an abomination. Lincoln thought it obviously wrong for men “to ask a just God’s assistance in wringing their bread from the sweat of other men’s faces.”21 These were strong intuitions of evil, tutored by religious faith but obviously not determined by the Bible.
The religious abolitionists had every reason to be drawn to the Declaration of Independence; there they found the religious inspiration for which they could search in vain in the secular monument called the Constitution. “We hold these truths to be self-evident, that all men are created equal.” Behind those created equal stands a Creator—the source as well of our basic human rights, for the text continues by listing the truths we hold to be self-evident: “that they are endowed by their Creator with certain inalienable rights, that among these are life, liberty and the pursuit of happiness.” This noncommittal Deist theme runs through the rhetoric of 1776. God is mentioned only as “nature’s God,” by virtue of which every people is entitled to “a separate and equal station” in the community of nations. This is the basis for the American people’s claiming that no government may rule them without their consent. The end of the Philadelphia Declaration resonates with another invocation of a higher power: “with a firm reliance on the protection of Divine Providence, we mutually pledge to each other our lives, our fortunes and our sacred honor.”
The religious refrain in the charter of our independence differs radically from the flat, secular tone of the 1787 Constitution, which makes no reference to any of the words, “God,” “Creator,” “Providence,” “divine,” or any of their synonyms. The Constitution recognizes no power higher than the will of “We the People.” Yet, the close bond of religious zeal and American politics returns in the Awakening in the early decades of the nineteenth century, a period leading not only to the abolitionist movement but also to the expression of religious passion in foreign policy, particularly in westward expansion under the ideology of manifest destiny.
The invocation of God in the Gettysburg Address is both accidental and entirely predictable. It is accidental in the sense that Lincoln spontaneously added the divine invocation as he neared the end of the address.22 The innovation was predictable. Lincoln’s association of the nation and God derived from his deepest convictions. He thought of Americans as God’s “almost chosen people,” successors to the Jews in a relationship with the Divine that could be described as “almost a covenant.”23 In the mid-nineteenth century, it was relatively easy to believe that we were in the grip of a great historical force, possibly emanating from a higher power. “IN GOD WE TRUST” became a popular motto, appearing for the first time on the nation’s coinage in 1864. Trust in God can generate diverse conclusions, but this does not subtract from the obvious way in which, at the time, faith in God and the Bible nourished the radical claims of human equality.
For modern readers, those who do not think instinctively in the idiom of Genesis and the Psalms, it is worth reviewing the kind of argument for equality found in biblical sources. The central idea that generates the concept of universal humanity or universal brotherhood is that we are made in the image of God. As the story has come down to us from Genesis 1, 26, and 27:

And God said, Let us make man [Adam] in our own image after our likeness, and let them have dominion over the fish of the sea, over the birds of the air, over all the cattle, and over every creeping thing that creeps on the earth. So God created man in his own image, in his own image He created him, male and female He created them.24

There is much to be said about the proper reading of this passage, particularly in relation to the contrary story of creation in Genesis 2, a story that supposedly justifies the subordination of women. The proper reading of the text, as I have argued elsewhere,25 has God creating a single being, both male and female. God gives this being, called Adam, dominion over all the animals but not over the first woman, yet to be created. Only in the later story of the Garden of Eden do we encounter the curse and subordination of Eve. For those who look to the Bible for guidance, therefore, it makes a tremendous difference whether one relies primarily on the egalitarian message in chapter 1, of ultimate human dignity for all, or on chapter 2, with its story leading to the curse of women that they be “ruled by their husbands.”
That creation in the image of God resonated in the culture of the abolitionists is undeniable; the advocates of emancipation readily read into the line “all men are created equal” the vision of creation set forth in Genesis 1. If you believe that an individual is created in the image of God, it is difficult to deny his or her ultimate worth. There is no higher value than God, and therefore partaking of that value confers upon all human beings ultimate human dignity. This point is brought home in the grounding of the prohibition against homicide in Genesis 9:6:

Whoever sheds man’s blood by man shall his blood be shed;
for in the image of God he made Adam. . . .

The infinite dignity of the potential victim generates an absolute ban on killing. The dignity of the victim is as great as any person who might wish to kill him and, therefore, the homicide of an innocent is never justified. This is a remarkable passage for an era in which the killing of the stranger, the “other,” was a routine occurrence.
The basic ideas of Genesis receive their best secular rendition in the moral philosophy of Immanuel Kant, who takes the idea of creation in the image of God and bequeaths to us the idea of universal humanity. We are all essentially alike as members of the human family. We all partake of infinite human dignity:

In the kingdom of ends everything has either value or dignity. Whatever has a value can be replaced by something else which is equivalent; whatever, on the other hand, is above all value, and therefore admits of no equivalent, has a dignity.26

The idea of human dignity, which we now take to be a shared premise of Western civilization, became the backdrop for our current faith in human rights and crimes against humanity.
The Fourteenth Amendment is our placeholder in the evolution of egalitarian thinking. We know very little about how much equality the framers of the amendment intended to secure, and frankly it does not matter. Each generation must struggle to assay how far they are willing to go in the name of egalitarian justice or, by contrast, how far they wish to surrender to the surviving counter-values of hierarchy. In the aftermath of the Civil War it was clear, ironically, that black men were far ahead of white women in ascending the scale of egalitarian possibilities. Black men acquired, at least nominally, both the right to vote and the right to serve on juries. White women and black women alike would acquire neither until well into the twentieth century.
Some might argue that because the United States lagged in recognizing equal legal rights for women, the mood of 1863 would have been hostile to recognizing that women as well as men were equal in the sight of God.27 When Lincoln said, “All men are created equal,” therefore, he meant men—only males were equal in the sight of the Creator. This objection is easily countered. Lincoln explicitly invoked the figures of women in his discourse on human dignity. In 1857, in his speech attacking the Dred Scott decision, Lincoln explicitly refers to the dignity and inherent equality of black women:

In some respects she certainly is not my equal; but in her natural right to eat the bread she earns with her own hands without asking leave of any one else, she is my equal, and the equal of others.28

Even if the textual evidence were silent, however, we would have to interpret “all men are created equal” as inclusive of all human beings—all variations of women, men, and children. This inclusiveness follows from anchoring the great maxim in the idea that human beings were created in the image of God: “So God created man in God’s own image, in the image of God created God it, the first being, male and female God created them.”29 (I recognize that one reading of the biblical text, widely accepted in various religious traditions, holds that God did create a male Adam in his own image and later removed a rib to create Eve.)
Recognizing the inherent moral equality of women in 1863 did not mean, however, that they would receive full legal and political equality as did black men. The notion of “appropriate roles in life” still governed relations among equals and it would take decades for Americans to grasp that the politics of equality can not brook the coercion of women into domestic, apolitical roles, nor could some misguided theory of social organization tolerate the relegation of blacks to a limited number of lower-status professions.
Human Dignity as a 
Placeholder for Equality

One basic value remains curiously absent from those enthroned in the postbellum legal order. The movement to redeem ourselves from the evil of slavery should have prompted a commitment to a value even more basic than equality: the infinite human value of all human beings. In the wake of the Holocaust, the Germans recognized that this was the proper way to initiate the catalogue of basic rights in the 1949 Basic Law (Constitution): “Human dignity is inviolable. All state power is obligated both to protect this value and to respect it.”30 This provision clearly bears the imprint of Kantian moral philosophy, which treats respect for human dignity as an absolute duty of all individuals, including officers of the state.31
The structure of Article I of the German Basic Law bears a striking resemblance to the Thirteenth Amendment, which in its core provides: “Neither slavery nor involuntary servitude shall exist within the United States.” If we think of the prohibition against slavery and involuntary servitude as an affirmation of autonomy, then the passive sentence of the Thirteenth Amendment could be rewritten, without change of content, in the form of the German Basic Law:

Human dignity and autonomy are inviolable. All state power is obligated both to protect and respect autonomy, by eliminating slavery and involuntary servitude.

This would, admittedly, be an unconventional way of formulating the demands of the Thirteenth Amendment. The usual commentary on the amendment stresses simply that it omits the requirement of action by state officials that we find in the Bill of Rights and in the Fourteenth and Fifteenth Amendments. Yet, it is clear that the postbellum order sought to declare a fundamental value as the symbol of the new United States. The motive was similar to the impulse of the German drafters seeking to ground their postwar constitution in the humanistic values of human dignity. There may be intriguing and important differences between human dignity and autonomy, and we shall return to these later. For now, it is important to note merely that the postbellum legal order begins with a commitment of all state power to eliminate the evil that had cursed the United States since its founding.
Significantly, both human dignity and autonomy, both due process and equality, transcend the limits of the nation. It is not only our nationals who are entitled to these basic human rights. All human beings, all persons, should enjoy the same rights—at least so far as they are within the jurisdiction of the state securing those rights. Our commitment to nationhood generates the reciprocal sympathy that enables us to make the move from particular to universal. We may come to understand the meaning of basic rights in the context of the nation but then we are driven to see that all persons, whether members of the nation or not, are entitled to the same treatment.


Alternative Readings

Not everyone agrees that the equality of all persons represents the moral breakthrough of the Fourteenth Amendment. In an alternative version of the postbellum legal order, also based on the value of nationhood, Charles Black stresses the reliance on national citizenship in the first sentence of the Fourteenth Amendment: “All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.” Membership in the nation is now defined by birth on the land, and the fact of nationality, legally recognized as citizenship, generates the most basic right of the new legal order. Black reasons that the amendment places citizenship at the center of the new constitutional order. “No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States.” The centerpiece of the new order, therefore, should have been citizenship and the elaboration of the “privileges and immunities” of citizenship.
The appeal of Black’s reading of the postbellum legal order is that it, too, draws on the Declaration of Independence and the Gettysburg Address. The key phrase in his reading of the Declaration is not the commitment to equality but the clause immediately following: “that they are endowed by their Creator with certain inalienable rights, that among these are life, liberty and the pursuit of happiness.” Black imagines these words coupled with the language of the Ninth Amendment, which implies an unspecified catalogue of rights “retained by the people.” These “inalienable rights” should express themselves in a catalogue of human rights, including the right to sexual privacy, to reproductive freedom, and to governmental services necessary for the “pursuit of happiness.”32 The latter might plausibly encompass education, medical care, a minimal standard of welfare, and perhaps even guaranteed employment.
There is much to be said for Black’s interpretation of the constitutional text. He brings together strands of our legal culture that until his writing seemed to lack internal coherence. He grounds his argument in the familiar rhetoric of rights. He builds his interpretation on critical planks of the postbellum legal order, namely the ideas of nationhood and national citizenship. Yet, the content of his argument reverts back to the language of rights, inalienable rights, rights retained by the people. He invokes the rhetoric we associate with our eighteenth century Constitution enthroning freedom over equality. True, as the title of Black’s book reminds us, Lincoln’s address does rely on one phrase to establish a link with the old legal order: A New Birth of Freedom. Yet, Black ignores the cardinal values of equality and democracy, which, along with nationhood, represent the cornerstones of the postbellum legal order.
Taking the “privileges and immunities” of citizens as the pivotal value of the new order, as Black does, creates its own problems of equality under law. Why should only citizens and not resident aliens enjoy the inalienable rights of “life, liberty and the pursuit of happiness?” Do not immigrants and even undocumented illegals have rights as human beings? The universalist language of the Declaration of Independence hardly dovetails with the parochial category of citizenship in a particular governmental polity. If all men are created equal, if we are endowed by our Creator with certain inalienable rights, it cannot be the case that these rights are limited to those who are classified as the subjects of a particular sovereign.
To be sure, the Reconstruction Amendments had to define citizenship in the United States, at least to heal the divisive scars left by the Dred Scott decision. That infamous act of judicial will, which served only to fuel the passions for war, held that a former slave could never become the citizen of any state. That is why the amendment adds that citizens of the United States are citizens also “of the State wherein they reside.” They could avail themselves, therefore, of a body of law already developed to secure the mutual recognition of the states of “all Privileges and Immunities” of citizens in sister states.33 As history would have it, however, the “privileges and immunities” clause of the Fourteenth Amendment has not had—at least until recently—any impact on constitutional debates.34 The language has lain latent in the text of the Fourteenth Amendment. Whether it will find a suitable purpose in a constitutional scheme built on equality and due process remains to be seen.
Black pursues the theme of freedom and ignores the phrase that in fact requires emphasis in reading Lincoln: a new birth of freedom. The redemption and renaissance of our country would become possible only by confronting our “offences,” and that meant recognizing and compensating for the evil of slavery. The issue that could stimulate a new birth of the nation, therefore, was not freedom itself but freedom tempered by equality before the law.
Yet, there is reason to applaud Black’s reading of our history, as there is to honor the divergent views found in Bruce Ackerman’s and in Akhil Amar’s writings. Ackerman focuses on the de facto transformation of government wrought by the Fourteenth Amendment, enacted by a rump Congress in violation of the express language of the Constitution.35 Amar, too, reads the history in his own way. The postbellum legal order, in his view, shifts our focus from rights that enable us to participate in government to rights that celebrate individual freedom.36 May all these readings flourish. They testify to the innate multiplicity of meanings inherent in the second founding of the United States in the postbellum legal order. Our only problem, then as now, is that we are not sure which way the revolutionary refounding of the nation should go.


The Cusp of Revolution

By 1868 and the enactment of the Fourteenth Amendment, we were perched on the threshold of a constitutional revolution. An entirely new legal order was yearning to work its way clear from the turmoil of the 1860s. The foundation of this new order was painted bold in the phrases that resounded at Gettysburg: nationhood, equality, and democracy. The mechanism for implementing these exhortations would be the new grant of congressional authority in the final clause of the new amendments: “The Congress shall have power to enforce, by appropriate legislation, the provisions of [these articles].” A more powerful central government was a critical part of the new constitutional order. This would be a government that would raise income taxes, as it started to do during the war. This government would enact welfare legislation to care for the widows and orphans of the war. And, most important, it would be a government that would have the capacity to supervise private relationships. The Constitution was no longer focused just on the individual struggling to secure his freedom against the government. The government would have an active role in protecting and securing the autonomy of its citizens. As my rewriting of the Thirteenth Amendment would have it: Securing and protecting the autonomy of labor would become the duty of all state power. Government would have to keep a vigilant watch on all labor transactions to insure that there never again would arise relationships bordering on slavery or involuntary servitude.
In 1866, Congress began to act on its responsibility to guard against the aftershocks of slavery by prohibiting discrimination in all facilities open to the public. African Americans were part of the public, and they should be entitled, as a matter of equality with others, to have access to public transport, theaters, and hotel accommodations. The first Civil Rights Act, therefore, would seek, in the later words of Justice Harlan, to eliminate “the badges of slavery.”37
The commitment, first and foremost, of the new constitutional order was to the equality of all persons affected by the laws of the United States. No one knew how far our collective promise to realize equality in American life would take us. The Fourteenth Amendment could conceivably have been sufficient to insure equal voting rights for all, doing away with the need for the Fifteenth, the Nineteenth, and later amendments to secure the franchise.
With these ideals in place, we have to recognize that the guns of war had stilled very few of our fundamental social conflicts. The rough and tumble of postbellum politics pitted one segment of the nation against the other. The freedmen could aspire to power in the region where they previously had been slaves. Northern carpetbaggers could join forces with Southern scalawags to remake the agricultural South in the image of the industrial North. At stake was the class structure of the South with its landed gentry commanding a servile class of laborers. Behind the political conflicts, however, was a remaking of the American conception of government. And the states would fight by any legal means necessary to realize the position they could not secure with their sacrifices on the battlefields of recent memory.
If war, in the famous saying of Clausewitz, represents a continuation of politics by other means,38 then postbellum legal disputes stood for a continuation of war by other means. All the disputes that eventually led to armed conflict between the states would begin, in the period after 1865, to plague the courts and throw into question the values that the war should have secured. States’ rights, the holding of blacks in a form of servitude called segregation, withholding the franchise from women—all of these would remain central issues for at least another hundred years.









With his carefully crafted two-minute speech at Gettysburg, the best political address in the nation’s history, Lincoln created a Nomos, a world of norms and meaning, for comprehending the mass slaughter on American soil. The new understanding of why we were in mourning pointed to a resolution of the conflict and the beginnings of a new constitutional order. Rereading the speech now as the preamble to that new order, we can begin to understand the significance of the phrases so carefully chosen. The words of the Gettysburg Address are too powerful, they represent too much concentrated energy and wisdom, to be absorbed in the two minutes that it takes to read them slowly. I suggest that we proceed and listen, sentence by sentence, phrase by phrase, to these words heard so often.
The first sentence states the heart of the matter and sums up the past, present, and future of the American commitment. Four score and seven years ago our fathers brought forth on this continent a new nation, conceived in liberty and dedicated to the proposition that all men are created equal. This sentence alone was enough to formulate the preamble to the new constitution. It harbingers the themes that follow in the address and that will come to dominate American life for the rest of the 1860s. Let us read each of these phrases as elements in the preamble to the postbellum constitutional order.
Four score and seven years ago. . . By 1863, a historical consciousness had taken hold in American thinking. Rooting ourselves in the past stands in sharp contrast to the preamble of the 1787 Constitution, which begins simply, without setting the context: “We the people of the United States, in order to form a more perfect Union. . . .” There is no reference in the 1787 document to the first settlement dating back some 160 years, no sense that the new country was the outgrowth of an English-speaking culture across the seas. In 1863 the nation still desired to create “a more perfect Union,” but it had in addition a past that both inspired and troubled the newly indigenous psyche.
The particular past that Lincoln cultivates retains its ability to surprise and to make us take notice. One would expect the president to root his address in the Constitution that created his office, but the great address is defiantly silent about the initial Constitution. As the 1787 document was silent about its great embarrassment, slavery, Lincoln passes over a national charter that carried within it the seeds of war. In this preamble for a new order, the original Constitution is nowhere mentioned. Lincoln locates the birth of the nation four score and seven (eighty-seven) years prior to 1863. Until you do the arithmetic, you do not realize that, in Lincoln’s mind, the critical moment of the founding was 1776, the signing of the Declaration of Independence. For those who knew Lincoln well, this might not have been a surprise, for he had said two years before: “I never had a feeling politically that did not spring from the sentiments embodied in the Declaration of Independence.”1
The historical retreat to the Declaration of Independence left Lincoln with a major paradox. He claims to be speaking as president, and his office owed its existence to Article II of the Constitution of 1787. Yet, he thought himself back prior to the Philadelphia convention and the creation of the presidency. He pulled the rug of legitimacy out from under his own office. To be able to advocate the principle that all men are created equal, that a nation was born committed to this principle, he had to speak from a time prior to the creation of the government for which the Union troops died.
The precursor to this unusual mode of dating comes in an unexpected place—in the final paragraph of the Emancipation Proclamation, which went into effect on January 1, 1863:
Done at the City of Washington, this first day of
January, in the year of our Lord one thousand eight
hundred and sixty three, and of the Independence of the
United States of America the eighty-seventh.
By the President: ABRAHAM LINCOLN

It did not occur to Lincoln that there might be some dissonance between his relying on 1776 as the beginning of the American nation and his acting in an office constituted by a document drafted in 1787. When he returned to the same figure of eighty-seven years in November of the same year, he meant to stress the continuity of the nation. In Lincoln’s vision, the men who died at Gettysburg gave their lives not for a government, not for a constitution, but to realize the peculiarly American blend of nationhood and a set of ideas, particularly the idea that the nation was “conceived in freedom.” There might be some disagreement about the moment of national coalescing, but to be sure, the nation was at war by 1775. A year later, American patriots exposed themselves to great risk by appearing to have committed treason. It is with some appropriate fear of reprisal that they conclude the Declaration of Independence: “We mutually pledge to each other our lives, our fortunes and our sacred honor.”
Lincoln’s posture toward the 1787 Constitution was less than reverent. He treated the founding charter of the government more as a guideline to action than as a set of absolute restrictions on his actions. His decisions, particularly in the early stages of the war, suggest a willingness to assert extraconstitutional executive power and, thus, to permit the exigencies of war to restructure the government. In April 1861, in the immediate shadow of the shelling of Fort Sumter, he declared a blockade on Southern ports. Whether the Union forces could properly seize ships without congressional approval became one of the early legal controversies of the war.2 And then came the dispute about Lincoln’s authorizing his generals in the field to suspend the writ of habeas corpus—the great writ by which the courts retain the power to supervise the arrest and detention of criminal suspects. The Constitution permits suspension of this protection in times of civil unrest—but fails to specify whether the president may act unilaterally in ordering suspension. Sitting alone as a circuit judge, Chief Justice Taney interpreted the constitutional provision to require congressional authorization for suspending the writ.3 In light of Taney’s notorious opinion in the Dred Scott case,4 his views hardly carried much weight in the White House. In a move widely regarded as authoritarian, Lincoln simply disregarded Taney’s opinion. Lincoln justified his unilateral action with a famous claim of necessity, articulated in a message to Congress on July 4, 1861:

The whole of the laws which were required to be faithfully executed were being resisted . . . in nearly one third of the States. Must they be allowed to finally fail of execution, even had it been perfectly clear that by the use of the means necessary to their execution some single law, made in such extreme tenderness of the citizen’s liberty that, practically, it relieves more of the guilty than of the innocent, should to a very limited extent be violated? . . . Are all the laws but one to go unexecuted, and the government itself go to pieces lest that one be violated?5

Read with our current sensitivity to civil liberties, these are embarrassing words. Lincoln argues, in effect, that he can justify violating a constitutional prescription by appealing to the necessity of the moment. Of course, if the stark option were posed—violating this “one law” or letting the government “go to pieces”—most of us would agree that the government should survive the emergency, even by transgressing the Constitution. Yet, there is no evidence that the country’s circumstances were anywhere near this flashpoint of imminent destruction. And Lincoln’s casual disdain for the writ of habeas corpus (“it relieves more of the guilty than of the innocent”) reveals a lack of appreciation for the point of constitutional protections in criminal procedure. My own reading is that Lincoln’s suspending the writ on his own initiative and disregarding Taney’s supposed invalidation of the decision testifies to an altered state of constitutional thinking. The Constitution of 1787 lay suspended in the fires of battle. A new constitutional order would arise from the war, but no one quite knew what shape it would take.
Of course, during the war, the 1787 Constitution remained nominally in force. There was little suggestion of a “military dictatorship,” though some Northern critics of the government invoked the phrase. Lincoln’s elected term came to an end in March 1865. In the midst of the war, therefore, he was constitutionally required to stand for reelection. This event in itself warranted the stability of American institutions, but still ambiguity reigned on the shape of the postbellum constitutional order. The confusion came to a head in 1868 when the House impeached Lincoln’s successor, President Andrew Johnson, for arguably asserting excessive executive power in firing his Secretary of War Edwin Stanton. The outcome of that impeachment trial is well known: Johnson avoided conviction by one vote. Less well known is the outcome of the struggle to develop a new constitutional order, the struggle that is signaled in Lincoln’s address commemorating the dead at Gettysburg.
. . . our fathers brought forth on this continent. . . The biblical cadence of these words resonates in memory. We know that we have encountered it someplace before. They remind us of the way God introduces himself to Moses in the Book of Exodus: “I am the God of your father . . . So I have come down to rescue [my people] from the hand of Egypt, to bring it up from that land to a land, goodly and spacious, to a land flowing with milk and honey. . . .” It is not surprising that Lincoln would evoke the style of Exodus. Even the introductory phrase “four score and seven” has a prophetic ring. The Bible, after all, was one of Lincoln’s favorite books—along with the works of Shakespeare and Aesop’s Fables.
Garry Wills makes much of the Greek influence in shaping Lincoln’s style at Gettysburg.6 But of the biblical influence on the Gettysburg Address, Wills has almost nothing to say. This is a rather curious twist in seeking to understand the president whose thinking and rhetoric were probably more influenced by the biblical idiom than the writings of any other president. Lincoln’s second inaugural address is replete with references to the Bible, including, notably, the latter part of Psalm 19, 10: “The fear of the Lord is clean, enduring forever; the judgments of the Lord are true and righteous altogether.” Lincoln saw the entire Civil War as a righteous judgment of the Divine. It is almost inconceivable that he would seek to formulate a framework for understanding the war’s place in American history without relying on biblical imagery.
Of all the biblical themes that shaped Lincoln’s thinking, the Hebrews’ Exodus from Egypt was the most compelling. In a speech he gave in Trenton, New Jersey in 1861, he referred to the American people as “His almost chosen people.” The “His” refers, of course, to God. The Americans stand, one almost dares to say, in the place of the Jews in a covenantal relationship with God. The idea that some institution or some people replaced the Jews in their covenantal relationship was a familiar Christian theme. The Pilgrims brought the idea with them as they founded their first settlements. Now Lincoln comes close to repeating the Puritan idea. This accounts, I believe, for the apparent redundancy in “brought forth on this continent.” His audience would surely have understood that Lincoln was talking about the United States “four score and seven years ago” without locating the events “on this continent.” But this continent was the locus of the new covenant. The Pilgrims had made a journey to a new land, and the new land promised a partnership with God that was not possible without an exodus from the old world. The single word “continent,” reminding us of the journey, invokes an entire theology.
We should remember that although the Declaration of Independence overflows with references to the Creator and the imprint of the Divine in American destiny, the Constitution of 1787 is a totally secular document. In style as well as substance, Lincoln returns to the religiosity of the 1776 Declaration.
. . . brought forth on this continent a new nation. . . The use of the word “nation” signals a major theme of the address. In the remaining 252 words, it will appear four more times.7 By accentuating the term “nation,” Lincoln sets himself at odds with the first preamble’s invocation of “We the People” as the source of all legitimacy. Now, in place of the people appears the nation, a term that with its connection to birth (nasci, Latin for “to be born”) suggests a conception of the American people that extends over generations—reaching back to the founding eighty-seven years before and encompassing those who will survive the war and flourish in its aftermath.
“We the People” are sovereign in every generation. A single cohort can found a constitution and another can presumably decide to withdraw from the commitment. Thus some scholars have argued that the people of every generation retain the authority both to transform the Constitution or, if they so choose, to repeal it entirely.8 I disagree. If the American people are understood as a nation including the dead and the unborn, then no single generation can undo the work of the past or renege on its implicit promise to the future. There is no way that those who happened to be alive in the 1860s could overrule the confirmation by preceding generations of the American union. Thus, by extending themselves out over history, Americans became a nation in the European sense, in the same sense as had already been realized in England and in France and was then making itself felt in the unification movements in Italy and Germany.
The mid-nineteenth century was a time in which the nations of the West, tracing their lineage to common linguistic and historical roots, built political movements grounded in a shared national identity. In the same year that the Civil War broke out, Italy’s Risorgimento, or nationalist awakening, entered its critical phase. Thanks to the political leadership of Camillo Benso di Cavour in the north and the military prowess of Giuseppe Garibaldi in the south, Italy achieved a unification of diverse states, including Piedmont, Sicily, the papal states, and Sardinia. Victor Emmanuel II of Sardinia became the first king of the united nation. In 1871, by a combination of military annexation, diplomacy and bribery, Otto von Bismarck was able to unify the northern and southern German states in the Imperial Reich, with Prussia as its central power. There followed, in the same year, the enactment of the first pan-German criminal code.
This process of unifying the European nations and, at the same time, establishing a state to govern the nation had given us the idea of the nation-state. The nation as a prepolitical reality finds its embodiment in the apparatus of state power. The traditional view is that the United States was different, that Americans were not a nation in the European sense. I beg to differ.
My claim is that Lincoln’s address expresses the same idea that was then current in Europe. Each people of common history and language constitutes a nation, and the natural form for the nation’s survival was in a state structure. The idea that Americans constituted an organic national unit explained, implicitly, why the eleven Southern states could not go their own way. As he assumed the presidency, Lincoln still spoke of the Union rather than a nation; but in the course of the debates in the decades immediately preceding, the notion of union had acquired the metaphysical qualities of nationhood. In his first inaugural address, Lincoln invoked the “bonds of affection,” and even before shots were fired on Fort Sumter in Charleston Harbor, he stressed the unbreakable ties of historical struggle:

The mystical chords of memory, stretching from every battlefield, and patriot grate, to every living heart and hearth-stone, all over this broad land, will yet swell the chorus of the Union. . . .
The nation was bound together by historical experience and by its destiny, its “manifest destiny,” in the phrase used to explain the push westward that occurred in the decades leading up to the Civil War.
Lincoln’s purpose on November 19, 1863, was not to intensify but to transcend the war effort. Significantly, the “nation” of which he speaks includes the South as well as the North. He was speaking at the dedication of a Union cemetery, but there is hardly a partisan word to be heard in the entire address.9
My sense of the literature of American history is that our scholars not only ignore the biblical influences on Lincoln’s thinking at Gettysburg but also fail to understand the significance of the “nation” that “our fathers brought forth on this continent.” The common mistake, particularly of lawyers, is to read the “nation” in this context as equivalent to the national government, as opposed to states, or to the national territory as opposed to local geographical units. In this limited sense, the “nation” is constituted by a federal government in Washington or by a physical space staked out on maps and recognized by other countries. The nation is then equivalent to the Union or the federal government. But the issue is not the authority of the “national” government in contrast to states’ rights. The derivative sense of nationhood as denoting “unified at a federal level” is surely present as a subsidiary meaning in Lincoln’s invocation of the term, but this could not possibly be all that he meant to say.
The American nation, as it existed in 1863, was a nation in the European sense. The assumption that drove the movements of national unification on the continent was that each nation should be able to govern itself. And self-government requires that each nation should be able to constitute itself as a state. If this was the thrust of mid-century European history, the same was to be expected of the immigrant nation of the United States.
. . . a new nation, conceived in liberty and dedicated to the proposition that all men are created equal. Thus ends the remarkable first sentence of the address. The nation of which we speak is immediately qualified. This is not simply a nation of common lineage—an extension of tribal identity. We are indeed different from the European nations, for our nation is born of an idea. It is conceived in liberty and dedicated to an aspiration of equality.
What exactly does it mean to be “conceived in liberty?” This phrase is so redolent with meaning that we simply savor it without reflection. Does it mean that the nation is conceived free, as if it were in a state of nature? Is it only after its conception that the nation binds itself by the strictures of government? It could mean these things. Or it could simply mean that our first constitutional commitment was to freedom, which, as we shall see, was certainly true. Yet, somehow the glorification of freedom of speech, freedom of religion, the right to bear arms—among the freedoms sanctified in the Bill of Rights—fails to capture the measure of being “conceived in liberty.” Our liberty persists as our birthright, even as we search for the proper way to build a democratic nation of equal citizens.
A stylistic point should intrigue us. It is hardly an accident that in this phrase “conceived in liberty,” Lincoln chose the Latin-based “liberty” rather than the Germanic “freedom.” “Conceived in freedom” might have had roughly the same meaning, but it would have lacked the lyrical ring. The reason, I believe, is that both “conceived” and “liberty” derive from Latin as opposed to Germanic sources. We return to this point later in the address, when Lincoln links “freedom” rather than “liberty” with the image of a new birth.
What, then, is the relationship between liberty and equality in Lincoln’s vision of a new order? We are conceived in liberty and dedicated to the proposition of human equality. That was the way it was then, and it is the way it is now. The realization of equality in practical affairs will always elude us. Even after this aspiration was incorporated into the Fourteenth Amendment, the ideal of equality remained a distant point on the spectrum of political possibilities. Eventually, women would be rendered politically equal and receive the franchise; eventually, the schools would be integrated and the laws against mixed marriages would, with a sense of shame that they ever existed, be struck down. None of this was obvious in 1863 or 1868 or even in 1900. Yet, the commitment Lincoln made at Gettysburg—all men and women, as individuals, are created equal—became a moral lodestar testifying to the equal dignity of all human beings, whether the legal culture had validated that equality or not.
Implicit in this structure—conceived in one value, dedicated to another—lies a conception of an ordered legal culture. Some values are stated in rules that are capable of immediate realization; others are stated as principles of aspiration. The latter are ideals to be pursued, opportunities for self-improvement. Liberty is a given. Equality remains the promise.
Some stylists have objected to Lincoln’s labeling the great maxim of the Declaration of Independence as a “proposition.” Encountering this word in the first sentence, the great English poet Matthew Arnold reportedly stopped reading in literary disgust.10 “Proposition” was too legalistic for his taste. But it was critical for Lincoln to restate his understanding of the Declaration’s vision of equality. As he said in his Springfield speech in June 1857:

They [framers of the Declaration] meant simply to declare the right, so that the enforcement of it might follow as fast as circumstances should permit. They meant to set up a standard maxim for a free society, which should be familiar to all, and revered by all, constantly looked to, constantly labored for, and even though never perfectly attained, constantly approximated, and thereby constantly spreading and deepening its influence. . . .


Immediately following the victory in Gettysburg, in an informal talk at the White House on July 4, 1863, Lincoln began the process of looking to and reiterating the “standard maxim” of 1776. Thinking of equality as a “proposition” gives it a reality, an ontological presence in our lives, not quite captured by alternative terms like “ideal” or “vision.” We are conceived in one value and live anchored to another proposition, not yet instantiated in our daily practices.
In structural terms, this means that the Constitution of 1787 and, notably, the Bill of Rights represent the baseline. They enshrine the liberty in which we are conceived. But the ideals toward which we yearn are incorporated in a charter morally superior to the Constitution, namely the Declaration of 1776. The Declaration served both as a legal brief for the War of Independence and as the standard for criticizing the compromise represented by the Constitution of 1787. The freedom achieved in the war against the English necessitated another war in 1861 to redeem us from tolerating the South’s “peculiar institution.”11
In this magisterial first sentence of the Gettysburg Address, there lurks ammunition for both sides in the great conflict that surrounded the calm of November 19, 1863. The forces of the Union could draw sustenance, as I have suggested, from the reconceptualization of the American people as an organic nation. But so far as the address also validates the case for separation from England, it also provides an argument for secession from the Union. What, after all, was the difference between America’s seceding from England and the South’s leaving the Union? The Confederate loyalists could well argue that as their grandfathers had consented to the Union, they were entitled to withdraw their consent. They as a group were equal to the people of the North, and, therefore, they could choose which form of the social contract would work for them.
We sometimes forget the context in the Declaration of Independence in which we find the phrase: All men are created equal. The claim of equality prepares the reader for the more important thesis that all men, as equals, possess certain inalienable rights, “that among these are life, liberty and the pursuit of happiness.” The purpose of government is to secure these rights. The people consent to government as their agent to realize these ends. But if “any form of government” should be perceived as “destructive” toward these ends, then the people that originally gave their consent are entitled to withdraw it. They are entitled to “alter or abolish” a government that departs radically from the one to which had given their consent. It follows, supposedly, that the colonists were entitled to withdraw their consent to the government of King George III.
When fully stated in this fashion, the argument of 1776 invites several observations. First, the colonists never officially gave their consent to the government of George III. They grew up under the tutelage of the English monarchy and their adhering to the government of the Crown was something like a child’s joining its family. The most that one could say is that they never consented and that therefore when they matured and reached the age of consent they were entitled to say no. By contrast, the Confederate states did join the Union by signing the Declaration of Independence as states and ratifying the Constitution as states. If they gave their consent to a form of government, they—by the logic of 1776—should be able to withdraw from the pact. Paradoxically, it seems, the logic of the Declaration of Independence applies more cogently to the claim of the Confederacy against the Union than to the arguments of the Americans against the British.
Note further that in the structure of the argument, the premise of equality plays a curious role. All men are created equal. So what? How does that strengthen the case against the Crown? The cornerstone of that case is that governments derive their legitimacy from the consent of their governed. If a people has not consented to their form of government, the government is not legitimate. This would be true even if within the society, human beings were not all of equal dignity and status. Whether some people were intrinsically superior to others or not, they could all enjoy a collective right to withhold consent from a repressive regime.
What, then, is the point of the Declaration’s claim that all men are created equal? The answer is twofold. First, there is an implicit claim that as a people the Americans are equal to the British and to all other peoples. If any people should be able to consent to their government, then the Americans, too, enjoyed that fundamental right. That they were a colony—nurtured as the metaphoric child of the Crown—did not mean that they could not assume the posture of an equal people. If this is the meaning of equality in the Declaration, then it provides little support for Lincoln’s claim that the nation was dedicated to a proposition that implicitly required the abolition of slavery.
A more compelling reading of “All men are created equal” would be that all human beings are equal among themselves as well as being equal as collective entities. They are equal among themselves precisely in that they possess inalienable rights—the same inalienable rights to “life, liberty, and the pursuit of happiness” possessed by everyone else. Reading the document in this way enables us better to understand Lincoln’s posture toward abolition. There is ample evidence that Lincoln regarded blacks as morally and socially inferior to whites. He said so in numerous speeches in the 1850s. But despite these “racist” assumptions that were common to his time, he fervently regarded slavery as an evil. It was an evil precisely because it deprived blacks of their inalienable rights to life, liberty, and the pursuit of happiness. They could not enjoy the fruit of their own labor. Slavery was a system under which slaveholders were “wringing their bread from the sweat of other men’s faces.”12
The nation is born dedicated to this proposition that all men are equal with regard to their basic human rights. This idea is extracted from the Declaration of Independence, but the rest of its argument is discarded as outdated. There is no mention at Gettysburg of the requirement that the people consent to their government and that they should have the right to withdraw consent when unsatisfied. Nor, in light of the argument’s utility to the Confederacy, would Lincoln have acceded to the language of 1776. He would have little reason to argue that every generation had the right to consent or withhold consent to its government. Now the nation was in place, and the nation made claims across time. No particular generation could undo the work laid so carefully in the past.
The address continues with a second sentence that locates us in the present. Now we are engaged in a great Civil War, testing whether that nation or any nation so conceived and so dedicated can long endure. Thus begins the internal portion of the address, which is devoted to the war and its dead. Lincoln repeats the conventional label for the four-year indulgence in bloodletting—the “civil” war. The word has the connotation of the private or domestic (Code civil) or of a phenomenon arising spontaneously up from the citizenry (civil society). The South preferred the expression the “War between the States,” by which they hoped for recognition that the war was more than a rebellion and that the Confederacy had full legal status as a belligerent under international law. Lincoln’s choice of the favored Northern expression is his only partisan word in the address.
I prefer the unconventional label: “The War between Brothers” or the “Brothers’ War.” That is indeed what it was. Brothers met and fought each other in the field. But even more significant, the slaying of 620,000 men should be understood as an offering on the altar of fraternity. For every seven slaves who were liberated, at least one man had to die. They gave their lives so that the nation “might endure.” Significantly, in this sentence, Lincoln repeats the claim of nationhood and stresses that the great evil of the war is not that it threatens the federal government, the Constitution, or the Union. The great danger is that the Civil War threatens the survival of the nation. The nation, of course, includes both sides in the conflict.
This conception of a single American nation accounts for Lincoln’s religious language in his second inaugural address delivered, as victory seemed near, on March 4, 1865. Here Lincoln thinks of North and South as bound together in their religious devotion: “Both read the same Bible, and pray to the same God; and each invokes His aid against the other. . . . The prayers of both could not be answered.” The massive bloodletting of the four-year war is seen as a divine response to evil in the American founding.
The Almighty has his own purposes. “Woe unto the world because of offences! For it must needs be that offences come; but woe to that man by whom the offence cometh!” The terrible war is seen as a “woe” and a “scourge” inflicted for the terrible “offence” of slavery. The offense was committed by all—those who were active and those who were passive. The nation suffered punishment for its collective sin. But it could return to normalcy with the same sense of collective compassion, and thus Lincoln extends his hand: “With malice toward none, with charity for all; with firmness in the right, as God gives us to see the right.” The president ends his second inaugural address in the expectation of peaceful reconstruction and with a gesture of solidarity toward the widows and other victims of the killing fields.
The policy of “malice toward none, charity toward all” is anticipated in the affirmation at Gettysburg of a single nation enduring, as it were, a calamity imposed for its sins. Yet, there was a deep contradiction between this charity expressed toward the enemy and the military objectives that were becoming obvious in the fall of 1863. In order to achieve the newly set goal of emancipation, to achieve the end that in 1865 he calls the “right, as God gives us to see the right,” Lincoln would send his generals to wage total war against the civilian population. Philip Sheridan’s destruction of the Shenandoah crops, William Tecumseh Sherman’s conquest of Atlanta, and then his march to the Atlantic all anticipate the terror that became commonplace some eighty years later in the bombings of Hiroshima and Dresden. From Gettysburg to Appomattox, Lincoln will maintain a political policy of charity and reconciliation, coupled with a military posture that would leave no doubts about the right in the minds of the defeated.
The choice of the words “Civil War” to describe the conflict also expresses charity toward the rebellious Confederacy. They are not treated as criminals attacking federal installations and killing federal troops. Rather they are in a joint effort with their fellow countrymen to determine the future of the nation.
There follow seven sentences in which Lincoln ties together the mourning of the moment with our commitment to higher ideals:

We are met on a great battle-field of that war.
We have come to dedicate a portion of that field as a final resting place for those who here gave their lives that that nation might live.
It is altogether fitting and proper that we should do this.
But in a larger sense, we cannot dedicate—we cannot consecrate—we cannot hallow this ground.
The brave men, living and dead, who struggled here have consecrated it far above our poor power to add or detract.
The world will little note nor long remember what we say here, but it can never forget what they did here.
It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced.
It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain. . . .

Let us leave this sentence in the middle and reserve the final peroration for a closer look. Here, in the heart of the address, it becomes clear that the key themes of the preamble for the postbellum legal order are three: nation, death, and dedication. And the three ideas conveyed by these words are intimately connected. The notion of the nation and the fact of death root us in the past. These are irreversible facts. The nation is born of history; the dead link us to time past. The fantasies of power, the aspirations of “We the People” cannot undo the defining power of history. The nation is implanted in time, and the dead are interred in the plots that lie before the speaker’s dais. Yet, the dead can live, and the nation can live, if these shadows of the past are transformed into memory, and memory is nourished by dedication to the values that define the nation.
Lincoln remains ambiguous about the “great task” to which we should be dedicated so that “these dead shall not have died in vain.” The long-range objective is the redemption of the nation from its “offences”—from its original sin of having tolerated entrenched inequality in the very framework of its original Constitution. The immediate task is finishing the war and reuniting the nation. We are not informed of the task that matters until the concluding two clauses of the address: that this nation, under God, shall have a new birth of freedom, and that government of the people, by the people, for the people shall not perish from the earth. Along with the first sentence, these words have taken on a nearly sacred quality in America’s conception of itself and its mission in the world. They retrace the three themes of nation, death, and dedication. The “nation” is present, now in conjunction with God. The nation shall defeat “death:” it shall have “a new birth” and it “shall not perish.” The nation will surmount death with its new dedication—to freedom for all.
These words have entered into the civil religion of the United States. They are better known than the preamble to the Constitution of 1787. Let us pause and take a closer look.

. . . that this nation, under God, . . .

The invocation of the Divine signals a major departure from the resolutely secular nature of the Philadelphia Constitution. The Declaration of Independence itself repeatedly refers to the Creator. Yet, the Constitution of 1787 studiously avoids any word suggestive of a power higher than the will of the people. The purpose of the 1787 national charter is to serve the goals enumerated in its preamble (justice, domestic tranquility, the common defense, the general welfare, and securing liberty), and its legitimation lies exclusively in the possibility that a federal government will advance these worldly goals. This was fitting for a Constitution that sought to distance itself from countries that had established churches at the national level and that relied on religious tests for public office. There would be none of that in the United States.13
Significantly, the abolitionist movement in the 1830s, 1840s, and 1850s brought a passion for religious truth in American politics that had not previously existed. Theodore Parker, among other devout leaders of the movement, preached against “the Slave Power” in tones that made one think that the devil was marching into the new territories. The recognition that slaves, too, were “made in the image of God” provided a powerful rallying point for a crusade to correct the original mistake of 1787. Of course, various biblical passages served the other side as well, but the ardor for abolition drew heavily and indispensably on the sense of a higher law.
The Gettysburg Address, as written, apparently did not contain the reference to “this nation, under God.” As he spoke, Lincoln spontaneously broke with his prepared text. The reference to God appears in neither of the drafts that his assistants, John Hay and John Nicolay, said were the prepared texts. Yet, the four journalists who were present reported hearing the divine invocation, though some observers have Lincoln saying “this nation shall under God have a new birth” rather than the word order that has come to be accepted “this nation, under God, shall have a new birth.”14
The reference to “this nation under God” reinforces the conception of the nation as an organic entity, a single subject that could, like the Jews, enter into a covenant with a God. The substitution of the Americans for the covenanted Jews—however sacrilegious the idea may sound—landed in the New World with the Puritans and became a standard item of Protestant theology. Thus, we can understand Lincoln referring at Trenton to the Americans as “His [God’s] almost chosen people.”15
The Civil War was not only a war to establish the unbreakable bond that unites all Americans. It was also a war understood by many, Lincoln included, to have theological significance. It drew its power from religious claims about the humanity of all human beings, and its leaders found their solace in psalms and prayers. To close his second inaugural address, Lincoln expressed the faith: “The judgments of the Law are true and righteous altogether.”16
We can date the advent of civil religion in the United States to this period of theological ferment in American politics. It was at this time, 1864, that the government initiated the practice of printing “IN GOD WE TRUST” on our coins and currency. It is hard to imagine that any other country in the Western world would permit their money—the currency of secular commerce—to advertise a religious message. Yet, nondenominational expressions of faith have become normal in the rituals of the American people. Opening sessions of Congress with a prayer, using the Bible in swearing-in ceremonies, recognizing Christmas and Easter as national holidays—all of these rituals testify to an abiding nondenominational religiosity. Americans are virtually united in their willingness to advertise a widespread faith in God. For some reason, this is not generally understood as contradicting the principle of separation of church and state laid down in the First Amendment.
The phrase “nation under God” has acquired an almost casual banality. A generation after the end of the Civil War, in 1892, the practice of reciting the Pledge of Allegiance spontaneously swept the country. In the original version of the pledge, we swore allegiance to “one nation indivisible. . . .” In 1954, the sense that something was missing persuaded President Dwight Eisenhower to return to the formulation that crossed Lincoln’s lips at Gettysburg: “One nation, under God, indivisible, with liberty and justice for all.”
As a “nation under God,” Americans have been both blessed and cursed by a sense of mission in the world. Covenanted with higher powers, the nation has a destiny—a “manifest destiny” as journalist John L. O’Sullivan dubbed our policy of westward expansion in the mid-1840s. The phrase took hold and gave American politicians a sense of national purpose as they annexed Texas in 1845, negotiated a division of the Oregon territory with England, and led the country into war with Mexico a year later.17 This was territorial aggrandizement in the name of the “nation under God.” These were the aggressive moves that established most of the boundaries of the western United States as they are today.
The firm belief in “manifest destiny” and territorial expansion led ineluctably to the Civil War. As long as the Union was fixed at a certain number of slave states and a certain number of free, both sides could calculate the future. The South could count on the continuation of its “peculiar institution” despite fierce opposition in the North. But the westward expansion and the absorption of new territories led to intrigue and suspicion about whether slavery would be permissible in the new states that would eventually develop out of these territories. The acceptance of slavery in the original Constitution might have been an unholy compromise. With manifest destiny and the occupation of new territories, the compromise became not only unholy but unstable.
. . . shall have a new birth of freedom, . . . Here, near his peroration, Lincoln reaffirms the foundational value of the Bill of Rights. Freedom of speech, of the press, of the right to bear arms in a “free” state—these were the motivating values of the original constitutional order. They would be cherished in the new order as well, but for the first time freedom would be available to all. There would be no scar in its connotations, as there was in the three-fifths compromise, which for purposes of representation in Congress counted “the whole number of free persons” and three-fifths “of all other persons.”18 That distinction between the free and the unfree would disappear in the birth of a new constitutional order.
Our stylistic question recurs. Why did it seem more natural for Lincoln to use the word freedom in this context than liberty? Somehow it would not do to speak of “a new birth of liberty.” The opposition of “conceived in liberty” and “new birth of freedom” convinces me that the Latin origins of the first (conçue en liberté in modern French) and the Germanic roots of the second (eine neue Geburt der Freiheit in modern German) lends internal harmony to these phrases. It is almost more than one can expect of Lincoln, the great stylist, that in forging a new nation of black and white he should recall for us the melding of the English language from Latin and Germanic sources.
. . . and that government of the people, by the people, for the people shall not perish from the earth. In this final phrase that, along with the opening “four score and seven years ago” has become the most familiar cadence of the address, Lincoln formulates an additional commitment of the postbellum era. The government should be elected “by the people,” it should be “of the people” and exist “for the people.” The entire nation would vote at the polls. And government would serve the entire nation. At least, this was the aspiration. It would take several more generations for the nation of voters to absorb not only black men but also women of all races.
The hypnotic cadence “of, by, for the people” did not originate with Lincoln at Gettysburg. In an 1850 speech to an antislavery convention in Boston, Theodore Parker had used similar language in explaining the new American conception of democracy:

That is, a government of all the people, by all the people, for all the people; of course, a government of the principles of eternal justice, the unchanging law of God.19

There might be a strong link between thinking of the United States as a single organic nation and bringing God into politics, but it is much harder to make out Parker’s view that a democratic government would function “under the unchanging law of God.” The democratic idea is that people remain free to change the law by majority vote. A more generous interpretation of this phrase is suggested, however, by Parker’s linking the law of God to the “principles of eternal justice.” As the law of judicial review would eventually develop in the United States Supreme Court, these “principles of eternal justice” provide the bedrock for testing the constitutionality of state and federal justice under the “due process” clause of the Fourteenth Amendment. One could well accept, then, the idea of a universal popular franchise exercising its authority to make and change the law under the check provided by “eternal principles of justice.”
Parker’s and Lincoln’s commitment to popular democracy represents a clean break with the limited forms of indirect democracy recognized under the Philadelphia document drafted in 1787. According to the élitist republican scheme envisioned at the founding, the only institution that would be popularly elected would be the House of Representatives, and that body would be chosen by the group that was qualified to elect “the most numerous Branch of the State Legislature.”20 Two delegates to the Senate would be elected by each state legislature.21 The president was, and still is, to be elected by an electoral college chosen by the voters in each state.22 The original Constitution was silent not only about who was entitled to be a citizen but also on the questions of whether only citizens and which citizens should be entitled to vote. All this was left to state law and the states generally limited the franchise to white male adult citizens who owned the requisite amount of property. The word “democracy” is not even mentioned in either the Constitution of 1787 or the Bill of Rights.
War has a democratizing influence. Men fight side by side and when they lay down their arms they expect to be able to rule side by side. It is not surprising, then, that in the aftermath of the Civil War we find a new commitment to government by all the people. The postbellum constitutional order takes the expansion of the franchise as one of its first priorities. In 1870, the Fifteenth Amendment secured the right to vote regardless of “race, color, or previous condition of servitude.” Of the ten succeeding amendments from the Sixteenth to the Twenty-Seventh (leaving aside the Eighteenth on Prohibition and the Twenty-First repealing the Eighteenth), seven have addressed the extension of the power of the people to choose their government.23 In short, the securing of Lincoln’s promise of universal popular suffrage became the primary focus of the new constitutional order.
The Gettysburg Address, understood as the preamble to a new constitutional order, underscores four values that stand in radical relief to the motivating concerns of the Constitution as it stood, with the Bill of Rights, in 1791. In outline form these are the constitutional structures:

Revolutionary ConstitutionCivil War Constitution
Dates: Dates: 
Proposed 1787, ratifiedPreamble in 1863,
1787, went into force 1789, amendedReconstruction amendments
by the Bill of Rights 1791in 1865, 1868, and 1870

Source of authority:Source of authority: 
We the PeopleThe Nation as Defined 
by History

Primary value: Primary value: 
FreedomEquality

Mode of government: Mode of government: 
RepublicDemocracy

Highest power: Highest powers: 
Will of the livingCommand of history, 
divine mission

The contrast could not be stronger. And, most significantly, the four new points of reference were all articulated in the Gettysburg Address.
Each one of these groupings hangs together with internal coherence. It makes sense for a constitution that glorifies the will of the living also to take freedom as its highest value. Our Philadelphia charter was very much a document of eighteenth-century reason: it placed faith in the capacity of men to order their affairs as they saw fit. Four score years of history proved that their self-ordering led them, as Lincoln put it in the second inaugural, into committing “offences” for which they would pay with a “terrible war.”
The new constitutional order begins more humbly with obeisance to both God and the finer strains in our own historical tradition. It partakes of the historicist thinking that dominated German Romantic thought at the beginning of the century. The “spirit of the times”—the Zeitgeist in Savigny’s classic phrase—was speaking in the triumph of the American nation and its commitment to the equality of all.
The new constitutional order cohered as a compelling ideological whole. The values of nationhood, equality, and democracy were interrelated and mutually supportive, precisely as was the original trilogy of 1787—peoplehood, freedom, and republican élitism. But Lincoln’s vision of a new constitutional order may have been too radical for the jurists of the time. There emerged reactionary forces that sought to mystify and entrench the values of 1787. Before turning to the counter thrust of postbellum history, we need to understand more fully the internal coherence of the constitutional order signaled by the Gettysburg Address.









A specter is haunting Europe,” Karl Marx and Frederick Engels wrote in 1848, as the first sentence of The Communist Manifesto. The specter they had in mind eventually became a political movement that came to dominate nearly half the world in the twentieth century. Behind this movement, however, lay an even more powerful idea that Marx had inspired—a Marxist conception of reality. The marketplace of economic relationships is not what it seems to be. Workers enter into seemingly voluntary contracts with employers, but underlying this system of apparent cooperation is a vast system of exploitation. Those who hold capital reap profits off the backs of those whom they hire as their laborers. This generates a dynamic of history that should, according to the theory, eventually produce a revolution by the exploited class of laborers. This theory failed to recognize the just contribution of capital in generating the opportunity to work, and the political incarnation of Marxism turned out to be historically more transient than expected. Nonetheless, the insight remains with us that relationships of employment—indeed all forms of relationship—require more than nominal consent to be legitimate. Behind the appearance of voluntary interaction there lurks the ever-present possibility of unjust exploitation.
The Marxist challenge was but the beginning of a continuing critique of the idea of freedom, so revered at the close of the eighteenth century. Behind the nominal appearance of freedom lies a structure of influence, a set of conditions that influences people to make the choices they do. Sometimes these influences are morally desirable. Peer group and family pressure can lead people to finish their university degree or to stay in difficult marriages or to remain loyal when tempted to act in self-interest. Looking back, individuals who make these choices under social influence are often grateful for the external inducement to do the right thing. Yet, economic and social conditions can also lead people to enter into socially and economically oppressive relationships, abusive marriages, and postures of dependence on drugs and alcohol. They can be induced to undress and prostrate themselves on stages in front of booths with one-way windows. The fact that people are influenced by others or their economic and emotional needs is, in itself, morally neutral, but the results can vary widely.


The Paradox of Freedom

This is the paradox of freedom in modern times. We still believe that freedom is the great contribution of American democracy to the culture of the West. “Freedom” was our rallying cry in the decades-long battle against the political enemy that Ronald Reagan labeled the “evil empire.” Although Martin Luther King, Jr. dreamed of a society committed to the proposition that would realize the American vision of equality under law, the word that would sound from the mountaintops would not be “equality” but “freedom.” “Let freedom ring,” King reminds us in the memorable refrain of his dream. In his choice of words, King harks back to Lincoln, who recognized our commitment to the proposition that all men are created equal but hoped that the emancipation would generate “a new birth of freedom.”
We may be willing to die in the name of freedom, but we can no longer pretend that we live in the uncomplicated moral world of the eighteenth century. In a post-Marxist world, we know that freedom requires more than the experience of choosing. We cannot escape our recognition that nominal freedom leads, sometimes, to exploitation and oppression.
The late eighteenth century was indeed a marvelously simplistic time. Adam Smith could write, in the same year as the Declaration of Independence, of the wonders of a free market, based on the voluntary cooperation of producers and consumers, and its invisible hand that would produce the maximum possible welfare for humankind.1 Immanuel Kant could glorify freedom in his theory of law, published in 1795, a theory based on the absolute right to enter into any contract that one chooses to make.2 And, of course, the great monuments to the eighteenth-century understanding of freedom are the Constitution and the Bill of Rights. These documents are revered because they are designed to protect the individual sphere of freedom from a presumptively aggressive and overreaching central government. The basic freedoms protected in the first Ten Amendments, ratified in 1791, include freedom of speech and the press, freedom of religion, the right to bear arms, the right to privacy against state intrusion in one’s home and papers, and a plethora of rights designed to protect suspects of crime against the federal government’s power to investigate and prosecute. All of these freedoms or rights are understood to be a matter of opposition of the individual against the government. They imagine a dyadic conception of government—the individual pitted against the state.
The significant feature of our basic freedoms—apart from the franchise and those that arise in the criminal process—is that we can imagine enjoying all of them in a state of nature. We do not need government in order to exercise our freedom of speech or religion, to bear arms or to be free of state intrusion in our homes. As these rights are formulated, government acquires the image of the interloper, the enemy, the potential violator of our freedom to do as we please.
And who do we fear will invade and intrude upon our island of freedom? At the time of the revolution, the fear was directed toward King George III and his colonial governors. In the newly established Republic, the fear was redirected toward the federal government. This dyadic opposition between individual and state underlies most constitutional thinking to this day. The fear of the federal government has grown into distrust toward all government. According to the official doctrine, the Bill of Rights only applies to limit “state action” encroaching upon individual liberty. As Akhil Amar recently formulated the idea, officials of the state are likely to act for their own benefit rather than the benefit of its citizens.3 Therefore, we must be eternally watchful against overreaching by the state. The purpose of the Constitution is to arm us with the legal means to check the tendency of the state—federal government and indeed all forms of government—to limit our natural freedom.
But there is another model of thinking that recognizes the paradox of freedom. If freedom can generate exploitation, then the task of the state should be to intervene to protect the individual against the exploitation by other private individuals. The paradigm of the exploitative, oppressive relationship in the American experience is, of course, slavery, and therefore in 1865, as the first task of the new constitutional order, we banned the very possibility of private relationships of slavery, established either by force or by consensual agreement between master and slave. The Thirteenth Amendment charges the federal government with the responsibility to make sure that neither “slavery” nor “involuntary servitude” shall come to exist in the United States. The amendment does not say that the state may not create relationships of subordination or slavery. It says simply that these private relationships, however they might come about, “shall not exist.” The important point about this formulation is not merely that it dispenses with the requirement of “state action.” It does that and more.
The Thirteenth Amendment betokens an entirely new way of thinking about government—not as an ever-threatening enemy, but as a necessary partner in the building of a society free of interpersonal exploitation. The focus of the Thirteenth Amendment is not on the potential evils of government but on the wrongs committed by private parties. Unjust private relationships do not cease existing just because one declares them not to exist. They can arise spontaneously, and in a state of nature some people would inevitably come to dominate others. The passive voice of “Neither slavery nor involuntary servitude shall exist” means that the government must be ever watchful, lest relationships of exploitation come into being.
The new function of government departs radically from the dyadic structure—the individual pitted against the state—underlying the Bill of Rights. The relationship of government to private individuals becomes triadic or three-cornered. The relationship arises between two private parties: slave owner and slave, dominator and subordinate, aggressor and victim. The third pole is the government, which must intervene to insure that the incipient relationship of “involuntary servitude” shall not exist.
A triadic relationship between two people and the government represents an entirely new kind of constitutional order. A dyadic focus takes the government to be the enemy. The triadic orientation accepts the government as a partner in conquering evil. The dyadic picture assumes that the desired form of liberty exists in a state of nature and it treats the transition to government as a threat to liberty. The triadic conception recognizes the evil of domination inherent in a state of nature and treats government not only as necessary to rid us of that evil but as a welcome partner in the effort to build a civilized society.
This difference in the attitude toward government parallels a different understanding of freedom and how it comes into being. The freedom celebrated by the Bill of Rights resembles an island of solitude, a retreat from society. Its ideal is the individual in the state of nature, intimated by Henry David Thoreau’s retreat to Walden Pond.4 The individual stands alone, fearful that a far-off agent called government will aggress against him and limit his freedom. But the liberty that comes to the fore in the intended postbellum constitutional order and under the Secret Constitution requires the intervention of government. Liberty is born in the state’s assertion of responsibility to oversee and prevent relationships of oppression. The relationship between rights and freedom is thus turned on its head. Those who identify with the Bill of Rights and the mentality of 1791 think of both rights and freedom as islands of autonomy protected by the walls of the law against the threat of government. The view that comes to the fore in the Secret Constitution recognizes that freedom as well as rights depend on the proper interaction with government. Government is not the enemy of freedom but rather the mechanism by which freedom is secured in a society that tends toward domination and oppression.
The assertion of a triadic conception of government brought us into line with the middle European conception of freedom as the privilege that arises from living in a matrix of protective state regulations. It is not nature but the law that makes us free. Freedom is realized not by the state’s absence but from the construction of a network of laws that liberate the individual from the oppression that would otherwise occur. Compulsory temperance and drug laws generate freedom for those who are able to stay clean. Prohibitions against sexual self-degradation and peep shows strengthen the inner freedom of our human selves.
This is the European conception of constitutional freedom. When the German Basic Law of 1949 declares human dignity to be the foundational value of the constitution, the implications run through all relationships that may come into being. This “third-party effect” means that private individuals are bound to respect the human dignity in each other, precisely as they are bound not to subject each other to relationships of involuntary servitude or, during Prohibition, not to sell each other alcoholic beverages. Today, men and women must avoid sexual harassment on the job, even though in this case the “third-party” effect arises not directly from the Constitution but from federal legislation.
An activist tripartite conception of government requires funding. Fighting a major military campaign to suppress the Southern insurrection required a stronger financial base than the government had needed up to that time. The war drove up spending from the customary 2 percent of the gross national product to 15 percent. (By comparison, in the early 1990s, government spending represented 20 percent of the GNP.)5 With no place left to turn, a Republican Congress approved the first income tax in 1862. By 1865, the income tax generated over 20 percent of federal revenue, the balance coming from tariffs and reintroduced excise taxes.
The Civil War income tax lapsed in 1872, and when the direct tax against income returned to the national agenda in the 1890s, the times were different. The disputes took on the tones of class struggle. This time, it was the Democrats who favored the tax as a measure of social justice. Many of the wealthy who were affected by the modest 2 percent tax denounced the measure as socialist. Almost immediately after the tax’s introduction, a challenge under the original Constitution made its way to the Supreme Court, where five of the nine justices were convinced that any form of income tax violated the prohibition against direct taxes not in proportion to the census.6 Progressive politics as well as the government’s demand for revenue generated a coalition that supported a constitutional amendment to reverse the decision of the Supreme Court. By 1913, the Sixteenth Amendment found the necessary three-fourths vote for ratification, and the income tax became a basic tool of modern state finance.
The origin of the income tax in the Civil War has largely symbolic meaning. It testifies to the government’s beginning to conceive of itself as an aggressive agent charged not only with winning a total war against states in insurrection but also with taking charge of the postbellum constitutional order that would be based on different premises from the social order of freedom and fear of government.
In the second founding of the United States, thirty-seven states constituted themselves as a single nation “conceived in liberty and dedicated to the proposition that all men are created equal.” The government would assume the task of supervising relationships in the commercial and private spheres to assay whether they were impermissible relationships of domination—relationships morally equivalent to “involuntary servitude.” The government was newly envisioned as a triadic structure powered by an activist, well-financed government. Unfortunately, the Supreme Court did not clearly get the message.


Two Conceptions 
of Government

The tension between two conceptions of government—bipartite and tripartite—came to a head in a classic decision of the Supreme Court in 1905. The State of New York had enacted legislation designed to protect workers in the bakery trade. Among other provisions, the legislation limited the permissible hours of work to ten per day and sixty per week. The legislation was based rather clearly on the assumption that employees are at a serious bargaining disadvantage and cannot protect their interests adequately simply by negotiating the number of hours they want to work. The state was reaching out to the worker, motivated by compassion for those who lacked the bargaining leverage to limit their hours of employment.
The defendant, Lochner, was prosecuted under a provision of the statute that made it a misdemeanor to employ someone in excess of the limit. The Supreme Court concluded by a large majority that the statute violated the liberty of the employer and presumably of the employees as well—although the latter were not complaining about being prohibited from working too many hours.7 A majority of five on the Court read the notion of liberty in the due process clause (“no person shall be deprived of life, liberty, or property without due process of law”) as including freedom of contract. The dyadic structure prevailed. A similar analysis in the Peep Show case would have led to the conclusion that the women and their employers had the right to contract any form of self-exhibition they thought desirable. Any other result supposedly implies paternalism. Autonomy (if not dignity) requires freedom of contract as a basic right.
The alternative view of the case, winning support from four justices, including Oliver Wendell Holmes, Jr. and John Marshall Harlan, was that limiting hours of employment was a legitimate way for the state to exercise its responsibility to protect the health of those who chose to work as bakers. The dissent, written by Justice Harlan, explicitly addressed the problem of unequal bargaining power between owners and bakers:

It may be that the statute had its origin, in part, in the belief that employers and employees in such establishments were not upon an equal footing, and that the necessities of the latter often compelled them to submit to such exactions as unduly taxed their strength.8

Justice Holmes had the same point in mind when he wrote, apodictically, “The Fourteenth Amendment does not enact Mr. Herbert Spencer’s Social Statics.”9 In other words, the principles of the free market economy need not be entrenched as a dimension of constitutionally protected liberty.
Lochner ranks among the more widely scorned decisions of the Supreme Court. The general complaint is that the Court ignored the interest of the state in furthering the health and welfare of its citizens. To put this objection in other terms, the opinion ignored the ascendancy of the tripartite conception of government. The issue remains with us—if only in a slightly different guise. Since the late 1930s, the principle of freedom of contract has given way to the propriety of the state and federal measures to protect working people on the job. Yet, the question of liberty and its potential abuse in an oppressive relationship remains a flash point of debate. Although the concept is not mentioned in the Constitution, the freedom to say “yes” or “no” to particular commercial relationships has become an essential dimension of personhood. It is as much a part of the basic liberty protected under the due process clause as the right to be free from unjustified physical restraint.
Freedom of contract enables individuals to express their personhood, but it also facilitates relationships of oppression, including “slavery and involuntary servitude.” After all, it is possible to choose to enter into a contract of slavery. The book of Exodus permits the purchase of a Hebrew slave, but after six years of service “he shall go out free, for nothing.”10 Yet, there are people, the Bible recognizes, who prefer the condition of servitude:

And if the servant shall plainly say, I love my master . . . I will not go out free, then his master shall bring him . . . to the door or to the door post, and his master shall bore his ear through with an awl and he shall serve him Forever.11

In this example, the servant chooses the condition of servitude. We know from the fate of many long-term prisoners that after a certain period they choose a life of dependence, free of the responsibility of caring for themselves. It is not impossible that someone might actually prefer the secure life of the slave to the anxious life of the free person who must care for himself.
There are two distinct grounds on which the law might sensibly prohibit the possibility recognized in Exodus. First, the claim might be that freedom and its blessings represent a great gift that no individual “made in God’s image” should be able to forfeit as though it were a disposable piece of property. Alternatively, the argument might be that in principle people have the right to choose to forego their freedom, but that in reality these choices are always influenced by personal necessities that becloud the choice actually made. This is especially true under market conditions, where the need for sustenance can drive people into relationships that they would not choose in and of themselves. It is clear that even the choice of the Hebrew slave discussed in Exodus can never be shown to be completely free. The legal arrangements also stipulate in the same passage that if during his period of servitude the slave acquired a wife or children, then he must leave them behind when he leaves his master’s service. Some purchased servants might decide to opt for permanent servitude simply because they cannot bear to live without their wives and family. The full text in the quoted passage reads: “I love my master, my wife, and my children, I will not go out free.”12 The cruelty of subjecting him to the choice between freedom and leaving his family obviously means that his choice is not free in any meaningful sense.
Under modern capitalism there are many conditions that render choices less than fully free. Material necessity is the most obvious. But, as we have learned from the history of alcohol and cigarette consumption, advertising and peer group influence can lead people to develop habits that they later regret. The same is true of heroin consumption, which may readily develop into a condition of dependency in which the addict may enjoy the illusion of freely choosing not a hole bored in his ear but rather numerous telltale holes bored in his veins.
The question of exploitation and manipulation of consent has shifted from the economic to the sexual arena. That is why the peep show case so beautifully captures our concerns about equality and human dignity. The right to enter the romantic and sexual relationship of one’s choosing is surely an important dimension of freedom. It includes the right to marry the person of one’s choice, to choose and act upon a sexual orientation, gay or straight, to enjoy (within appropriate limits) reproductive freedom, and to say “no” to sex if one is so inclined.
The law of rape has become a major battleground of American law. The central question has become whether nominal consent to sexual relations constitutes actual consent, deep agreement in the heart. As in the economic context, power tends toward exploitation. The problem is particularly acute when the party seeking sexual favors—usually a man—is in a position of authority over his desired partner. The most hotly debated cases are spun from skepticism about whether nominal consent actually generates the kind of voluntary relationship that should be regarded as an expression of freedom rather than of exploitation. The same is true of regulation of sexual harassment on the job. If the boss promises advancement or threatens disadvantaged treatment on the job, the appearance of complete and voluntary participation is readily undermined. So far, in the name of equality, we are willing to tolerate rather intrusive regulation of dating practices in corporate or university settings, but one can sense a coming backlash favoring the principle that students old enough to vote should be old enough to make a responsible decision about their sexual lives.13 Making it a crime or private action for damages for coworkers or costudents to have sexual relations would surely violate the right to sexual autonomy now recognized as an aspect of liberty protected by the due process clause.14
The problem of exploitation in apparently voluntary sexual relations has long been with us. In the late nineteenth century, the problem was whether the Mormon practice of polygamy should be regarded as protected as liberty and the free expression of religious conviction. Those who defended the institution, as provided in the accepted Mormon religious doctrines of the time, cited its social benefit of caring for all the women and children in a society in which the available men had fallen victim to the hardships of settlement and warfare. The critics, by contrast, claimed that the choice of the women in these cases is not really free and voluntary. John Stuart Mill, a great advocate of liberty, sided with the critics of polygamy.15 Western governments have had no qualms about prohibiting the practice, sometimes for parochial religious reasons, sometimes out of solicitude for women who are subjected to an institution that arguably diminishes their status. The Mormons sued, thinking they had the kind of argument that eventually prevailed in the Lochner case. In 1878, the Supreme Court upheld the conventional view that the prohibition represents permissible intervention by the state to protect the weak against entering into exploitative relationships.16 Many voices today argue that this decision was wrong. The freedom to choose any form of domestic arrangement one wants should prevail against the state’s concern to protect people against their own potentially bad choices.
The same problem recurs in the current debate over physician-assisted suicide. The argument for freedom and autonomy holds that individuals should be able to choose when and how to end their lives. If they need the assistance of a physician to be able to die with dignity, they should have that right. The contrary view stresses the dangers of manipulated consent. Once the possibility of voluntary euthanasia is recognized, the danger presents itself that terminal patients will encounter social and economic pressure to consent to an early and painless death. Again, the problem is whether choices are as free as they seem on the surface, or whether they represent the subtle pressures that lead us to think that the government should intervene to protect people from manipulation and exploitation.
The anchor for this new conception of government—a government that intervenes in private choices in order to protect individuals from exploitation—lies in the Thirteenth Amendment. Yet, it seems very ambitious to derive all of this from a black-letter prohibition against private arrangements of “slavery and involuntary servitude.” The fact is that we are not entirely sure how far we should extend the prohibition against unjust relationships of domination. At the time the amendment was enacted, it was fairly clear that the drafters and the public had a broad construction in mind, for the Thirteenth Amendment became the constitutional foundation in 1866 for the first Civil Rights Act—indeed, the Act that is still used today to prosecute those who, like the police who beat up Rodney King, engage in racially motivated deprivations of civil rights.17 Because the deprivations of civil rights were understood to be an instantiation of relationships of unjust domination, it is clear that the framers envisioned a new constitutional order much broader than merely business as usual, just without slavery.
Academic writers have found the Thirteenth Amendment a rich source for constitutional speculation. Some have claimed that the amendment goes so far as to require the government to be watchful and intervene against child abuse.18 Others have argued that the amendment offers convincing grounds for recognizing abortion rights. Requiring a mother to carry a child to term arguably amounts to an oppressive form of involuntary servitude.19 A third voice holds, much in line with the argument of this book, that the potential ambit of “involuntary servitude” includes all forms of employment and labor that are unjust and oppressive.20 These are imaginative readings, and others are possible.21
Some restraint is necessary. We have to be mindful of the prospect that the values of the Secret Constitution might play themselves out more effectively as the informal restraints of civil society rather than as binding rules of law. As we have seen, our impulse to promote religion, love for the nation, and “politically correct” speech seems to yield greater results when the state holds back and limits itself to a gentle nudge in the right direction. But, more significantly, we have to recognize that we are locked in ongoing contradiction between the values of our first and our second constitutions.
The first Constitution commits itself to freedom and the second builds both on a preference for equality and the recognition that freedom is often an illusion. The lovers of freedom want the government to keep its hands off, lest Big Brother’s intermeddling do more harm than good. The skeptics of the Secret Constitution place their trust not in the natural mechanisms of social interaction but in the judgment of a vigilant hierarchy.
The first Constitution plays on the theme of distrust in government. We must secure our freedoms against potentially abusive officials seeking “rents” by pursuing their own bureaucratic interests.22 The second constitution presupposes trust in an aggressive government, a watchdog of transactions that might slide into the forbidden territory of “involuntary servitude.” In this regard, public opinion seems to be at odds with the de facto tolerance of Americans for governmental action that is becoming ever more intrusive. The public supposedly suffers from declining trust in government.23 Yet, in fact, the average person tolerates actions by government that can make sense only on the assumption that those potentially affected by governmental abuse see Washington officials as their allies in a common struggle. A good example is the census and the popular reaction. The census form for the year 2000, like several before it, poses probing questions about racial and ethnic identity. The government wants to know how many blacks and other minorities live in particular sections of the country. The questionnaire imposes a detailed grid of racial variations on people who might otherwise simply have thought of themselves as Americans or perhaps as “minorities.” This information becomes relevant, it is said, to Justice Department officials monitoring the distribution of voting power in congressional districts.24
Americans would not cooperate in answering these questions if they did not trust the government not to misuse the collected information. There was a time when the government sought indirectly to find out how many Jews still spoke Yiddish at home. One can be sure that the purposes of early twentieth-century officials, ever concerned about swelling immigration patterns, were not benign. And yet, today the common assumption is that our officials may be trusted with a precise racial and ethnic map of the American nation. Popular attitudes even go beyond tolerance for the intrusion into our personal identities. Many people of multiracial backgrounds prefer to identify themselves as “black,” on the theory that it enhances the interests of the African- American population to appear as numerous as possible.25 For the government to serve as the vanguard of a new constitutional order, the people must trust officials in Washington with additional powers and run the risk of governmental abuse.
This trust makes sense—despite the surveys in which people report distrust—on the assumption that the nation chooses to cooperate in the ascendancy of the government as the watchdog of equality and popular democracy. The breach of equal treatment need not be feared, and information on the distribution of potential voting blocks serves the cause of securing fair representation of all major groups in American society.
Yet, the very effort to secure this fair representation of all voting groups threatens both the sense of common nationhood in the United States and calls into question the integrity of individual decision making in democratic elections. Encouraging people to identify themselves as hyphenated Americans encourages multicultural consciousness and generates a growing sense of puzzlement about what it means to say that all Americans are of a single nation. Also, the assumption that black candidates can be elected only by black voters places us on a path that we cannot pursue to a logical conclusion. It would hardly be consistent with the premises of popular democracy to consider—even as a thought-experiment—voting districts that consisted primarily of women or gays. The notion that particular groups are entitled to congressional representation merely as groups eventually runs squarely into the principle that in a democratic system individuals vote not as representatives of groups but solely as individuals. They have no duty to a hyphenated consciousness.
Yet, a trusted government can do much to remedy past discrimination and eliminate the badges of slavery. A new conception of government might yet emerge to realize the ambitions of Gettysburg, to ensure equality of all those “created equal” as it simultaneously promotes a “new birth of freedom.” It is as though nothing has been resolved. When the pursuit of equality begins to encroach upon our basic freedoms we are unsure where to turn.









In the Western experience with evil, we choose repeatedly to put our faith in law and the legal culture to redeem ourselves from sin. Over and over again, we find states indulging in total war, terror, genocide, and the mass killing of their own people, and then turning to the legal culture in the hope that they can atone for the iniquity and live once again as a civilized nation. This view—that the law shall make us clean—should give us pause. Faith in the law has not been an unqualified virtue in the Christian West. One might expect individuals influenced by Jesus’s Sermon on the Mount to turn first to love and charity as the means of atonement. But nations—organized, organic societies—must take a different path. A nation must proceed collectively to find redemption.
I write in this chapter of religious ideas and their value in understanding our legal experience. This, admittedly, is an unusual take in our rigorously secular academic world. The American university world has distanced itself from the sensibilities of ordinary Americans who take the Bible seriously as a source of wisdom and who live their lives with devotion to values of faith and redemption. In this interpretation of law as the path to national redemption, I seek to find a middle way between Jewish and Christian thinking. There is no doubt that the nations whose struggles I describe—France, Germany, and the United States—think of themselves as Christian nations. Yet, the very idea of redemption of the entire nation through law resonates more with the older tradition of the Jewish national mission under the Torah revealed at Mount Sinai. My account seeks to unite the divergent strains of all religions that trace their roots to the original idea in Exodus of a nation living under God and under law.
To understand the phenomenon of communal redemption, we must turn to the Bible as our source. The model of the Hebrews’ deliverance from servitude and their ensuing acceptance of God’s law at Mount Sinai have repeatedly appealed to dominant powers of the West and often to opposite sides of the same conflict. In the rhetoric of the abolitionists, slavery in the United States made the country into “a House of Bondage.” Both blacks and whites identified with the same story of liberation from this domain of oppression. Nat Turner thought he was recreating the biblical story when he led a slave revolt in 1831. The slaves whom Harriet Tubman led to freedom in the North called her Moses. Abraham Lincoln readily saw himself in the image of Moses leading his people out of bondage into the realm of freedom.
The Hebrews fled Egypt in order, eventually, to accept the law revealed at Mount Sinai: delivery from servitude requires more than violent revolt. The message of Exodus is not simply liberation from slavery but the domesticating of violent sensibilities under the rule of law. Jews celebrate this submission to God’s law in the holiday of Shevuot, which commemorates the revelation of the Torah at Mount Sinai and is celebrated fifty days after the night of the Exodus. Christians have reinterpreted this event as the descent of the Holy Spirit, celebrated in the analogous spring holiday of Pentecost.
The idea that freedom exists only under law is often understood as a Central European or German approach to the individual in society. Americans tend to subscribe rather to the myth of a Lockian state of nature, where individuals exist prior to the organization of society under a social contract. The Declaration of Independence relies heavily on the principle that the “consent of the governed” is indispensable to the legitimacy of government. Yet, in actual American practice, the law—particularly constitutional law—serves the same function of sanctifying the social order as it does in the European experience. Before turning to the details of the American appeal to law after the surrender at Appomattox Courthouse in April 1865, let us examine first two significant European efforts to domesticate tendencies toward violence under the rule of law.


Redemption by Law in 
France and Germany

Think first about the way in which the French sought repose from post-revolutionary terror in their Code civil. The country passed through fifteen years of regicide, terror, and mass executions. Amidst voices clamoring for stability and security, Napoleon staged his coup d’état in late 1799. High on his agenda was revamping the legal system. In 1804, he charged a group of lawyers with the task of drafting a new civil code in language accessible to ordinary people. The committee produced the elegant Code civil, now a mainstay of French culture and a model for civil codification all over the world. The language is so refined that the novelist Henri Stendhal reportedly reviewed the style of ten code provisions every night before retiring. Today, when the Francophones in Quebec preach the distinctiveness of their culture, they never fail to mention their Code civil, modeled after Napoleon’s effort to use the law as the means of restoring civilized order to France.
The Code civil has proved to be remarkably durable in French culture. Constitutions have come and gone and the French have endured recurrent changes of regime, including communes, dictatorships, and five distinct republics. Yet, through all this, the civil code has survived. It is the cultural monument that unites the French across history.
In its substantive content, the Code civil is strongly identified with the achievements of the 1789 Revolution against the ancien regime. The code sweeps away the vestiges of feudal influence in the law of property and in the law of evidence and proclaims a liberal legal order. The end of feudalism in the law of property meant that a single concept of ownership would replace the ancient system of embedded estates. The implication was that all land would be freely alienable, without being burdened by the residual control of lords higher in the feudal chain. The code thus provides the legal foundation for a market economy. The end of feudalism in the field of evidence means that the testimony of a nobleman is no longer worth more than the oath of a peasant. Thus the code institutionalizes the égalité of all citizens, as promised in the slogan of the Revolution.
Standing for these liberal values, incorporating the messages of revolution, and surviving all changes of political regimes, the Code civil functions like a constitution for the French. It is the bedrock of the legal culture. In their code, the French have found an enduring symbol of the rule of law, a conviction that the language, concepts, and rules of the legal order can hold back the impulses toward violence, terror, and reciprocal vengeance. Faith in the code has redeemed the nation from the nightmare of the guillotine.
The metaphor of redemption should not pass our lips lightly. In its original meaning, it has legal connotations; something on loan gets returned to its owner. The older Jewish law of homicide relied on the metaphor of the Goel haDam, “the redeemer of blood” to refer to the victim’s next-of-kin who, under certain circumstances, could pursue the murderer and kill him. David Daube has interpreted this practice against the background assumption that at the time of a natural death, the life force—symbolized by blood—always returns to God.1 If the death occurs at the hand of another, the manslayer unnaturally acquires control over the victim’s “blood.” The Goel haDam, the redeemer-of-blood, executes the manslayer in order to release the victim’s blood, thus enabling it to return to its divine source. The notion that our life force belongs to God accounts for the views of virtually all secular liberal systems that no one can validly consent to his or her own killing at the hand of another.
It is tempting to extend this idea and to think of all humanity as enjoying a temporary privilege of life on earth. God somehow will redeem all of us at the end of history. In fact, the Jewish view, as it has evolved and matured, seems to have avoided this universalization of the idea that individual life stems from God. As the idea developed, the agent of redemption would be the Messiah, who would bring a reign of peace and harmony to life on earth. The redemption occurs in life as we know it. Orthodox Jewish culture takes the observance of God’s commandments, living under the rule of revealed law as interpreted by the rabbis, as the way to hasten the Messiah’s reign of harmony and order. The law, then, becomes the path toward redemption. Until the Prince of Peace comes to “fulfill the law,” or until the Apocalypse at the end of days, the secular law of the nation is the only means we have to work toward the perfection of life on earth.
The place of “blood” in the religious tradition of redemption proves to be subtle and problematic. There are some strains in the Jewish tradition that link the letting of blood with returning the soul to God. The “redeemer of blood” reminds us of that connection, as does the popular view that the founding of Israel stood in some kind of organic relationship with the Holocaust. The connection between blood and salvation becomes much stronger, however, in the Christian interpretation of its Jewish legacy. The theme of blood spilling from the body becomes powerful in the crucifixion and reaches its apotheosis in the faith that a great battle, an Apocalypse, must precede the Second Coming of the Messiah. The spilling of blood in a great battle is understood instinctively as the suffering that must precede redemption. As John Brown was led to the gallows on the eve of the Civil War, having unsuccessfully sought to stimulate a slave revolt, he handed one of his guards a note, “I John Brown am now quite certain that the crimes of this guilty land will never be purged away but with blood.”2
But blood alone does not save a nation from its sins. The argument here is that indulgence in evil—slavery, mass killing, persecution—must first issue in the suffering of the people. To overcome their sense of self-inflicted brutality, they turn to the law as the path of secular redemption. They search for stability after having succumbed to their baser instincts. The law provides a source of hope that the civil order can resist the recurrent slippage into violence and brutality. The important point is that the rule of law—not charity, not prayer, not animal sacrifice—should provide the means of secular redemption.
For nations as a whole to seek redemption, they must find a discipline that operates on them as a group, as a community. Individual acts of devotion will not suffice. Needed is the discipline represented by the law—the expression of communal cooperation, par excellence. The compromises and obligations of life under the law hardly makes sense to individuals standing alone, preoccupied by their own values and their own needs. The law redeems not the individual but the community or the nation as a whole.3
This view of the relationship between law and redemption finds expression in the Hebrew Bible, the Old Testament. It continues to inspire the law-based thinking of Judaism, Islam, the Catholic Church, and some Protestant theologians. The law given at Sinai, the law embedded in the covenant, is not the expression of individual aspiration but only of collective obligation. Seeking redemption or salvation through the church or through faith provides a way of cleansing ourselves of sin and, as it were, perfecting our individual creation.
Legal cultures, too, must seek to perfect themselves. They cannot exist simply as the product of will. When legal cultures lose sight of their natural end of bringing a reign of justice and harmony to human affairs, they decline into corruption and the arbitrariness of power. The German philosopher Gustav Radbruch defined the ideal of Law as the practice of establishing rules in the pursuit of justice.4 Communal life seeks, through law, to perfect itself. This secular idea parallels the eschatological aim of perfecting the creation of the world under God’s reign.
Seeking redemption under the law cannot simply be a desire for one’s parochial values to triumph in the courts. It matters which values are in play. And it matters how these values are debated in the legal culture. Debate about legal issues must be open and robust, and the very process of legal argument must communicate respect for the opposition. At the end of a legal argument, both sides must have the sense that they have been listened to, and that the dignity of the losing party is affirmed in the process of decision. Here, as well, we have much to learn from the model provided by the Jewish tradition of Talmudic debate. When a rabbi questioned how two of the greatest sages, Rabbis Hillel and Shammai, could persistently disagree, the response was: “These and these are the words of the living God.” Although Rabbi Hillel’s views are generally followed, Rabbi Shammai is treated, in defeat, with the greatest respect.
It is not surprising that when the established authority’s respect for the political opposition is debased, the legal culture invariably suffers. This is most noticeably clear in dictatorial societies where legal debate is reduced to little more than efforts to placate the powers that be. Although the National Socialists purported to rely on legal forms and administrative regularity, their contempt for free and mutually respectful discourse led to a corruption of the legal culture. The Nazis’ conception of law fluctuated between two unpalatable extremes. Sometimes the slogan was that law was what Hitler wanted and commanded (Recht is das, was der Führer will). At other times, utility to the German people was the ultimate source of legitimacy (Recht is das, was dem Volke nutzt).5 The National Socialist Party’s manipulation of these slogans and their observance of legal forms served only to bring the culture to a deeper level of corruption.
It is an extraordinary feature of postwar German culture that a new generation of jurists managed to save, to redeem, their concept of law from its racist and Nazi associations. In the wake of their unforgettable crimes against humanity, the West Germans, too, sought redemption in the rule of law, in the Rechtsstaat that they have cultivated along with economic prosperity. Living by the law, and seeking justice within the law, redeems the humanistic side of German culture. It has suppressed the romantic will to break all restraints for the sake of glory in power.
The Germans, too, have a civil code that has united them, since 1900, through the transitions from Bismarck, to Weimar, to the Third Reich, to the present. Yet, under the National Socialists, the code, which contains the provisions on family law, became tainted with notions of racial purity. Jews and Aryans could not marry. Of course, this stain disappeared in the postwar reform, but the memory remains of a corrupted civil code. Not surprisingly, then, Germans have sought redemption by promoting both a new constitution, enacted in 1949, and the rule of law in a united Europe. More than any country seeking redemption under law, the Germans identified their new constitution, the Grundgesetz, as the focal point of state authority. The sanctity of the constitution—and not the personal head of state—became the interest protected under the reformed law of treason. When West Germans felt their infant postwar republic endangered by Communist subversion, they appointed an agency to protect the integrity of the government. The announced aim of the agency was to protect the constitution (Verfassungsschutz).
The preamble of this charter, called the Basic Law (Grundgesetz), repeatedly reminds Germans of the imperative to atone for the sins of the past:

Conscious of its responsibility before God and humanity, possessed of the will to serve the peace of the world as an equal member of a United Europe, the German nation [Volk] commits itself, by virtue of its inherent constitution-making authority, to the following Basic Law.6

No other constitution, so far as I know, stresses its sense of “responsibility” and declares as one of its primary purposes “to serve the peace of the world.” These gestures recall the descent of the German nation into the evils of aggressive war and crimes against humanity.
The first article of the Basic Law invokes the humanistic Kantian underpinnings of German culture: “Human dignity is inviolable. All state power is obligated to protect it and respect it.” This provision provides the backdrop for interpreting all the basic rights guaranteed under the constitution. The protection of human dignity is the fundamental value suffusing the entire legal order. The highest virtue of the postwar German constitutional order, then, was precisely the greatest casualty of the Nazi regime. The path to redemption lay in reclaiming the liberal and humanistic values most systematically violated in their darkest hour. The point is carried forward in the second article: “Everyone has the right to flourishing of his or her personality. . . . Everyone has the right to life.”
These are provisions that enabled Germans to redefine their identities. They would no longer be the people devoted to the Volk above all. They would become the nation of human dignity that served the cause of human flourishing and the sanctity of human life. For the postwar Germans, then, the law, and particularly the Basic Law became the means for suppressing evil impulses and returning to the promises of an earlier national self. This is what redemption means in a secular legal world.
The redemptive impulse leads national courts to place an emphasis on values that resonate against past sins. The German Constitutional Court has made a number of controversial decisions that make sense primarily as efforts to resolve the burden of memory. The court decided to uphold a law abolishing the twenty-year statute of limitations for concentration camp murders.7 It invoked the constitutional “right to life” to strike down a liberal abortion law that permitted abortion on demand in the first trimester.8 And, more recently, the court rejected an East German statutory justification for border guards who shot at their own citizens trying to flee the country for the West.9 All of these decisions brought to the fore fundamental values of protecting life and punishing those with contempt for life. Yet, the particular German emphasis on these values would probably not appeal in the same measure to other European courts.
The Germans themselves have coined a unique, hard-to-translate phrase to describe the controversies that have driven their system of justice for the last fifty years. They call it Bewältigung der Vergangenheit—“overcoming” or “coming to grips with” the past. Settling accounts with the past provides a critical perspective on the process of redemption from evil. We cannot avoid the past, for we are all prisoners of it. In real life, we cannot reenact the forty years of wandering in the desert that the Hebrews had to endure before they could shake off their ingrained ways and a new generation could seek redemption under the law. In the world of practical politics, we must act now, and criminal punishment often provides the mechanism for distancing ourselves from the past so that we can start anew.


Civil War as the Path 
to Redemption

As France and Germany had their experiences of seeking redemption after reigns of terror, Americans, too, indulged in the mammoth bloodletting on the killing fields of the Civil War. When Lincoln sought to resupply Fort Sumter in Charleston harbor, and General Beauregard chose in response to fire on the federal fort, the long-simmering feud between North and South bled into brothers’ killing each other at close range. They fired their canons on Fort Sumter, they fixed their bayonets at Little Round Top, they lobbed shells onto Vicksburg until troops could seize the forts reigning over the Mississippi, they burned down Atlanta, and under William Tecumseh Sherman they scorched the earth on their march to the sea. The blue and the gray fell everywhere. And they were not sure why. They only had abstract ideas in their heads—some died for the Union, others for their separate nation. Over six hundred thousand lives stained the ground, more than all the former and subsequent American wars put together.
Having barely won reelection midway in this slaughter, Abraham Lincoln could only say of the reign of terror, “Woe unto the world because of offences!” We had descended into the bloodiest war of our history without clear purposes or any understanding of how it might end. “For it must needs be that offences come; but woe to that man by whom the offence cometh!” The self-inflicted pogrom is seen as a “woe” and a “scourge” inflicted for the terrible “offence” of slavery. Lincoln’s second inaugural address prayed for redemption. The nation had bled its sins onto its own soil and craved a rebirth of American civilization.
The survivors turned to law. One year into the war, after a string of Union defeats, Lincoln learned that the old Union could not possibly survive. “A new one had to be embraced.”10 And the new Union would have to be based on a new constitutional order. A nation of free Americans, including emancipated slaves, would bear responsibility for rebuilding the United States on the basis of a constitution acceptable to all. Formally speaking, the original charter of 1787 would remain in place, but it would be so radically transformed that it would stand to the ancien United States as the Code civil related to the French feudal order or, as any redeemed legal culture compares to the brutality and chaos that precedes it.
The American hope for a new beginning lay in the Reconstruction Amendments—the Thirteenth, Fourteenth, and Fifteenth—all enacted in quest of a new definition of freedom and equality under the law. The first clause of the Fourteenth Amendment specified who would be a member of the new polity: “All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States. . . .” With a single stroke the new constitution erased the effects of one of the worst blemishes in American constitutional history—the Dred Scott decision of 1857, which held that persons of African descent could never become citizens of the United States. In the new United States, there would be no discrimination based on blood. The only question that mattered was whether you were born within the polity and whether you were therefore likely to come to maturity with the language and consciousness of American culture.
With just boundaries of the new nation-state properly defined, the highest order of business was to define the basic rights of its citizens. The structure of these rights follows the pattern established in the Declaration of Independence: life, liberty, and the pursuit of happiness. Yet, there was a new recognition that the inalienable rights of all Americans were now to be realized not in the state of nature but under the rule of law. The naturalistic “pursuit of happiness,” celebrated in the Declaration, gives way to the quintessential creature of the law’s definition—property. Yet, the basic rights of life, liberty, and property are inalienable without being absolute. The ideal must be adapted to the practical demands of competing claims. The legal system would have to decide when individuals could fairly be deprived of liberty or property or even of life; thus, the coining of the famous and influential clause of the American Constitution, namely that no “State [shall] deprive any person of life, liberty, or Property, without due Process of law.” The law would define the content and the limits of the inalienable rights celebrated in the Declaration of Independence.
Also, for the first time, the law would define duties incumbent on the states. The individual state governments must not only guarantee due process for all persons within their jurisdiction, they must also secure “the equal protection of the laws” for all to whom their power extends. True, the original Constitution places some limits on the legislative competence of the states. They must defer to the supremacy of federal law and recognize the privileges and immunities of the citizens of all other states.11 And there were specific restrictions: They could not enact bills of attainder, ex-post facto laws, or any “law impairing the obligation of contracts.”12 In the postbellum constitutional order, however, the states acquired a pervasive duty to treat their residents—those subject to their jurisdiction—decently.
This was a revolutionary change. The states were no longer the autonomous sovereigns that they thought they were when they claimed the right of secession. They were now, in fact, servants of their people. Governments existed to guarantee due process and equal justice for all. The local law was no longer simply a creature of the states. The states themselves were enmeshed in the law and subordinate to it.
In addition to embedding the states in the rule of law, the new constitutional order embarked on an affirmative program to ensure equality among those citizens subject to the jurisdiction of the United States. The heart of the new consensus is that the federal government, victorious in warfare, must continue its aggressive intervention in the lives of its citizens. It must protect the weak against the risk that they would slip into states of subordination resembling the past from which they sought to escape. According to the Thirteenth Amendment, there could never again be relationships of slavery or involuntary servitude in the United States. The federal government would have to be ever watchful to insure that this kind of slippage would never occur in the private relationships among citizens. Furthermore, under the “equal protection clause,” the states must recognize and promote the equality of those subject to their jurisdiction. To round out the commitment to equality, according to the Fifteenth Amendment ratified in 1870, the states could no longer deny voting rights to citizens on the grounds of their race, color, or previous condition of servitude.
These objectives and guarantees are insufficient in themselves to create a constitution, a framework of government. One needs, in addition, a definition of legislative empowerment that would enable the federal government to realize its commitments. This definition is laid down in all three of the postbellum amendments. All three grant the power to Congress to enforce the basic framework “with appropriate legislation.” True, the new Congress takes as a given many of the provisions of the original Constitution. The new order inherits an operating Congress, Executive, and Judiciary. They would be recast in new functions, but the forms remained the same.
The argument, then, is that the three Reconstruction Amendments enacted a second American constitution. The terms of this constitution, as culled from the amendments—with some rearrangement and leaving out historically specific clauses—can be stated in a few words:

The Second American Constitution
§1. All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.
§2. No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States.
§3. No State shall deprive any person of life, liberty, or property, without due process of law.
§4. No State shall deny to any person within its jurisdiction the equal protection of the laws. 
§5. Neither slavery nor involuntary servitude, except as a punishment for crime whereof the party shall have been duly convicted, shall exist within the United States.
§6. The right of citizens of the United States to vote shall not be denied or abridged by the United States or by any State on account of race, color, or previous condition of servitude.
§7. The Congress shall have power to enforce the foregoing provisions by appropriate legislation.

These seven propositions summarize the enduring content of the Reconstruction Amendments.13 The key provisions of these amendments define political membership, articulate basic rights, and provide an ambit of legislative competence. So reformed, the American system of government would be able to protect individual rights as well as promote the equality of all persons who survived the war. Of course, we must assume a set of institutions—a Congress, an Executive, and a Judiciary—that will continue to function according to the terms of their initial creation.
Still, there is something missing in this filtering off of the three Reconstruction Amendments and calling them a separate constitution. The missing factor is the consciousness of setting forth a new framework of government, a structure based on values fundamentally different from those that went before. To find that consciousness, we need to turn, I wish to argue, to the critical message of the Civil War, the address that would generate a new normative world in which to make sense of the epic war that consumed America from the firing on Fort Sumter to the surrender at Appomattox. The new Nomos, the new framework of values that necessitated a new constitution, comes forth in one of the great prayers of the American civil religion, the Gettysburg Address. It is worth recalling some of the enduring phrases of this civil prayer, the incantations that reverberated in American consciousness:

Four score and seven years ago our fathers brought forth on this continent a new nation. . . .
[This nation was] conceived in liberty and dedicated to the proposition that all men are created equal.
From these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion.
We resolve that these dead shall not have died in vain, that this nation, under God, shall have a new birth of freedom. . . .
Government of the people, by the people, for the people shall not perish from the earth.
In the ensuing chapters, we will look at these words and the entire address in greater detail. For now, I wish to make the unusual claim that these revered words serve as the preamble for the constitutional order that emerged from the unification of the nation. They are a preamble in much the same sense that the language beginning “Conscious of our responsibility before God and humanity” provides the organizing principle of the new German constitution or the following words echo in memory as the convening of the Philadelphia Constitution:

We the people of the United States, in order to form a more perfect Union, establish justice, insure domestic Tranquility, provide for the common defense, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America.

Constitutional preambles speak in prophecy. They set forth a vision of the future—for the broad purposes of the national charter that they introduce. And, most important, they define who the people are who share in the constitutional vision. The original preamble in the Philadelphia version stressed the position of “We the People” as the enactors of the Constitution. For Lincoln, the body politic expressing itself in the new constitution included the prior generations who “four score and seven years ago” adopted, with great courage, that proposition of equality that gave birth to the American nation. Those represented in the new order included the dead at Gettysburg and at all the battlefields of the war who, if the new order is realized, “shall not have died in vain.” And, furthermore, because he avoided all partisan references in his address, he clearly meant to articulate a conception of the nation that included the South as well as the North, black as well as white. Ultimately, the beneficiaries of the new order would be the future generations of the nation, those who would flourish under “a new birth of freedom.”
To say that the Gettysburg Address provides the preamble to a new constitutional order is, to say the least, a bold claim. When Lincoln took the train up to Gettysburg in November 1863, he had in mind only to comfort the mourners of those who died in the fierce four-day battle in early July. The bodies were being pulled together from the battlefield and spared further decay. The soil was turned and the dead laid to rest. The battle had turned the tide of the war—just barely, mind you—and it was time that the president began to articulate the meaning of the long suffering that culminated in the gruesome hand-to-hand fighting in the Gettysburg fields.
At the ceremony dedicating the Gettysburg cemetery, Lincoln was designated the second speaker. The renowned orator Edward Everett spoke for two hours before the president mounted the podium. He had a written text with him that amounted to about 268 words.14 Perhaps Everett prepared the audience to absorb the poignancy of Lincoln’s message. Perhaps the very brevity of Lincoln’s words lent them additional power. The impact of the address was felt not only by the mourners gathered at the new cemetery but by an entire country yearning for a sense of meaning in the bloodshed.
True, the Gettysburg Address was not legally binding, but preambles are never meant to have the status of positive law. They are designed to explain why it is necessary for the government to bind itself to certain objectives. Lincoln’s preamble, accepted in the hearts of the nation, explains the meaning of the war and provides a guide to the building of a constitutional order based on nationhood, equality, and democracy. The setting of clear goals in inspiring language—this is all one can expect of a constitutional preamble.
This constitutional order stands in radical contrast to the Constitution drafted in Philadelphia and amended by the Bill of Rights in 1791. It defines membership in the American nation, it brings the principle of equality to the fore, and it initiates the process of extending the franchise to virtually all adult citizens. The original Constitution did none of these things. It slighted the problems of nationality and citizenship, it sidestepped the problem of equality, and it minimized the significance of popular democracy.


The Irrelevance of 
Original Intent

At the outset, I should be clear about the claims I am not making and the methods I am not using. Above all, I am not making an argument about the “original intent” that lay behind the Reconstruction Amendments. Nothing strikes me as intellectually and morally more impoverished than the current trend in constitutional scholarship to believe that the wishes, desires, and intentions of the founders should determine the content of our Constitution. There are two major hurdles that the advocates of this method have never negotiated. First, we need an argument about whose wishes, desires, and intentions really matter. If we think we are bound by a certain take on the world that prevailed in 1787, 1791, or 1868, then we should decide whose sentiments matter. Should we look to the people who wrote the document, to the majority who voted for it, to the states who ratified it, or to the “people” as a whole for whom these various democratic agents acted? Among all these possible sources of “original intent,” there was intense conflict. I would imagine that even those who actually voted for and against various drafts suffered from doubt and changing sentiments. But even if each person voting had a concrete intention to support every sentence he or she endorsed, there is no coherent way of finding a common denominator among their divergent positions. A single intent cannot unify the inevitable cacophony of desires that stand behind every piece of legislation. But let us suppose there was a single intent of the group. We then encounter a more basic question: Why should we care what the founders actually thought?
The best political theory to support the relevance of original intent would be to think of the lawgiver as something like a military commander.15 The commander wants us to do something, and has used the language of the law to move us toward action. We should try to figure out what these purposes are and execute them. And if we don’t? Well, the commander cannot really punish us, but somehow we would be breaking faith with the framers if we don’t act with the appropriate subservience or at least act as though we were submissive to the original intent of the founders. This, I regret to say, is the best reconstruction I can offer for a view that never seems to get articulated; namely, why we should pay so much attention to the wishes and desires of the agents who bequeathed to us the words we live by.
In great historical moments of law making as well as literature, writers choose words that resonate far beyond their original context. When the representatives of the colonies “pledged their sacred honor” in July 1776 to a document that included the words “All men are created equal,” they may merely have intended to stress the equality of all “collective” peoples: the new Americans had as much right to choose their form of government as did the British. They also could have had the limited purpose of arguing that they were of the same moral status as King George III. If all men are created equal, then no one of them can claim to be anointed as ruler by divine right. The only source of legitimacy, as the Declaration argues, is the “consent of the governed.” Whatever their intentions as individuals or as a group may have been, their words had lasting significance. They bequeathed a great maxim to the American people—a maxim that would in due course serve as the battle cry of emancipation.
When the drafters and ratifiers of the Fourteenth Amendment adopted a commitment to equality under the law, they did not think particularly about whether they wanted to bring about integrated schools. Yet, a vast literature has grown up around the question of whether the “original intent” of the Fourteenth Amendment was to integrate the schools—an event that the Court did not mandate until 1954 in Brown v Board of Education.16 The dispute seems to be entirely irrelevant.17 The complex body of national and state legislators who drafted, passed, and ratified the Fourteenth Amendment did not think about a single system of education for blacks and whites. There were too many other issues on their minds. We cannot attribute to them an intention to have all Americans study together in the same classroom, nor can we burden their memory with a commitment to keep black and white forever apart.
Those who frame constitutions and constitutional amendments obviously have some purpose in mind, but the purposes are typically abstract. If they want to bring about equality among all Americans, they do not want to be bothered with working out precisely what equality means at each stage of historical evolution. If you had asked them whether, ninety years later, the schools should be desegregated, they would have been nonplussed by the question. “Well, that is the reason we have courts,” would have been the typical reply. The Fourteenth Amendment established an ideal, it affirmed an idea that has roots in the Declaration of Independence. The drafters implicitly endorsed the principle that all men are created equal and because they are created equal, they are entitled to equal treatment before the law. What this language should mean in practice was not their concern. Together with scholars who reflect on the ideas behind the law, the courts assume responsibility for the proper interpretation of the language that constitutes a shared heritage of government principles.
I never cease to be amazed that legal scholars, particularly in the United States, continue to be confused about the relevance of the framers’ original intent. Secular legal systems could not possibly be more demanding, more deferential to authority, than religious cultures that believe that their binding legal principles were declared by God. Yet, a story from the Talmud beautifully illustrates the folly of invoking original intent in a dispute about the meaning of God’s commandments. A group of rabbis were engaged in a debate about whether a particular earthenware oven was kosher or not. One of them, Rabbi Eliezer, said no; the other rabbis said yes. Rabbi Eliezer proceeded to invoke a variety of fantastic signs to support his view: at his command, a carob tree was uprooted and flew across the field, a stream flowed upstream, and the walls started to collapse before they were halted. The rabbis were not impressed by these signs. Then Rabbi Eliezer, desperate and alone, invoked the argument of original intent: “If I am right, let heaven be the proof.” A heavenly voice then proclaimed: “How dare you oppose Rabbi Eliezer, whose views are everywhere the law.” Rabbi Joshua arose and quoted Deuteronomy: “It is not in Heaven.” Rabbi Jeremiah explained the reference: Ever since the Torah was given at Mount Sinai, “we pay no attention to heavenly voices, for God already wrote in the Torah at Mount Sinai.”18 The point is that once the language is released and given to jurists to fashion to the needs of their time, the task of lawgivers is finished. Their intentions and desires cannot rule—either from the grave or from heaven.
The intention of those who framed the Reconstruction Amendments should, therefore, not control their interpretation today. But what about the intention of Abraham Lincoln, when he mounted the podium on November 19, 1863? There are some who will say that if Lincoln did not intend specifically to articulate the preamble to a new constitution, then the words spoken at Gettysburg could not possibly be, as I claim, the preamble to the postbellum constitution. If Roosevelt did not intend to amend the Constitution with his court-packing plan, then the resulting changes in Supreme Court attitudes could not constitute a de facto amendment, a radical transformation of American law.
Here we take a page from British constitutional history to understand how a practice can be become part of the accumulated historical constitution without this being the purpose of those who initiated the practice. The British Constitution remains, as is well known, famously unwritten. Customary rules determine the role of the Crown in a system that has evolved as a constitutional monarchy. Only the accepted practice of generations prescribes that the queen must sign legislation for it to be binding as law or that the queen may intervene, under certain circumstances, to break a party deadlock and select a nominee for prime minister.19 In all systems of customary law, the relevant perspective is not that of those who first engage in the practice but rather of those who witness the pattern of the past and adopt it as binding on themselves. So it is with the Gettysburg Address. The right question is not what Lincoln intended, but rather what the words meant to those who looked to them as the explanation of the war and as a charter for freedom and equality for all Americans. If the address had been ignored, it would not have mattered what Lincoln intended. But because these 268 words20 were adopted into the civil religion of the United States—the secular meditation on who we were and what we were about—their life after formal recitation by the president determines their constitutional status. They are the preamble to the constitutional order because we came to understand them as nearly sacred. And although we did not until now think of this secular prayer as the preamble to a new order of nationhood, equality, and democracy, that is what they became.
These words are, in fact, better known in the United States than the preamble to the first Constitution. Schoolchildren routinely recite them and thereby imbibe the intuition that these words defined America after the Civil War. Yet, because we know these resonant phrases, we rarely stop to listen and ponder the meaning of each well-crafted line. Let us now put ourselves among the crowd of mourners at Gettysburg. Let us transport ourselves back into the frame of mind of those suffering losses, those looking for the meaning of brothers slaughtering brothers.

Four score and seven years ago our fathers brought forth on this continent a new nation, conceived in liberty and dedicated to the proposition that all men are created equal. Now we are engaged in a great Civil War, testing whether that nation or any nation so conceived and so dedicated can long endure. We are met on a great battlefield of that war. We have come to dedicate a portion of that field as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. But in a larger sense, we cannot dedicate—we cannot consecrate—we cannot hallow this ground. The brave men, living and dead, who struggled here have consecrated it far above our poor power to add or detract. The world will little note nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain, that this nation, under God, shall have a new birth of freedom, and that government of the people, by the people, for the people shall not perish from the earth.









Zoot Suit
A style of suit worn by African Americans, Filipino Americans, and Mexican Americans during the 1930s and 1940s. In Chicano culture this style of dress is primarily associated with the pachucos of the 1940s. The fashion at that time was to wear very baggy pants with pegged legs, long jackets with high and sharp shoulder pads, thick-soled shoes, and long watch chains dangling from the belt. An addition to the whole style common to Chicanos was a particular haircut, long with a ducktail and a wide-brimmed hat.
The word zoot was known within the urban jazz culture of Harlem, and it meant something either exaggerated in performance or in style. Many African Americans wore an extravagant style of clothing, the baggy pegged pants and jackets with padded shoulders, that later became known as the zoot suit. In the novel Invisible Man by Ralph Ellison, he describes the zoot--suiters’ style, “walking slowly, their shoulders swaying, their legs swinging from their hips in trousers that ballooned upward from cuffs fitting snug about their ankles; their coats long and hip-tight with shoulders far too broad to be those of natural western men” (1947, 380). In the late-night jazz scenes of Harlem this style was “a killer-diller coat with a drape-shape, reat-pleats and shoulders padded like a lunatic’s cell” (380). Tyler makes the point that the zoot suit was an extremely symbolic costume, which gave the wearer the look of a child in adult clothing. The broad square shoulders gave a macho look to the youth, and the finger-tipped coat was made for fun and leisure. The long baggy pants were made for dancing, especially the jitterbug, and the wide Panama hats were another sign of adulthood. “The business of fun, dancing and dating were the key characteristics displayed by Zoot-Suiters. It was an escape from drudgery and futile labor to the bliss of free-wheeling movement in the city among youths in the new youth culture” (Tyler, 23). Prominent black entertainers wore the zoot suit, such as Cab Calloway, Sammy Davis Jr., and Duke Ellington. Ellington performed at the Orpheum in Los Angeles in 1941 and 1942 with a musical called Jump for Joy in which the performers wore zoot suits, also known as Gone with the Wind suits, after the style worn by Clark Gable in the movie by the same name.
Even though the zoot suit was worn by the young men of several different races and ethnicities, it is primarily identified with the pachucos of Los Angeles. Pachucos were mostly second-generation Mexicans, the sons of migrant laborers and working-class immigrants. Pachucos created their own subculture, an arrogant style of dressing, a bilingual secret argot, and for some individuals membership in petty criminal gangs. The zoot suit became a symbolic disguise that identified the zoot-suiter as neither a Mexican nor an American. It was not a bicultural or binational position, but rather a position between cultures, a “hanging in space” position. The overly confident, slow swagger of the pachuco, today exemplified by the cholo, made it appear in fact as if the zoot-suiter were walking on air.
During the summer of 1943 the attention of the whole country was on Los Angeles when gangs of sailors and zoot-suiters battled with each other in the streets of the city. It is unclear if this was a race riot or a riot of patriotic sailors who attacked, beat, and stripped young Mexican Americans whom they perceived to be unpatriotic zoot-suiters. Between the third and thirteenth of June zoot-suiters were open targets. Much has been written about these riots from both literary and historical perspectives.
During the late 1970s the zoot suit received wide recognition and popularity with the production of a successful play by Luis Valdez. In 1981 a film by the same name, Zoot Suit, was produced and directed by Luis Valdez, with performances by actors Daniel Valdez and Edward James Olmos.
See also Cholos; Pachucos
References Barker 1950; Cosgrove 1989; Ellison, 1947; Mazon 1984; Orona-Cordova 1992; Sanchez 1978; Stone 1990; Tyler 1994; Valdez 1992; Zoot Suit 1981
Zozobra
A giant, forty-foot effigy in the form of a puppet, which is burned during the annual Santa Fe Fiesta held in Santa Fe, New Mexico. The word Zozobra translates to “gloom” or “worry” or “anguished.” The Zozobra is ritualistically burned at the beginning of the fiesta, which symbolizes the end of destructiveness, gloom, and worry, setting the tone for a successful fiesta. The creation of Zozobra was introduced into the fiesta in 1926 by Will Shuster, who felt that the fiesta had become “dull and commercialized.” Throughout the years the image of Zozobra changed from a simple twenty-foot puppet to the elaborate forty-foot figure with animated eyes, arms, and mouth that he is today. In 1969 Shuster turned over the responsibility and copyright of Zozobra to the Kiwanis Club of Santa Fe. He is hung on a tall pole on a hill, outside the city, where the burning can be seen by the thousands of people who come to watch. The death of gloom is supposed to resurrect happiness.
In response to the tradition of the burning of Zozobra, a group of New Mexico Chicanos started a tradition of burning El Kookoóee, a figure known by many Chicanos as the bogeyman, during the Festival de Otoño.
See also El Kookoóee; Santa Fe Fiesta
References Cohen 1985; Grimes 1976; Weigle and White 1988










Yard Shrines
The creation of yard displays, as shrines or ofrendas (offerings), or nacimientos (nativity scenes) during Christmas, is an important way to commemorate many holidays such as Halloween, Día de los Muertos (Day of the Dead), Cinco de Mayo (Fifth of May), and even the Fourth of July. A yard shrine may be a permanent display in the form of a small chapel, a nicho (niche), or a gruta (grotto or shrine), set up in the front yard of a home. It may contain one or more holy images, of saints or the Virgin Mary, especially La Virgen de Guadalupe, flowers or potted plants, colorful garlands, and votive candles. These shrines are often just called nichos, and the word shrine is not even mentioned. During special holidays such as Christmas or on a saint’s feast day, a shrine may be lighted up for the community to share. It is a common practice to make the sign of the cross or recite a short prayer when walking past a religious yard shrine.
In many families the shrine is erected as the result of a promesa or manda (promise or vow) made to a particular saint, or in memory of a family member who has died. A yard shrine, whether called a nicho or a gruta, can be decorated in various ways. There are always plants and flowers, sometimes seashells decorate the outside if it is constructed of cement, and the decorations will reflect the holiday season of the year. At Christmas, there may be lights, tinsel, and poinsettias. During Lent there may be lilies and pastel paper chains. Yard shrines demonstrate that religion is integrated into the life of a family, and they are considered to be sacred sites for prayer and devotion. There is no division between the public life and the religious and devotional life of a Chicano family. A yard shrine is a public exhibition of a family’s religion and their devotion to a particular saint, as well as a display of an artistic sensibility, that emerges unconsciously from the family’s beliefs.
A related form of yard folk art, not necessarily religious, is the yard asamblea (assemblage). A well-known man in Los Angeles, referred to as “El Hombre de las Banderas” (The Man of the Flags), created spectacular scenes up until his death in 1992. Art created in the yard of one’s home serves to draw in the community and make it a participant. These yard sculptures are created from bits and pieces of contemporary life and popular culture, drawn from many different sources.
See also Folk Art; Grutas; Nacimiento; Nichos; Ofrenda; La Virgen de Guadalupe
References Boyer 1988; Griffith 1992, 1995; Husband 1985; Kitchener 1994; Ramos 1991; Vidaurri 1991; West 1991
Yardas (Gardens)
Although the Spanish word for garden is jardín, many Chicano families favor the term “yard” while referring to their gardens, pronouncing it in Spanish as yarda. Although yarda appears to be a pochismo (Chicano slang), it can be found in Cassell’s Spanish Dictionary. The layout and organizational aesthetics of Chicano yardas are unique enough that folklorists and cultural geographers have written about them. Many yardas can aesthetically constitute yard art, even though it does not appear that this is the intent of the creator. Besides planting shrubs, flowers, and sometimes grass, the gardener will bring into play the creativity that goes into decorating a yard unconsciously, with the result being a folk art display. Invariably, a yard will contain many potted flowers arranged in a patterned manner. The central focus of many yards is often a devotional shrine set up in memory of a family member, with a nicho housing a saint or Madonna, and the design of the yard’s plants and flowers is laid out in reference to the shrine. Some yardas may not have planted grass, but instead hard-packed dirt that is kept free of weeds, swept frequently, and kept prepared for family gatherings. But trees, preferably fruit trees, abound to make shade for family gatherings and outdoor cooking.
A common practice among many working-class Mexican Americans is to recycle as much as possible, although the concept that recycling is an environmentally correct thing to do is not always known. Common recycled objects that can be found in yards are tables, kitchen pots, painted tin cans, and car tires used as planters. Tires are cut across the width, making two containers, opened up and cut with a scalloped design around the edges. After being painted and filled with flowers and plants, these plant containers do not even resemble their original form. Recycled tire planters can line a driveway or establish the boundaries of a large yard. The practice of reusing objects that have lost their original purpose, such as kitchen pitchers and pots, is a means of keeping something familiar, something associated with a memory, alive and finding a new use for it. This practice probably originates from poverty, but the historical result has been that it creates its own aesthetic in adding adornment to one’s home and life. These “yardscapes,” as they’ve come to be called, are composed of bits and pieces of one’s personal life and as such can add visual charm and historical value to a home. A family’s religious and cultural values, as well as the special identity of being Mexican American, can be found in yardas.
See also Folk Art; Nichos; Yard Shrines
References Kitchener 1987; Ramos 1991
Yo Soy Joaquin 
See I Am Joaquin/Yo Soy Joaquin










Water Spirits
See Chanes
Wedding Customs
Chicano wedding rituals vary from state to state in the Southwest and the Midwest, often incorporating emerging American customs, but there are still common traditions that originate with Catholicism and the Spanish heritage that are shared from community to community. The Spanish word for a wedding is boda, meaning “nuptials,” and often Chicanos will call a wedding celebration La Boda. The southwestern region with the most researched and documented wedding customs is New Mexico, because the descendents of the early Hispanos have been conscious of describing and writing down their traditions. For instance Fabiola Cabeza de Baca, Cleofas Jaramillo, and Nina Otero all wrote about the weddings of northern New Mexico. In her book The Good Life, Fabiola Cabeza de Baca has a brief chapter on wedding traditions, including recipes and a detailed description of the preparation of the food.
When a couple married, three main ceremonies took place. These were initiated after the groom and his family had asked the girl’s family for her hand in marriage. If the girl or her family refused the offer, she would send a letter to her suitor with her negative response. This was termed as giving cala-bazas (squash or pumpkin) and was a great insult to the wooer. Of the ceremonies, first there was el día del prendorio (day of the engagement), when the bride and groom came together publicly for the first time. A great celebration would take place, usually in the home of the bride, with food, drinks, and music. This festivity would be equivalent to an engagement party. The day of the wedding was called el día del casorio and could last from two to three days. The upper classes held lavish wedding ceremonies that would last for days with lots of music and food for their many guests; the poorer folks also followed many of the same traditions, although in a more modest fashion. It was the tradition that the bridegroom’s family hosted the celebration after the church service. There was always an orchestra that played while the guests ate, and a big dance on the eve of the wedding day. After the dance, or at the conclusion of the feast, there was the entrega de novios (delivery of the wedding couple), when the wedding couple was formally returned to their parents and placed under their guidance. Songs from this ritual were collected by Juan Rael and reveal the solemnity of the ceremony.
The Hispano folklore does not specify the actual religious sacramental rituals, but more recent publications do describe church ceremonies that are still observed today. In very traditional weddings, the arras, thirteen coins or pieces of silver, are given by the groom to his bride as a symbol of security. After the wedding vows are stated during the Mass, a lazo, a cord with two connected loops, is draped over the couple, to symbolize the union of bride and groom. Just before the couple leaves the church, the bride, or sometimes a designated child, will pay tribute to La Virgen de Guadalupe by placing flowers at the foot of her statue or picture. There are always lots of padrinos (godfathers) and madrinas (godmothers), bridegrooms and bridesmaids, and of course Mariachi music.
Frances Toor’s classic book on Mexican folklore, A Treasury of Mexican Folkways, relates wedding customs of the various regions and indigenous groups of Mexico. A not-so-typical Chicano wedding from southern California in the 1950s is depicted in the novel The Wedding by Mary Helen Ponce.
References Cabeza de Baca 1982; Espinosa 1985; Fernandez Mines 1977; Haralson 1980; Rael 1942, 1975; Rivera 1976; Sawin 1985; Toor 1947
Wetback 
See Alambrista; Mojado
Witchcraft 
See Brujería
With His Pistol in His Hand
The title of a book by the eminent professor Américo Paredes that has become a classic in American folklore and Chicano studies. With His Pistol in His Hand: A Border Ballad and Its Hero, published in 1958 by the University of Texas Press, is not only one of the most important academic works on the history of the Chicano, but it is also respected as major scholarship in the field of folklore studies, and specifically on the genre of the ballad. It is a study of a border ballad, “El Corrido de Gregorio Cortez,” which looks at the history of the Texas-Mexican border and the life of Gregorio Cortez, and presents an analysis of the man as a ballad hero. As stated by Paredes himself in the introduction, “It is an account of the life of a man, of the way that songs and legends grew up about his name, and of the people who produced the songs, the legends, and the man” (1958, 1). It was in this work that Paredes proposed his theory of the production of Chicano folklore, and especially the border ballad, as a result of a process of border conflict generated by the invasion of Anglo culture and values into the Texas region in the early nineteenth century. The balladry of the Rio Grande border was “one of resistance against outside encroachment” (1958, 244). There was an “inner need” for the people to compose ballads that sang of the deeds of a man standing up for his rights, who in the process is transformed into a hero. Often, the man is nonviolent, but is coerced through persecution or abuse into killing his enemy, often a Texas Ranger, and must escape to the border. “His defeat is assured; . . . often he is killed or captured. But whatever his fate, he has stood up for his right” (149).
When the book was published it caused quite a stir in Texas because of its negative portrayal of the Texas Rangers. The chief editor at the University of Texas Press asked Paredes to delete his critical references to Walter Prescott Webb, J. Frank Dobie, and the Texas Rangers. The book was eventually published in spite of his refusal to make any changes. The timing of its publication was crucial, in 1958, for its powerful influence on Chicano students and intellectuals, since it came out just before the start of the Chicano movement of the 1960s. Its intellectual and political impact on a whole generation of Chicano scholars cannot be overstated. Almost all publications on Chicanos and Mexicanos up to that date had been written by Anglo American sociologists or anthropologists, and the few published Hispano scholars, such as Aurelio Espinosa and Arthur Campa, were only known within a narrow circle of folklore specialists. Gregorio Cortez, the border hero, and Américo Paredes, the scholar hero, both became figures that young Chicano students could respect and emulate.
See also “El Corrido de Gregorio Cortez”; Corridos; Paredes, Américo; Los Rinches
References Limón 1980a, 1986, 1990, 1992; Paredes 1958










Vaqueros (Cowboys)
The vaquero was the early Hispano cowboy and the antecedent of the Hollywood cowboy. Horses and cattle were brought to New Spain by the Spaniards. When Hernán Cortés landed on the eastern shore of Mexico, he had with him sixteen horses and at least three breeds of cattle. Cattle breeding was a tradition hundreds of years old in Spain, and Cortés brought this tradition to Mexico and eventually to the Southwest. The Spaniards introduced the system of el rancho, with vaqueros being the workers who herded the cattle and conducting cattle drives. Vaca means “cow” and a vaquero is “one who works with cows.” The Spanish mission padres recognized this labor and conscripted mestizos (mixed-race people), Indians, and Mexicans to take care of the cattle. It was these individuals who developed the system, equipment, practices, and traditions that have lasted these past few hundred years. The Anglo cowboy learned everything about cattle from the vaquero.
The Mexican vaquero was a laborer, a peon who was used by the missionaries to ride the horses and take care of the cattle. So it was the culture of the vaquero that became the basis for the romantic cowboy of Hollywood. The ensemble, equipment, and clothing of the vaquero evolved through the years as a combination of Spanish leather and regional indigenous fabrics. He always wore a sombrero with a wide brim, a leather chaqueta (jacket), tight-fitting knee-length sotas (breeches), and botas (leather leggings) for protection. The vaquero also wore iron spurs, like those worn by the Conquistadores, which are still worn to this day. The various styles of saddles, from the Moorish to the Spanish war saddle, eventually changed when the vaqueros began making their own saddles, more suitable for riding hard and for quick mounting and dismounting.
The early vaqueros, those of the sixteenth and seventeenth centuries, were mestizos, Indians, Negroes, and mulattos. When Anglo Americans moved into Texas and bought enormous tracts of land, they established huge ranches and hired Mexican vaqueros to work them. They recruited and moved whole families from Mexico to work and live on their ranches. The King and Kennedy ranches of east Texas are contemporary examples of this tradition and have many generations of Mexican vaqueros still living on their ranches. A social historical study of the vaquero life on the King and Kennedy ranches, from the early nineteenth century to the present, has been written by Monday and Colley.
The vaquero from California also worked on very large ranches, such as the Tejon ranch in the lower San Joaquin Valley. This way of life has been memorialized in the work of Arnold Rojas, who was a vaquero and has written about his life in California in the twentieth century. Rojas makes a distinction between the cowboy, the vaquero, and the buckaroo. The vaquero was originally Hispanic or Mexican, or Indian, and herded cattle in the Far West in the states of California, Nevada, Oregon, Arizona, Utah, and Washington, whereas the cowboys who herded cattle in the southern states were usually Negro or Anglo. The vaquero or buckaroo is a westerner and the cowboy is a southerner. The definition is a territorial one, with the cowboy working east of the Rockies and the vaquero west of the Rockies. It is this difference that Rojas writes about in his three-volume memoir of the California vaquero. Anglos coined the word buckaroo, meaning vaquero, because they disliked the word cowboy and did not want to call themselves by that name. Somehow when they pronounced vaquero, it came out of their mouths as “buckaroo.” The California Indians were trained by the Spanish missionaries to herd cattle, and they were the primary vaqueros until the mid-1800s. Mexicans from Sonora took over as vaqueros when they started migrating into California in the nineteenth century. The style of horse riding instituted by the Spaniards was called la jinete, a term that relates to the equipment used in riding. It not only includes the bits, spurs, and the saddles, but also the length of the stirrups, how the reins are held, and the amount of pressure of the knees on the horse. Rojas was born in California, as was his mother, who as a child had a pleasant encounter with the bandit Tiburcio Vásquez. He spent his whole life working as a vaquero and he states, “I speak as a vaquero—and I know whereof I speak” (Rojas, 1979, 119).
References Graham 1990, 1991, 1993; Mather 1992; Monday and Colley 1997; Rojas 1958, 1979; Verti 1990
Vásquez, Tiburcio (1835–1875)
A legendary Chicano folk hero who roamed through California’s San Joaquin Valley during the late nineteenth century. He came from an old Californio family who owned extensive property and a large ranch. But he also lived during a time when Anglo Americans were becoming dominant in the state, when overt discrimination against Mexicans who were considered foreigners was on the rise, and he fell into a life of crime. Compared heroically to Joaquín Murrieta, Tiburcio Vásquez is regarded as a proud man who resisted social domination and fought to maintain and preserve his culture. He actually lived fairly long but was eventually captured, tried, and hanged at the age of forty.
He was born in Monterey County in 1835 or 1837, where he was raised and attended school, becoming fluent in both English and Spanish. His career of flight and lawlessness started in 1851 when, with several other men at a fandango, he witnessed or was involved in the death of a constable named Hardimount. Not expecting to be treated justly, he fled to the hills, and from then on, Vásquez led a life of horse stealing, robbery, and hiding out in the foothills of California. The legend states that he shared his stolen goods with the poor Mexicans of the Salinas Valley. He was well liked and depended on the local people to hide him from the posses that were continually after him. He was captured several times and actually spent almost nine years in San Quentin prison, on two different occasions, first in 1857, then again in 1867. After being released in January of 1870, Vásquez spent the next four years in a life of banditry but also one of romance. Women were attracted to him and he frequently fell in love, and he had a special weakness for married women. He claimed to have never killed a single person, and when he robbed people in stores and stagecoaches, he’d tie them up and lay them face up on the ground, a tactic he used often during this period. One source refers to his “hog-tied” captives. He was shot and survived several times but was finally caught in May of 1874. While awaiting trial in the San Jose jail, Vásquez appealed for funds for his defense. Thousands of people came to visit him in jail, bringing flowers, food, and other gifts. With the funds raised he was able to hire two well-qualified lawyers. Even so, he was found guilty by a jury and sentenced to death. He was publicly hanged on March 19, 1875, in San Jose, California.
There are many stories recounting the legendary exploits of Vásquez, especially those dealing with his romantic life, as he was considered a true Don Juan. On several occasions it was a lady that saved him from the legal authorities by helping to hide him. Once, at a party or fandango, a woman hid him under her great hooped dress, where he crouched silently until the constable gave up his search of the premises. Another anecdote of narrow escape tells the tale of Vásquez being hidden in the bed, under the covers, of a newly birthed mother. His friends offered to hide him by letting him crawl under the covers at the foot of the bed while the mother showed off her newborn to the sheriff.
Luis Valdez wrote and directed a play about Vásquez titled Bandido!, performed at the Mark Taper Forum in Los Angeles in 1994. Valdez stated, “All I’m doing is raising Tiburcio Vásquez to his appropriate mythic status in the mythology of the Old West.”
See also Murrieta, Joaquín
References Burciaga 1993; Castillo and Camarillo 1973; Greenwood 1966; Jackson 1939; MacLean 1977; Siegal 1994
Vato Loco (Crazy Dude)
See Bato
La Vida Loca (The Crazy Life)
An expression that describes the urban gang life of Chicanos in large cities, such as Chicago and Los Angeles. La vida loca alludes to a way of life of thousands of young Chicano men and women who are submerged in a fast drug-using life, depending mostly on their friends and gangs for support and loyalty.
The dress style of the young men, sometimes called batos locos, usually teenagers, is a Pendleton shirt; perfectly pressed, loose khaki pants; a bright white undershirt; and shiny shoes. The girls, rucas (Indian girls) or cholas (mestizo girls), may wear the same khaki pants or short tight skirts, highly teased long hair, and lots of eye makeup. La vida loca is often romanticized, but it is the hard life of survival in an economically depressed environment and relying on a drug culture and gang members for support.
In the novel Maravilla, Laura Del Fuego shows la vida loca of the 1960s in the barrio of Maravilla in Los Angeles. Oscar “Zeta” Acosta, in his Autobiography of a Brown Buffalo, shows the life of batos locos in the barrios of Los Angeles, also during the 1960s and 1970s. Luis Rodriguez has written a wonderful memoir, dedicated to his son, that depicts the crazy life he led in Los Angeles in the 1970s. Gus Frias presents a much more somber picture of the violent way of life led by those in la vida loca.
A film titled Mi Vida Loca, produced in 1993, depicts the life of a group of homegirls, las locas, in the Echo Park area of Los Angeles. Teenage single mothers are portrayed as independent and strong, struggling with boyfriends involved in drugs, but also the friendships and strong relations among the girls are presented realistically. Several of the actresses in the movie were actual gang members. In 1999 the Latino singer Ricky Martin popularized the expression in American popular culture by using it as the title of a song.
See also Bato; Cholos
References Acosta 1972; Del Fuego 1989; Fregoso 1995; Frias 1982; Mirandé 1985; Rodriguez 1993 
La Vieja Inés y Los Listones (The Old Mother Game)
A very old game played by little girls that is known by various names. It is called Los Colores (the colors), Los Listones (the ribbons), and Tan Tan. The main players are la mamá and “Saint Inez,” who may also be called La Vieja Inés (Old Lady Inés) or La Virgen Inés (Old Maid Inés). All of the other players are given a color by the mamá: red, yellow, green, blue, or they may choose their own color. La Vieja Inés comes and pretends to knock on the door, Tan, tan. The mother asks, “Quién es?” (Who is it?) and the answer is “La Vieja Inés.” The mother asks, “Que quieres?” (What do you want?). “Quiero colores” is the answer. “Que color quieres?” (What color do you want?) “Quiero verde” (I want green), or any color is mentioned. The little girl whose color is mentioned runs away and La Vieja Inés tries to catch her before she reaches a spot designated as home base. The game goes on until all of the colors have been chosen and all of the girls are caught. In some versions the girls carry ribbons, each of a different color. Scholars who have analyzed the game point to the socialization of gender roles for little girls, and the game serves as a lesson in the inevitable eventual separation from the safety of home. This was one of the games collected by the Federal Writers’ Program in New Mexico during the 1930s. Although there were many games played by Hispano and Mexican children, this one appears to be one with a long historical tradition.
Jose Limón has written about a version found in Texas. It is an ancient game that can be traced to medieval Spain, to a place called Zafra. In the version from Zafra two teams are involved, one representing evil, the other goodness. One team is led by the devil, el demonio, and the other by an angel, ángel de la guarda (angel of the guard). Each player is named a color, and the two leaders, the devil and the angel, try to gain the most players. In this version it is a battle between good and evil to see who can win the most souls.
See also Hilitos de Oro; Naranja Dulce
References Cardozo-Freeman 1975; Ebinger 1993; Limón 1980b; Robe 1972; Writer’s -Program of New Mexico 1976
La Virgen de Guadalupe
Also commonly known as Nuestra Señora de Guadalupe, she is the Virgin Mary who appeared to Juan Diego, a Mexican Christian Indian, on December 9, 1531. Historical documents verify the story of her apparitions. She identified herself as the Virgin Mary, the Mother of God, and speaking in Nahuatl, she asked Juan Diego to go to the Spanish bishop and ask that a temple be built there where she appeared, the mount of Tepeyac. To Juan Diego she was a beautiful woman who spoke his language, so after much difficulty he sought to speak to the bishop, but his story was not heard, and he was asked to return another day. The beautiful woman appeared to Juan Diego a second time, and he was asked to seek the bishop’s audience again. On the second try Juan Diego saw the bishop, his story was heard and questioned, but was not believed. The bishop wanted a sign from the Great Lady so that he would know it was really she who was sending Juan Diego. Diego intended to go back to Tepeyac and inform the beautiful woman, but when he returned home he found that his uncle Juan Bernardino was extremely ill. The next morning, on December 12, as he walked to Tlatelolco to call a priest to come to his uncle’s side, the beautiful woman came to him a third time asking what was wrong. Diego told her of his sick uncle and of the request from the bishop. She told him his uncle was now well and would not die and sent him to the top of a hill to cut fresh flowers that he was to take to the bishop as proof of her existence. Diego followed her instructions and at the top of the hill he found beautiful roses of Castile, still covered with dew. He cut them and The Lady, the Mother of God, arranged them in his tilma (cloak) and sent him to the bishop, with the proof requested. When Diego unfolded his tilma in front of the bishop, the roses fell to the floor, and there on the tilma was an image of the Virgin Mary. Now the Spanish bishop believed, and as the beautiful woman requested, a church was built right on the mount of Tepeyac. The tilma with the image of the Virgin Mary still hangs in the temple called Guadalupe. The name that the beautiful Lady gave herself was Tlecuauhtlacupeuh, but to the Spaniards it sounded like Guadalupe, which they instantly recognized as “Our Lady of Guadalupe” from Estremadura, Spain. But the Aztecs understood that in the Nahuatl language the name Tlecuauhtlacupeuh meant “la que viene volando de la luz como el águila de fuego” (she who comes flying from the region of light like an eagle of fire).
Tonantzin was an Aztec goddess, literally called Our Holy Mother, also known as Tonan. Guadalupe appeared at what was once the temple of Tonantzin at the mount of Tepeyac. Even today in Mexico, La Virgen María is often called Tonantzin. The acceptance of La Virgen de Guadalupe by the indigenous population of Mexico was the beginning of Mexican Christianity and the conversion of the Aztecs to Catholicism. Guadalupe became the symbol of Indian Catholicism, different from the European Catholicism of the Spaniards. As the Aztecs adapted the Catholic religion to their indigenous beliefs, they created a religion that met their own needs and own way of life. She was declared the “Patroness of the Mexican Nation” in 1737, and in 1754 Pope Benedict XIV canonized Guadalupe as an official saint. She was crowned “Queen of Mexico” in 1895, showing how strong a symbol of Mexican nationalism she had become. Today she continues as the country’s strongest symbol of Mexican identity. The cathedral built in her honor can no longer be used because of structural damage, but a new one was built in the early 1970s. Masses are held every hour of the day and the church is constantly filled to capacity.
Faith in La Virgen de Guadalupe is one of the strongest convictions in Mexican and Chicano culture. Guadalupe has become a powerful cultural image. Her appearance was crucial in restoring dignity and humanity to a conquered people. Eric Wolf refers to Guadalupe as a “master symbol,” “a symbol which seems to enshrine the major hopes and aspirations of an entire society” (34). She is the mother of the mestizo race, La Raza (The People), and a political symbol for the oppressed and powerless. She is affectionately referred to as La Morenita, Virgencita, Lupita, Madrecita, Madre de Dios, and Nuestra Señora. Virgil Elizondo, a Chicano theologian, states, “Guadalupe is the key to understanding the Christianity of the New World and the Christian consciousness of the Mexicans and the Mexican Americans of the United States” (26).
Belief in her power as a mediator for the oppressed has prompted faithful followers to carry her image into battle for over 400 years. Father Hidalgo, during the Mexican War of Independence; Emiliano Zapata, during the Mexican Revolution; and César Chávez, during his battle for farmworkers’ rights against California agribusiness, all carried the emblem of La Virgen de Guadalupe. The image of Guadalupe provides support for those who believe in her divine power as the deliverer from oppression.
El Teatro Campesino has created a cultural piece titled La Virgen de Tepeyac (The Virgin of Tepeyac). For many years now it has been performed during the early part of December in the mission church of San Juan Bautista, California. It has become a Bay Area Christmas tradition to make the two-hour journey to the small mission town to experience the miracle of Guadalupe, although all Mexican American churches throughout the United States organize elaborate church ceremonies for December 12, the day of her appearance, so there are literally hundreds of celebrations one can choose from to commemorate the day.
Contemporary Chicanas continuously look toward Guadalupe and reevaluate her influence in their mothers’ and grandmothers’ lives and in their own lives. Although she is the preeminent representation of womanhood, she has become an icon for women’s subjugation and oppression. In the 1970s the artist Yolanda Lopez created a memorable image of working mothers by painting a garment worker at a sewing machine within the recognizable blue shield background that is easily acknowledged as the emblem of La Virgen de Guadalupe. In New Mexico a young Chicana created a dance theater piece titled Apariciones de la Madre, which incorporated modern ideas of women into the traditional images of the Aztec Guadalupe.
Chicano muralists have painted images of Guadalupe in her traditional Aztec setting on barrio walls since the late 1960s, and often other cultural symbols, such as a low-rider car, are added to emphasize the Chicano experience. La Virgen de Guadalupe is revered religiously, candles are lit for her, flowers are left at the church for her, and yet she is very much a part of popular culture. Her image is found on T-shirts, key rings, low-rider car hoods, and tattooed across adult male chests. Her face and form are frequently deciphered on tortillas, shadows on walls, and the trunks of trees. When such an image is found, thousands of people, whether in Mexico or the United States, flock to see and pray before the image. The influence of Guadalupe is as powerful today as it was 450 years ago.
See also El Teatro Campesino
References Alarcon 1989; Brundage 1979; Demarest and Taylor 1956; Elizondo 1977; -Johnston 1981; Lafaye 1983; Lea 1953; Quirarte 1992; Rodriguez, J., 1994; Vigil 1994, 1998; Wolf 1958










Ranchera (Country Song)
It is accepted that the word ranchera refers to a type of Mexican song, although sometimes it is an adjective that describes a character or a type of person. Ranchera comes from the word rancho, meaning a “cattle ranch, farm, or rural settlement.” A poor unsophisticated person may be called a ranchero or ranchera, implying he or she is from the countryside, the sticks, and a hick. In the context of Mexican folk music la canción ranchera is a love song, sung by the common folk, the peasants of the rural countryside. After the Mexican Revolution rancheras became more agreeable to the upper classes because of the movement toward a Mexican identity and nationalism and a rejection of European cultural values. The modern canción ranchera was made popular in Mexico City in the early 1950s by the songwriter José Alfredo Jimenez. The poetic structure of the ranchera is brief and simple, yet emotionally it is very intense. According to Rubén Campos as quoted by Gradante, “it is a moan and a sigh . . . , the briefest form of composition and, as such, requires a greater intensity of expression than any other compositional form. It must say precisely what it means” (1983, 105). The themes of rancheras are love and unrequited love, but from the point of view of the ordinary common man. Rancheras express the poetry of the masses. The famous ranchera singer Amalia Mendoza states, “the canción ranchera expresses the sensibility of the masses and reaches them: thus, its popularity. . . . One might say that the canción ranchera reflects the personality of the masses because it expresses something vital that we all have in common” (Gradante 1983, 105).
The ranchera originated in Mexico but is very popular in the United States among Mexicans and Chicanos. José Alfredo Jimenez wrote over 500 songs, many becoming classics that continue to be sung today by younger artists, that have a universal sentiment that speaks to the hearts of Chicanos. Because of the style of these romantic songs, sung to Mariachi music and sung in Spanish, untranslatable rancheras express the epitome of Mexicanness. The musical poetics arouse emotional sentiments about lost loves, nostalgia, and by extension about being Mexican. Songs such as “Ella” (Her), “Camino de Guanajuato” (Road to Guanajuato), “La Vida no Vale Nada” (Life Has No Value), and “Llego Borracho el Borracho” (The Drunk Arrived Drunk) all elicit memories of fathers, grandfathers, and stories of Mexico. Many are drinking songs, frequently shown in movies being sung in cantinas (bars), but they are also dancing songs, so they are played at celebrations and family gatherings. Although rancheras are intensely male centered, there are several female singers who became famous singing rancheras, such as Lola Beltran, Lucha Villa, and Amalia Mendoza. The performance of rancheras is always dramatic and emotional, whether performed by men or women, and the audience can always empathize with the situations depicted in the verses. The life experiences portrayed in the songs of José Alfredo Jimenez, who came from a poverty-stricken background himself, are about the struggles of Everyman, the need for social acceptance, personal happiness, and some type of financial security. These are concerns that the average Mexicano and Chicano can identify with. Although most rancheras speak of love, other life situations found in the songs deal with fortune, destiny, and life’s choices. In “Camino de Guanajuato,” these existential words open the song:
No vale nada la vida,
La vida no vale nada,
Comienza siempre llorando,
Y así llorando se acaba.
(Of no value is life
Life is worth nothing
It always begins with weeping
And with weeping it ends.)
References Gradante 1983; Peña 1985a, 1985b
Rascuache (Downtrodden Folk)
Also spelled rascuachi, rasquache, rasquachi, and rasquachismo, this Mexican word characterizes a poor people’s and working-class people’s worldview and defines how engaging and cultural beauty is created by them. It means that in spite of poverty, a pleasurable outlook on life inculcates a perspective that results in the creation of a pleasing cultural environment, composed of whatever elements are available. These elements may be art, home decorating, entertainment, language, the creation of religious objects, altars, anything connected to the creation of a special and spiritual life. For an individual it defines an attitude, a sensibility, or a social condition. It can describe the car, the house, clothes, a whole way of life. The Diccionario de Mejicanismos defines rascuache as pobre, “a miserable person,” poor, lowly, wretched. The rascuaches are the downtrodden, the lowly people, persona que no vale nada (person that is worth nothing). In English it could be interpreted as “funky,” humble, unsophisticated. What is most important about the concept of rascuache is that it captures a propensity or an aesthetic, according to Ybarra-Frausto, to persevere and make whatever one possesses, or has at hand, work well together. All resources are considered riches, and an inventiveness in the use of available resources results in a rascuache lifestyle. Whether one is cooking a meal, dressing for a party, assembling a garden, or decorating a Christmas tree and nativity scene, a rascuache sensibility will ensure that the final outcome will be elaborate, colorful, an unrestrained aggregate of rich resources. This aesthetic can be observed in the creation of yard shrines, graveyard sites, and in home decorating. Ybarra-Frausto has written a wonderful essay about rasquachismo that shows how Chicanos incorporate this spirit in the cultural life of the community. In his words, “Rasquachismo is brash and hybrid, sending shudders through the ranks of the elite who seek solace in less exuberant, more muted, and purer traditions. . . . To be rasquache is to be down, but not out” (1991b, 156).
This underclass aesthetic was vigorously exhibited by El Teatro Campesino (the Farmworkers’ Theater) in the creation of the stock characters that constituted the core of the Teatro’s actos (dramas). In the 1970s the group created and successfully performed a play called La Carpa de los Rasquachis (The Tent of the Rasquachis) about a family named Rasquachi. The figure of el pelado (the clown) distinctly exemplifies the rascuache outlook, the underdog figure, who is both victim and hero at the same time, a Cantinflas archetype. The prototype of the rascuache character was Pito Perez, the protagonist of the novel La Vida Inútil de Perez (The Futile Life of Pito Perez) by Jose Ruben Romero, first published in 1938 and reprinted many times, most recently in 1993; and also Don Chipote of Las Aventuras de Don Chipote written by Daniel Venegas in 1928, a journalist who lived in Los Angeles.
See also Carpas; El Pelado; El Teatro Campesino
References Broyles-Gonzalez 1994; Mesa-Bains 1999; Ybarra-Frausto 1991b
La Raza (The People)
The literal translation of this term is “the race,” but it has come to be used as an in-group name for Mexican and Chicano people. Translated as “the people,” it is recognized as meaning all mixed-race Spanish and Indian people, known as mestizos. The term encompasses all Latinos (Latin Americans) who are descendents of the Spanish and Indian encounter. The Mexican intellectual José Vasconcelos wrote a book in 1925 titled La Raza Cósmica: Misión de la Raza Iberoamericana. Publishing after the Mexican Revolution, Vasconcelos envisioned the successful future of Mexico to lie in the strong bonds of its mixed-race population. Before the Revolution, in the nineteenth century, Mexicans looked toward a European identity, and most of the upper classes considered themselves white Europeans. The indigenous population of Mexico was segregated and not racially mixed, and the mestizos were more closely aligned with the Indians than with the upper classes. Vasconcelos wrote his slim volume in his search for a Mexican identity for himself and for Mexico’s population. La Raza is used by Chicanos because they identify as mestizo people and see themselves as members of a special race, a group of people with a distinct heritage and destiny. Chicano writers, artists, professionals, musicians, and students are invigorated by the proclamation of “La Raza!” and inspired to work toward a creative and political unity. In the words of Jose Angel Gutiérrez, as quoted by Arnoldo Vento, “La Raza is the affirmation of the most basic ingredient of our personality, the brownhood of our Indian ancestors wedded to all the other skin colors of mankind. . . . As children of La Raza, we are heirs of a spiritual and biological miracle” (225). The “Viva la Raza!” chant is a frequent opening and closing statement at festivities, concerts, political meetings, anywhere Chicanos might come together. In the 1970s, the first political party to be formed by Chicanos in the U.S. was called La Raza Unida Party. October 12, known in the United States as Columbus Day, is celebrated throughout Latin America as Día de la Raza, or Day of the People. It is celebrated by New York Puerto Ricans and Cubans and Chicanos throughout the country. It marks the birth of Hispanic heritage and the beginning of Hispanic culture because it is the day Columbus landed in the New World. It is unclear if President Ronald Reagan was aware of this when he declared Hispanic Heritage Month to be celebrated September 16 through October 15.
References Schmidt 1978; Vento 1998
Relajo (Joking Behavior)
A form of joking behavior visible among Mexicans and Chicanos, with close friends and family, that creates solidarity within the group, but that also allows humorous or satirical discussion of taboo topics that are of importance to the group. Jorge Portilla’s essay on relajo is often cited as the fundamental study of this comic conduct found among the Mexican working class. His analysis focuses on the dynamics of this joking behavior, relajando, and how the working poor utilize it to disrupt values imposed on them by the social classes in power or the dominant culture. Mexicanos living in urban poor communities experience almost daily a breakdown in social relations. In brief, Portilla’s definition states, “In summary, relajo can be defined as the suspension of seriousness that rejects a value maintained by a group of people” (25). This suspension of seriousness in the face of officially serious issues, such as life and death, permits an individual to feel free and detached. Through verbal performances, joking, and narrating humorous anecdotes, an individual can suspend elements of gravity, snobbery, or socially imposed acceptable conduct.
In Mexican social thought the role of relajo behavior is shown to be a criticism of the political corruption of the government, but also a burlesque of the divisions of the social classes. Cantinflas, the Mexican actor, was the great relajero of all time. As a comic actor, he was the premier artist of the relajo, whereby in a single ludicrous, narrative monologue he could inadvertently chastise the urban poor, and champion the social needs of the upper classes, thus highlighting the obvious disparities. But his relajando behavior, the social situations and entanglements he got into, were also subversively configured to emphasize the extreme illegitimacy of the social structure. His personality not only entertained but also fulfilled a seditious function, taunting the excesses of the wealthy and the absurdities of a structured social system.
Relajo can also describe a joking relationship, a bantering back and forth, which through the laughter relieves tension and disintegrates the cause of the tension of the moment. But it is the breakdown of decorum, the rejection of a social value that everyone knows is necessary, yet proscribed, that the relajo subverts. The cultural consequence is that through this type of behavior one can become temporarily free from social constraints that in daily life cannot be rejected. If one could find a phrase in English that encompasses the relajo concept, it would be “to put one over on” a system or a situation. Relajando, or echando relajo (joking), can be lighthearted joking around or can be heavy in a serious way about a grave topic.
Farr has studied the joking behavior of Mexican women in Chicago and found that through echando relajo, married and young single women find relief from their gender roles and the social propriety imposed by their husbands, parents, and the Mexican culture. Laughter created by farcical comportment, or by satire, creates an opposition to the prescribed value and to the seriousness of it. Portilla calls the shared laughing una burla colectiva (a collective joke), and states that collective laughter facilitates the collective “negación a la conducta requerida” (negation of required conduct). Relajo can overturn values or what is assumed to be valued. El Teatro Campesino (the Farmworkers’ Theater) practiced the art of el relajo in the execution of its actos (dramas) and in the social protest messages propagated through satire and laughter.
See also El Teatro Campesino
References Barriga 1997; Broyles-Gonzalez 1994; Farr 1994; Fregoso 1993; Portilla 1966
Religious Folk Art
The creation of folk art is an unconscious aesthetic expression of community social and cultural values, and religious folk art is the aesthetic reproduction of images and symbols for a religious or spiritual purpose. The most obvious examples of religious folk art in Chicano culture are religious statues, the santos (saints), retablos (religious paintings), ex-votos, and paintings of La Virgen de Guadalupe. But there are many other shared religious experiences among Chicanos that result in the creation of religious folk art objects. The descansos, erected alongside rural roads where someone has died, become works of art that convey spiritual sentiments. Yard shrines that gradually swell with multicolored paper or plastic flowers, plants, statues of saints, and rosaries are also religious art when lovingly tended by family members. The same can be said for altars, nacimientos (nativity scenes), and camposanto (cemetery) graves, which are assembled with artistic care, while always communicating a devout religious sentiment. Bright coronas (wreaths) for cemetery grave markers with built-in nichos (niches) for saints and photos result in glorious displays of decorative art. During the celebrations of Día de los Muertos (Day of the Dead), galleries exhibit beautiful altars and ofrendas (offerings) assembled by artists for community viewing but also for the spiritual sharing that results. Religious icons carry great meaning in Chicano culture and always find their way into many folk art displays. La Virgen de Guadalupe is tattooed on the backs or chests of hundreds of Chicanos, and this too can be considered religious folk art.
See also Altars; Camposanto; Descansos; Día de los Muertos; Nacimiento; Retablos; -Santos
References Awalt 1998; Boyd 1974; Espinosa 1967; Griffith 1985, 1988; Vidaurri 1991; Wilder 1943
Religious Folk Practices
Folk rituals, customs, and traditions based on religious or spiritual beliefs and on the ceremonial disciplines of the Catholic Church. In Mexico and in small southwestern communities the church was often located in the center of town, and the soul and rhythm of the people were synchronized with the liturgical seasons of the Church. Processions, fiestas, blessings, home prayers, velorios (wakes), and religious societies were integrated into daily life. The rural nature of many Mexicano communities meant that often a priest or official church clergy was absent, so popular religiosity or folk religious practices developed among the strong spiritual people. Some neighborhoods had rezadores or rezadoras, spiritual leaders who led the community in prayer for funerals, saints’ day celebrations and whenever the priest was unavailable. The home shrine or altarcito (little altar) in many homes took the place of a house of worship. Margaret Clark’s study of the Mexican community in San Jose, California, in the 1950s found that over 50 percent of the homes had altarcitos.
The American Roman Catholic Church was not always receptive to Mexican or Hispanic Catholicism. In many communities the church clergy openly discriminated against Mexicans. In Emporia, Kansas, “the basement of the Sacred Heart Church was renovated and Mass was said for Mexicans two Sundays of each month” (Beeson, Adams, and King, xix). The lack of hospitality and the shortage of priests who spoke Spanish kept many Mexicanos from participating in the American Catholic Church.
This situation served to reinforce religious folk practices and rituals brought from Mexico, many based on a syncretism of Indian religious beliefs and medieval Catholicism from the sixteenth century. The strong spiritual faith in the power of particular saints was frowned upon by the American church and considered to be an “exaggerated superstitious” belief (Dolan and Hinojosa, 57). Recent histories of Chicanos and the Catholic Church suggest that Mexicans were not dependent on a priest-centered religion and developed their own popular devotions performed without a priest. “Mexican American spirituality developed both private and public expressions. Private spirituality, which was practiced individually or within the family, stressed sacramental and personal devotions, while the public religious stressed processions, fiestas, symbols, and symbolic action that displayed the beliefs of the Mexican Catholic to the rest of the community” (Dolan and Hinojosa, 177).
Eventually every Chicano community had its own parish, due usually to the commitment and work of one individual priest in the diocese. There is probably a Virgen de Guadalupe parish in every single Mexican community in the United States. In spite of the fact that in some regions there was hostility by church officials, the importance of the Catholic Church in creating Chicano communities cannot be overemphasized. It was the church that created an environment where people could speak Spanish; celebrate religious, social, and political ceremonies; cook the special foods of the holy days and holidays; and of course pray together. The experience of Chicanos in Kansas, as described by Beeson, Adams, and King, was repeated throughout the Southwest and Midwest. “The church remained the most powerful center and cohesive force in the Mexican American colony. It was a religious and social haven in an alien, often hostile, environment. In the church the immigrant could use his Spanish language, wear traditional costume, celebrate Mexican Independence Day with a fiesta, and eat traditional food. The church also perpetuated the separateness of the Mexican Americans and their Anglo neighbors” (Beeson, Adams, and King, xx).
Religious celebrations for a saint’s day brought a community together and reinforced religious conviction and ethnic solidarity. Throughout the Southwest, fiestas for San Juan, San Isidro, San Francisco, La Virgen de Guadalupe, and many other favorite saints incorporated religious rituals and secular revelry. When paying homage to a saint, the church held Masses and processions early in the day; picnics, horse races, corridas de gallos (rooster games), and dances were held later in the day and evening. A community’s social calendar was based on the Catholic liturgical calendar, which provided frequent occasions for religious and cultural celebrations. Lent started with Ash Wednesday, and the belief was that, if one received ashes, one would live to see the end of the year. La Cuaresma, Lent, was and still is a time of sacrifice, prayers, Vía Cruces (stations of the cross) every Friday, special meatless foods, and spiritual preparation for Semana Santa (Holy Week). Palm Sunday with the distribution of holy palms resulted in the palms being made into crosses and tacked over doorways to protect the family from illness or harm. Good Friday included processions and in some communities the burning of Judas. Sábado de Gloria (Holy Saturday) and the end of Lent was often celebrated with jubilation and a dance. Easter Sunday celebrations and the customs of new clothes and Easter egg hunts were adopted by Mexican American communities later, probably after World War II.
One of the most important religious celebrations is the fiesta for La Virgen de Guadalupe, held on December 12. It often includes a Mañanitas (dawn) Mass and serenade with Mariachi music, a procession through the streets, and a dinner and dance. During the Christmas season there are usually Las Posadas for nine nights and performances of Los Pastores (Shepherds’ Play).
Many religious practices and beliefs have survived in some families without anyone knowing the source of the custom. For example, there is a custom of kissing a parent’s hand after receiving Holy Communion. Before this act is performed the communicant drinks exactly three swallows of water. There are many beliefs, creencias, connected to Holy Week observances, such as not working on Holy Thursday and not taking baths on Good Friday. On el Día de San Juan, St. John’s Day, on June 24, there are also traditions about swimming and taking baths. In some regions this day is referred to as el día de bañar, meaning the day to take a bath of some kind. It could be jumping in a river, lake, or waterway, or just being splashed with water. The tradition is connected to the baptism of St. John, and throughout Mexico, it is common to see water fights on this day, with buckets of water thrown on friends and family. The maintenance of a family altar and reciting the rosary every day, lighting votive candles, blessing the children every night, the blessing of homes and yards, and making promises, mandas, to particular saints are all folk practices passed on from generation to generation. Believing in the benevolent power of the saints and developing a special relationship with one particular saint is still a common habit. Mary Helen Ponce, in her book Hoyt Street, has some wonderful descriptions about the religious practices in her family, from First Communion celebrations to Holy Week rituals.
See also Altars; Camposanto; Descansos; Hábito; Mandas; Religious Folk Art; Santos
References Arnold 1928; Beeson, Adams, and King 1983; Clark 1959; Dolan and Deck 1994; Dolan and Hinojosa 1994; Griffith 1985, 1988, 1992; Ponce 1993
Remedios (Remedies)
Folk remedies often involving the use of homeopathic methods, herbs, and medicinal plants. Remedios are also known as remedios caseros (home remedies). Herbal remedies have been used for generations by the people living in Mexico and the Southwest, and many of these are now of interest to general health care practitioners. Curanderas (healers) use herbs to heal, but many families rely on their own traditional remedios passed down from generation to generation. Family knowledge and use of remedios may involve the preparation of teas, salves, ointments, and the use of herbs for basic health maintenance. A person who specializes in the application of herbs for healing purposes is called a yerbero, and a person considered to be a healer is called a curandera or curandero. Some remedios are simple and basic, such as drinking yerba buena (mint) tea for an upset stomach, to very complicated ritual procedures only known to a trained curandera. Many of the herbal remedies used in Chicano and Mexican homes today were introduced to New Spain by the Europeans, and were ancient herbs used by the Greeks, Egyptians, and Arabs. They brought many herbs not native to Mexico and the Southwest, such as chamomile, anise, cinnamon, coriander, mint, oregano, rosemary, garlic, and orange blossoms.
There are literally hundreds of medicinal herbs used by the people of northern Mexico and the U.S. Southwest. Several collections of herbs have been catalogued and are located at the University of Michigan’s Ethno-botanical Laboratory. These have been described by Karen Cowlan Ford and are listed by both the Spanish name and the botanical name. In addition many Internet web sites have been established by health organizations, individual folklorists, and other entities for the purpose of collecting and disseminating information about homeopathic and herbal healing.
See also Curanderismo
References Ford 1975; Kay 1977; Moore 1990; Roeder 1988; Sandoval 1998; Spicer 1977; Torres 1983a, 1983b
Resting Places 
See Descansos
Retablos (Religious Paintings)
A retablo is a painting of a religious scene with a saint, santo, in a two--dimensional format. Found throughout Mexico, retablos date from the middle of the eighteenth century in New Mexico. The retablo paintings were painted on either hide or wooden boards, sometimes also on tin, but usually pine wood smoothed over on one side. The surface of the board was covered with gesso before the design was painted on it. Most were painted with tempera, using a gesso ground with bright colors, but contemporary retablos are often painted on tin. Some dyes and pigments were made from plants and earth, whereas others were probably imported from Mexico. Since the early twentieth century, retablos have been produced in the same form as they are to the present day.
These retablos may be painted for a specific saint in gratitude for a favor granted, or in praise of the powers of the saint. For example, Durand and Massey have compiled and written about the many retablos to the Virgen de San Juan de los Lagos in Mexico. The paintings usually depict an event survived or celebrated, an illness, an operation, imprisonment, or having received a passport to the United States, or they may depict a person praying to the saint. A few sentences written on the retablo express the favor granted, starting with the words “Doy gracias” or “Doy infinitas gracias a la Santisima Virgen de San Juan de los Lagos” (I give thanks, I give infinite thanks to the most holy Virgin of San Juan of the Lakes) and the reason for the retablo is written out, with the location and date added at the end.
Another expression for this religious art is retablo ex-voto, a votive painting created in payment to a saint according to a vow. The Latin term ex voto means “from a vow,” so the ex-voto is specifically created to complete a vow made to a particular saint. Other retablos may be painted in gratitude for something gained or accomplished but not because a vow was made. A retablo ex-voto is a work of art, a religious painting, and also a historical document. The painting depicts the favor or miracle that occurred, the holy image or saint responsible for the miracle, and a short text that describes what occurred, including the location and date of the event. The text describing the event may begin with “Doy Gracias” (I give thanks) and express a need to state the miraculous event and tell how at the moment of crisis “me encomendó a la Virgen” (I entrusted myself to the Virgin). The text usually ends “por eso dedico este retablo” (this is why I dedicate this retablo). The retablo is then placed in a church or a shrine devoted to that particular saint. The tradition of creating votive paintings goes back hundreds of years in Mexico, and can be found along the U.S.-Mexican border region and in the cities of the Southwest. Many people immigrating from Mexico, for instance, have painted or commissioned a retablo in gratitude for surviving a disaster or an illness. Art exhibits in the United States have shown retablos ex-votos that depict the treacherous experience of immigrating to the United States.
See also Mandas
References Awalt 1998; Boyd 1959, 1974; Durand and Massey 1990, 1995; Mills 1967; Toor 1973
Riddles 
See Adivinanzas
Los Rinches (The Texas Rangers)
The Texas Rangers, known by Tejanos as Los Rinches, probably a Spanish pronunciation of “ranger,” became notorious within Chicano communities because of their brutality. Established in 1835, right before Texas’s independence from Mexico in 1836, the Texas Rangers were viewed as a state militia. They were actually organized by Stephen F. Austin, who hired the first ten in 1823 to wage war against Indians. Often portrayed as heroic figures, protectors of law and order, by Hollywood and in literature, Los Rinches were greatly feared and hated by Texas Mexicans. During the U.S.-Mexican War they led the way for General Zachary Taylor’s march to Monterrey, Mexico.
The Rangers have evolved over the years and have had periods of low activity and other periods of important law enforcement work. Today they are under the Texas Department of Public Safety and have become a kind of detective agency. As they have become better trained, better educated, with high-tech equipment and higher salaries, they are looked upon as the elite law enforcement of Texas.
But there were many bloody periods when the Rangers were extremely violent and cruel along the Texas-Mexican border. Between 1914 and 1919 they killed about 5,000 Mexicans. It is believed that many of the folk narratives and superhero legends known about the Texas Rangers were created at the expense of the Mexican population. Among the Mexicanos of the border they were known as Los Diablos Tejanos, “the Texas devils.” The Rangers’ battles with Texas border Mexicans helped create the image of the fearless fighters. The word rinches as used in the border area is almost equivalent to the word pig, when used in relation to their law enforcement responsibilities. According to Richard Flores, “The term ‘rinche’ not only signifies mistrust or deceit, but also the violence and exploitation inflicted upon the Mexicano community by the Texas Rangers” (1992,171). Corridos (ballads) from the Texas-Mexican border originating from the late 1800s until the turn of the century narrate episodes of border conflict in which the antagonist is often a member of the dreaded rinches. Several Tejano folk heroes, such as Gregorio Cortez, Juan Cortina, and Catarino Garza became memorialized because of their confrontations with the Texas Rangers.
See also “El Corrido de Gregorio Cortez”
References Flores 1992; Meed 1992; New Handbook of Texas 1996; Paredes 1958; Samora 1979
Rio Grande Blankets
A Rio Grande blanket was a blanket woven in New Mexico during the nineteenth century that was meant to be worn during the day and used as bedding at night. Blankets were woven before this period, actually since the seventeenth century, but not many survived from the period of 1600 to 1800. The Rio Grande blanket has particular characteristics, with designs that include wide bands and various zones of narrow stripes. During the early 1800s the wool was not dyed and was left in colors of brown and white. It was called churro (a kind of sheep) wool, because it came from the common sheep introduced by the Spaniards. Later, the wool was combined with natural dyed yarns of indigo. This wool was woven on a narrow treadle loom. The designs for the Rio Grande blankets are very distinct, with indigo-dyed stripes, and later were influenced by Saltillo sarape motifs that were introduced in the late 1800s. There was much borrowing and exchange of materials, fibers, and dyes between the Pueblo Indians and the Spanish in the textile weaves of New Mexico. The Saltillo sarape motif has a large complex diamond in the central layout of the blanket, and sometimes is surrounded by a scalloped border. Rio Grande blankets from the late nineteenth century incorporated many of the Saltillo sarape motifs. Today, reproductions of the Rio Grande blankets can be found on stationery, cards, and other types of artwork.
See also Sarape
References Fisher 1994; Museum of International Folk Art 1979; Siporin 1992; Spanish Colonial Arts Society 1996
Rodeos 
See Charreadas
Romance (Sixteenth-Century Spanish Ballad)
The romance is a very old ballad form introduced by the Spaniards to the New World. It was the main ballad tradition in New Spain until the corrido evolved from it, around the period of Mexico’s independence. Research into the literary folklore of New Mexico reveals a great love of traditional poetry, and the romance is a form that flourished for over 300 years. Written in a sixteen-syllable verse, it is usually printed in eight-syllable lines. Lea classifies the romance into three types: those of a religious nature, those that were sung to children or are of a nursery rhyme nature, and those about universal and emotional adult topics. The subjects of the romance were not the doings of the common folk, but rather of those in the higher classes or in military office. Two very old romances still sung in the Southwest are “La Delgadina,” which deals with incest, and “La Aparición,” which dates from the fifteenth century in Spain. J. D. Robb lists eleven variants of “La Delgadina” in his 1980 collection. Espinosa collected many romances from Californios in the 1920s. The romance is actually an old form of lyrical poetry that dates from medieval Spain.
See also Corridos; Folk Songs
References Campa 1930; Espinosa, A. M. 1924; Lea 1953; Rivera 1989; Robb 1954, 1980
Rooster Game 
See Corrida de Gallos










Quermes 
See Kermés
Quetzalcoatl
A god, one of the major deities of the Aztecs. Quetzal is a Nahuatl word referring to a bird found in Central America, and coatl means “snake,” so Quetzalcoatl means a “feathered serpent,” and this god is often called the Plumed Serpent. Stories about him indicate that he was an earthly hero, a light-skinned man, who acted as the ruler of the Toltecs for some time. In one legend Quetzalcoatl is sent to the underground to get the bones of the ancients. After the end of the Fourth Sun (an Aztec era), when the ancient people have been drowned or changed into fish, the spirits decide he should go seek the bones in order to start a new race. He must try three times, overcoming many obstacles, before he succeeds in bringing the bones to the sky. They are ground to a powder and placed in a bowl by the goddess Cihuacoatl. The other gods shed blood into the bowl and humans are born. Quetzalcoatl discovered corn, which he brought for the new humans to eat. He saw an ant bringing a kernel of corn from inside a mountain, and he changed himself into an ant and followed it. Lightning was used to split open the mountain to bring the corn to the people. He left the Toltecs to return to his home. It just happened that Quetzalcoatl promised to return in the same year that Hernán Cortés landed in Veracruz. It was to the Spaniards’ advantage to use the Indians’ belief in Quetzalcoatl’s return. Cortés was well received because he was thought to be Quetzalcoatl and the conquest of the Aztecs by the Spaniards was legitimized.
Quetzalcoatl is one of the better-known Aztec gods and has been greatly idealized by the moderns, including Chicanos. His image has influenced artists, writers, philosophers, and painters for hundreds of years. As the celestial dragon, he is patterned after the rattlesnake, a common mythical creature in Mesoamerica. This dragon has come to symbolize the Chicanos’ early heritage and has been embraced by Chicanos, especially those coming of age in the 1970s. Quetzalcoatl can be found in the literature, murals, and graphic art reflecting Chicano culture and the Chicano movement of the 1960s and 1970s. In 1970 an American Indian and Chicano college was started in northern California with the name Deganawidah-Quetzalcoatl College. This college was still in existence in the year 2000 and has struggled to maintain a curriculum that meets the needs of both Indian and Chicano students. Deganawidah was the name of the chief of the Iroquois Federation, and after the college was given his name, it was learned there was a common belief that the name could not be mentioned publicly. Since that time the college has become known as D-Q University.
References Bierhorst 1990; Brundage 1979; Carrasco 1992; Lafaye 1983
Quinceañera (Fifteenth Birthday Party)
A coming-of-age celebration and ceremony for a young girl on her fifteenth birthday. The word Quinceañera comes from the Spanish word quince, meaning “fifteen” and añera, which together mean “the fifteen-year-old.” This celebration marks the beginning of adulthood for a young woman. It is a custom throughout Latin America, Mexico, the Caribbean, and in many areas of the United States to distinguish this birthday with a special observance. It is -assumed the custom has origins in pre-Columbian cultures, as a coming-of-age ritual for young women. In his Historia de Nueva España, Bernardino de Sahagún narrates that it was traditional for the parents of a young Aztec maiden to formally acknowledge her passage into womanhood. “Advice of an Aztec Mother to Her Daughter” is reprinted in William H. Prescott’s The Conquest of Mexico.
Communities in Texas have formally observed Quinceañera birthdays for many generations, whereas such celebrations are not as common in California and other parts of the Southwest. Traditionally this ceremony serves as a coming-out party to indicate that a girl has reached womanhood and is ready for marriage. In the United States this is no longer the case, but the celebration does symbolize the transition from childhood to womanhood. In some celebrations a doll called la muñeca de los recuerdos (the doll of memories) or la última muñeca (the last doll) is given to the celebrant as a symbol of the childhood she is leaving behind. Some people see it as the last vestiges of childhood and la última muñeca as the last doll she will ever receive.
Although not a religious sacrament, the celebrations of Quinceañeras take on a strong religious undertone. The ceremony usually includes a special Mass, where the parents give thanks for having a wonderful daughter, and she gives thanks for having a wonderful family, and the young woman may receive a formal blessing from the priest. The Mass is very similar to a wedding Mass, with the celebrant and her entourage slowly marching down the center aisle of the church. A ceremonial dinner and a dance with live band music usually follow. The celebrant wears a long white gown, similar to a wedding dress; has fifteen maids, damas, with their escorts, chambelanes; and sometimes performs a choreographed dance or waltz. Quinceañera celebrations are held in major cities with large Latino populations, such as Miami, San Antonio, Chicago, Los Angeles, and El Paso. These cities now offer many businesses that cater to Latino families planning Quinceañera celebrations. Although this is a family tradition and ritual, some families use the occasion to lavish on their daughters an extravagant day, never to be forgotten.
Besides the traditional doll, other folkloric elements continue to be incorporated into Quinceañera ceremonies. In Idaho and Oregon, Eva Castellano has continued a tradition she learned from Mexico of making coronas (crowns) made of waxed and paper flowers to be worn by the young girl. Only unmarried girls wear the coronas, which symbolize innocence and purity. Much of the research on Quinceañeras shows that families want to maintain a cultural historical tradition, and the celebration of a daughter’s fifteenth birthday is a means of continuing cultural ties to a Latino heritage.
A booklet by Angela Erevia provides an outline of the Catholic Mass including biblical readings and a schedule of the types of classes required of a young lady. Michele Salcedo’s book is a planning guide that discusses everything from the dress to the invitations, the music, the limousine, and the food, including the recipes. Internet sites are now available to guide a parent in planning every aspect of this ritual.
References Chavéz 1983; Davalos 1996; Erevia 1980; Horowitz 1993; Martinez-Chavez 1989; Ortiz 1992; Salcedo 1997; Siporin 1984; Vigil 1998
Quinto Sol (Fifth Sun)
The narrative of the Fifth Sun is based on an Aztec myth that has become an important cultural expression commonly incorporated into Chicano cultural events. The first publisher of contemporary Chicano literature in the 1960s, based in Berkeley, California, was named Quinto Sol Publications. Worship of the sun was an integral part of Aztec culture. The sun was viewed as a warrior with the solar rays as his darts. Time consisted of a fifty-two-year calendar that was divided into five ages, or series of ages, called Suns. The first age was the Age of the Earth Sun, and the god was Tezcatlipoca, whose familiar animal was the jaguar. The second age was the Age of Great Winds, the sun was Quetzalcoatl, and the age ended with great hurricanes. Then came the Age of Fire with the sun Tlaloc, and it ended with volcanic eruptions. Next was the Age of Floods with the goddess of waters, Chalchiuhtlicue, as the fourth sun. This age ended when the sky fell upon the earth and the waters gushed up, turning men into fish. The present and fifth age, El Quinto Sol, has Nanahuatl, also known as Tonatiuh, as the god, and it is the Age of Earthquakes. With El Quinto Sol a full culture was created, with maize grown for the first time, fire domesticated, and the creation of the Toltecs. This age is supposed to end with earthquakes. Each age came about when the god of an aeon died or sacrificed himself to be reborn as the sun of the next aeon.
References Bierhorst 1990; Brundage 1979; Florescano 1999; Griffith 1990










Pachuco Cross
A design in the form of a small cross that is tattooed on the left hand, between the thumb and forefinger, with lines, or dashes, radiating out from it. George Carpenter Barker states that it must be seven rays, or lines, that radiate from the cross. It is a well-known symbol among Chicanos and has been traced to the era of the pachucos (1940s urban youth), hence its name. It is also known as the cruz del barrio (cross from the neighborhood) and has been found throughout major cities of the Southwest. Tattoos of Christian images have always been popular among Chicanos, and the custom of tattooing images of Jesus Christ, crucifixes, La Virgen de Guadalupe, and other Madonnas has a long history. In the Middle Ages the Crusaders cut a cross into Chris-tian converts on the hand a little above the wrist. Some social scientists believe that the pachuco cross was meant to symbolize violence and membership in a gang. But it is known that it was used as an initiation ritual among friends and peers, to show solidarity and allegiance to a particular barrio. In describing the tattooed cross Haldeen Braddy is of the opinion that each ray jetting out from the cross represented a six-month stay in jail. In his view, pachucos liked to stay in the jaula (cage, jail) so that they could “accumulate these ‘rays’ as souvenirs of their imprisonment” (1971, 142). There is no evidence to support this speculation.
References Barker 1974; Braddy 1960; Chicano Pinto Research Project 1975; Coltharp 1965; Demello 1993; Govenar 1988
Pachucos (-as) (1940s Urban Youth)
A name adopted by Mexican Americans and Mexican nationals to designate those who make up a fascinating urban subculture, detached from U.S. culture and from Mexican American urban life also. The first appearance of pachucos was in the El Paso–Juárez area during the 1920s and early 1930s. It is thought the word pachuco was a colloquial way of referring to El Paso. A person from El Paso was referred to as del pachuco. Sometimes a person considered a pachuco was called a chuco. Haldeen Braddy discusses the origin of the word pachuco, providing several theories. One is that the pachucos of the 1930s came from the city of Pachuca in the state of Hidalgo, Mexico. He also pre-sents the definition from the Diccionario General de Americanismos, stating that pachuca is a five-card poker hand in which all the cards are of different suits, or in other words, a poker hand with no value, a losing hand. Braddy believes this well describes the pachucos of El Paso (1971). The other theory is that pachuco comes from the Nahuatl word pachtli, which refers to a grass like hay that grows parasitically on trees.
Pachucos were identifiable by their clothing, hairstyles, and a distinct language with its own vocabulary. The men wore “zoot suits,” that is, pegged pants, long coats with padded shoulders, and pancake hats. Their hair was worn long and slicked back with a ducktail effect. Some also wore a long chain hanging from their pants, well displayed and connected to a belt. Pachucas were the girlfriends of the pachucos, but they also had a dress style all their own. They wore short, very tight skirts, with their hair high and long. Makeup was heavy, especially around the eyes. Supposedly they were very streetwise and liked to hang out with their pachuco boyfriends.
Large numbers of young men from El Paso, speaking the pachuco argot, settled in Los Angeles during the early 1940s, and it was there that they became recognized as an identifiable group, and considered to be gang members. Young men who relocated and settled in Los Angeles, even for short periods of time, upon returning home to the small towns of the Southwest, would spread the pachuco beliefs and jargon to their communities. In this way pachuquesmo, a Mexican subculture, became known throughout the Southwest.
The pachuco speech, a combination of English and Spanish, also called caló, was a fascinating fusion drawing from many linguistic sources. Caló was originally the language of the Spanish gypsies, or a dialect of Spanish showing traces of many languages acquired by the gypsies throughout their world wanderings. The pachuco argot utilized several linguistic sources in developing a vocabulary or jargon. These sources were southwestern Spanish, the older archaic Spanish from New Mexico, Mexican slang, standard Spanish from Mexico City, and also words invented by the pachucos themselves. The pachuco dialect was the product of an urban environment, and it is believed the language may have originated in the underworld and drug scene of El Paso. George Carpenter Barker pinpoints almost exactly where the pachuco jargon originated, from the 7-X gang who first met in the neighborhood of Florence and Eighth Streets in El Paso. Arthur Campa believes that pachucos originated as a linguistic group first and had no distinctive dress style. That came later as they moved into a more stable economic environment and had some financial resources.
Expressions and vocabulary used by Chicanos today come from the pachuco argot of the 1940s. For example, such words as órale (what’s happening, or O.K.), bato (guy, as in bato loco), califas (California), hay te wuacho (I’ll be seeing you), and la pinta (jail/prison) have been used for generations. The film Zoot Suit, written and directed by Luis Valdez in 1981, depicts the dress, language, and problems of Mexican American youth and especially pachucos in Los Angeles in the 1940s.
During the 1940s a caricature of the pachuco was created for the Mexican media in the person of Tin Tan, whose real name was Germán Valdéz (1919–1973). He was an actor and performer who dressed as a stereotypical pachuco and zoot-suiter. Tin Tan made several Mexican films portraying the Mexican American pocho who code-switches between English and Spanish, and speaks caló.
The pachuco was disdained in the U.S. by both the Mexican American and Anglo communities, and likewise in Mexico by the media and the intellectuals. Octavio Paz, much quoted, disparagingly discusses the phenomenon of the pachuco in his book The Labyrinth of Solitude, published in English in 1961. Although almost any urban Chicano who was young in the 1940s was affected by the style and language of the pachuco, the stereotypic pachuco was often associated with violence and deviancy. The zoot-suit riots of 1943 are held up as the epitome of the pachuco experience, totally disregarding previous and later experiences. According to Alfredo Mirandé, “The pachuco has been an especially visible symbol of cultural autonomy and resistance. His distinctive dress, demeanor, mannerism, and language not only express his manhood but set him off culturally from the dominant society. To be a chuco is to be proud, dignified, and to uphold one’s personal integrity as well as the honor and integrity of the group. It is at once an affirmation of one’s manhood and one’s culture” (1985, 179–180). The pachuco is the precursor to the bato loco, the cholo, and the low rider of more contemporary times.
The pachuca was the counterpart of the pachuco of the 1940s but also the home-girl archetype that comes together in the young Chicana growing up in an urban ghettoized environment. During the 1940s, pachucas were the girlfriends of or those who hung around with pachucos. They developed their own style of dress, wearing very tight short skirts and sweaters and doing their hair in a pompadour style. Their behavior was loud and brash: they smoked cigarettes in public, wore lots of eye makeup, and supposedly were quick to fight. Pachucas knew the vernacular of the times, speaking pachuco and scandalizing their families. They were not necessarily gang members, but they can be considered the precursors of present-day cholas.
See also Caló; Cholos; Low Rider; Pocho; Tin Tan; Zoot Suit
References Barker 1974; Braddy 1960, 1971; Campa 1979; Cerda and Farias 1953; Coltharp 1965; Cosgrove 1989; Fregoso 1995; Griffith 1948; Hinojosa 1975; Katz 1974; Keller 1985; Luckenbill 1990; Madrid-Barela 1973; Mazon 1984; Mirandé 1985; Montoya 1977; Orona-Cordova 1992; Paz 1961; Plascencia 1983; Valdez 1992

Paintings (Religious) 
See Retablos
Palomilla (Group of Friends)
A term used primarily in south Texas during the 1940s and 1950s to describe an informal group of guys that hung around together. Paloma means “dove,” so a palomilla is a flock of doves. One rarely hears the expression today, but it is occasionally used in literature, such as the short stories of Mario Suarez. A palomilla would be one’s peer group, or a very close group of friends, but not a gang. Consisting of a core of three or four males, with a few fringe members, a palomilla was an important socialization unit that provided a safe space for young men to joke and express themselves. Arthur Rubel writes about the supportive social environment provided by the palomilla of young coming-of-age Chicanos in the barrio of New Lots in south Texas. Joseph Spielberg describes the quick wit and aggressive bilingual humor found among the members of his palomilla during the early 1960s, and how their jostling and jesting allowed for the full bloom of each person’s personality.
References Cerda and Farias 1953; Limón 1994; Rubel 1965; Spielberg 1974
Papel Picado (Cut Tissue Paper)
The craft and final product of cutting out intricate designs and patterns on sheets of tissue paper. In Mexico the artists who do this work have been doing it for several generations and can cut through fifty or more sheets at a time. A pattern is made and used as the top sheet while the outline design is cut out with different-sized chisels. Most often the small banner-sized sheets are made to decorate altars and nacimientos (nativity scenes), or for such celebrations as Cinco de Mayo (the Fifth of May) and El Diez y Seis de Septiembre (the Sixteenth of September). Mexican restaurants are often decorated with streams of colorful papel picado. Some of the cutout designs are scenes related to specific holidays, such as skeletons for Día de los Muertos (the Day of the Dead), dancers, floral patterns, the Mexican flag, and other patriotic scenes. In Mexico, experienced paper cutters can make large wall hangings and tablecloths out of papel picado. Papel picado is often taught in public schools, although on the small eight-by-eleven-inch paper.
See also Cinco de Mayo; Día de los Muertos; El Diez y Seis de Septiembre
References Carmichael and Sayer 1991; Lomas Garza 1999; Trenchard 1998; Vigil 1998
Paredes, Américo (1915–1999)
Considered the foremost scholar of Chicano folklore, Américo Paredes was a professor emeritus of English and anthropology at the University of Texas, Austin. His classic work, With His Pistol in His Hand: A Border Ballad and Its Hero, first published in 1958, has become a standard work in Chicano studies and American folklore. A whole generation of Chicano scholars regard Paredes as their intellectual role model and mentor, and his original research on Chicano folklore engendered a new wave of scholarship and academic achievements.
As a young man, Paredes was always interested in music, corridos (ballads), and singing. His early published scholarship focused on ballads and ballad heroes of the Texas-Mexican border, and through this research he developed a theory about the formation of Chicano folklore. The resistance to an encroaching foreign culture, the loss of political and economic power, feelings of social marginality, and the resulting conflict of cultures all contributed to the creation of folklore in the form of legends, jokes, and songs by the Chicano people. His research and publications encompass various disciplines from anthropology to literature to social history.
Américo Paredes was born in Brownsville, Texas, on September 3, 1915. He attended Brownsville Junior College in the early 1930s, earning an A.A. degree in 1936. In 1944 he joined the army, wrote for the military newspaper Stars and Stripes, and worked in Japan for a couple of years. Returning to Texas in 1950, he earned a B.A. degree from the University of Texas in 1951, an M.A. in 1953, and a Ph.D. in 1956.
The distinguishing feature of Paredes’s scholarship has been his humanistic approach to conducting research. Besides knowing and studying his own culture and ethnic community, he was able to bring another consciousness to the study of folklore in general and to Texas-Mexican folklore in particular. He taught that the examination of a cultural or folkloric phenomenon cannot be divorced from the social context in which it is performed or expressed. Before the publication of Paredes’s work, most of the Hispanic and Chicano folklore collected was classified, published, and placed on a library shelf. Paredes’s research emphasized the importance of the informant’s culture, and the social setting and history of the community of the informant. It was in his book, With His Pistol in His Hand: A Border Ballad and Its Hero, that Paredes proposed his theory of the development of Chicano folklore through a process of cultural conflict generated by the invasion of Anglo culture and values into south Texas in the 1800s. Many writers have dedicated their books to him, and the journal Aztlán devoted a double-issue volume to him in 1982. Besides publishing over sixty articles in academic journals, he was editor of the Journal of American Folklore from 1968 to 1973 and published Folktales of Mexico in 1970 and A Texas-Mexican Cancionero: Folksongs of the Lower Border in 1976.
Besides his scholarly writings, Paredes was a poet and novelist. His first publication was a collection of poetry titled Cantos de Adolescencia in 1937. Most recently he has published George Washington Gomez: A Mexico Texan Novel in 1990, Between Two Worlds in 1991, and The Shadow in 1998. Don Américo died unexpectedly in April of 1999.
References Leal 1987; Limón 1980a, 1986, 1992, 1994; Paredes 1958, 1976, 1978
Los Pastores (Shepherds’ Play)
A religious medieval nativity folk play. Also known as La Pastorela, the complete title of this folk drama is El Coloquio de los Pastores, and it is written in verse and performed on Christmas Eve. It is an ancient mystery play, brought to the New World by the Spanish Franciscan priests, and is performed throughout the Southwest. As a folk production, it is performed for entertainment, but it is also a religious presentation that is maintaining a long tradition. The full title means “the dialogue of the shepherds,” and it is an interpretation of the dialogue and reaction the shepherds may have had when they learned of the birth of Jesus Christ. It narrates the story of the shepherds who are visited by Michael the Archangel who informs them of the birth of the infant Jesus and urges them to go to Belén (Bethlehem). Before the shepherds decide what to do, they are visited by Lucifer, who is angry about the birth of the Christ child to the Virgin Mary. Lucifer tries to challenge the shepherds but Michael the Archangel returns just in time to defeat him. The shepherds then continue on their journey to Bethlehem bringing gifts for the infant Jesus. The structure of the play is formulaic, and so the sequence of acts can be rearranged into many different patterns, with jokes, songs, speeches, and other events added at different points. The underlying story of the drama is the universal battle between good and evil. It has evolved from the literature of sixteenth-century Spain and the indigenous traditions of Mexico, and for this reason the play has provided a political format for the poor masses throughout the last 400 years.
Because of its ancient history there are many variants of Los Pastores, and several versions have developed a comic dialogue between Lucifer and Cucharón, Bartolo, and the other characters. One character is named Bato, as in bato loco (crazy guy), a phrase of contemporary usage among Chicanos today. Variants of this play have been collected in Texas, New Mexico, and California, and it has been performed in Mexico since the sixteenth century. In San Antonio the performance of Los Pastores at Our Lady of Guadalupe Church as been ongoing since 1913. Richard Flores, both as an ethnographer and as a performer, presents a thorough analysis of the historical conditions that continue to provide an environment for the performance of Los Pastores as both ritual and drama. In 1991 El Teatro Campesino produced a video film of their production of Los Pastores titled La Pastorela—The Shepherds’ Tale.
References Bandini 1958; Cole 1907; Espinosa 1985; Flores 1995; Herrera-Sobek 1995a; Igo 1985; Lea 1953; Lucero-White 1940; Ortega 1973; Pearce 1957; Rael 1965; Robb 1954; Robe 1957; Romero 1984; Silverthorne 1990; Wright 1920
Pedro de Urdemalas
Also known as Pedro di Urdemales or Pedro Ordimales, meaning “Peter of the holy water font,” he is a rogue folk hero with hundreds of tales to his name. This trickster character is known throughout the Spanish-speaking world and the Southwest of the United States. He is the classic Spanish picaro (rogue), who incorporates “three ancient literary types, the wanderer, the fool, and the have-not,” according to Claudio Guillen. He is the trickster figure who is constantly dissatisfied, always wanting more, yet is always outwitting everyone and acting as the social critic along the way. Pedro de Urdemalas lives by his wit, has no shame, and at different times makes a pact with the devil, God, the Virgin Mary, and St. Peter. Tales of Pedro de Urdemalas collected by Aurelio M. Espinosa in Spain and in New Mexico were published in the Journal of American Folklore in 1914. Ramón Laval gives a brief literary history of de Urdemalas and publishes a small series of tales collected in Chile in the late nineteenth century. Cervantes wrote a play about him in 1615, Comedia Famosa de Pedro de Urdemalas, so we know Pedro de Urdemalas was already a folkloric character in the seventeenth century. Wardropper states, “Pedro de Urdemalas is a shadowy, even elusive, figure in the oral tradition of Spanish folktales. Because these tales were not—as far as we know—collected in the Renaissance and because, like ballads and songs, they must have been subject to endless variation and mutual interference, we cannot now know the Pedro de Urdemalas who endeared himself to the folk” (218). But it is clear that Pedro de Urdemalas is a Hispano precursor to Don Cacahuate, el pelado, Tin Tan, Cantinflas, and an antecedent of Chicano joking behavior.
See also Don Cacahuate; El Pelado; Tin Tan
References Guillen 1971; Lamadrid 1995; Laval 1943; Wardropper 1982
El Pelado (The Plucked One)
Literally, “plucked,” or “bald,” el pelado was a designation used for a clownish performer, an improvised character type developed by performing theater groups in the 1920s, in Mexico and in the Southwest. Also known as peladito, this comic hobo is the underdog, a nobody who is criticized and made fun of by the whole world. The pelado was a verbal artist who, according to Samuel Ramos, “has created a dialect of his own, a diction which abounds in ordinary words, but he gives these words a new meaning. . . . His terminology abounds in sexual allusion” (1962, 59). Many carpas (tent theaters) featured pelado or peladito characters, and the agringado (anglicized) and the pocho (half Mexican) were special targets of his comic wit and satire. Beloved by working-class audiences, the peladito, using caló (Spanish slang) and pochismos (Americanisms), particularly poked fun at the acculturation of Mexicans who couldn’t speak Spanish and pointed out to them American discrimination against Mexicans. Similar to Charlie Chaplin, and later developed by the Mexican actor Cantinflas, el pelado was a homeless type who in dialogue could state the unthinkable and mock everything and everybody. Many Chicanos, who may not have known the appellation pelado, nonetheless became familiar with the comic vagabond through Mexican films. El Teatro Campesino (the Farmworkers’ Theater) effectively used this character type in skits and actos (dramas) and succeeded in intensifying, with humor, the serious social issues presented in their performances.
See also Agringado; Carpas; Pocho; El Teatro Campesino
References Broyles-Gonzalez 1994; Kanellos 1990; Limón 1998; Ramos 1962; Spielberg 1974
Penitente Chapels 
See Moradas
Los Penitentes (The Penitents)
A Catholic fraternal order of men, formally known as La Fraternidad Piadosa de Nuestro Padre de Jesus Nazareño, or informally as Los Penitentes. This lay religious society related to the Roman Catholic Church is still found in rural northern New Mexico and southern Colorado. Originally it was organized for religious observances and practices, including pious prayer and bodily penance, but the society eventually became very important in providing mutual aid to the local communities. Los Penitentes cared for the sick, arranged funerals, and conducted the religious rituals associated with wakes. Their social role in contemporary New Mexico is not as pronounced but some moradas still remain active.
Their primary religious ceremonies commemorated the passion and death of Jesus Christ, during the celebrations of Semana Santa, “Holy Week.” It is speculated that the starting date of the brotherhood is somewhere between 1790 and 1810. The origins of Los Penitentes have been debated for years, but it is likely they were heavily influenced by the Franciscan Third Order, who were the friars in New Mexico until Mexico separated from Spain in 1821. Los Penitentes became a strong institution in rural New Mexico because there were too few Catholic priests to oversee the religious life of the people during the early nineteenth century. The village chapters governed themselves without benefit of the few priests in the colony. Consequently Los Penitentes had strong influences in conserving the language and culture of the Spanish Americans of New Mexico. Membership consisted of between thirty and fifty adult men per chapter (called moradas) and were divided into two groups: common members, called hermanos disciplantes (brothers who discipline), and officers, called hermanos de luz (brothers of light). By the early twentieth century the various chapters had become secret societies with restricted membership.
Journalism about Los Hermanos Penitentes has been sensationalistic, with lengthy descriptions of their Semana Santa rituals, especially when Anglo Americans migrated to New Mexico during the late nineteenth century. Their custom of self-punishment, in the form of flagellation during the Holy Week ceremonies, aroused much interest and was reported widely in many East Coast publications. The most sensitive and nonjudgmental writing and research have been conducted by de Cordova, Henderson, Sprott, and Weigle. A worthy, contemporary (1970–1986), descriptive account of the ritual ceremonies associated with Holy Week in Cordova can be found in Charles Briggs (1988).
References Boyd 1974; Briggs 1988; Brown 1978; Darley 1968; De Cordova 1972; Espinosa, G., 1972; Henderson 1937; Horka-Follick 1969; Rael 1951; Sprott 1984; Steele and Rivera 1985; Weigle 1970, 1976; Woodward 1935
The People 
See La Raza
Pichilingis (Elves)
Elves or leprechauns that Anthony John Campos refers to as little people, pichilingis are goblins who perform mischievous pranks. Santamaria’s Diccionario de Mejicanismos’ definition for pichilingo is chiquito, muchachito, and niño pequeño, meaning “very small” and “little child.” The word piciligue, which comes from the Aztec, has the meaning of “to become small that which was thick or large.” Another closely related word also found in Santamaria is pichilingui, which is a common word for pato silvestre (wild duck), which is found in lakes in the interior of Mexico. Pichilingis are similar to duendes (goblins) and are possibly the indigenous version of a duende, and have only been found in the folklore literature of New Mexico. Duendes are very common in Chicano folktales, and many people still believe in them. They are often invisible yet their presence is felt because of the annoying tricks and antics they concoct.
See also Chanes; Duendes
Reference Campos 1977; Santamaria 1978
Pilón (Bonus)
A custom, often expressed only after it occurs, of giving a little extra when making a transaction or closing a bargain. For instance, when buying candy, the vendor may add one extra piece, de pilón, to surprise and make a child happy. John Bourke writes about an ancient custom in Mexico still used in the late nineteenth century: a merchant kept a tin cylinder for each customer, and after each purchase he’d drop a bean into it. After the total number of beans reached sixteen or eighteen, the customer was given six cents in money or goods. This was the pilón, a type of dividend given to the client for purchasing from the same merchant.
The phrase de pilón is used when referring to the occurrence of an unplanned episode or accident. In narrating a personal story with an unhappy ending, an individual might add, “Y de pilón me caí” (and to top it off, I fell down). Although it is not found in common usage among contemporary Chicanos, many will remember how their parents used this expression. The word has several meanings, including “a heap of stuff,” such as a heap of grapes, a heap of mortar, a heap of something, but it also means a lump of sugar. In her personal memoir A Place in El Paso, Gloria Lopez-Stoppard has a delightful de-scription of the use of pilón during her childhood. Thus de pilón may express something positive, or something unexpectedly negative.
References Bourke 1895; De Leon 1982; Lopez-Stoppard 1996
Piñatas
A colorfully decorated clay pot or papier-mâché figure filled with toys and candies, confetti, or party favors that is brought to celebrations such as birthdays, Christmas festivities, and other parties. Often it is decorated as a star or an animal, such as a burro or elephant, but it can also be a fruit or a puppet. The size varies from small to very large. Piñatas have traditionally been a part of birthday and Christmas celebrations, but are now also brought out for other holidays. In Mexico a piñata was always broken on Christmas Eve, especially among the poorer classes, so that children would receive small inexpensive gifts from the piñata. The real Christmas gifts were not presented until Día de los Reyes on January 6, also known as Epiphany in the Catholic calendar.
A game is made of breaking the piñata, and a song accompanies the game. The piñata is hung from a tree, with a long rope that is manipulated by an adult, who is able to move the piñata up and down, so it won’t be broken too quickly. A child is blindfolded, twirled around three times, handed a bat, and led to the piñata. Everyone will usually have a turn or two, and finally the manipulator allows someone to break it. The candy and prizes fall to the ground and everyone jumps to grab some.
The custom of breaking a piñata during the Christmas Mass celebrations was introduced by the Augustine priests in the seventeenth century. Later the custom of celebrating many Christmas Masses evolved into Las Posadas (Christmas pageant). The piñata was considered to be a symbol of evil, with the clay pot representing Satan or his spirit and the colorful decorations serving to tempt humanity. The candies and goodies inside the piñata were the unknown pleasures that Satan held out to attract man. The blindfolded child was supposed to represent innocence and faith, which must be blind to combat the evil spirit. The breaking of the piñata symbolized the struggle that man must sustain to destroy evil and receive the gifts and pleasures of God (the candy).
The word piñata derives from the verb apiñar, which means to cram, tie, or join together. In Italy pignattas were hung from the ceilings during masquerade balls. It is accepted that there is an oriental influence, since piñatas are always decorated with colorful crepe paper. It is thought piñatas originated in China and were brought to Sicily and Spain by the Arabs and to New Spain by the Spaniards.
See also Las Posadas
References Burciaga 1993; Gallegos 1991; Griffith 1988; Ortega 1973; Perl 1983; -Silverthorne 1990; Verti 1993
Pintos (-as) (Prisoners)
Pinto is a term used for prison and also for a Chicano prison inmate. A pinto is a male prisoner, a pinta a female prisoner. La Pinta, referring to prison, is believed to come from the word penitenciaria, or “penitentiary.” Other common words for prison are bote, meaning “can,” and corre, which is short for “correctional institution,” referring specifically to one in Texas. “Joint” is another word frequently used to mean prison.
There has been a lot of sociological literature written about the formation of gangs in prisons as a means of surviving incarceration in the United States. The media, including 60 Minutes, has done stories about the activities of the Mexican mafia and La Familia. Often ignored is the subculture of the pinto experience that is exhibited in behavior, art expression, and published poetry. In the early 1970s several Chicano magazines devoted whole issues to literature and art by pintos, always referring to it as pinto art and pinto poetry. A combination of Mexican and prison cultural values dictates the behavior of pintos inside prison and out on the street. Chicano prisoners have a strong sense of family and community and feel they are constantly being watched by their barrio, family, women, and their home-boys peer group. Most Chicano convicts have little education, speak primarily in Spanish, and have a strong sense of Mexican nationalism. Regardless of place of birth, mexicanismo and machismo are a very important part of being a pinto. Ex-pintos are often identifiable by their mannerisms, gestures, language, haircuts, and dress. They are usually extremely clean and well groomed, have very short hair, wear well-pressed pants, and are in excellent physical shape. Within the prison world pintos have established a well-defined and -structured social environment, which they carry to the outside world when released. In discussing the film American Me, Rosa Linda Fregoso states that Edward James Olmos depicts extremely well the expressive behavior of pintos both in prison and outside. In her words, “Besides rendering a Chicano pinto presence in the rhythms of speech, Santana [the movie character] represents it in the stylized walk and prose of a pinto, a stance honed in the corridors behind prison walls or in the barrios of East L.A.” (1993, 130).
The pinto experience is a subculture of the Chicano experience. Because of the low socioeconomic status of a large percentage of Chicanos in the United States and the lack of equal opportunities in education and employment, many Chicano families have been inadvertently introduced to this subculture. A special issue of the Chicano magazine De Colores, vol. 3, no. 1, was devoted to “Los Pintos de America,” and the issue was published as a separate monograph in 1976 by Pajarito Publications. Female Chicana prisoners also undergo the pinta experience, and one scholar, Letticia Galindo, has written about the specialized language use and street experiences of pachucas, cholas, gang members, and female prison inmates.
See also Cholos; Pachucos
References Chicano Pinto Research Project 1975; Coltharp 1965; Davidson 1974; Estrada 1971; Fregoso 1993; Galindo 1992, 1993
Placas (Insignias)
The word placa means “an insignia of an order,” and in the United States it also means the license plates of a car. But within cholo and youth gang culture it refers to the sign and name of a gang or club as it appears on the walls of buildings in the barrios of Chicano communities. What may appear as graffiti is actually the placa of a person, or of a gang. Where the placa appears signifies that territory as belonging to that gang, and it may also serve as a challenge to other gangs. The use of public walls for asserting a fraternal identity is really an ancient tradition, and within Chicano culture it can be traced back to at least the 1930s. Chicano street culture uses plaqueasos as a system for conveying information about territory and youth socialization customs. If one placa is written over by the placa of another gang, it is accepted as a challenge to a confrontation.
A placa also refers to the individual name of a gang member. Nicknames are very common among Chicanos, but a placa is specifically a gang-related name and often very well describes the person as perceived by friends or other gang members. Names, such as “Sad Girl,” “Diablo” (devil), “Joker,” and “Malo” (bad) could be names used within a gang, and may signify sadness, wildness, or craziness. Sometimes the writing of names on walls is referred to as plaqueasos, or in contemporary terms, “barrio calligraphy.” In more recent times the individual who writes on walls has been called a tagger, and the art of writing is tagging. Many Chicano taggers use a stylized medieval writing, such as Old English and German Gothic forms.
Sanchez-Tranquilino has analyzed the displacement of graffiti by murals in Chicano communities and finds that murals can be an extension of the barrio calligraphy rather than an attempt to control gang vandalism, as is sometimes assumed.
See also Cholos; Con Safos; Graffiti
References Chabran and Chabran 1996; -Cockcroft 1992; Cockcroft, Weber, and -Cockcroft 1977; Harris, M., 1988, 1994; Kim 1995; Sanchez-Tranquilino 1995
Pochismos (Americanisms)
A term that describes the use of English expressions in Spanish, or Americanisms interjected into conversations when speaking Spanish. Sometimes this kind of speech is called Spanglish, or Chicano Spanish, or just pocho talk. Examples of some pochismos are words such as parkear, meaning to park (the car), and wachar, meaning to watch (hay te wacho, “I’ll see you”), also spelled guachate, meaning “watch out.” Other simpler examples are dona for doughnut, el dompe for the dump, troque for truck, and yarda for yard. According to Manuel Peña the word jaitón, meaning “snobbish,” evolved from the words “high tone” when one was discussing music. It came to be used to mean pretentious high class, as in “se crea muy jaitona” (she thinks she’s real high-class), but at the same time it can mean that one has elegance or style.
Various dictionaries of Chicano Spanish and Chicano slang have been compiled that list many other pochismos. Chicano novelists and poets have consciously incorporated the use of pochismos in literary works to reinforce the precarious cultural and linguistic status of Chicanos in American society.
See also Caló; Pachucos; Pocho
References Campa 1977; Galvan 1985; Hernández-Chavez, Cohen, and Beltramo 1975; Peña 1985b; Vasquez 1975
Pocho (Half Mexican)
A pocho is a term used in Mexico to describe a person of Mexican heritage born and raised in the United States. It is meant to describe a person who may not be fully fluent in Spanish, or “Mexican enough,” culturally and linguistically. The word can also mean “discolored,” “truncated,” or “small.” It has been adopted by some Chicanos to describe and ridicule themselves as they survive within an antagonistic and discriminatory environment. The word became more nationally known in 1959 with the publication of the novel Pocho by Jose Antonio Villarreal, which depicted the coming-of-age of a Chicano growing up in the Santa Clara Valley of California during the 1940s.
Mexicans like to call Chicanos pocho, ridiculing their sometimes poor Spanish and their lack of knowledge about Mexico and Mexican customs. Mexicans who have spent time in the United States and have acquired the mannerisms, values, and the English language may be considered pochos because they’ve become agringados (anglicized). In the 1950s and 1960s the Mexican cinema produced several films depicting the lives of pochos, from both sides of the border, but emphasizing the importance of maintaining mexi-canidad. Titles of some of these films are Soy Mexicano de Acá de Este Lado (I Am a Mexican from This Side) (1951), Los Desarraigados (The Uprooted) (1958), México de Mi Corazón (Mexico of My Heart) (1963), and El Pocho (The Half Mexican) (1964).
As with the word cholo, individuals have attempted to find the origin of the use of the word pocho in reference to Chicanos. In his autobiography, Barrio Boy, Ernesto Galarza writes about the pochos he found in Sacramento, California, in the second decade of the twentieth century: “They had learned to speak English of sorts and could still speak Spanish, also of sorts. . . . Concerning the pochos, the chicanos suspected that they considered themselves too good for the barrio but were not, for some reason, good enough for the Americans” (1971, 203).
In Los Angeles, the writer Lalo Lopez has created a comic industry based on pocho caricatures that includes a comic strip, political cartoons, Pocho Productions, an Internet web page, Pocho Magazine, a political satire zine, and a calendar. He refers to a modern Aztec calendar as a Pochteca calendar, which features wisdom from the “wise guy ancestors of the modern day Pocha and Pocho.” The whole Southwest is referred to as Pocholandia. A Chicano who does not speak fluent Spanish may be said to speak pocho Spanish, but the reverse is never stated about a Mexican who cannot speak fluent English. Many English and Spanish words that have become altered by the opposite language, through cultural contact, are called pochismos. Some examples of pochismos are yonque for “junk,” tichar for “to teach,” and carro for “car.”
See also Agringado; Caló; Pochismos
References CHICLE 1995; Galarza 1971; Maciel 1992; Madrid-Barela 1976; Paredes 1993a; Vasquez 1975; Villanueva 1978; Villarreal 1959
Las Posadas (Christmas Pageant)
A tradition marking the beginning of the Christmas season with the dramatization of the search for lodging in Bethlehem by Joseph and Mary. It always includes a procession with singing and music and starts nine days before Christmas. The story, in the form of a novena (Catholic nine-days devotion), is based on the gospel of St. Luke. For nine consecutive nights before Christmas Eve, la Noche Buena (the good night), los peregrinos (the pilgrims) representing Joseph and Mary visit a different home each night, reenacting the search for an inn by Joseph and Mary. Los mesoneros, those who portray the innkeepers, keep refusing them lodging. Los peregrinos form a procession, and children and angels hand-carry the small figures of the Holy Family. When they arrive at a home they ask for shelter and sing carols. Las Posadas occurs from December 16 through December 24. Nine different homes are opened to the pilgrims and food and drink are offered after the peregrinos have been denied lodging. Most homes will have a nativity scene, a nacimiento, set up for the prayers and singers. An important tradition of these festivities is the piñata that is brought out and broken by the children. There is evidence that piñatas originated from this Christmas celebration.
Posadas are still held today in many Mexican communities in the United States. Some are organized by church groups, but recently others have been organized for commercial purposes by city entities. The reenactment of Las Posadas is an ancient tradition that can be traced back to the early conquest in Mexico and to the christianization of the Aztecs by the Augustine priests. They originated in the small village of San Augustin Acolman located near the pyramids in Teotihuacán. The Aztecs celebrated the birth of their god Huitzilopochtli for one night, and celebrations were held all of the following day in every home. This occurred about the same time of the year that the Catholic Church celebrated the birth of Christ. The Augustine priests saw the similarity between these Aztec celebrations and the Christmas festivities and chose this opportunity to teach the new religion to the Aztecs. While the Aztecs were celebrating the birth of Huitzilopochtli, the priests reenacted the pilgrimage of Mary and Joseph. The nine nightly journeys symbolize the nine months of pregnancy for Mary. These Christmas Masses, as they were called, were celebrated in the convents and churches, but eventually were moved to the haciendas, farms, and ranches, and finally to the neighborhoods. The celebrations ended with firecrackers and the breaking of a piñata. Today many cities in the Southwest reenact this pilgrimage for one night with a procession winding through city streets. In Monterey, California, the whole city comes out for Las Posadas, and in San Antonio, Texas, a posada is held during the Fiesta de las Luminarias (Festival of the Bonfires) that includes a procession on the Paso del Rio (river pass).
See also Nacimiento; Piñata
References Campa 1934; Chabran and Chabran 1996; Espinosa 1985; Heisley and -MacGregor-Villarreal 1991; Ortega 1973; Silverthorne 1990; Sommers 1995; Steele 1992; Verti 1993; Vigil 1998; Waugh 1955
Prisoners 
See Pintos
Promises 
See Mandas
Proverbs 
See Dichos










Ofrenda (Offering)
Sometimes used interchangeably with altar, ofrenda means “an offering” and is set up as a component of an altar. On Día de los Muertos, the Day of the Dead or All Souls’ Day, an offering is made for a particular individual who has died, or for several members of a family who have died, such as parents and grandparents. An ofrenda may be set up in a home and personalized for a particular person. In some homes an altar is permanently set up for general and daily prayer, but an ofrenda is specifically for Día de los Muertos. An ofrenda will have lit votive candles that are meant to help guide the soul to the ofrenda. It will also have bread and a glass of water, because these elements are considered to be the main supports of life. In addition the personal favorite items of the deceased will be placed out for him or her, such as sweets, beer, beans, photographs, and even an especially liked shirt or dress. During Día de los Muertos, altars are set up in galleries and exhibit halls as artistic and cultural expressions, with ofrendas created for particularly known individuals.
See also Altars; Día de los Muertos
References Cash 1998; Morrison 1992; Portillo 1989; Sommers 1995
The Old Mother Game 
See La Vieja Inés y los Listones
La Onda Chicana (Chicano Wave of Music)
A phrase used to describe Chicano music, especially that of the late 1960s, which is a combination of Mexican and American music styles. In musical terms, La Onda Chicana was created by the Texas orquesta, which synthesized the elements from different music styles, such as ranchera and big band swing, to create a blend of music that characterized Chicano music of the 1960s and 1970s. La Onda Chicana also reflected a cultural and political sentiment, an ethnic pride in being Chicano and working class, and it also embodied a recognition of being American and accepting American popular culture. The lyrics of the songs may be in English or in Spanish, and sometimes both languages are used in the same song. Although the conjuntos of norteño music and the orquestas of Texas were all accepted as Mexicano and Chicano, the music of La Onda Chicana was purely Chicano music.
One band that typified this sound was Little Joe y La Familia (Little Joe and the family). Little Joe Hernandez was born into a migrant farmworker family in Texas and started his musical career as a teenager. He sang with his cousin’s group, David Corona y Los Latinaires, for two years before taking it over and calling it Little Joe and the Latinaires. When that group split up he reorganized it as Little Joe y La Familia. He recorded many successful albums in the 1960s, and has been called the “King of Brown Sound.”
Peña describes La Onda Chicana well: “It synthesized all the musical elements. . . . to achieve a highly innovative bimusical sound that combined a ranchera (country music) and jaitón (high class music) within the same piece.” Other bands that fit into this genre were Sunny Ozuna and the Sunliners, Los Lobos, Los Alacranes Mojados, Ray Camacho and the Tear Drops, and La Rondalla Amerindia.
See also Conjunto Music; Los Lobos; Ranchera
References Loza 1993; Peña 1985; Villarino 1992
Oremos (Christmas House Visits)
A custom from New Mexico and parts of Texas, at least El Paso, where on Christmas Day children go from house to house asking for treats, much like on Halloween. This custom was sometimes just called Oremos (literally, “we pray”). Children would knock on the doors of their neighbors and chant:
Oremos, Oremos
Angelitos somos
D’el cielo venimos
A pedir Oremos
Si no nos dan,
Puertas y ventanas quebrarémos.
(We pray, we pray
Little angels we are
From heaven we come
To ask we pray
If we don’t receive
Doors and windows we will break.)
The chant states that they’re angels from heaven and are asking for gifts, although if they receive none, they may break doors and windows. The origin of this custom is not known, but some believe it is to remind society that the stranger at the door should not be forgotten. Lorin Brown reports that in northern New Mexico the children went out on Christmas Eve, but in Canutillo, Texas, around the 1920s, it was the custom for children to go door to door on Christmas Day, although they didn’t recite the above chant. The neighbors expected them and were ready with gifts of fruits and candies.
Lottie C. Devine makes reference to the Papago Indians in Arizona, saying that on “Christmas Day most of them came to town, all dressed in party clothes, and went from house to house ‘calling Christmas.’ Everyone gave them candies and apples and many of them in turn gave baskets or pottery” (29). Cabeza de Baca refers to this custom as aguinaldos, and the chant she records is similar to the one above, except that the last line is “A pedir Aguinaldos y Oremos.” Aguinaldos are gifts given during the Christmas season.
See also Aguinaldos
References Brown 1978; Cabeza de Baca 1982; Devine 1964
Oso, Juan
The name of a folk character found in tales collected in Spain and New Mexico by Aurelio Espinosa and his son, Jose Manuel Espinosa. In some tales Juan Oso (John Bear) is the son of a princess and a bear. The princess is kidnapped by a bear when she is out of the palace and is taken to a cave where she eventually has a son who is half bear and half human. Finally she and Juan Osito, her son, are able to run away from the bear and go live in the palace with her father. After Juan grows up he leaves his mother to wander the land, and from this point on, various tales describe the different adventures of Juan Oso. In a variant of the tale, a young woman and her baby son are captured by a bear and taken to live in a cave where the son grows up learning the ways of the bear. They also escape and return to live with the woman’s uncle, and Juan Oso wanders off to explore the world. Even though he is half wild, Juan Oso develops into a strong, smart, and sensitive man who will not be outwitted. In variants collected by Elaine Miller in Los Angeles, where he is called Juan del Oso, he has magical abilities. After he saves three princesses he is usually allowed to marry one of them.
References Espinosa, A. M., 1985; Espinosa, J. M., 1937; Miller 1973

Otero-Warren, Nina (Adelina) (1881–1965)
Nina Otero-Warren is known primarily as the writer of the book Old Spain in Our Southwest (1936), a memoir of life in early New Mexico. It is more than an autobiography, since it is interspersed with folklore narratives, Hispano traditions, and early southwest history. Nina Otero was born in Los Lunas, New Mexico, a town named after her grandfather’s family, a descendent of an early influential Hispanic family. They were fairly wealthy and the marriage of her mother and father in 1880 was lavish and elaborate. The details of the wedding are well described by Charlotte Whaley in her biography of Nina. Her father, a member of the famous Otero family, was killed in a shoot-out when Nina was still a baby, and her mother later married A. M. Bergere. They had a large family together, all of whom are well-known citizens of New Mexico. Nina attended school on the East Coast, married and divorced, and eventually settled into New Mexican politics. She was appointed superintendent of schools in the Santa Fe area and was active in the Congressional Union and the Republican Party and lobbied for the vote for women in 1920. In 1922 she ran for the U.S. House of Representatives but was defeated. She continued working for government agencies as an educator and supporter of Indian education. In the early 1960s she worked as a consultant for the Peace Corps, which had a training program at the University of New Mexico in Albuquerque. Like her contemporaries Cleofas Jaramillo and Aurora Lucero-White, she had an interest in folklore, and her book Old Spain in Our Southwest was one of the first private ethnographies to be published by a woman of her era. In it she describes the early Spanish settlers, life on the hacienda, the religious fiestas, the santos (saints), foods, folk songs, folktales, and the customs of the region. In her later years, up until her death in 1965, she was a businesswoman in Santa Fe.
References Otero-Warren 1936; Ponce 1992; Rebolledo 1989; Whaley 1994
The Outcast 
See El Tiradito










Nacimiento (Nativity Scene)
From the Spanish word nacer, nacimiento is the name for a Christmas nativity scene. In the Southwest the creation of nacimientos has been a tradition since the seventeenth century. A nacimiento may resemble a religious altar in that it is an assemblage of many articles and objects, all depicting the recent birth of Jesus Christ in the manger, but a nacimiento can also include other Christmas-related images, biblical scenes, and possibly artifacts relating to the life experiences of the creator. The set of the nacimiento can vary in size from a small table to half a room, or to the whole front yard of a home. Outdoor nacimientos will have life-size figures of Mary and Joseph and various other biblical characters and animals. This custom is not particular to the Chicano community, and nativity scenes can be found throughout the country during the Christmas season. It is thought that Saint Francis of Assisi is the saint responsible for much of the veneration of the infant Jesus, and the custom of creating nativity scenes or monuments to the birth of Christ has been going on for hundreds of years.
In private homes nacimientos are usually set up for the first night of Las Posadas, which starts on December 16 and continues until December 24. A nacimiento is left in place until El Día de los Reyes, Epiphany, on January 6, when the three kings arrive to visit the Christ child.
See also Las Posadas
References Griffith 1988; Heisley and MacGregor-Villarreal 1991; Kitchener 1994; Sommers 1995
Naranja Dulce (Sweet Orange)
A very popular old children’s game and song frequently recited in novels and poems. Children form a circle with one child in the center and they sing this song:
Naranja dulce
Limón partido
Dáme un abrazo
Que yo te pido.
Si fueran falsos
Mis juramentos,
En algun día se olvidaran.
(Sweet orange
Sliced lemon
Give me a hug
That I ask of you.
If my promises were false
Someday they will be forgotten.)
After this verse is sung, the child in the center of the circle chooses one from the group that is forming the circle and embraces that child. The child picked enters the center and the other child moves out. While this is going on they keep the circle moving around, and clapping hands, they sing the following verse to a fast beat:
Toca la Marcha
Mi pecho llora
y adiós Señora
Yo ya me voy.
(Play the march
My breast [heart] cries
Good-bye my Lady
I am leaving.)
For many generations mothers have sung this little verse to their babies as they lull them to sleep. Girls play this game in Mexico also, with a boy as the center player, which Inez Cardozo-Freeman interprets as a portrayal of betrayal and abandonment preparing little girls for marriage.
References Cardozo-Freeman 1975; Gonzáles 1974; Writers’ Program 1976
Nativity Scene 
See Nacimiento
Neighborhood 
See Barrio
New Mexico Folklore
Of all the areas of the Southwest where Chicanos have settled and lived, it is New Mexico’s culture and folklore that has been historically studied the most. Aurelio M. Espinosa was the first Hispano (a person of Spanish heritage born in New Mexico) to conduct research into the culture and language of New Mexicans. His most important work was published during the early part of the nineteenth century, 1910–1916, with a series of publications in the Journal of American Folklore. He collected folktales, folk songs, proverbs, superstitions, riddles, children’s games, and much more. Students who were trained by Espinosa and who later continued folkloric work in New Mexico were Arthur Campa, Juan B. Rael, and Espinosa’s son, Jose Manuel Espinosa, who published Spanish Folk-tales from New Mexico in 1937. Rael published Cuentos Españoles de Colorado y Nuevo Mejico in 1957, which is considered by Américo Paredes to be one of the best collections of Mexican folk narrative. Campa’s work includes collections of folk poetry, riddles, folk songs, and folk drama from the late nineteenth and early twentieth centuries, published mostly in the 1940s and 1950s.
John Donald Robb (1892–1989) collected folk songs throughout New Mexico in the 1940s and 1950s using wire recorders. He came to the University of New Mexico as chair of the music department in 1941. He was a composer and educator but always had an interest in folk music. The John Donald Robb Archive of Southwestern Music is located at the university’s library. His two books on New Mexico are Hispanic Folk Songs of New Mexico (1954) and Hispanic Folk Music of New Mexico and the Southwest: A Self Portrait of a People (1980).
Hispanic women have always been involved in creative and artistic work in New Mexico even up until contemporary times. Although there have been many publications about the santeros (saint makers), wood-carvers, tinsmiths, and other male artists, very little has been written about the work accomplished by women. Women have created religious folk art, such as santos (saints), retablos (religious paintings), straw appliqué crosses, and tinwork. Women wove blankets and embroidered colchas (blankets). Whitewashing and plastering of homes have always been women’s work. Those who do it are called enjarradoras, and today they continue this work, also making adobe hornos (ovens) and fireplaces for the International Museum of Folk Art located in Santa Fe. Marianne Stoller writes of the work of New Mexican women artists and why they have been left out of history.
Several New Mexican women who descended from the early Spanish settlers of the region wrote personal life histories that incorporated the traditional way of life of the Hispano community of the late nineteenth and early twentieth centuries. Fabiola Cabeza de Baca, Nina Otero-Warren, and Cleofas Jaramillo each produced several books that present the folklore, rituals, and customs of the New Mexicans. Rebolledo discusses how these women used their writings as “narrative strategies of resistance” because they saw their culture and way of life slowly eroding away and being assimilated by a dominant and foreign culture. Because they all came from upper-class families, they were educated in Spanish traditions and language and consequently ignored the mestizo (mixed-race) and indigenous aspects of the culture, often depicting their past in romantic pastoral terms. Nevertheless, they all wrote of the loss of land and loss of culture, and sought to preserve the folklore, customs, and stories of their grandparents, close friends, and those who worked for them.
The Penitentes, the ancient religious brotherhood, have attracted much research and been scrutinized by many writers and journalists. De Cordova, Henderson, Sprott, and Weigle have conducted the most perceptive and sensitive writing on the Penitentes. The popular arts of colonial New Mexico, particularly the santos and santeros, have received a lot of attention by such researchers as E. Boyd, Marta Weigle, and William Wroth.
In recent years Chicano writers from New Mexico have collected folklore from their ancestors and friends. Nasario Garcia has published several collections depicting the way of life of the elders of the Rio Puerco Valley, and Rudolfo Anaya has written several children’s books that bring forth the folklore of the region. Because of its long history New Mexico will always be a bountiful reservoir for the serious folklorist.
See also Adobe; Hispano Culture; Los Penitentes
References De Cordova 1972; Espinosa, A.M. Jr., 1947; Henderson 1937; Rebolledo 1993, 1994; Sprott 1984; Stoller 1986; Weigle 1976; Weigle and White 1988
Nichos (Niches)
A nicho is a nook or niche built into a wall that is similar to a shelf inside of a home. It can be as small as six inches or as high as one foot or even three feet. Anything can be placed in a nicho, from books to knickknacks, but the usual purpose is to house a holy picture or statue of a saint. Consequently in some Chicano homes the word carries almost the same meaning as altar or shrine. A nicho decorated with votive candles and saints becomes the site for daily devotional prayers. Nichos are also constructed as part of yard shrines to house a favorite saint or La Virgen de Guadalupe or another Madonna. Yard shrines that incorporate a nicho are set up as a place of worship in the yard to commemorate a deceased relative or as a fulfillment of a vow. In some parts of the Southwest these outdoor shrines are also called grutas, “grottos,” and the two words are often used interchangeably. A cemetery shrine may also incorporate a nicho or a gruta. Since a gruta is primarily outdoors it can be constructed as a yard or cemetery shrine. Nichos that are found in front yards may be constructed of cement or wood, and may appear as a small house, chapel-shaped, or as a small cave. A wrought-iron door may be installed for privacy or to prevent vandalism. Yard nichos can vary in size from one foot to six or eight feet high. Invariably they are decorated with plastic flowers and plants, and are often painted in pastel colors.
See also Altars; Grutas; Yard Shrines
References Cash 1998; Griffith 1992; Ramos 1991; Vidaurri 1991; West 1991
Nun’s Habit 
See Hábito










Machismo
Machismo describes a stereotypic image of a Chicano/Latino man who is extraordinarily aggressive, stresses dominance over his wife and family, exhibits physical and sexual prowess, and places strong emphasis on masculine rigidity. Chicano social scientists have authored studies about machismo, noting that it is a stereotype often used against Chicanos to blame them for their underclass social position in American society. Macho literally means “male,” and machismo is the concept of “maleness,” but in American culture it has come to mean an exaggerated masculinity. A masculinity associated with violence, self-centeredness, chauvinism, or alcoholism is not a macho concept recognized by most Chicanos. For Chicanos, un hombre macho is a man who symbolizes dignity, takes care of his family, has respect for all women, especially his mother, and possesses a strong sense of self-identity and character. Many Chicanos grew up influenced by Mexican movies, with characters like Pedro Infante, Cantinflas, Antonio Aguilar, and Jorge Negrete, as men who sang to the beautiful girls and defended the poor by fighting for justice and social equality. These were positive images of machos.
The famous Mexican folklorist Vicente Mendoza has stated that the concept of machismo, and the word macho, were not prevalent in Mexican corridos (ballads) and popular culture until the 1940s. Supposedly the word gained popularity after Avila Camacho became president of Mexico because in ballads macho easily rhymed with Camacho.
In an article published in 1975, José Armas describes machismo as a mode of behavior necessary for an individual to live life with integrity, self-reliance, and dignity. He states, “Machismo is a personal code of honor that is self imposed in a world devoid of universal moral law or justice. It is maintained and sustained by individual pride and dignity” (56).
A Latino men’s group calling themselves Hombres Latinos was formed in California with the purpose of redefining the image and concept of machismo. This was reported in a Los Angeles Times article in 1992 written by Christopher Heredia. The group is organized on the “the compadrazco system,” meeting regularly and holding yearly retreats.
Their definition of the Macho is:
  1. He who is dignified
  2. He who is a protector
  3. He who is responsible
  4. He who is nurturing
  5. He who is spiritual
  6. He who is faithful
  7. He who is respectful
  8. He who is friendly
  9. He who is caring
10. He who is sensitive
11. He who is trustful
12. He who provides
(Tello, ca. 1988)

For some Chicanos machismo is an emblem that symbolizes resistance to social and historical control. Excessive masculinity is seen by some as adaptive behavior in situations where Chicano men feel racial oppression and discrimination. The idea of exaggerated masculinity has crept into American popular culture and language, so most Americans have an idea of the meaning of machismo and we find it regularly used by the media. For instance the Marlboro Man is viewed as a macho man, strong and independent as he rides his horse herding cattle. This was a model that many young men grew up -trying to emulate, but this symbol is no longer acceptable to modern American society.
See also Pintos
References Andrade 1992; Armas 1975; Baca Zinn 1982; Castillo 1994; Davidson 1974; Heredia 1992; Limón 1978; Mirandé 1985, 1986, 1997; Najera-Ramirez 1994; Paredes 1993a; Peña 1991
Mal Ojo (Evil Eye)
Mal ojo, or “bad eye,” is commonly known as “the evil eye.” It may also be called mal de ojo, or just ojo. It is a syndrome, a folk illness, believed to be transmitted by certain individuals, witches, some think, who have a special power. Mal ojo may be transferred by a peculiar person who gazes at a weaker person, a woman or a child, and the ill effects are felt immediately. Socially, it can indicate that a person has been more familiar with another person than social and cultural manners permit. The glance or power of a stronger person causes an adverse consequence on the weaker person, who is often a baby or a child. The fear of mal ojo also indicates that mothers and other adults are distrusting of a person who acts in a more familiar way than is culturally appropriate. It is thought that people with “weak blood,” sangre liviana, are more susceptible to receiving mal ojo. The symptoms of mal ojo are vomiting, diarrhea, loss of weight, and sometimes even death. Witches can deliberately give someone the evil eye; other times it is done unintentionally by persons who just happen to have a powerful gleam. A person may give another the evil eye because of a feeling of jealousy or covetousness. If a person covets or is envious of a child he or she may give that child the evil eye. Preventive measures that may diminish the possibility of a child getting mal ojo are to touch the child’s cheek, or make the sign of the cross on the child’s forehead. Sometimes the evil eye may be undone and the illness avoided if the person who cast the glance pats the person’s head or temples, immediately relieving him or her of the curse. If the illness is induced by a witch another type of remedy must be sought.
Belief in the evil eye or that someone can harm another by looking at him or her in a certain way is found all over the world. It has been documented in Mediterranean countries, eastern Europe, North Africa, Central America, Mexico, and in the southwestern United States In many of these countries the evil eye is associated with envy and malice.
Various cures for mal ojo exist; one well-documented method is to barrer con un blanquillo, (sweep with an egg) sweep the ill person with an uncooked unbroken egg. The egg is swept over the body of the person without touching them, while prayers are recited, such as the Hail Mary and the Our Father. The egg serves to extract the fever from the ill person, and is then broken into a bowl of water and placed under the bed of the person. During the night the egg is believed to still be extracting fever from the patient, and in the morning if the egg is found to be cooked, it is a sign that the patient had mal ojo. The egg is then thrown over the shoulder of the mother, in the direction of the sun.
References Baer and Bustillo 1993; Dundes 1992; Hand 1981; Jaramillo 1972; Kearney 1976; Martinez and Martin 1966; Roeder 1988; Rubel 1966; Simmons 1974; Spicer 1977; Torres 1983a
La Malinche (c. 1502–c. 1528)
This is the common name given to the Aztec princess Malintzin Tenépal, also known as Doña Marina. Although of noble birth, she was sold as a child into slavery to Mayan merchants, supposedly by her own mother. In 1519 she was one of the women given to Hernán Cortés when he landed in Mexico. She spoke both Nahuatl and Maya, among other Indian languages, and quickly learned Spanish, becoming Cortés’s translator and also his mistress. Upon learning her name, Cortés had her christened as Doña Marina, and she became known to everyone by that name, although her Aztec name was Malintzin, which possibly the Spaniards pronounced Malinche, so she was also called by this name. She bore one son by Cortés. During the whole Spanish Conquest period she spoke for the Indians to Cortés and translated Montezuma’s dialogue to him. According to Mexican and Chicano folklore she metaphorically represents the raped Indian woman that produced the mestizo (mixed Spanish and Indian) race, the Mexican, but she is also considered a double-crosser. She informed Cortés about a planned ambush at Cholula, which saved his life and caused the massacre of thousands of Indians. She became known as La Lengua, meaning “the tongue,” because of her work as a translator for Cortés. Del Castillo believes that Doña Marina was following her religious faith and belief in a godly force, the prophecies of Quetzalcoatl, and did not think she was betraying her people. Cortés is supposed to have stated, “After God we owe this conquest of New Spain to Doña Marina.” Because she gave birth to the first mestizo, the first Mexicano, she is considered the mother of la raza cósmica (the cosmic race).
In Chicano culture a person who turns his back on his people is call a malinchero or, if it’s a woman who has betrayed her community, a malinche. Contemporary Chicanas have taken La Malinche as a positive role model to illustrate and explain the survivalist psyche of the Chicana in modern society. Her influence in the conquest of Mexico may be debatable, but there is no doubt that she is considered a heroine, almost on the same plane as La Virgen de Guadalupe. Octavio Paz writes of La Malinche as the “violated woman,” La Chingada, and his writings have influenced several generations of Mexicanos and Chicanos in seeing the Mexican people as “hijos de la chingada,” that is, “sons of a conquest by rape.”
Cortés married Doña Marina off to one of his lieutenants, Juan Jaramillo, and they had one daughter. She went with them to Central America and there died of an illness when she was approximately twenty-three years of age. Some scholars regard La Malinche as the archetype of La Llorona and others think of her as the original Llorona (weeping woman), while some consider her to be the source of La Llorona legend.
To many Chicanas Malinche has become a symbol for the socioeconomic and educational limitations of contemporary life. They feel the defamation of her character is equal to the denigration of Chicanas. The victimization and criminalization of Malinche, a double oppression, is parallel to the experiences of young Chicanas and Mexicanas. Malinche and La Virgen de Guadalupe are two archetypes of womanhood in Mexico and in the Southwest, the whore and the virgin, who symbolize the precarious dilemma of being female. Malinche has played an enormous role in the literary production of Chicana writing, in essays and short stories, but especially in poetry.
See also La Llorona
References Alarcon 1989; Candelaria 1993; Del Castillo 1977; Glantz 1994; Harris 1996; Paz 1961; Rebolledo and Rivero 1993; Soto 1986; Zinam and Molina 1991
Mandas (Promises)
The Spanish dictionary definition of manda is a “proposal” or an “offer.” It comes from the verb mandar, meaning “to order” or “to command,” and the phrase mandar hacer means “to have made” or “to command to be made.” In folk religious practices a manda is interpreted as a promise or contract made with a saint, the Virgin Mary, or God. The contract is not a legal commitment nor made with the approval of a priest or the Catholic Church. It is purely a personal promise made to fulfill or complete a journey, a devotional act, or to recite a certain number of prayers. This promise is in exchange for the curing of an illness or for a solution to a problem. The manda may involve the placing of a milagro (symbol of a miracle) at the shrine of a saint, La Virgen de Guadalupe cathedral in Mexico City for example, or the lighting of candles at the local church. Although the fulfillment of the manda in itself may not be difficult, its completion often involves some sacrifice, and this aspect is also considered part of the manda. Lighting daily candles could be a financial strain, and a pilgrimage may take several years to complete, yet neither is ever forgotten, and a manda is taken more seriously than a legal written contract. There may be fear of retribution from a saint if the manda is not fulfilled, and sometimes individuals actually suffer this retribution. If a woman makes a manda asking for a cure to her child’s illness and the child is cured but she does not complete the manda, the child may become ill again. The woman will believe the second illness was caused because she did not complete her manda. A manda may be completed after the request is fulfilled in thanksgiving, or it may be fulfilled before the petition is answered, with the assumption that it will be answered. Mandas are very private and often only very close family members are aware that a person has made one.
References Cantú 1991a; Durand and Massey 1995; Egan 1991; Oktavec 1995
La Mano Negra (The Black Hand)
In parts of the Southwest, children were disciplined by parents who narrated scary stories of The Black Hand. If they didn’t behave or do as they were told, La Mano Negra would take them away. In the Ernest Baughman Collection at the University of New Mexico Library, an informant narrates being told by her grandfather in Tesuque, New Mexico, about La Mano Negra. A young woman remembers, “My grandfather used to tell us when we were little, about La Mano Negra, that appeared every time little kids were bad and that if we weren’t good and helped him carry in wood and water and feed the animals ‘la mano negra’ would come for us at night. It would get really big, take us from our beds and never bring us back home” (November 1974). Members of the academic electronic listserv CHICLE have held discussions and reminisced about La Mano Negra. One member remembered it by the name of La Mano Pachona without knowing its origin, but the fear of it was well remembered by all.
Marc Simmons writes about a legend of La Mano Negra from the town of Bernalillo, New Mexico. An old priest dies, but the villagers believe he was unable to complete all his work because his spirit frequently returns. When the bell of the church is heard ringing late at night, the local Indians come to listen, and they see the spirit of the priest going into the church and praying. They call the Hispanos to come and see, and when the priest is seen in the church one of the observers cries out. At this point the priest places his hand on the missal and vanishes. “Burned through several pages was the scorched imprint of the padre’s hand, La Mano Negro.” Simmons states that he recalls a similar legend from Ireland (2).
References CHICLE 1995; Ernest Baughman Collection; Simmons 1989
Mariachi Music
Mariachi music is the most traditional music associated with Mexico. This type of musical group has become a national symbol of Mexico and of most Mexicanos living in Greater Mexico. They are contracted to play at traditional ritual celebrations, such as baptisms, weddings, quinceañeras (fifteenth birthday parties), fiestas patrias (patriotic festivals), most festivals, and sometimes funerals.
A traditional Mariachi group can consist of anywhere between five and thirteen musicians. The uniqueness of the group is that it is composed of brass and string instruments only: trumpets, violins, and guitars. Some groups may also include a harp, a guitarrón (bass guitar), or a string bass. Mariachis have traditionally been male musicians, but since the 1980s female musicians have been accepted into many groups, and there are now complete groups composed of only females.
The attire of the Mariachis is a charro (horseman) suit that incorporates elements of the Spaniards’ dress of the eighteenth century: boots, tight-fitting pants, short waist-length jackets, all embroidered with braid or silver ornaments. White shirts with ribbon ties made into bows, and the traditional wide-brimmed sombrero complete the ensemble. Some outfits are all white, black, dark blue, or even red, and can be very striking when twelve or more musicians, all standing, start playing a typical Mexican song, such as “La Negra” or “Las Mañanitas.” According to Najera-Ramirez the early Mariachi groups dressed like peons with white muslin shirt and pants. It was not until 1901 that they started wearing charro costumes, following the example established by Miguel Lerdo de Tejada and his orquesta típica, the national folkloric orchestra. “By the 1930s the charro costume became an institutionalized part of the Mariachi tradition when the government required Mariachis performing for official functions to wear charro outfits” (1993, 17).
Mariachi groups have been very popular in southern California since the 1930s, and currently hundreds of groups have been formed in the Los Angeles area. Even students at the University of California at Los Angeles formed a group in 1970 called Mariachi Uclatlán. One famous group from Los Angeles is Los Camperos de Nati Cano (The Horsemen of Nati Cano), organized in 1961, who perform at their restaurant La Fonda, owned by Nati Cano. This Mariachi performs at many Mariachi festivals and is also on a university -campus circuit and can often be seen in theaters throughout California. Nati Cano recorded with Linda Ronstadt on her famous Canciones de Mi Padre album, and received a lot of fame from this exposure. He is also an adjunct lecturer at the University of California, Los Angeles.
In the last thirty years Mariachi festivals have become very popular throughout the Southwest. They have been held in San Antonio, Texas; Tucson, Arizona; San Jose, California; and even Universal Studios in Hollywood originated a festival in 1985. Los Angeles is home to the largest assemblage of Mariachi musicians in the United States.
Theories about the origin of the word Mariachi are interesting. There is the idea that it evolved from María, the name of the mother of Jesus Christ. Another idea is that it comes from the French word for marriage. But it is likely that the etymology of the word is of an indigenous nature. Mariachi groups originated in the region of Jalisco, even before it was named as a state, a region greatly influenced by the Coca people, and in fact the Nahuatl word for contemporary indigenous performers is mariachitos.
References Harpole 1990; Loza 1985, 1993; Najera-Ramirez 1994; Narváez 1978; Pearlman 1988; Rafael 1983
Masseuse 
See Sobador
Los Matachines (Dancers)
The name of the dancers and the dance they perform on Christmas Eve in many parts of the Southwest. In New Mexico the dance is performed by the Pueblo Indians in honor of the Madonna. The dance is also performed in Mexico, Texas, and Arizona during other holidays and saints’ days. Controversy over the origin of this ritual dance-drama has not been resolved, and the literature and research produced keep growing. It is based on a medieval Spanish mystery play, but in the New World version, influenced by Aztec culture and customs, it portrays the betrayal of Montezuma by the Spaniards, and the acceptance of Christianity by Montezuma. Its Iberian origins lie in the conflict between the Christians and Moors. The Danza de los Matachines is probably the only ritual dance that is danced by both Hispanic and Native American communities in New Mexico.
The word matachines can translate to mean “clowning” or “trickery,” but can also mean “puppet player,” “jester,” and “buffoon.” Matachines refers to the men who dance as a group; the group is composed usually of twelve men, but can have from ten to fourteen. In sixteenth-century Europe a matachin was a masked dancer, an entertainer who danced with a sword. It is likely that the Moors transplanted the dance to Europe and that matachin may come from the Arabic word mutawajjihin, meaning “to assume a mask.” There are many eighteenth- and nineteenth-century literary references to a matachine sword dance, indicating that such a dance was performed in Europe.
Similar to the dance-drama of Los Moros y Cristianos, the dance of Los Matachines was taught to the subjugated Indians by the Spanish missionaries as a custom to celebrate on Christian feast days but also as a means of converting them to Catholicism. Flavia Waters Champe’s interpretation is that the dance was brought to New Mexico by Spanish and Mexican settlers who came with De Vargas at the time of the second conquest in 1692.
In New Mexico the dance group is open only to men and it is considered an honor to be a part of it. The masked men, with decorated headdresses, dance in two parallel rows, in bright costumes decorated with long ribbons that appear to be a combination of Aztec and southwest Indian in origin. The main characters in the drama are El Monarca, the King, who represents Montezuma, and four Capitanes. The swords referred to earlier have become three-pronged palmas (palms) in the New World. In the performances of some groups there is a queen, La Reina, but in others she might be called La Malinche, the Indian woman who became the mistress of Cortés, who represents innocence or the Church. La Reina is often a little girl dressed in a white dress. In some locations it is believed the dancers represent the Twelve Apostles, but in others they are just ordinary men. They carry an image of the Madonna and move along in a candle-lit procession. One and sometimes two prominent performers are El Abuelo (the grandfather) and La Abuela (the grandmother), who act as leaders and also as clowns throughout the dance. El Abuelo wears a rubber mask, and is dressed somewhat like a white man, sometimes carrying a whip, and directing the rest of the dancers. He calls out songs and dance instructions and cracks his whip against the ground. Another dancer, sometimes a small boy, will represent El Toro (the bull), who initiates a bullfight with El Abuelo and is slain. This side battle symbolizes the battle between good and evil. The music is usually played with nonindigenous instruments like the violin and guitar. The costumes and masks of the dance are very important and are usually made by the dancers themselves or their families.
In some towns Los Matachines perform their dance on Christmas, New Year’s Day, or the town’s patron saint’s day. There is documentation of the Matachines dance performed during church fiestas and funerals by the Tarahumara Indians of northern Mexico. In Laredo, Texas, the Matachines from the Ladrillera barrio venerate the Holy Cross and La Virgen de Guadalupe as their patron saint. In this instance the tradition here is closely related to the Yaqui and Mayo matachines.
Interestingly both Native Americans in the United States and Mexicans in Mexico are still performing a dance introduced into the New World over 400 years ago. This tradition performed today in the United States reinforces a heritage with roots in the culture from the eighth century. Because Indians, Mexicans, and mestizos (mixed-race people) perform it, the dance has evolved with different interpretations and has different meanings for each group. The experience of having a religion imposed on a culture is very different for the people it was imposed on, than for the people who imposed it.
References Ancona 1995; Bennett 1935; Cantú 1991b, 1995; Champe 1983; Harris 1996, 1997; Kent 1986; Ortega 1973; Robb 1961, 1980; Rodríguez, S., 1994, 1996; Romero 1993
Menudo (Tripe Stew)
A soup-type dish made with tripe, the stomach lining of a cow, pig’s or calf feet, and maize, such as posole (corn) or hominy. The tripe with onions and garlic is cooked for several hours, posole or hominy is added, along with red chile. Sometimes it is made without chile and may be called menudo blanco. In parts of Mexico some people may call it panza, which is a slang word for “stomach.”
In South Texas during the early 1900s, menudo was called café de hueso by street vendors and local people, literally, “bone coffee” or “coffee from bone.” This name may refer to its understood medicinal value, which is to cure a hangover, known as la cruda. It is typically eaten early in the morning, anytime after midnight, and on such holidays as New Year’s Day, or other big celebrations. It is served in deep bowls and topped with chopped onions, lemon juice, crushed oregano, and more chile. Spicy hot, with lots of chile along with hot tortillas, it is a delicious dish that somehow does cure many ailments. A body feels fortified and strong after such a meal. One can find Chicanos proudly wearing t-shirts with the slogan “Menudo, Breakfast of Champions” boldly printed on the front.
In the novel Fabricated Mexican, the author Rick Rivera describes how he and his stepfather cut and cook menudo in their garage, since his mother refuses to let them cook it in the kitchen, because of the awful smell. There is a very distinct odor to tripe as it cooks.
Everyone has their own way of cooking menudo, and recipes can be found throughout the literature and folklore of Chicanos. In many southwestern cities, menudo cook-offs are held as fund-raisers and social events. Keith Cunningham discusses the difference between the menudo from northern Arizona and that found in the southern part of the state and even compares the Tucson menudo to French cuisine.
References Cunningham 1980; Montaño 1992; Rivera 1995
Mermaid 
See Sirena del Mar
Lo Mexicano
An expression and concept that came into usage in Mexico around 1900, but was not completely culturally defined until after the Mexican Revolution in the late 1920s. The concept had to do with Mexican nationalism and a sense of self-identity with a Mexican consciousness. The term conceptualized a new identity and an awareness of Mexicanness that was native, drawing on the indigenous and the mestizaje (mixed-race nature) of the country. It was in the 1920s when the term lo Mexicano became more known in association with nationalism and could be seen in the life of Mexico and in the art and literature produced after the Revolution. Even in the United States, the art of Mexican painters, such as Diego Rivera and José Clemente Orozco, was admired and well received because of its Mexican character. The writings and research of the Mexican philosopher Samuel Ramos brought attention to the national character of the Mexicano, and to a definition of Mexican identity. Lo Mexicano referred to the Mexicanidad, the national character of the Mexican, which was mestizo (mixed-race) and not European.
This essence called lo Mexicano can be found in art, literature, music, and folklore, for it encompasses the whole experience of being culturally Mexican. The lore of Mexicanidad has migrated to the United States from Mexico with the waves of immigration in the last 100 years, and lo Mexicano forms part of the identity of all Chicanos. Américo Paredes’s life work was an attempt to understand lo Mexicano of the Chicano experience through folklore, in the text of narratives and in the context of folk performances.
References Nájera-Ramírez 1989, 1994; Paredes 1982; Peña 1983; Schmidt 1978
Mexico Lindo (Beautiful Mexico)
A nationalistic sentiment among Chicanos of the United States or el Mexico de afuera (Mexico from the outside) exhibited by patriotic activities such as parades, fiestas patrias (patriotic festivals), and celebrations of Mexican holidays. The expression was used to reflect a nationalistic ideology during the 1920s and 1930s in the United States that in effect reduced regional differences among the various Mexican communities throughout the United States The Mexico Lindo sentiment expressed a patriotism and a love of homeland and anything Mexican. It made difficult life experiences of immigrants in the United States more acceptable. The concept was popularized by a song with the same title sung to Mariachi music by the famous singer and actor Jorge Negrete. The last stanza of the song states:
México lindo y querido
Si muero lejos de ti
Que digan que estoy dormido
Y que me traigan aquí.
(Mexico, beautiful and dear,
If I die far from thee
They should say that I am asleep
And bring me back here.)
These words have brought tears to the eyes of Mexicans born in the United States, including many who have never traveled to Mexico.
Reference Rosales 1996, 1999
Mica (Green Card)
This is the Mexican people’s slang term for the government card issued to legal immigrant residents, also known as the “green card,” in the United States. The legal name of the card is Alien Registration Receipt Card (Form I-151 or I-551). The card is no longer a green color, but it has continued to be called this since at least the 1970s. Illegal trafficking in the mica is very common, and there have always been forgeries of the green card and social security cards as well. Undocumented immigrants manage to learn where to purchase such forgeries. In the streets of southern California a person who sells micas is referred to as a miquero. It is unknown how the word mica originated as a name for the green card. In Spanish a mica is a female monkey, but it is used for a woman who flirts with men or a coquette. The mica is definitely an enticement that lures men to the United States.
Illegal immigrants come from Mexico in search of work in California and other states of the Southwest, and most are willing to do anything for employment. The folklore generated from this experience has been frozen into legends and family oral histories. The mica is a coveted trophy that opens doors to employment. Sometimes it can be gotten illegally by purchase or legally by marrying an American and becoming a legal resident. These experiences are dramatized in corridos (ballads). One corrido, “Mi Micaela,” hides the word mica in a woman’s name Micaela, but the first line gives it away: “Tú eres mi Mica, Mica, mi Micaela, Tú representas todo lo que mi alma anhela” (You are my Mica, Mica, my Micaela, You represent all that my soul desires). Later in the song there is the following line: “Tienes que ser mi Mica, mi Micaela, Verde como los pastos de las praderas” (You have to be my Mica, my Micaela, Green like the pastures in the fields) (Herrera-Sobek 1993b). The play on words, unknown to the average observer, refers to the acquiring of the green card, the mica.
Reference Herrera-Sobek 1993b
La Migra (Immigration Officials)
La migra is an abbreviated and slang term for the Immigration and Naturalization Service (INS) and the Border Patrol. The phrase “hay viene la migra!” has been cried out in fear for many generations in Mexicano and Chicano communities and in the workplaces where they are employed. Raids by la migra are commonplace and have been depicted in films, novels, jokes, and verbal narratives for many years. Migra is short for the Spanish word immigración, and has become an important and viable character in the vocabulary and culture of Chicanos and Mexicanos alike. Cartoons and jokes often depict la migra officials as overweight policemen who chase down innocent women and children. In the folk dramas of El Teatro Campesino (the Farmworkers’ Theater), la migra was often characterized as an unscrupulous arrogant patrol officer who accepted bribes from the growers and ordered raids in the agricultural fields to arrest undocumented immigrants the day before payday. Starting in the late 1940s and into the present, la migra made raids in the San Joaquin Valley of California, rounding up braceros who had overstayed their contract time allocation. In recent years la migra has acquired a much more sinister image as individual abuses are shown on television evening news programs. Still, many Chicanos grew up being threatened by their parents that if they didn’t behave, “te vay llevar la migra,” la migra would come and take them away, presumably to Mexico. Native-born Chicano children have played a game of “la migra chasing the Mexican,” similar to the “cowboys and Indians” games of earlier generations.
See also El Teatro Campesino
References Calvillo 1981; Herrera-Sobek 1991, 1993b; El Teatro Campesino 1985
Milagros (Miracles)
A milagro is literally a miracle, but in folk religious practices milagros are tiny objects presented to a saint at a shrine or church, as a token or offering intended to fulfill a vow made to that saint. Sometimes these objects are called ex-votos, meaning “from a vow,” and are in the shape of the object that symbolizes what the vow was about. For example the milagro could be in the shape of an arm, heart, leg, or baby. In Mexico and the Southwest such vows may be called promesas or mandas and can be fulfilled by prayers, pilgrimages, and promised visits to a saint’s shrine if the wish or favor is granted. This is an important folk religious tradition common among Latinos and Chicanos in the Southwest, Mexico, and throughout Latin America. A mother may make a promesa to La Virgen de Guadalupe, to visit her shrine in Guadalajara, if her daughter is cured of breast cancer. When the promesa is fulfilled this mother may leave a tiny silver breast, a milagro, to symbolize the realization of the promesa.
Milagros are made out of wood, wax, or bone, but the most common material is silver or a silverlike metal, and they are usually very tiny objects, about one inch in diameter. The custom of offerings to saints goes back hundreds of years and can be traced to the Mediterranean among pre-Christian Greeks, Romans, and Iberians. The tradition as it has evolved in the New World is an amalgamation of African, Native American, and Spanish beliefs. Saints are very important among Chicano Catholics, influencing every aspect of daily life and acting as mediators between man and God. Promesas made to saints and the milagros presented are a reflection of their strong predominance in daily life. In the Southwest, this custom has been documented since the colonial period and was undoubtedly introduced by the Spanish missionaries.
It is known that Hernán Cortés, the conqueror of Mexico, had a milagro made in the shape of a gold scorpion, which he offered to the patroness of his home, Our Lady of Guadalupe, in Guadalupe, Spain. This was in thanks for surviving the bite of a scorpion that he received in Yautepec, Mexico, in 1528. In the past most milagros were commissioned, and the local silversmith made them out of silver or sometimes gold. Today they are mass-produced and can be bought at religious stores. Thousands may be found in various shrines, cathedrals, and on saints’ clothing throughout the Southwest and of course in Mexico. The milagros are pinned to the clothing of the saint and left there until collected by the priest or caretaker of the church.
See also Mandas; Retablos
References Durand and Massey 1995; Egan 1991; Oktavec 1995; Toor 1973
Mojado (Wetback)
A translation of the word “wetback,” sometimes spelled moja’o, which literally simply means “wet.” It is a pejorative expression, although it is sometimes used by Mexican people to describe themselves and their experience of illegally crossing the Rio Grande to come to the United States. Also it is a designation used against all Chicanos, with the same prejudicial meaning as “greaser” or “spic.” Some Chicanos use the term to refer to recent Mexican immigrants and also to differentiate themselves from undocumented immigrants. Among teenage Chicanos the word mojado is translated to English and illegal Mexicans are often just called “wets.”
Descriptions of the wetback experience have been chronicled and narrated in corridos (ballads) and novels. In Mexico, the term sometimes used is espaldas mojadas, a literal translation for the word wetback. In 1955 a well--established Mexican director released a film titled Espaldas Mojadas, which intended to persuade Mexicans not to go to the United States. It was a political film that incorporated all of the standard characters that would appear in countless other films and novels of the Chicano experience: the wetback, the pocho (half Mexican), the coyote (smuggler) who smuggles people into the United States, and the grower Mister Sterling. An ironic, yet justified ending shows Mister Sterling dumped into the Rio Grande by Mexicans, and as he swims to the U.S. side of the border he is shot by the Border Patrol. In a 1998 article Herrera-Sobek discusses the use of corridos in several Mexican films that depict the plight of the illegal immigrant, or el mojado.
References Cordova 1990; Herrera-Sobek 1993b, 1998; Madrid-Barela 1975; Mora 1982
Mollera, Caída de (Fallen Fontanelle)
Caída de mollera (literally, the fall of the fontanelle) is a medical condition that can occur in infants, is often classified as a folk illness, but has obvious medical symptoms. The fontanelle, on the top of an infant’s head, is a membrane-covered opening between two incompletely grown bones, a soft spot that will disappear when the bones grow together as the child grows. Mexican children are greatly guarded so la mollera will not fall and cause grave illness to the child. The soft spot on the top of the head may fall if a child falls or is knocked around, shaken too hard, or suffers a trauma or an accident. It is believed that la mollera has fallen when a baby becomes ill with ceaseless crying, fever, diarrhea, and possibly vomiting. Remedies for caída de mollera involve trying to return the fontanelle to its proper position. This can be done by sucking on the soft spot, by pushing upward on the roof of the infant’s mouth, by holding the child upside down and patting the feet, or by using a warm compress. If the mollera is not repositioned death can occur.
There is considerable evidence to support the idea that the concept of caída de mollera is of Aztec origin. It is not a health concept found in Europe or even in other countries of Latin America. The Aztecs believed in an inner force that provided warmth, courage, vitality, and in children, growth. This force was known as tonalli, and was found throughout the body, but resided primarily in the head. If this force was lost through violence or a trauma, death could occur. Children were especially at risk, because this force could be lost through the fontanelle, which was not yet fully closed. By not cutting a child’s hair and by watching the mollera and the head, mothers took care to not lose the tonalli. Some of the remedies for caída de mollera reportedly performed by the Aztecs are similar to those still used by Chicano families and curanderos. Many of a child’s symptoms, as described by mothers, can be linked to medical conditions such as dehydration, which can occur from diarrhea.
La mollera is also considered important as the child grows older. Before entering a pool of water, or getting wet at the beach, many mothers insist that their children first wet the top of their heads, so as not to catch a cold or another illness. “Mójese la mollera antes de entrar al agua,” children are instructed. Some Mexican Americans refer to this condition as a Mexican folk disease because American doctors may not recognize the medical conditions. Often the only person who can cure caída de mollera is a curandera.
See also Curanderismo
References Clark 1959; Kay 1977; Martinez and Martin 1966; Ortiz de Montellano 1987; Roeder 1988; Trotter, Ortiz de Montellano, and Logan 1989
Moradas (Penitente Chapels)
A morada is a meetinghouse and chapel of Los Penitentes, The Brotherhood of Our Father Jesus of New Mexico. Each chapter of the Penitentes has its own morada, which functions as a community center for the members as well as a prayer house and center for religious rituals. Some moradas consist of one room whereas others have two or three rooms, sometimes lined up in a row. Moradas were usually constructed of adobe and were set apart from the rest of the village or the town center. They were located on the outskirts of the town. One of the rooms was always a chapel with an altar. One morada in Abiquiu, a three-room adobe structure built between 1820 and 1850, is considered the oldest surviving morada in the state of New Mexico. See Wallis and Varjabedian for contemporary photographs of ancient moradas still found in northern New Mexico.
References Ahlborn 1986; Boyd 1974; Bunting 1964; Romero and Larkin 1994; Wallis and Varjabedian 1994; Weigle 1976
Los Moros y Cristianos (The Moors and the Christians)
A folk dance and drama first performed in Mexico in the year 1531, according to Bernal Diaz del Castillo. There is documentation indicating it was staged by Juan de Oñate in New Mexico in 1598. The drama originates in Aragón, Spain, during the twelfth century, when Jaime I reconquered a region in southern Spain that was controlled by the Moors. It used to be performed completely on horseback and seems to have traveled the world, following the Spanish army into Mexico, Cuba, the Philippines, British Guiana, and California. In Mexico it became a warlike spectacle, involving many soldiers riding the best horses and wearing extravagant clothing. Unlike the religious plays performed in New Mexico, this one is secular. Although it was traditionally performed on horseback, since the Indians of New Mexico were not allowed to use horses, they performed it as a dance. The objective of the drama is to have the Moros steal the Holy Cross that sits in the center of a plaza and the Cristianos win it back by staging a sword battle between the two battalions of soldiers, the Moors and the Christians. Once the cross is returned to the Spaniards (Christians) the Moors (infidels) pledge obedience to the Spanish king. The defeated Moors are forgiven and become Christians in the last scene. In New Mexico the drama was staged to show the Indians that their subjection was already complete, just as it happened to the Aztecs. The ideological message is that enemies of the Spanish are not annihilated but rather absorbed as fellow subjects of the empire. In New Mexico, the famous Chimayo Moros y Cristianos continue to perform this drama up to the present day. Lea’s book reproduces the dialogue of the drama, and she states that no other complete copy exists “of this, . . . the first play to be presented on the American continent” (23).
In contemporary Spain, the province of Alicante continues to have a major festival known as Las Fiestas de Moros y Cristianos that is a combination of religious and secular processions, with up to 5,000 lavishly costumed participants. The festival is celebrated from three to four days, with several battles taking place to win back the Holy Cross. For a day or two the Moors are in the lead, but eventually they lose to the Christians.
References Aceves 1988; Gutiérrez 1993; Harris 1994; Lamadrid 1993; Lea 1953
La Muerte (Death)
Death, personified as a woman and dressed in white clothing, is a well-known character in Chicano and Mexicano folklore. Commonly accepted as just La Muerte, she is a frequent personality in legends, urban belief tales, and is integrated into many family folk belief systems. Death is sometimes feared, but it is also accepted as the transition to another stage of the life cycle. A common saying is “De la muerte y la suerte nadie se escapa” (No one escapes from death or luck) (Espinosa, A. M., 1910, 404). She habitually appears late at night, to men who are out alone, some intentionally, others innocently on their way home from work. In tales collected in the Southwest, La Muerte is seen standing at streetlights, or waiting by a bridge or the side of the road. She appears to be a beautiful, young voluptuous woman, wearing a long flowing white dress, with her face covered or averted. Once she is picked up and seated in the car, or on the horse, she shows her face to her victim. She has no face; what the men see is a skull. In South Texas she is called La Vieja Blanca, the old lady in white, and she acts as a siren, enticing men, but when they get a look at her face, they see her hideous white skull instead. The men faint, run away, or become deathly ill of susto (fright). In most tales of La Muerte her appearances occur after midnight to men who have nonmoral or immoral schemes. The basic structure of the legend of La Muerte will involve a man alone at night, in his car, buggy, or he may be on a horse, and he sees a woman in white, often with blond hair, standing by the side of the road or near a river. The man is immediately attracted and wants the woman, but when he gets near her and sees the skull face, he faints and hours later awakens in the hospital with his wife and family surrounding him. Tales of La Muerte are narrated by relatives, parents, grandparents, and friends to reinforce an adherence to social cultural norms and marital fidelity. The legend of the appearance of another woman, La Llorona, is structurally similar to stories of La Muerte, and sometimes the same story will use both characters interchangeably.
La Muerte is also known as Doña Sebastiana in New Mexico. She is found in the death cart of the Penitentes, in the form of a skeleton sitting and carrying a bow and arrow. During Holy Week ceremonies Los Penitentes pull the death cart along in their processions.
See also La Carreta de la Muerte; Doña Sebastiana; La Llorona; Los Penitentes
References Espinosa 1910; Flores-Turney 1996; Glazer 1980, 1984; Miller 1973; Vigil 1994
Muralismo (Mural Art)
The artistic movement of painting murals in Chicano barrios. The development of Chicano Muralismo grew out of the political context of the Chicano civil rights movement, a nationalistic political struggle waged by Chicanos during the 1960s. It imitated the Mexican mural art that was created during the postrevolutionary period of Mexico’s history, and was intended to promote political action and raise consciousness. In California the mural movement started about 1970. It involved a variety of interested individuals; as described by Alicia Gonzales, “The emergent Chicano Mural Movement brought together the self-taught artist, the sign-painter, the house painter, the mass-production painter from the billboard companies, the college art student, and the graffiti artist” (155). A statewide meeting of Chicano mural artists was held in September of 1974 as a means of developing cooperation and communication for the artists working throughout California. The early murals were considered public folk art because of the common themes of community and civil rights and because most of the murals were located in working-class neighborhoods and urban barrios. Often, these early murals were referred to as a people’s art. This concept was well expressed by a group of women artists in San Francisco who called themselves Mujeres Muralistas (women muralists). “Our interest as artists is to put art close to where it needs to be. Close to the children; close to the old people; close to everyone who has to walk or ride the buses to get places. We want our art either out in the streets or in places where a lot of people go each day, the hospitals, health centers, clinics, restaurants, and other public places” (Cockcroft, Weber, and Cockcroft, 107).
The scenes of many early Chicano murals consisted of pre-Columbian indigenous themes and motifs that reflected a mestizo (mixed-race) heritage and a Mexican cultural nationalism. Images of Aztlán, a concept from the pre--Conquest, and other Aztec symbols represented cultural pride and national loyalty. Chicano and Chicana artists turned to symbols that portrayed the traditions of Chicanos, traditions that distinguished them from mainstream American culture. These images can still be found in murals located in Chicano communities across the United States. Chicano muralists followed the tradition of the Mexican muralists Diego Rivera, David Alfaro Siqueiros, and José Clemente Orozco, and used murals to rewrite the history of the Chicano experience. Murals were also intended to educate the community on the antiquity and ancestry of the Mexicano. What was not provided in textbooks and the classroom was flashed across walls in Chicano neighborhoods. The Chicano muralists sought to paint the history they knew, a history often based on “oral traditions, legends and myths” (Romo, 136).
Finally, as Tomás Ybarra-Frausto explains, Chicano/a art reflects a “continual effort toward developing an enhanced art of resistance—an art which is not a resistance to the materials and forms of art, but rather a resistance to entrenched social systems of power, exclusion and negation” (1990, 67).
See also Aztlán; Chicanismo
References Cockcroft, Weber, and Cockcroft 1977; Drescher 1994; Dunitz 1993; Goldman 1982, 1990a; Gonzales 1982; LaWare 1998; Romo 1992–1996; Ybarra-Frausto 1990, 1992
Murrieta, Joaquín (18??–1853)
The legend of Joaquín Murrieta is the romantic story of a handsome Mexican highwayman, considered a bandit by history but a great folk hero by Chicanos. At a time when the Mexican people were terribly mistreated in California, it is believed that Murrieta was falsely accused of crimes he did not commit and this prompted him to fight for his rights and those of his people. Joaquín Murrieta, whose name is also spelled Murieta and Murietta, roamed the back roads and hills of northern and southern California from Mount Shasta to the Mexican border in the mid-1850s, stealing horses and robbing Yankees and Chinese alike. There have been countless books, chapters, and articles written about Murrieta or about the legend of this famous Mexican bandito. According to the legend, Joaquín Murrieta was born in Sonora, Mexico, and migrated to California with his new bride in search of gold. He became a bandit and robber after many wrongs were committed against him by Americans. There are several variants of his story, but all have a similar general theme as to why and how he became a bandit.
During the mid-1850s there were at least five men named Joaquín, all of whom are credited with committing robberies and banditry. There was Joaquín Murrieta, Joaquín Valenzuela, Joaquín Carrillo, Joaquín Ocomorena, and Joaquín Botilleras. Some say that Valenzuela and Ocomorena were one and the same, and when he was hanged, two Joaquíns were eliminated. Although it is possible that Murrieta used all of these names as aliases, it is likely that there were at least two Joaquíns at the time. Murrieta started his life of banditry and crime after his home was invaded by white miners, who raped his wife Rosa and beat up Joaquín. Later he and his brother Carlos were accused of stealing a horse, a crime for which Carlos was lynched and Joaquín flogged.
There have been over twenty-one published versions of the Joaquín Murrieta legend. The first and for many years the one considered most -authentic was by John Rollin Ridge, serialized in the California Police Gazette and eventually published under the title of The Life and Adventures of Joaquín Murrieta, the Celebrated California Bandit in 1854. John Rollin Ridge, a Cherokee also known as Yellow Bird, wrote his story one year after the death of Murrieta. This is the basic story of Joaquín that all subsequent histories are based on. In 1859 the California Police Gazette printed Ridge’s story in ten installments and this publicity helped to further disseminate the story. The book was translated into French and Spanish and for many years it was better known abroad than in this country. In doubting the details of the Murrieta legend, researchers go back to Ridge’s version, which some say was based on newspaper stories about the various bandits named Joaquín. It is believed by some researchers that Ridge just applied the name Murrieta to the Joaquín that was finally captured and decapitated. As a Native American, Ridge identified with the discriminatory treatment of California Mexicans, and he stated that he wanted to do justice to the Mexicans.
Joaquín Murrieta’s life has been depicted in novels, stories, newspaper serials, and movies. Charles E. B. Howe wrote a play about Joaquín in 1859 that covers his escapades from the spring of 1851 to July 24, 1853, the day he was captured and killed by Captain Harry Love. It is not known if the play was ever performed, but the portrayal of Murrieta is moving and especially interesting because of all the negative publicity following his capture and death. Howe portrays him as an aristocratic intelligent leader and a man who commits crimes to avenge the wrongs committed against himself and his countrymen.
Joseph Henry Jackson’s work traces the history of the legend, claiming all the information came from the John Rollin Ridge version and that he should be credited with starting the “fictitious” legend. Although Jackson does quote from the San Francisco Alta newspaper demonstrating that many people suspected it was not Joaquín Murrieta who was killed and decapitated by Captain Harry Love, but quite possibly another Joaquín, “every murder and robbery in the country has been attributed to ‘Joaquín.’ Sometimes it is Joaquín Carrillo that has committed all these crimes; then it is Joaquín Murrieta, then Joaquín something else, but always Joaquín!” (Jackson, 13).
Marcus Stewart wrote a long epic poem in 1882 titled Rosita, A California Tale, in which he speculates on the life of Murrieta. In this poem, Joaquín lives and flees in a ship to Mexico or South America, and the body that is decapitated is actually that of his good friend Ramón. Ramón’s girlfriend, Rosita, also disappears at the time of his death, and only after her death, thirty years later, is it revealed that she had been living the life of a man. This story is commingled with the story of Charlotte (Charlie) Parkhurst who lived as a man in California during the latter half of the nineteenth century. The Murrieta legend has also been written by Latinos and Europeans, and Pablo Neruda, the Nobel Prize winner, wrote an opera about Murrieta entitled Splendor and Death of Joaquín Murrieta, insisting that Joaquín was actually Chileno and not Mexican.
Arnold Rojas, a Californian vaquero, writer, and memoirist, writes that Joaquín Murrieta was from the city of Alamos, Sonora, Mexico, where church records show that he and Rosita were married. When his wife was raped and he was beaten, Murrieta saw the faces of his murderers. According to Rojas, Joaquín lived for revenge, and he searched every mining camp in California until he found all thirteen men who committed the crime and killed them. After this he returned to Sonora to live out his life. Supposedly he is buried in Cucurpe, Sonora.
Major Horace Bell (1927) states: “In any country in America except the United States, the bold defiance of the power of the government, a half year’s successful resistance, a continuous conflict with the military and civil authorities and the armed populace—the writer repeats that in any other country in America other than the United States—the operations of Joaquín Murrieta would have been dignified by the title of revolution, and the leader with that of rebel chief. For there is little doubt in the writer’s mind that Joaquín’s aims were higher than that of mere revenge and pillage. . . . it is easy to perceive that Joaquín felt himself to be more the champion of his countrymen than an outlaw and an enemy to the human race” (100).
Chicanos have taken the legend of Joaquín Murrieta seriously and identify with his heroic exploits of stealing from the rich and giving to the poor. He is viewed as a social bandit and a cultural leader, and several corridos (ballads) describe his life and death. At the University of California in Berkeley, a Chicano cooperative student house first established in 1970 is named Casa Joaquín Murrieta after this famous folk hero.
References Bell 1927; Castillo and Camarillo 1973; Herrera-Sobek 1993b; Howe 1983; Jackson 1949; Klette 1928; Leal 1997; MacLean 1977; Neruda 1966; Pitt 1966; Ridge 1927; Rojas 1979; Stewart 1882










Legends 
See Leyendas
La Leyenda Negra (The Black Legend)
La Leyenda Negra is the term used for a myth that describes a very negative attitude many believe pervades the historical perspective regarding Hispanics and Mexicans. The Black Legend embodies a belief that Spaniards are basically a cruel, evil, lazy, greedy, treacherous, and fanatical people. It originated in the era of Inquisitorial Spain and has misrepresented the history of Spain since the 1500s. The printed history of the conquest of the New World depicts a violent and corrupt invasion, but there is a belief that the Black Legend has influenced the way this history has been written.
The Black Legend originated in the sixteenth century during the Protestant Reformation, with the beginnings of a rejection of Catholicism and abhorrence of the political and military power of Spain. When Spain and Portugal remained loyal to Catholicism, and expanded their empires by settling in South America, Central America, the Caribbean Islands, and parts of North America, the rest of Europe looked on very disapprovingly. This viewpoint has continued to color everything about Spain since then, including the grim legacy left by Spain in the New World. It has justified the dictatorial treatment of Latin America and Mexico by the United States since the early nineteenth century. Biased attitudes toward Catholic Spain were inherited by Anglo Americans and brought to the New World colonies by Protestant English settlers.
The term Leyenda Negra was assigned to this belief by Julian Juderias, a Spanish intellectual, in 1914. He stated that anti-Spanish propaganda and misconceptions had continued to develop since the sixteenth century, and historical distortions in both Europe and America constituted a Leyenda Negra. It is thought that the Black Legend is actually the basis for the discriminatory treatment of Mexicans by Anglo Americans during the conquest of the frontier in the 1800s, and even for the current treatment of Chicanos in the United States in the twentieth century. The cause for derogatory stereotyping of Mexicans, and other Latin Americans, is difficult to understand, and the negative stereotype seems to have no historical basis, until one understands the history of the Black Legend. Publications by early American travelers to the Southwest and Mexico depict the Spanish Mexicans in not only horrendous terms, but with extreme passion. Thomas Jefferson Farnham, a New England attorney, wrote in the 1840s, “In a word, the Californians are an imbecile, pusillanimous, race of men, and unfit to control the destinies of that beautiful country” (Weber, 295). Stephen Austin, in 1822–1823, after a trip to Mexico City wrote, “To be candid the majority of the people of the whole nation as far as I have seen them want nothing but tails to be more brutes than the apes” (Weber, 298).
During the U.S.-Mexican war of 1846–1848 the uncivil treatment of Mexicans and Californios and the public conviction in the righteousness of the war are cited as examples of how Mexico was disrespected by Americans. Historically powerful stereotypes of inferior Mexicans and Mexican Americans, perpetuated by arrogant Americans such as Austin, led to the accep-tance of Manifest Destiny as America’s right. “The result of such efforts to discredit Mexico and justify war was a widespread belief that the God--forsaken Mexicans were unworthy to keep the valuable resources and land they had inherited from Spain” (Sanchez 1990, 9).
The popular image of a Mexican with a large sombrero sleeping under a cactus very likely originated from these early writings of traveling Americans, with the result that the icon has become imprinted forever upon the collective character of Chicanos and Mexicans. The common reference to “finally the sleeping giant awakens” when conferring on Mexican American social-political issues is made often by educated and acculturated Chicanos, manifesting an internalization of an image imposed from outside the Mexican culture. Although no one actually mentions the Black Legend belief, its legacy permeates a lot of Chicano oral folklore.
References Powell 1971; Sanchez 1990; Weber 1979
Leyendas (Legends)
A leyenda, a legend, is an oral narrative different from a folktale in that it is narrated as if the event described occurred in the recent past and the story is believed by the narrator to be true. There is often a supernatural element to the narrative, such as a person’s disappearance into thin air, yet it will be recited as having occurred in a specified locale. Often the narrator states where the story originated and explains that the events were observed by a grandmother, cousin, father, or friend. The names of persons and places in the narrative will be familiar to the audience. In Chicano oral tradition, stories about La Llorona, the Blue Lady, or Joaquín Murrieta can properly be called legends and almost always tell a story the audience wants to believe. The Chicano community’s cultural belief system is inherent in the narrative, otherwise the legend would not be recited and retold, again and again. There are hundreds of variants of the La Llorona legend, all narrated about known encounters with her, during the past 200 years. Her tragic story is believable, and one can say she is probably the quintessential legendary figure of the Chicano folk belief system.
The urban belief tale, sometimes just called an urban legend, is a subtype of the legend and is called such because it circulates among all classes and ages and reflects modern stresses and anxieties. It is not only found in urban centers but in rural regions as well. In addition to the legend of La Llorona (Weeping Woman), another widespread legend in Chicano folklore is the Vanishing Hitchhiker, although not always known by this name. A California folklore journal first carried an article about it in 1942, and a Chicano version appears in Miller’s narrative collection from Los Angeles with a date of 1939. The story usually involves a driver who picks up a hitchhiker, often late at night and often a young girl, and he drops her off at or near her home. She leaves something in his car, or he lends her a jacket or sweater, and the next day he returns to retrieve it and learns that she was a ghost, and has been dead for several years. Sometimes she is met at a dance, and asks a boy to drive her home, or she might be a nun, but the ghost is rarely a male. Brunvand calls it a classic automobile legend, and its prevalence has increased since cars became affordable to all social classes. Interestingly, the Vanishing Hitchhiker legend is one of the few narratives shared by both Anglo American and Chicano folklore. Mark Glazer discusses a collection of 152 variants from the Rio Grande Folklore Archive at Pan American University in Texas and states that the legend is “part of a culture which believes in miracles, mystery, and romance” (1987, 35).
See also Agreda, María de Jesus Coronel de; La Llorona; Murrieta, Joaquín
References Brunvand 1981; Glazer 1986, 1987b; Miller 1973; Robe 1980
Limpia (Cleansing)
A folk medicine ritual also called a barrida, from the Spanish verb barrer, meaning a “sweeping,” as in housecleaning. Limpiar means to clean and a limpia is similar to a barrida. Both words mean a cleansing, in a medical and in a spiritual sense. Some people use the word limpieza instead of limpia, but the significance is the same. An individual may seek a limpia from a healer if the person is not feeling well with no specific cause or feels that bad luck or misfortune is prevalent in his or her life. A limpieza can expel the hostile forces and also provide spiritual strength so that the person can effectively fight off negative energy. Spiritual healers who are not curanderos perform limpias, although mostly it is curanderos who perform this ritual. The patient may be standing, sitting in a chair, or lying down while the ritual is performed. The healer will sweep the patient with a little broom made of herbs, such as sage, rosemary, and rue, believed to be effective in eliminating evil influences. Herbal water, holy water, or alcohol is sprinkled over the person in the form of a cross, and the healer’s hands are used to sweep along the whole body, pushing away the evil spirits. While this is being done prayers are recited. The prayers may be the Lord’s Prayer or Las Doce Verdades del Mundo (The Twelve Truths of the World). Instead of herbs some curanderos use an object for the sweeping, such as an egg or a lemon, believing that it will absorb the harm or illness affecting the patient. These objects are burned after the ritual, ensuring the recovery of the person. The person is swept on all sides, front and back, and if there is pain in a particular spot, special attention will be given to that area. Trotter states that “the presence of the curandero, the soothing effect of the sweepings (touching), and the low-key monotone chant of the prayers produces in the patient a light trance state that is comforting and reassuring” (Trotter and Chavira 1997, 82).
See also Curanderismo; Las Doce Verdades
References Roeder 1988; Trotter and Chavira 1997
La Llorona (The Weeping Woman)
This is the name of probably the most famous legendary woman found in Greater Mexico. The ancient legend of La Llorona has been traced to pre-Columbian times in Mexico, and there is continuing discussion whether it may also have medieval European origins. Most Chicanos heard of her as children, read about her in literature, or learned of her from friends. La Llorona, meaning “the weeping woman” or “the howling woman,” may be represented as an Indian woman, an ugly old witch, or a beautiful woman in white with long flowing hair. She always appears late at night, and her crying and weeping can be vividly heard as she shrieks, “Ayyy, mis hijos!” (Oh, my children!).
According to the tragic legend, there once was a woman who was abandoned by her husband, or lover, and left with two or three children. Angry and seeking revenge, she kills her children by throwing them into a river, or sometimes by other means. When she realizes what she’s done, she goes insane. She is condemned to spend eternity searching for her lost and dead children. Consequently she is often heard in the night calling her children. She frequents rivers and other bodies of water, and is sometimes seen floating above the water looking, searching for her children. Her legend has been recited for over 300 years, and in contemporary times she is still believed to be wandering the streets in large cities, as well as in the small towns of the Southwest where numerous people report encounters with her. At times she is seen as a beautiful woman, wearing a white dress, roaming back streets and country roads, crying and weeping. Sometimes she becomes visible to the wayward husband who is out late, drinking, and when he approaches her, she turns into an ugly horse-faced hag, scaring him into swearing abstinence forever. Parents use her name to scare little children into obedience: “Hay viene La Llorona . . . portaté bien” (The Llorona is coming, behave yourself). Even adults who’ve heard the story many times and do not want to admit belief still fear a late-night encounter with La Llorona.
There are ancient texts of indigenous mythology narrated by the Aztecs and recorded by the Spaniards that very closely resemble the La Llorona legend. In some tales she is believed to be Cihuacoatl, the patron goddess of women who die in childbirth. It is said that Cihuacoatl carried a little baby cradle on her back, or a dead baby in her arms, as she roamed the country crying through the nights. Those who saw her considered it an ill omen. Sahagún mentions in The Conquest of Mexico that “a woman was often heard [as] she went weeping and crying out. Loudly did she call out at night. She walked about saying: ‘O my beloved sons, now we are about to go!’” (Horcasitas and Butterworth, 208). Horcasitas and Butterworth reprint several texts of these early chronicles. Diego Muñoz Camargo (ca. 1529–1599) also reported that before the Spaniards arrived, “many times and many nights was heard the voice of a woman who cried out in a loud voice, drowning herself with her tears, and with great sobs and sighs, wailing” (Horcasitas and Butterworth, 209).
Contemporary texts of La Llorona collected in Mexico assert that the original Llorona was La Malinche, the mistress of Cortés. Cortés abandoned her to return to Spain, and according to the legend Malinche killed their son with a knife. This could be the source of another characteristic of the La Llorona legend. In many variants the reason for her abandonment by her lover is their class differences. He leaves her for someone of his own class, or she is an Indian woman or a mestiza (mixed-race woman) and he is of pure blood. In other variants, she is a woman of the streets, who doesn’t want her illegitimate children, so she throws them into the river. She is always described as having long hair, down below her waist, and is seen wearing a white gown. Sometimes men see her as a temptress and a siren; she entices them to follow her, and then she frightens them with her horrible looks. They are usually found dead the next day. What appears to be an unjust punishment is that La Llorona is condemned to wander for eternity, crying and repenting, searching for her lost children. All mothers who have lost children identify with her, and feel her pain.
The prodigious amount of published literature about La Llorona, by folklorists, literary critics, anthropologists, and feminist writers, attests to the complexity of the legend. Children’s books, short stories, novels, and films have been created based on this basic story of infanticide and repentance. We find narratives in rural and urban areas of the Southwest, on college campuses, in juvenile halls, in large cities of the Midwest such as Chicago, and among the native populations of Mexico.
Many Chicanos see themselves as orphans of La Llorona, as the lost children of the marriage between the Aztecs and the Spanish Conquerors. She is a beloved female archetype among contemporary Chicanas, who write poems, short stories, and academic research articles about her. As one writer put it, “It is finally time to let go of a single, narrow understanding of the tale and to see La Llorona instead as an always evolving emblem of gender, sexuality, and power—and, too, as another female victim of history’s tender mercies” (Candelaria, 115).
See also Leyendas; La Malinche; La Muerte
References Anaya 1984, 1995; Arora 1981; Barakat 1965; Candelaria 1993; García 1992; Gonzalez Obregon 1947; Horcasitas and Butterworth 1963; Limón 1988b; Paz 1961; Rebolledo and Rivero 1993; Simmons 1974; Vigil 1994; Zinam and Molina 1991
Los Lobos (The Wolves)
The name of a musical group formed in 1973 in East Los Angeles, with the full name of Los Lobos del Este de Los Angeles. The group has been together ever since, with four of the same musicians, all raised in East Los Angeles. Starting out playing Top 40 band music, they eventually decided to play traditional Mexican folk music, using traditional Mexican instruments. They’ve incorporated into their music the instruments, such the bajo sexto (a twelve-string guitar), el guitarrón (a bass guitar), and el quinto (a five-string guitar).
Their repertoire reflects the variety of Mexican and Chicano music, such as Tex-Mex, Música Norteña, rock and roll, blues, salsa, rhythm and blues, and other Latino styles. The group plays norteño music interspersed with rock and roll. They played and recorded the music for La Bamba, Zoot Suit, and other films and have toured worldwide. Rolling Stone Magazine named the group Band of the Year in 1985. They received a Grammy Award for “Anselma” in 1984, a 75-year-old Mexican song.
In 1988 they produced an album, La Pistola y el Corazon (The Pistol and the Heart), of acoustic Mexican folk songs, which is considered a great collection of Mexican folk music.
References Freedman 1987; Guevara 1985; Loza 1985; Monsalvo 1989
Low Rider
The expression “low rider” is used to describe the car, the subculture, and the person who drives a vehicle that has been lowered, rides very low, and has been customized. A car, truck, bicycle, van, or motorcycle that has been lowered—and this can be achieved by various methods—means that it sits very close to the ground and has a sleek streamlined appearance. The driver and/or owner is called a low rider and the act of low riding refers to all the activities associated with driving the car: cruising, caravanning, and hopping. Low riders have commonly been associated with cholos (1990s urban youth) and gangs, but traditionally Chicanos seriously involved in low riding and customizing low-rider cars are not involved in gangs, and low-rider clubs actually present an alternative to gang involvement. Low-rider car clubs communicate a message of cultural pride and unity. Although different, the cholo subculture can be closely linked to the low-rider subculture.
It is not clear when low riding started, but it was already a custom by the 1930s in Los Angeles and Sacramento, although the name “low rider” did not come into usage until the 1960s. After World War II, because of the growth in the economy, many Chicanos could afford to buy cars, old and new, and the practice of customizing cars and cruising became very popular throughout the Southwest and California during the 1950s. The most popular cars to lower are long ones, such as Fords, Buicks, and Chevrolets. Hydraulic lifts are used to lower and raise both the front and rear ends of a car. Before it was discovered that a hydraulic lift could be used with the batteries stored in the trunk of the car, different methods were used to lower the chassis of the car. Early crude methods were to place heavy bricks and cement bags in the trunk, or to cut the spring’s coils, or lower the car’s blocks. To give the car that lowered look the top might be cut back to lower the roof. In recent times, once a car is “lifted” or “all juiced up,” the driver controls the lift with a hand control.
The painting and decorating of the exterior and interior of the car are very important for appearances, personal identity, and also for belonging to a car club and participating in car shows. The interior may be upholstered in crushed velvet, red or black, have wall-to-wall carpeting, a bar, a chandelier, a TV, and a stereo tape deck. The exterior may be painted in two tones, a lacquer mixed with iridescent flakes, or have a pearl finish. Sometimes the undercarriage is chromed and gold-plated. Painting low-rider cars is a specialty only available at certain paint and body shops, so low riders must be aware of such businesses. Besides the painting of the car, other decorative designs or motifs may also be applied, such as pinstriping, fancy lace (a fire design), and murals. Murals of an Aztec or Mayan scene or La Virgen de Guadalupe are popular icons painted on the trunk, hood, or roof of the car. Even though there is similarity in the styles, each car is very different in the final production. There are many techniques employed to arrive at a unique personal style. For instance accessories from different-year models are interchanged, such as side panels from a 1957 model may be cut and welded to a 1952 car, or “’57 Cadillac tail lamps on a ’62 Chevy Impala” (Bright, 196).
Low riders are usually young urban Chicanos, between the ages of eighteen and thirty, and there can be two and three generations of low riders in one family. The cost of fixing and maintaining a low-rider car is fairly high, so the owner typically is a working person. Since finding older cars, say from the 1950s, is becoming difficult, some low riders now customize small trucks, motorcycles, and bicycles as well. The movie Mi Vida Loca (My Crazy Life) depicts the work that goes into customizing a pickup truck.
Cruising involves driving very slowly up and down city streets, such as Mission Street in San Francisco, Whittier Boulevard in Los Angeles, and King and Story Roads in San Jose, California. The objective of cruising is to socialize, to see and be seen, to give others the opportunity to admire one’s car and to admire the other cars; consequently the driving must be very slow, muy despacito. Driving a great customized car, beautifully painted, is a unique experience for the low rider. Cruising slowly and smoothly, sitting low in the driver’s seat, glancing out at the street, nodding the head slightly when being recognized, all these make up an experience only a Chicano low rider who has invested lots of time and money in his car can appreciate. Cruising is often compared to the custom of promenading around a plaza, referred to as el paseo in many Latin American and Mexican cities. In this sense, the low-rider car becomes a cultural vehicle, as represented by the artist Gilbert Lujan in his series titled “Cultural Vehicles.”
A low-rider 1969 Ford LTD called “Dave’s Dream” is on display at the Smithsonian National Museum of American History in Washington D.C., the first and only low-rider car in the museum. From Chimayo, New Mexico, Dennis Martinez, Richard Martinez, and David Jaramillo worked on customizing the car, starting in 1975. It has two hydraulic pumps, with the batteries stored in the truck, that lift and lower the car and can make it rock from side to side and give it an appearance of dancing. Actually “car dancing” is an event held at low-rider car shows.
Within the low-rider subculture there exist several divisions of traditions. For instance, car clubs are an important aspect of the culture and a way to showcase cars in competitions. One of the oldest ongoing car clubs in Los Angeles is named the Dukes. Members of car clubs are referred to as “clubbers,” and they compete for trophies, ride in car caravans, and often participate in fund-raising events. “Cholos” are considered another group, less financially stable with more modern cars, less ornate, and likely more Mexicano in orientation. A third group, the “cha chas,” are Mexican immigrants, who drive the Toyotas and Volkswagens, and are a smaller group.
Low Rider Magazine was founded during the 1970s to provide a forum for low riders and the culture that surrounds low riding. Low Rider has been very instrumental in the widespread growth of low-rider car clubs, and “Low Rider Happenings,” throughout the Southwest. Low riding is looked upon as a very Chicano cultural phenomenon, yet it has spread to other ethnic communities. There are many non-Chicano car clubs, and the Japanese have also adopted it. Low Rider has been publishing a Japanese edition for the past four years and has organized low-rider car shows in Tokyo and Osaka. As a form of artistic expression and folk art, the customizing of low-rider cars by Chicanos is an expression of tradition and cultural pride.
References Bright 1994, 1995; Chabran and Chabran 1996; Gradante 1985; Griffith 1988; Marks 1980; Parsons 1999; Plascencia 1983; Stone 1990; Thomas 1994; Vigil 1991
Luminarias (Bonfires)
Not to be confused with farolitos, luminarias are small bonfires, and the custom of lighting them dates back to the Roman history of Spain. These small fires are built in New Mexico to celebrate La Noche Buena, Christmas Eve, and to light the way for the announcement of the birth of the Christ child. One family may light three luminarias in front of their home, one each for Jesus, Mary, and Joseph, while another may light twelve, one for each of the twelve apostles. It is believed luminarias originate from the huge bonfires built in pre-Christian times to celebrate rituals to the gods and goddesses. Also in ancient times shepherds built fires to keep themselves warm and to scare off the wolves. This tradition continued in New Mexico with the shepherds’ fires to illuminate the way for the coming of Jesus Christ. They are not as well known as farolitos in contemporary American popular culture, and one often finds farolitos mistakenly called luminarias, and magazine articles describe how to make them, especially during the Christmas holidays.
References Anaya 1995a; Brown 1978; Ortega 1973










Cabeza de Baca, Fabiola (1894–1991)
Born in northern New Mexico on May 16, 1894 (although some sources give her birth date as 1898), Fabiola Cabeza de Baca became a famous home economist, teacher, folklorist, and writer. She was one of several New Mexican women, such as Cleofas M. Jaramillo and Nina Otero-Warren, who wrote of the culture and heritage of their Hispano ancestors. Her parents came from long-established Hispano families who had been in New Mexico for over 200 years. Her grandparents raised her from the age of four, after her mother died, leaving Fabiola with one brother and two sisters. She attended the Loretto Academy in Las Vegas and after graduating from high school became a teacher in a rural area six miles from her father’s ranch in La Liendre. In 1921 she received a B.A. degree from New Mexico Normal (now New Mexico Highlands University) and in 1929 a B.S. in home economics from New Mexico College of Agriculture and Mechanic Arts (now New Mexico State University). In between she also spent one year studying in Spain.
For over thirty years she worked as an extension agent, teaching the traditional ways of preparing foods and emphasizing the nutritional value in the native diet. Two of her books, Historic Cookery and The Good Life, depict the way of life of the Hispanos in the late nineteenth and early twentieth centuries. In We Fed Them Cactus she presents a biography and ethnography of her family, especially her grandmother, a strong woman and a curandera, and retells the stories narrated to her by her father. She depicts the arrival of the Hispano pioneers on the llano (plains) of western New Mexico in the 1830s, and also that of the Anglos in the 1880s, the loss of land, the fencing-in of the plains, and the end of the era with the death of her father. The title of the book refers to the custom in New Mexico of feeding cattle cactus to keep them alive during droughts. In The Good Life, not a long book, Cabeza de Baca creates a fictional family, the Turrietas, and uses their story to narrate the rituals, customs, food, and culture of New Mexico. The customs of Christmas, Lent, marriage, and a funeral are presented, along with many recipes of the foods prepared for these celebrations. She wrote many articles for various New Mexican publications. In 1959 she retired but continued to work giving lectures, writing, and acting as a consultant to the Peace Corps. She died at the age of ninety-seven on October 14, 1991.
Genaro Padilla refers to her writing as “folkloric autobiography,” a significant genre, since it is one of the few kinds of writing by Hispanos that depicts the life they either experienced or learned from their ancestors at the turn of the century. Her folkloric work is extremely important because she wrote about women and how their complicated and elaborate daily work so profoundly maintained the culture and traditions of the Hispanos. Cabeza de Baca was an active member of many community organizations and was president in 1955 of the New Mexico Folklore Society.
References Cabeza de Baca 1954, 1982; Padilla 1991; Perrigo 1985; Ponce 1992; Rebolledo 1989, 1994
Calavera (Skeleton)
A bony skeleton and/or the skull of a skeleton. The calavera has become the symbol of the downtrodden, who must laugh at life in order to survive it. It is also used to mean a drunkard or a very stupid person. During the celebrations of the holy day Día de los Muertos, candy skulls are made and sold in bakeries throughout Mexico and the United States. These skulls may be placed on home altars or given as gifts to children, family, and friends. The Mexican artist and printmaker Jose Guadalupe Posada started drawing calaveras during the late nineteenth century to coincide with this holiday. Their popularity is primarily attributed to him and his work. His images of calaveras have been reproduced thousands of times and can be found year-round, but especially during celebrations of Día de los Muertos. Posada printed many calaveras during the period of the presidency of Porfirio Díaz and during the Mexican Revolution. He introduced the humorous satirical calavera that showed the objectionable side of life, that engaged in regular daily activities such as eating, dancing, drinking, fighting, enjoying life, and being a regular Mexican. The Mexican concept of death is exemplified in the satiric antics of the calavera and this perspective is also found in the art, literature, and performance arts of Chicanos. Calaveras are depicted dancing, drinking in cantinas (bars), crowding and falling out of buses, and playing instruments in musical groups. El Teatro Campesino in its performances always has a calavera character that either represents La Muerte (death) or typifies a disturbing alter ego of one of the main characters.
A Mexican tradition of the late nineteenth century was the publication of a poetic broadside that was called a calavera. Published before or during the festivities of Día de los Muertos, these calaveras carried poems that poked fun at socially prominent people such as politicians and the very wealthy. Some calaveras, such as the poems, were printed in newspapers, but most were small pamphlets or single sheets that were sold on the street. For a small fee, people could hire a composer to write a calavera for them and draw a skeleton to go with it. According to Tinker, “their main functions are to remind us in a good-humored way that we all are mortal, and to poke fun at friends and attack public officials. These last are supposed to take it all in good grace. Calaveras are still published every November 1 in many cities of Mexico, and in some cities in Texas, notably San Antonio” (Tinker 1961, 20). The calavera is now an integral element of Mexican and Chicano folk art and it adorns murals, stationery, postcards, party invitations and decorations, and even religious art.
See also Día de los Muertos; La Muerte
References Carmichael and Sayer 1991; Día de los Muertos 1983; Morrison 1992; Tinker 1961
Califas (California)
An in-group name for California used continuously since at least 1940. It was originally used by the pachucos (1940s youths) in the jargon they developed in the 1930s. Los referred to Los Angeles, which was also called Losca, meaning Los Angeles, California. Barker’s glossary of pachuco words from Arizona shows that the name Califa, without the s, was used to mean a boy from California. Today, Chicanos continue to refer to Califas, when speaking of California, in an affectionate and proprietary manner. The name can be found in art and literature as well as in academic and official documents. Not infrequently the return address on an envelope will be Califas, Aztlán.
See also Pachucos
References Barker 1974; Braddy 1971
California Folklore
The settlement of California by Spanish colonizers happened much later than in New Mexico and Texas. The first Franciscan mission was established in San Diego in 1769, 200 years after the exploration of New Mexico. A second great difference was that many of the Spanish settlers came by way of Mexico, so many of them represented a mestizo (mixed-race) culture rather than a purely sixteenth-century Spanish culture, as the earlier explorers had. Many were Mexican Spaniards and of course did not bring the Spanish language and culture of the Golden Age of Spain with them. Their Spanish language and culture had evolved into a slightly New World variant.
The population of California did not grow much during the eighteenth century, and after the independence of Mexico from Spain in 1821, Spanish culture quickly declined in the region. Many Spaniards left the region, and the great migration of thousands of Anglo American gold seekers took place, so the Spanish culture and language could not survive in California as it did in Texas and New Mexico. By 1880 the Mexican, or Californio, inhabitants of the state represented 1 percent of the total population. At the turn of the century the Chicano population in Los Angeles was only 5 percent. It wasn’t until 1910, with the beginnings of a revolution in Mexico, that the first large wave of Mexican immigration was felt in California.
In discussing Hispano folklore, Aurelio M. Espinosa, the foremost Mexican American folklorist of the early twentieth century, delineated three generations of Hispanics in California. First were the Mexican Spaniards who settled the region in the eighteenth century and their descendents, called Californios, who represented the California Spanish traditions that Espinosa most wanted to study. Second were the Mexicans who continued to migrate into California during the nineteenth century, and these people, as Espinosa delicately put it, were “gente de mas baja condición y cultura” (people of a lower condition and culture) (1930, 301). And third, as he wrote his study in the 1920s, he found many Spaniards who had recently immigrated to California from Andalucía in Spain and who represented a Spain from a different era, and not that of the Spanish Californios. As he states, he collected romances from the true Californios, mostly from the Monterey region. In addition, he collected folktales, proverbs, ballads, and other lore, which were published in the California Folklore Quarterly in the 1940s.
A renowned proponent of Mexican Spanish folklore in the Southwest and California was Charles F. Lummis (1859–1928), a self-taught photographer, ethnologist, musicologist, journalist, and the founder of the Southwest Museum in Los Angeles. Lummis “discovered” the Mexicans in Colorado, New Mexico, and California in the 1880s and 1890s and became enamored of the Mexican way of life, especially of their “hospitality, courtesy, and respect for age” (Heisley 60). He collected oral traditions, specifically Spanish folk songs, from Mexicans in New Mexico and California and felt an urgency to record them before they disappeared. The Southwest Museum holds hundreds of songs he recorded on wax cylinders, songs in Spanish and in twenty-four Indian languages from southern California. He equated Spanish folk songs with the romantic past of the Californios and Mexicans and felt almost a nostalgic fascination for early California history and the era of the large ranchos. In his own words, “The Romance of California is Spanish Romance. Everybody knows that who knows anything” (1923b, 9).
Although not a trained folklorist, Arnold Rojas writes of the vaquero (cowboy) culture of California, especially in the San Joaquin Valley at the turn of the century and into the first third of the 1900s. He describes the life of the Mexican vaqueros, how their lives were spent working on large ranches like the Tejon Ranch and the Kern County Land Co. Their lives were very narrowly focused on cattle and ranch life and they all spoke mostly Spanish. In his reminiscences of vaquero culture and of the impact Mexican Sonorans had on California, Rojas shows a side of Chicano culture not commonly known. Born in California, where his mother and grandmother were also born, it is clear he loved the life he lived. He writes of La Llorona and Joaquín Murrieta, and of Tiburcio Vásquez, who once gave food to his grandmother and mother when they were fleeing from the gringos in Los Angeles.
There are no overall written accounts or collections of the oral traditions and folklore of the early Californios as we have of the Hispanos of New Mexico. In Angustias de la Guerra, Ord’s Occurrences in Hispanic California, she describes some customs, but her work was not intended to preserve for history the way of life of the Californios. Glimpses of customs, games, dances, theater, and other traditions can be found in the writings of early western travelers, although these were often depicted prejudicially and with a lack of historical context. Spanish-language newspapers from the late nineteenth century exhibit folk customs and traditions. The folklore collected from Mexicans and Mexican Americans in the twentieth century, even if it’s from a third- or fourth-generation Chicano, generally will be folklore from Mexico transplanted to California since the turn of the century by immigrants fleeing a revolutionary war, or those coming to work in the agriculture fields. Of course it could also originate in New Mexico or Texas, since there has been much migration into California by Chicanos from those states. Folktales, jests, folk songs, corridos (ballads), and customs related to religious and secular holidays, foods, and other folk traditions found in contemporary California will have a lot in common with those found in other southwestern states and with Mexico. Chicano students have taken an active interest in folklore in the last twenty years, and archives established at the University of California at Berkeley and Los Angeles hold growing collections of many genres of Mexican American folklore. There are published collections from the 1970s and 1980s of folk medicine rituals and folk narratives collected primarily from Mexican immigrants in the Los Angeles area, but there is still much fieldwork to be done in this area.
See also Espinosa, Aurelio Macedonio
References Espinosa 1925, 1930; Espinosa Jr. 1947; Heisley 1985; Lummis 1923a, 1923b; Miller 1973; Ord 1956; Peña 1989; Robe 1976; Roeder 1988; Rojas 1958, 1979; Sanchez 1993
Caló (Spanish Slang)
Caló comes from the gypsy word zincaló, which is one of the idioms of the Spanish gypsies. It is a very old argot influenced by many languages, including French, English, Italian, Greek, and Hebrew, and was spoken by the gypsies of Spain. It was brought to New Spain by the Spanish conquistadores, where it continued to be identified as the language of the poor, the uneducated, and also the criminal class. Caló became the dialect of the underworld of Mexico City and migrated into the Southwest, as some believe, through the city of El Paso.
Published studies of the speech of the Chicano investigate the diverse communication modes by examining the language that reflects the cultural experiences of the various subcultures of Mexican and Chicano communities. Some of these idioms are the pachuco dialect, Chicano Spanish, New Mexico colonial Spanish, south Texas vocabulary, caló, and the argot of the tirilones of El Paso. The pachuco dialect has been especially influenced by caló; it was and still is primarily a male speech and if used by women they were considered to be street women or girlfriends of gang members. Today, however, many words from caló are fully integrated into the standard -vocabulary of Chicano Spanish, and writers incorporate it into poetry, short stories, and novels. What makes caló and its appropriation into Chicano Spanish distinct is its use by working-class Chicanos and Mexicanos. It is a shared language across the Mexican-U.S. border, equally used on both sides.
The vocabulary of Chicano Spanish is congested with Old World words, words from the pachuco era, and consequently heavily influenced by caló. Chicanos have a sense of pride in being aware of these words and expressions, and knowing how to use them. There are many studies that examine the Spanish spoken by Chicanos and several published dictionaries of Chicano Spanish and of caló. Most of the studies provide examples of the male use of caló, but there is recent research that shows that female cholas and pachucas also have an extensive vocabulary in caló. Galindo’s studies of Chicana prisoners show the social importance of caló in conveying a “sense of intimacy and camaraderie between women who shared similar life experiences and acquaintances” (1993, 34).
One published dictionary of caló, by Jay Rosensweig, presents caló in a rather harsh manner, referring to it as gutter Spanish, which prompted a reader to take the privilege of writing a comment on the title page of the book. This example of “book graffiti” is presented here because it is an excellent example of the use of Chicano Spanish influenced by caló and used at an opportune moment:
Este gabacho pendejo y su pinche libro no valen ni un coraje
—que vaya a agarrar las nalgas a la puta que le parió.
(This stupid gringo and his f— book aren’t worth anger;
he can go grab the buttocks of the whore that gave him birth.)
“La Vida de un Bato Loco,” written by an informant of Linda Katz and reproduced in her work, provides a good example of the literary uses of caló. Katz includes a glossary of the caló words used in the story.
See also Bato; Cholos; Pachucos
References Barker 1974; Cerda and Farias 1953; Coltharp 1965; Galindo 1992, 1993; Hinojosa 1975; Katz 1974; Ortega 1977, 1991; Rosensweig 1973; Sagel 1992
Campa, Arthur Leon (1905–1978)
One of a handful of Hispanic folklorists who have spent their careers studying the folk songs, folk theater, customs, traditions, and folkways of the Hispanic population of the Southwest. Arthur Leon Campa was a pioneer in his study of the folklore of the Hispanic population primarily of New Mexico and Colorado. His great achievement and comprehensive work, Hispanic Culture in the Southwest, was published in 1979, one year after his death. Campa was born on February 20, 1905, in Guaymas, Sonora, Mexico, the third of five children. His early years were spent mostly in Mexico, in Baja California and Sonora. His father, Daniel Campa, was a lieutenant in the Federal Army and was killed in 1914 by Pancho Villa revolutionaries. His mother, Delfia Lopez de la O, American-born, returned with her children to the United States. First they settled in a ranch outside of El Paso, and later she moved to Albuquerque, where she opened a store and restaurant.
Arthur Campa earned a B.A. (1928) and an M.A. (1930) from the -University of New Mexico, and a Ph.D. from Columbia University (1940). Campa taught at the University of New Mexico from 1932 to 1942, and again after World War II from 1945 to 1946. In 1946 he became the chair of the Department of Modern Languages and Literature at the University of Denver, and he stayed there until he retired in 1974. Campa wrote nine books, nine bulletins, and forty-nine articles, mostly about folklore, but also on the Spanish language. He considered Hispanic Culture in the Southwest his most important achievement. This comprehensive work is a cultural history of the Hispanic population of California, Colorado, Arizona, New Mexico, and the Texas-Mexico border region. Campa presents the salient char-acteristics of Hispanic culture—customs, language, arts and crafts, and witchcraft—while also discussing distinctive character traits such as individualism, as well as the right to be and the right to do, perspectives on time, and remnants of the medieval honor code. He married Lucille Cushing in 1943 and they had four children. He died of a heart attack on May 13, 1978.
References Arellano and Vigil 1980; Campa 1976, 1979, 1980
Camposanto (Cemetery)
The place where Chicanos and Mexicanos bury their dead is called a camposanto, a “holy field” or “field of the saints.” Although some people use the better-known term cementerio, meaning “cemetery,” camposanto is a word still used in many families. Interestingly, some Spanish dictionaries define the word as a “cemetery for Catholics,” whereas they define cementerio as an “enclosed place for burying the dead.”
Camposantos are important in Chicano families, and the concept of death is always present in personal narratives, songs, and in the religious holy days observed. El Día de los Muertos, or All Souls’ Day, is a religious and folk holy day that is devoutly celebrated; it usually includes a visit to the cemetery. The family cleans the grave sites of loved ones, sets up flowers and candles, and visits with and prays for the departed. During the rest of the year, attendance to burial sites does not diminish, and graves are kept decorated and colorful.
During the colonial period of New Spain, burials were made within the church itself, as was the tradition in medieval Spain. Spaniards and the clergy were allowed to be buried in the missionary churches, whereas the mestizos (people of mixed race) and Indians were buried in the camposanto located in front or to the right of the church. By the late eighteenth century, the Catholic Church forbade additional burials inside churches, supposedly for public health reasons, but the ricos, the well-to-do, continued to buy their way into the churches. So the camposantos were still left for the poor mestizos. A recognizable sign of a colonial frontier camposanto was a large public, eight-foot wooden cross that stood in the front or center of the cemetery. Some can still be found today in rural parts of northern New Mexico and Texas. Another feature that can also still be found in parts of the Southwest is segregation and isolation from Anglo cemeteries. Many were located side by side but were fenced off and had separate entrances. The sites chosen for rural camposantos were often on tierra muerta, barren land that was too poor to cultivate.
Cemetery and graveyard decorating traditions have been researched and written about as a means of appreciating and understanding Mexican folk beliefs about death and grieving. The adornment of grave sites reflects religious folk practices, and ethnic and family attitudes about death and remembrance. Some of the customs include decorating and designing a space that will be revisited by a family for many generations. The intent is to keep the deceased person alive in the family’s memory. Some design motifs that are distinctive to Chicano cemeteries are the construction and design of crosses. Terry Jordan’s book has an illustration of twelve different “subtypes of wooden Latin crosses found on Mexican graves in Texas” (78). In the nineteenth and even into the twentieth century crosses were built of wood, but these didn’t last long, being destroyed either by the elements or by vandalism. More common today are crosses made of molded concrete. Many grave sites have a cerquito, a low wood, metal, or concrete fence, an enclosure that surrounds an individual grave. Another common trait is to construct a cement grave marker, with a nicho (niche) built into it, so that the statue of a saint, La Virgen de Guadalupe, or a photograph of the deceased can be placed in it. Sometimes a concrete cross will have a nicho built into its base for the same purpose. Although fresh flowers are often placed at grave sites, paper and plastic flowers are more common. Colorful plastic wreaths are sometimes attached to the wooden or cement cross. Another dis-tinguishing feature in Chicano camposantos is the wide range of materials used in decorating a grave. As with home yard shrines and home altars, everyday objects are used as personal and artistic statements. It is often in the performance of highly charged personal rituals that people create folklore, folk art, and folk music.
Many grave markers are brightly painted, and some even have religious scenes painted on them. This tradition has been linked to Mexico’s indigenous heritage, for, as Terry Jordan states, “Such use of color in a sacred context has ample pre-Columbian precedent in Mexico, where even the huge pyramids once bore bright paints” (80). He goes on to say, “Hispanic graveyards are places of color, where paints, flowers, and tiles combine to comfort the bereaved and startle the gringo” (88).
See also Altars; Folk Art; Nichos
References Barber 1993; Gosnell and Gott 1992; Griffith 1985; Jordan 1982; Sanborn 1989









Bailando con el Diablo (Dancing with the Devil)
A popularly narrated legend found throughout the Southwest, south Texas, and even parts of northern Mexico that tells of the appearance of the devil at community dances, dance halls, and discotheques. Called the “devil at the dance” legend or “devil haunts the dance hall” in folklore literature, it is considered to be an urban belief tale that has been adapted to contemporary situations. The devil makes his appearance elegantly dressed, usually in a suit; he is strikingly handsome, muy suave (smooth and poised), tall, and refined. Consequently, he stands out from among the rest of the men. Besides his stunning appearance, he is always an amazing dancer, knows the latest dance steps, and selects the prettiest girl to dance.
As the tale is often narrated, a disobedient young girl goes to the dance without her parents’ permission, or she goes against her mother’s express wishes. While at the dance a handsome beautifully dressed man asks her to dance. They dance all night, until she suddenly notices with a shock that he isn’t wearing shoes, and in fact he doesn’t even have feet; instead he has chicken feet, goat’s hooves, or a pig’s foot and a chicken foot. It is usually at this point, after he’s discovered, that he disappears into thin air, leaving the odor of sulfur in the air, or, in some versions of the legend, just runs out the door. The girl he was dancing with either faints or burns to death as she goes up in smoke. If the girl doesn’t die, as in some stories, she might suffer a burn on the shoulder or a man’s handprint might be found on her back. A small circle of people who are present at the dance observe this encounter, and the narrator of the story usually says that she or he heard it from someone who was there.
The lesson learned is that one must not disobey one’s parents, for the handsome man is known to be the devil and the personification of evil. It is noted that mostly women narrate these legends, among themselves or from mothers to daughters, in a didactic fashion, to instill fear in young women so that they will not disregard parental authority. In some variants a young girl specifically transgresses religious beliefs by insisting on going to a dance on Good Friday, a religious holy day, and a revered day of prayer in Chicano Catholic households. The appearance of the devil on this day is an especially ominous sign.
Robe’s collection of New Mexico legends contains thirty-four variants of the devil-at-the-dance tale. Although the legends in this collection are from rural northern New Mexico, collected in the 1950s and 1960s, we find contemporary versions of the devil-at-the-dance tales in south Texas and in Baja California from the 1980s. Limón and Herrera-Sobek discuss versions of the tale circulating in nightclubs and discotheques among urbanized young people.
Of course, not everyone believes such stories. Martin’s book contains a story by a man born in 1904, who says his friend played a trick on his community in Tucson by coming to a dance dressed in black, with a fake rooster foot. Eventually someone noticed his foot and yelled, “The Devil! The Devil!” The narrator says he was there when his friend played the trick, so he doesn’t believe in the legend (50).
References De Leon 1982; Glazer 1984,1994; Herrera-Sobek 1988; Limón 1994; Martin 1983; Robe 1951; Robe ed. 1980; West 1988
Baile (Dance)
El baile is an individual dance step, a party, or a ball. El baile is historically one of the most important social traditions among Mexicans and Chicanos throughout Mexico and the United States. Since the Spaniards conquered the Southwest, bailes have been important community social and cultural events. In Texas, New Mexico, and California, because of the isolation of the communities, dancing became the principal source of entertainment. The social status of women in Spanish colonial society was limited and cloistered, with their primary social venues consisting of church and home. El baile provided entertainment and physical activity. As an early California traveler put it, “I was astonished at the endurance of the California women in holding out, night after night, in dancing, of which they never seemed to weary, but kept on with an appearance of freshness and elasticity that was as charming as surprising” (Shay 100). It was at el baile that courtship occurred (since girls, although they may have gone to the dance chaperoned, were allowed to dance with boys); it was at el baile that families and relatives interacted, that the week’s work was forgotten, and that life’s mysteries were discussed. The local dance brought the community together and allowed interaction between the sexes. A girl was never able to reject a request to dance from a boy, because to turn down an invitation exposed the boy to embarrassment and ridicule for his failure in competition, and could be cause for revenge. Countless corridos (ballads), leyendas (legends), and chistes (jokes) narrate events that are supposed to have occurred at el baile, from fights to courtships to elopements. Encounters with the legendary weeping woman, La Llorona, often occur after a dance when a solitary man is finding his way home. From the devil-at-the-dance narratives to the tragic death of Rosita Alvarez, recounted in the corrido of the same name, we learn of the importance of el baile in both rural and urban Chicano communities. Major Horace Bell describes the difference between a baile and a fandango in Mexican California history and Arnoldo De Leon describes the baile in eighteenth-century San Antonio.
Most Mexican national holiday celebrations such as Cinco de Mayo and El Diez y Seis de Septiembre will end with a community dance. Even in modern times, professional Latino and Chicano associations often close their national conferences with a baile, bringing in popular Chicano bands. Jose Limón discusses the narratives of bailando con el diablo (dancing with the devil), and Manuel Peña shows us the ritualized structure of a Chicano dance.
See also Bailando con el Diablo; Cinco de Mayo; El Diez y Seis de Septiembre; Fandango; La Llorona
References Bell 1927; De Leon 1982; Limón 1983, 1994; Peña 1980, 1985b; Shay 1982
“Ballad of Gregorio Cortez” 
See “El Corrido de Gregorio Cortez”
Ballads 
See Corridos
Ballet Folklórico
The term refers to folk dance groups, grupos folklóricos, that perform traditional Mexican regional dances. The dances are carefully choreographed and well rehearsed; they are representative of the dances from the different regions of Mexico. An important characteristic of the dance performances is the elaborate beautiful costumes, very full and colorful dresses, that are the traditional dress from the various states of Mexico, such as Jalisco, Veracruz, Chihuahua, and Durango. The dances, many of which have been danced for decades, such as El Jarabe Tapatio and La Negra, are danced to Mariachi music, and performed on the Mexican national holidays, Las Fiestas Patrias, such as Cinco de Mayo and El Diez y Seis de Septiembre.
These folk dance groups became popular in Mexico right after the Mexican Revolution, but did not become prevalent in the United States until the 1960s. It was the influence of the Chicano civil rights movement, el movimiento Chicano, that launched the institution of ballets folklóricos as symbolic of a Mexican American cultural identity. El Ballet Folklórico de Mexico, founded and directed by Amalia Hernandez in the early 1950s, became the official cultural representative of the Mexican government and has often toured the United States. Amalia Hernandez based her folklore costumes and folk dances on the authentic folklore traditions of the Mexican people. This folklórico group became the model on which most Chicano folklórico groups are based.
Mexican folklore traditions, folk songs, and folk dances had been taught within Mexican colonias (neighborhoods), today known as barrios, since before the 1930s, usually through the efforts of a single individual in the community, in church halls and mutual aid society halls, but not in the public schools. There was one exception: in Tucson, Arizona, a teacher named Margarite Collier started a Mexican Folklore Club in 1937 in an elementary school, for the specific purpose of maintaining the cultural traditions from Mexico. This club existed until the 1970s, and it established a long tradition of performing Las Posadas through the streets of Tucson. Madelyn Loes Soloman documents that in Los Angeles the teaching of folk songs and dances was done by a Mexican-born man in the late 1930s. But it was in the late 1960s and 1970s that there was a revival in the formal organization of elaborate performances by large dance groups, many made up of young children and teenagers. Folklórico groups perform for community events, Cinco de Mayo festivals, school functions, Fiestas Guadalupanas (celebrations of La Virgen de Guadalupe, December 12), political events, and other holidays. Ballet folklórico dances are now taught in many schools, and students entering college often bring with them a knowledge of the dances and an interest in participating. Several university campuses in California and the Southwest have dance groups totally comprised by and maintained by college students.
See also Las Posadas
References Collier Archives; Griffith 1988; Najera-Ramirez 1989; Soloman 1941
“La Bamba”
The title of a song, as well as the title of a movie directed by Luis Valdez in 1987. The film is about the life of the Chicano singer Ritchie Valens, who recorded the song and made it very popular in 1958. The song actually goes back to early Mexican colonial history; it has been traced to 1790 when it was performed at the Coliseo Theatre in Mexico City. There are printed sources that cite the song being sung and danced in Veracruz during the nineteenth and early twentieth centuries. By the 1830s it was also a popular dance in Mexican California.
“La Bamba” is considered to be a son jarocho (country folks’ dancing music), an example of the mestizo (mixed-race) musical tradition, with strong African influences, from the state of Veracruz. The instrumentation of the traditional son jarocho included a small harp, a small eight-string guitar (jarana), and a small four-string guitar (requinto). The dance that went with son jarocho was a zapateado, a foot-stomping dance. There are two different accounts about how Ritchie Valens learned the song, since he supposedly never learned Spanish. One source states that he heard the song on a short trip across the border into Mexico, and another states he learned the song from his uncle when he was five years old. His innovative style mixed jarocho music with a rock ‘n roll beat. His recorded version of “La Bamba” in 1958 is the first known U.S. recording. “La Bamba” has now been recorded more than 150 different times in the United States; for example, in 1966 by Trini Lopez, in 1979 by the Plugz, and in 1980 by Los Lobos. The Rice University Marching Band and the Mormon Tabernacle Choir have also recorded it. The movie, with the soundtrack recorded by Los Lobos, was very successful with mainstream audiences and launched the acting careers of several Latino actors.
References La Bamba 1987; Guevara 1985; Holscher, Fernandez, and Cummings 1991; -Lipsitz 1990; Loza 1982; Sheehy 1979
Bandidos 
See Folk Heroes
Barbacoa de Cabeza (Barbecued Beef Head)
Barbacoa refers to a method of cooking meat, in a pit of hot wood coals. The English word barbecue comes from barbacoa. Barbacoa de cabeza is the cooking of a beef head in this manner. It is an old custom and cultural event that in parts of south Texas occurs every weekend, with the barbacoa eaten on Sunday mornings. In other parts of the Southwest this style of cooking is reserved for special events such as weddings, funerals, and large family gatherings. According to the Diccionario de Mejicanismos (Dictionary of Mexicanisms), barbacoa is “carne asada en un hoyo que se abre en tierra, y se calienta como los hornos” (grilled meat cooked in a hole in the ground heated like an oven). Cooking the beef head with this method means all the parts can be eaten, such as the brains, eyes, tongue, lips, literally everything. Although originally a discarded part of the cow, now it is considered a delicacy and is prepared and sold in many neighborhood stores and restaurants along the Rio Grande border region. Today the term barbacoa is used only to mean the cooking of meat in a pit, also called pit cooking.
References Montano 1992; Peyton 1994
Barrio (Neighborhood)
A barrio is a neighborhood, a city district, or a ward in an urban area where Mexicans and Chicanos live. In the early 1900s, Mexican communities were called colonias, as they are in Mexico today, but at some point after World War II, Chicano neighborhoods became known as barrios. In Chicano culture, barrios are identified by given names that in some way describe a characteristic of the neighborhood or reflect its history. Some barrios are only a few blocks, whereas others encompass large urban areas. Some of the oldest barrios can be found in major cities, like Los Angeles, Chicago, El Paso, and San Antonio. In San Fernando, also known as San Fer, two very early barrios were La Rana and El Bajillo (The Frog; The Little Low One). Hoyo Marvilla, another well-known barrio in East Los Angeles, was famous because it was where farmworkers lived and was extremely poor. Barrios are sometimes called ghettos; even though there are very negative and sometimes few positive attributes to living in barrios, they can’t always be presumed to be ghettos in the sense of places where a group is forced to live against its will. Vigil’s work on gang culture explains the allegiance felt by gang members toward their barrio. Mary Helen Ponce writes in Hoyt Street about the barrio where she grew up in Pacoima, California, during the 1940s and 1950s. Many Chicano novelists have set their stories in the barrios of the Southwest and Midwest. Raúl Salinas, in his poem “A Trip through the Mind Jail,” writes about his barrio, and all barrios, while he serves time in prison. In one section of his poem he affirms the positive role of the barrio:
LA LOMA . . . AUSTIN . . . MI BARRIO . . .
I bear you no grudge
I needed you then . . . identity . . . a sense of belonging.
I need you now.
So essential to adult days of imprisonment,
You keep me away from INSANITY’S hungry jaws;
Smiling/Laughing/Crying.
I respect your having been:
my Loma of Austin
my Rose Hill of Los Angeles
my West Side of San Antonio
my Quinto of Houston
my Jackson of San Jose
my Segundo of El Paso
my Barelas of Albuquerque
my Westside of Denver
Flats, Los Marcos, Maravilla, Calle Guadalupe, Magnolia,
Buena Vista, Mateo, La Seis, Chiquis, El Sur and all
Chicano neighborhoods that now exist and once
existed; somewhere, someone remembers
References Chicano Pinto Research Project 1975; Ponce 1993; Salinas 1970; Vigil 1988, 1996
Barriology
The social science of barriology was conceived of as a discipline of study in the pages of Con Safos magazine in 1969. Con Safos: Reflections of Life in the Barrio was one of the early Chicano periodicals published by college students; it printed humorous, political, and literary articles. It is an example of a publication where Chicanos could express cultural and political satire. Barriology was created as a spoof on the academic social sciences; it involved testing those Chicanos not so fluent in the traditions and rituals of living in Chicano neighborhoods or barrios. Con Safos carried monthly examinations developed by Antonio Gómez, “PhD, Barriologist Emeritus.” It was also a way of gently poking fun at Chicano culture, reminding the readers of the uniqueness of the Chicano culture. Some of the exam questions consisted of multiple-choice answers; others required the reader to fill in the answer. Some sample questions follow:
Menudo is made from tripe, which is:
a. the cow’s stomach, b. the cow’s flank, c. horse meat, d. mutton
Someone who is described as a lechusa is a:
a. lettuce peddler, b. leach, c. milkman, d. night person
Capirotada is the traditional food during what time of year? 

Complete the following children’s chant:
Pelon Pelonete, Cabeza de quete, Vendiendo Tamales, (De cinco y de siete.)
Everyone knows that Juan Charrasquiado’s death was caused by
———————. (title and character from a corrido who was killed in a -cantina).
Each exam included a rating scale so that those who took the exam could determine their level of knowledge of the Chicano culture. For example a score of 23 to 28 indicated a Chicano Barriologist was “muy de aquellas” (very Chicano); 18 to 22 indicated High Potential, “o ya casi” (almost a Chicano); 13 to 17 was half Mexican, half American, or “keep trying, you”; 8 to 12 was a “vendido” (sellout or culturally deprived); and 0 to 7 was a “pendejo” (dummy, jerk).
References Gómez 1970a, 1970b, 1971
Bato (Dude)
Bato is a word centuries old that can be translated as “guy” or “dude.” Most recently it has been spelled vato, transposing the v for the b. In Chicano communities, in-group chatter, and published literature one frequently comes across the expression bato loco, meaning a “crazy guy,” a “cool dude,” or a “wise guy.” Bato was a word incorporated into the pachuco jargon of the 1940s, and it is still very much a part of Chicano vocabulary today. The bato loco, or vato loco, is the descendent of the pachuco and a close relation of today’s cholo (urban youth). The bato is often mentioned in connection with his barrio, as in el vato loco del Hoyo Mara.
The bato loco is tantamount to an archetype in Chicano culture; he is that crazy guy who isn’t afraid of life. He may be a gang member, a drug user, or just an entertaining street person. He could also be fully immersed in la vida loca as described by Luis Rodriguez in his book, Always Running, and by Oscar Zeta Acosta in The Autobiography of a Brown Buffalo. In the novel The Road to Tamazunchale, Ron Arias creates a streetwise character, a bato named Mario, who acts as a sidekick to the main character, Fausto. The two wander through a mythical Los Angeles in search of “the song of life.” For the contemporary Chicano male, el bato loco is not only a symbol of ethnic identity but also an icon of the urban coming-of-age experience itself.
In standard Spanish, bato means “simpleton” or “foolish fellow,” and it has been in use in rural areas of New Mexico since the seventeenth century. In Los Pastores, or the Shepherds’ Play, a mystery play performed in Mexico and the Southwest since the sixteenth century, the shepherd who plays the role of a buffoon, a jester, is named Bato.
Another good example of the life of a bato loco is “La Vida de un Bato Loco,” a short memoir written by an informant of Linda Katz, reproduced in her thesis on the pachuco language and culture written for a master’s degree at the University of California, Los Angeles.
See also Cholos; Pachucos; Los Pastores
References Arias 1975; Barker 1950; Cerda and Farias 1953; Katz 1974; Rodriguez 1993; Smethurst 1995
Bazaars 
See Jamaicas
Beans 
See Frijoles
Beliefs 
See Creencias
The Black Legend 
See La Leyenda Negra
Blankets 
See Colchas
The Blue Lady
See Agreda, María de Jesus Coronel de
Bogeyman 
See El Coco; El Cucui; El Kookoóoee
Bolillos (Bread Rolls)
A bolillo is a small loaf of white bread or a large dinner roll, which in the United States is sometimes called French bread. Bolillos, also known as birotes, can be found in most Mexican and Mexican American bakeries and are often served in Mexican restaurants. The folkloric use of bolillo occurs when it is derogatorily applied to Anglo Americans, supposedly because they are as white as bread, and because the Americans invaded and annexed Mexican territory, the Southwest. Although not as popularly known, it carries the same meaning as gringo or gavacho. Chicanos also often use the term, as they do agringado, to describe an overly acculturated Chicano, one who is trying to be “white.”
It is believed the word was originally used to describe French soldiers when they occupied Mexico in the 1860s. Although written references to its use in this way have not been found, there are references to the French eating small loaves of white bread in corridos. Américo Paredes cites a stanza from a corrido (ballad) the Mexican soldiers sang after the Battle of Puebla (celebrated on Cinco de Mayo) that taunts the vanquished French soldiers with the following words:

Qu’es de las piezas de pan?
Aguárdenlas que ahi’ les van. Pam!
(Where are the loaves of bread?
Get ready, for here they go. Bang!)
(1993a, 37)
See also Agringado; Cinco de Mayo; Gavacho; Gringo
References Paredes 1961, 1993a
Bone Setter 
See Huesero
Bonfires 
See Luminarias
Bonus 
See Pilón
Bourke, Captain John Gregory (1846–1896)
An early writer of Chicano folk culture and folklore from the Texas-Mexican border. Although Bourke was first and foremost a military man, he became interested in ethnology and anthropology and wrote extensively on these subjects. Born in 1846 to Irish Catholic parents in Pennsylvania, he enlisted in the Fifteenth Pennsylvania Volunteer Cavalry during the Civil War. In 1865 he attended West Point, graduating in 1869 with a commission in the Third Cavalry. He served with General George Crook from 1871 to 1886, and in 1891 wrote a well-received book titled On the Border with Crook.
Through his friendship with the director of the Bureau of American Ethnology at the Smithsonian Institution, Bourke studied anthropology and broadened his interests to include ethnology and folklore. At various times he wrote pamphlets for the Bureau of Indian Affairs. He gained fame as an Indian fighter, but was also known as an anthropologist and writer. Although primarily a military man, he managed to conduct fieldwork among several -Indian tribes, and was considered an expert on the Apaches. He was stationed along the Rio Grande for two years, during the era of the Catarino Garza revolt, and his diaries from this period are a valuable resource on the Garza movement. He learned the Spanish language, apparently because of his ethnological interests, and wrote on the Tejano and Mexicano culture of the border region. During the 1890s he published ethnographic articles about the Texas-Mexican border in the Journal of American Folklore and the American Anthropologist. Bourke observed, chronicled, and wrote both as a journalist and anthropologist about the folk medicine practices and the folk foodways of the Rio Grande region.
His approach to folklore study was that of the established tradition of the times, which examined current customs, traditions, folkways, and folk narratives as survivals of an earlier civilization. Sometimes this survivalist perspective carried with it an attitude about the prior culture, where the customs originated, as having been a higher civilization. Accordingly, when Bourke became interested in Mexican customs and language, he approached them as the cultural remains of a higher Spanish-Arabic civilization. In spite of the fact that his nineteenth-century biases are very apparent in his writings, the data he collected are valuable for the study of Chicano folklore of the Texas-Mexican border. He was elected president of the American Folklore Society in 1895, and he died in 1896. He is buried at Arlington National Cemetery.
References Limón 1994; New Handbook of Texas 1996
Braceros (Laborers)
Mexican workers recruited from Mexico under the Emergency Farm Labor Program known as the Bracero Program, which was in effect from 1942 to 1964. The word bracero comes from the Spanish word brazo (arm), which is used, as English uses “hand,” to mean “laborer.” In the same way bracero commonly means a man who works with his hands, a laborer, and is used when speaking of all farm and agricultural workers. There was a shortage of farm laborers during World War II, and this program offered an answer to that problem, although some braceros also worked on the railroad. Until only recently bracero was applied to any Mexican farmworker, and is often used interchangeably with words like “wetback” or “greaser.” The number of workers brought from Mexico ranged from a low of 4,180 in 1942 to a high of 62,091 in 1944. It is estimated that by 1947 nearly 220,000 braceros had worked in the United States under this program. It continued even after the war, and between 1955 and 1959 over 480,000 braceros were still working in the United States. Some have compared the Bracero Program with legalized slavery, and the impact on the perception of the Mexican farmworker by American agribusiness has been to foster contempt and disdain. Many braceros chose not to return to Mexico when their contracts ended and -instead stayed and hid from la migra, the feared Immigration and Naturalization Service (INS).
Many Chicanos of the Southwest and Midwest are descendants of braceros who came to the United States and stayed, never returning to Mexico. The bracero experience has been written about in novels and depicted in numerous movies, and although the image presented is often a negative one, like other Chicano folk heroes the bracero has become an archetype of the culture. He is in the company of the historical mestizo character of Yo soy Joaquín, the revolutionary figure of Joaquín Murrieta, the mythical pachuco, the stately learned persona of Dr. Paredes, the gentle leadership of César Chávez; the bracero is the universally exploited farmworker, the campesino of the world. Many corridos (ballads) describe the experience of coming to work in the agricultural fields of the Midwest and the Southwest. Maria Herrera-Sobek -describes the prototype of the bracero, as represented in countless corridos, in her book The Bracero Experience. In Mexico the experience was written about from the perspective of those who returned, as in such books as Aventuras de un Bracero, by Jesus Amaya Topete, published in 1949 and reprinted several times, and in the United States the novel Macho! by Edmund Villaseñor, published in 1973.
References Acuña 1988; Galarza 1964; Gutiérrez 1995; Herrera-Sobek 1979, 1993b, 1998; Madrid-Barela 1975; Nelson 1971; Paredes 1993

Bread Rolls 
See Bolillos
Brujería (Witchcraft)
Witches and brujería (witchcraft) are accepted facts of life in Mexican and Chicano culture. Belief in witches and witchcraft is common in the Southwest, as can be seen by the large number of folk narratives and legends about witches collected in New Mexico and Texas in the last century. This form of occultism is an integral part of the culture of Mexico and the Southwest. The Spanish conquerors and colonists who settled New Mexico in the sixteenth century communicated to the indigenous communities a belief in witchcraft. Beliefs in witchcraft were prevalent in Europe during the fourteenth, fifteenth, and sixteenth centuries, and the missionary friars brought these beliefs to the New World. The Spanish Catholic missionaries worked hard to convert the indigenous populations of New Spain, and any non-Christian belief that was not acceptable to the Spanish friars was often attributed to sin, evil, the devil, or witchcraft. Consequently it was easy to assign unexplainable natural phenomena to the work of witches, and these beliefs have persisted over hundreds of years. Contemporary witches can prepare love potions, lift spells, cure and cause illnesses, and in general cause great harm. They can also take on any form they desire, such as a cat, pig, or owl, and so can make themselves difficult to identify. In folktales from New Mexico, they often appear as balls of fire flying across the sky. Curanderas are sometimes mistaken for witches because of their healing power, but they are also often called upon to undo the work of witches.
Many of the folktales, legends, and cuentos (stories) collected in New Mexico by Aurelio Espinosa, Juan Bautista Rael, and R. D. Jameson (Robe 1980) are about witches and witchcraft. In the 1930s, writers employed by the Works Progress Administration (WPA) as part of Roosevelt’s New Deal collected many cuentos and legends about witches from the people of northern New Mexico, and many beliefs expressed then are still held today. For instance, the way to tell if a person is a witch is to stick two needles in the form of a cross into the sill above a door; if the person in the room is a witch, she won’t be able to leave the room. Another belief is that only men named Juan or Juan Bautista or women named Juana have the ability to catch or overpower a witch. Conversely the power of a witch cannot be exerted over a person named Juan or Juana. A witch cannot sense the presence of a Juan, so he may be able to trap her by drawing a circle on the ground and throwing his shirt, turned inside out, into the circle.
Witches often take the form of an owl, in New Mexican Spanish called a tecolote, from the Nahuatl word teolotl. The hoot of an owl is an evil omen, so one must be careful to stay away from owls. In other parts of the Southwest owls are sometimes known as lechuzas. A lechuza is a woman who has sold her soul to the devil and becomes an owl by night. Only a woman can become a lechuza.
A prayer meant to keep witches away was recited at night in a low voice:
Cuatro esquinas tiene me casa
Cuatro ángeles que la adoran
Lucas, Marcos, Juan y Mateo
Ni brujas ni hechiceras
Ni hombre malhechor
En el nombre del Padre,
Y del Hijo y del Espiritu Santo.
(My house has four corners
Four angels adore it
Luke, Mark, John and Matthew
Neither witches nor charmers
Nor evil-doing man
In the name of the Father,
and of the Son
and of the Holy Ghost.)
(Simmons 1974a, 11)
Besides being present in folktales and legends, the world of brujas seeps into discussions of love and lovers, literature, and other forms of Chicano folklore and culture.
See also Curanderismo; Espinosa, Aurelio Macedonio
References Brown 1978; Delgado 1994; Espinosa 1910; García 1992; Jaramillo 1972; Rael 1957; Robe 1980; Simmons 1974a, 1974b; Ulibarri 1977; Weigle and White 1988
Burritos
Literally a little burro or little donkey, a burrito has come to mean a taco made of a wheat flour tortilla instead of a corn tortilla, filled with meat, rice, frijoles (beans), and chile, then folded and rolled up. There are several theories about the origins of the name burrito, and there may be some truth to all of them. One theory is that when flour tortillas became available in northern Mexico, tacos de frijoles, or bean burritos, were easy to carry in the saddle-bags of the vaqueros (cowboys), so for this reason they came to be called burritos as though they were the sidekicks of the vaquero’s horse.
Tacos made from corn tortillas are much older; they have been around since the epoch of the Aztecs. Wheat and flour were introduced into New Spain by the Spaniards, and one can see that the flour tortilla is similar to the flat bread found in many Mediterranean countries. Once flour tortillas were discovered, the move to making tacos from flour tortillas was logical. Since corn tortillas are small, and can only bend or fold over once, and flour tortillas are more pliable and can be rolled several times, the flour taco was a natural outcome. A burrito can be made with any type of filling, such as beans, potatoes, chile con carne, chile colorado, carnitas (chile with meat, red chile, roasted pork meat), or even peanut butter.
Flour tortillas and burritos are found in northern Mexico and the Southwest, but are not known in other parts of Mexico. Since at least the 1920s, Chicanos from Texas have been making what came to be called burritos. Originally they were called tacos; another story about the origin of the name is that in the 1940s there was an establishment in Juárez, Chihuahua, Mexico, called Los Burritos that sold tacos made of tortillas de harina (flour tortillas). It became a well-known place to go, and people spoke of going a los burritos (to the burritos) when they wanted tacos of that kind. Commercial burritos became available in San Francisco in 1961, according to an article in the San Francisco Chronicle, and now there are supposedly over 150 burrito taquerías (taco restaurants) in the Mission District of that city. Burros is the name reserved for the very large tortilla burritos, in which the tortilla may be a foot and a half to two feet in diameter.
See also Tacos
References Griffith 1988; Roemer 1993









El Abuelo (Grandfather)
An old-man figure called el abuelo (the grandfather) played the role of a bogeyman in Hispano folklore. In literature it is sometimes spelled aguelo, and some scholars speculate that it may be a borrowed word from the language of the Pueblo Indians. In Spanish it means “grandfather,” and has become synonymous with coco, cucui, and bogeyman. This folk character is more known in northern New Mexico than in other parts of the Southwest. He appeared at Christmastime to test and discipline children who did not know their catechism or prayers. He was a scary figure, dressed to terrify children with a black cape and a mask with large horns, and always carrying a whip. Children were terribly frightened because of his horrid appearance. Instead of a mask he sometimes had a tortilla plastered on his face, wore buffalo horns and a horsetail, and of course carried the whip. A few days before Christmas, he’d knock on the door of a home, give a bloodcurdling cry, crack his whip, and yell at the children, “Han sido buenos muchachos estos?” (Have these children been good?) The children would cringe and hide while the parents defended them. Then el abuelo would say, “Pues que recén y se acuestén” (Well, let them pray and go to bed). Sometimes he made the children dance Las Palomitas, loosely translated as “the little doves.” Espinosa describes this experience. “After making them pray, he makes them form a circle, and, taking each other’s hands, they dance around the room with him, singing,
Baila paloma de Juan turuntún (or durundún) [sic]
‘Turun tún tún
Turun tun tún!’
(Dance dove of Juan confused or disoriented
Confused, confused!)
(1910, 402)
A description of el abuelo making children “dance the little dove” is also available in Steele’s work (1992, 25). Throughout the year if children misbehaved, parents would threaten them, “Si no te sosiegas, llamo el abuelo” (If you don’t behave, I’ll call the bogeyman).
El abuelo is also a prominent figure in the dance of Los Matachines, and plays a comical role in which he makes jokes and shouts out instructions to the rest of the dancers. In some performances there is a female character, la abuela, who acts as el abuelo’s accomplice and plays a similar role. Although he is not heard of often in contemporary times, references to el abuelo can be found in the folktales and literature of New Mexico.
See also El Coco; El Cucui; El Kookoóee; Los Matachines
References Brown 1978; Cobos 1983; Espinosa 1910; Steele 1992
La Adelita (Mexican Revolution Woman Soldier)
A feminist symbol of the Mexican Revolution, La Adelita was the name of a woman soldier, a soldadera, who followed the troops, helped to set up camp, and cooked for the soldiers. Some soldaderas were employed to cook and fulfil the needs of a particular soldier, whereas others were relatives or lovers. The legend states that Adelita was a woman who fought in the Revolution, but it is not known if she actually existed as an individual; she came to epitomize all soldaderas and courageous women of that period. In popular culture, literature, and the cinema, soldaderas have been portrayed as self-sacrificing women, usually mestizas (mixed-race women) from the lower classes, but La Adelita is often seen as a güera (light-skinned), “sweetheart of the troops, a woman who is valiant, pretty, and a wonderful helpmate to the soldier” (Salas 121). Several corridos (ballads) have been written about her, and she is a powerful symbol for Mexican and Chicana women, representing bravery, self-discipline, and romantic love. In fact, it is primarily through the corridos that Adelita is known today. Historically, all soldaderas became known as Adelitas. In performances by ballet folklórico groups, the dances and music of the Revolution are often called Las Adelitas.
La Adelita is more than a romantic image to modern-day Chicanas. She continues to symbolize feminine independence, integrity, the fight for justice, and a proud heritage. Because the major influx of Mexican immigration into the United States was during the Mexican Revolution, many Chicanos and Chicanas grew up hearing stories about soldaderas and La Adelita from relatives, parents, and grandparents. In the late 1960s Chicanas who joined the Brown Berets de Aztlán, a political pseudomilitary youth group, often dressed as Adelitas, wearing rebozos (shawls) and bandoliers crisscrossed over their chests.
One play about La Adelita, titled Soldadera, written by Josephine Niggli, was produced and performed in the United States in 1936, and is still performed today. Niggli was 25 years old when the play was written. She went on to write Mexican Village, a novel that incorporated many of the Mexican people’s folk customs and traditions. Born in Monterrey, Mexico, she lived in Mexico City and was taught at home by her mother. Later she moved to San Antonio, Texas, where she attended high school. She went to the University of North Carolina for playwriting, sometimes acting in her own plays. Soldadera is a play about the women in the Revolution, “women who left homes to follow their men, cooking for them, tending their wounds, guarding their ammunition, fighting when necessary,” as Niggli put it. The Adelita character dies in the play, and Niggli idealizes her bravery.
One variant of the corrido “La Adelita” follows:
En lo alto de una abrupta cerrania
acampado se encontraba un regimiento
y una moza que valiente lo seguia
locamente enamorada del sargento.
Popular entre la tropa era Adelita
la mujer que el sargento idolatraba
porque a mas de ser valiente era bonita
y hasta el mismo coronel la respetaba.
Y se oía que decía aquel que tanto la quería. . . .
Y si Adelita fuera mi novia,
y si Adelita fuera mi mujer,
le compraría un vestido de seda
para llevarla a bailar al cuartel.
Y si Adelita se fuera con otro
la seguiría por tierra y por mar
si por mar en un buque de guerra
si por tierra en un tren militar.
(On the loftiest of the sierras
A regiment is camped
And a brave young girl follows
A sergeant that she crazily loves.
Popular among the troops was Adelita
The woman that the sergeant idolized
Because besides being brave she was pretty
And even the colonel respected her.
And one could hear him that loved her so. . . .
If Adelita was my girlfriend,
And if Adelita was my woman,
I’d buy her a silk dress,
To take her dancing at the barracks
If Adelita ever left with another
I would follow her by land and by sea
If by sea, in war ship, and
If by land on a military train.)
References Arrizón 1998; Herrera-Sobek 1990; Niggli 1938; Salas 1990
Adivinanzas (Riddles)
Adivinanzas are riddles. Many Chicano children remember being entertained with riddles narrated by parents and grandparents. A riddle is an intellectual brainteaser, in Spanish called a quebracabeza; facts are framed in the form of a question in such a way that the respondent cannot possibly know the answer. An example in Spanish is, “Qué camina de cuatro patas por la mañana, dos patas en el medio día, y tres patas en la noche?” (What walks on four legs in the morning, two legs in the afternoon, and three legs at night?) The answer is man, who as a child, in the “morning” of life, crawls on four legs; as an adult walks on two legs; and as an old man uses a cane for support, thus walking on three legs. Another example is a “true riddle,” which is a comparison of something to the unknown answer, and that something is described in the question. For example, “Tengo ojos y no miro; boca pero no hablo; qué soy?” (I have eyes and cannot see; a mouth, but cannot speak; What am I?) The answer is a photograph. Another type of riddle is the conundrum, where the answer is contained in the riddle itself, such as “Agua pasa por mi casa cate de mi corazon” (Water passes by my house pain of my heart). The answer is “agua-cate” (avocado). Or, “Lana sube, lana baja” (Wool goes up and wool goes down). The answer is “la navaja,” la-na-baja (the knife). Conundrums contain wordplay and in Chicano culture are sometimes bilingual, playing with words in both the Spanish and the English language. Another type of riddle is the riddling question, such as “Qué le dijo la luna al sol?” (What did the moon say to the sun?) The answer is “Eres tan grande y no te dejan salir de noche” (You are so big and yet are not allowed to go out at night).
Many Spanish riddles collected in the Southwest reflect in some way the characteristics of the Southwest, both linguistically and environmentally. Since the problem presented in a riddle is linguistically and culturally based on both the teller’s and the audience’s culture, they must all be members of the same community or group to comprehend the puzzle. Bilingual riddles, those narrated in both English and Spanish, are clearly a Chicano invention growing out of the bicultural experience. Riddles are fun and educational as well. It is usually children who enjoy telling and listening to riddles. Like other folklore genres, riddles serve a function, helping children learn to interpret facts and form an opinion. They use language, humor, and a verbal fun activity to challenge a child’s intellect.
References Brown 1978; Campa 1937; Espinosa 1985; Glazer 1994; Lucero-White 1941; McDowell 1979; West 1988
Adobe (Sun-dried Brick)
Adobe is a word with Arabic origins that means “unburnt bricks made from earth.” Adobe bricks are made from a mixture of clay and sand, sometimes just called mud-straw, and are slowly dried by the heat of the sun. Various structures, homes, buildings, and churches are built of adobe bricks and then plastered with more adobe mud. Buildings made of adobe have lasted for centuries when sufficient and constant care is provided to prevent erosion of the mud. Contemporary adobe architecture, as found in what is called the Southwest style, is a fusion of native New Mexican Indian and Spanish forms. The basic structure, adobe walls supporting a flat roof, is an Indian tradition thousands of years old. When the Spanish moved into New Mexico and the Southwest, they adopted this basic structure, but incorporated their technique of forming the mud into bricks. Most of the Catholic missions were built out of adobe. Adobe homes and buildings provide a sense of security and protection from outside noise with their two-to-four-foot thick walls. Often the literature about adobe also mentions the sense of continuity with the earth one feels when living in an adobe home.
Making adobe bricks and adobe hornos (outdoor ovens) is still a tradition in New Mexico. Native American and Hispanic women have a long tradition in the construction of adobe structures. The Spaniards noted that it was the Pueblo women who built the adobe walls. Within the Hispanic community it has been the role of women known as enjarradoras to plaster the walls of the structures, a task that is done with the bare hands. A saying in Spanish describes this as, “El hombre las levanta, la mujer las enjarra.” (The man builds the walls and woman plasters them) (Romero and Larkin 1994, 44). In contemporary times, the Museum of International Folk Art in Santa Fe sponsors demonstrations of adobe brick making and horno construction, performed by women who are well-known master adoberas (makers of adobe) and master enjaradoras.
In southern Texas and northern Mexico, small huts called jacales were also constructed of mud-straw. Even though this mud was of almost the same composition, it was not called adobe. The mud was not formed into bricks, and the structures were considered temporary, even though many have existed for decades.
References Boyd 1974; Brown 1978; Bunting 1964, 1974; De Leon 1982; Graham 1991; Romero and Larkin 1994; Weigle and White 1988; West 1988
Agavachado
See Agringado
Agreda, María de Jesus Coronel de (The Blue Lady)
A woman dressed in a blue veil or the blue habit of a nun who appeared to help the sick and the afflicted during the seventeenth century. Legends of the appearance of the Blue Lady circulated in New Mexico and Texas during the mid-1600s. There are stories that narrate how she especially liked to help women in need and poor children, although it appears her goal was also to Christianize the Indians of the Southwest, whom she visited often. She was able to speak various Indian languages and would speak to the members of each tribe in their own tongue. Fray Damian Manzanet, while visiting Texas in 1690, reported that the chief of the Tejas Indians spoke of being visited by a beautiful woman dressed in blue garments. The chief was requesting blue fabric that his people wanted to use in the burying of their dead. There is much written evidence of her appearances in Texas, where she was referred to as “The Mysterious Woman in Blue.” The Jumano Indians of Texas were reportedly visited by her approximately 500 times between 1621 and 1631.
The first reference to her is in the memoirs of Fray Alonso de Benavides in 1631. Every report we have of her appearances indicates that the Blue Lady was actually María de Jesus Coronel de Agreda. She was born in Spain in 1602 and died May 24, 1665. She never physically visited the Southwest, but she stated that she made “flights” to New Mexico to help the Indians. María de Agredo lived in a convent and wrote several books, including one with the title The Mystic City of God.
Adina de Zavala cites a San Antonio legend about a mystifying woman in blue who appears once in a generation, out of the hidden underground passages of the Alamo, bearing a distinctive gift that she bestows on a woman. The woman is always a native Texan; she may be young, old, or middle-aged, but she is always a special woman, “pure and good, well bred, intelligent, spiritual, and patriotic.” The gift that is bestowed on her is the ability to see “to the heart of things,” and the woman is instructed to use the gift for the good of the people of San Antonio and of Texas.
References Bullock 1972; Castañeda 1936; Colahan 1994; DeBaca 1988; Dobie 1964; Hallenbeck and Williams 1971; Sturmberg 1920; Zavala 1917
Agringado (Anglicized)
An expressive term used among Chicanos to describe other Chicanos who have become very gringo-like, very anglicized (inglesado), or americanizado. Another word used interchangeably is agavachado, meaning too much like a gavacho, an Anglo. In a bicultural environment, or even in tightly knit Mexican communities, when individuals become thoroughly acculturated to American society and values, the individual may be criticized by close friends and relatives, and be called an agringado. Agringado is a particularly strong term in comparison to americanizado, because the word gringo connotes a strong negative image of a North American. All Chicanos are americanizados to a certain extent, by learning English and attending public schools. But the behavior of an agringado might involve the changing of one’s given name, so that Carlos becomes Charlie, Guillermo becomes Will, or Consuelo becomes Connie; or changing a surname, so that Rivera becomes Rivers or Puentes becomes Bridges. In the verbal folklore repertoire of Chicanos, jokes abound about Mexicans who become Anglos and adopt the values, mannerisms, food, clothing styles, and verbal expressions of the dominant society. Besides becoming gringo-like, a Chicano agringado may overtly reject Mexican American culture, the music, the values, and even the Spanish language, by pretending not to speak it. Such a person sees the Mexican way of life as inferior to the Anglo, and the agringado may marry an Anglo and completely turn his/her back on Chicano culture. An agringado will not self-identify because this kind of behavior is perceived as negative or disloyal to his/her cultural group. Rather, identifying or pointing out agringado behavior tends to be done by family or peer group members, who use teasing, joking, and narrating exemplary anecdotes characteristic of folkloric behavior. This type of behavior is an outcome of living in a bicultural and bilingual environment and serves to strengthen the in-group’s sense of cultural identity.
The agringado figure has become a stock character in Chicano culture and is frequently encountered in folklore, literature, and popular culture. The film Mi Familia, directed and released in 1995 by Gregory Nava, includes a comical scene depicting the agringado son, a UCLA student, bringing his Anglo girlfriend home to meet his Mexican family.
References Limón 1988a; Madsen 1964; Peña 1985b
Aguinaldos (Christmas Gifts)
The translation of this word found in Spanish dictionaries is a “gift given at Christmas.” In the folk tradition, it is a small gift given at a Christmas party or celebration, usually in the form of food or candy. During Las Posadas, the reenactment of the pilgrimage of Mary and Joseph’s search for an inn, when celebrations are held in private homes, the hostess will pass out aguinaldos to the children. These can be small bags or baskets filled with candy, nuts, fruits, or toys. It is a gift given as a sharing, a memento, a remembrance, rather than as a Christmas present. Mention of the custom of aguinaldos is found in Cabeza de Baca’s book, The Good Life. Américo Paredes describes a slightly different tradition of aguinaldos that he learned in song form from his mother in South Texas. During the days between Christmas and Día de los Reyes (the Day of the Kings, or Epiphany), January 6, young boys went from house to house singing carols called aguinaldos, and asking for food and gifts. Homes were opened to them and they were offered good things to eat and drink. In this context aguinaldos are Christmas songs.
This expression has also been used when describing a children’s custom in the Southwest. On Christmas Day children went knocking on doors and visiting homes, asking for and receiving candy or small toys. Sometimes they would sing a song that sounded more like a prayer or a chant, called Oremos. Lottie Devine describes a custom in Arizona where the local Indians visited homes on Christmas Day, receiving food and drinks. This was referred to as “calling Christmas.”
See also Oremos
References Cabeza de Baca 1982; Devine 1964; Paredes 1976; Sommers 1995
Alabados (Hymns)
Ancient religious hymns that praises the Virgin Mary, Jesus Christ, or a patron saint. The Spanish word alabar means to praise, or to glorify, so most ala-bados start with the words “alabado sea” (praised be). Alabados are usually sung with religious fervor, and many are extremely long with an indefinite number of verses. The Penitentes of New Mexico were known to sing alabados during Lenten rituals, Holy Week processions, and other religious ceremonies. The songs are mystic in nature; many narrate the story of Christ’s life, his anguish, betrayal, his crucifixion and resurrection, and others praise the virtues of suffering and penance. Alabados were sung as ritual prayers in homes, at dawn, noon, and at nightfall, and they were almost always sung at funeral processions. Their melodies are fusions of indigenous music and medieval chants. Stories of Mexican California narrate the singing of alabados first thing in the morning by a family, each member in his/her own room, but all together at the same time. Like the décima (ten-line poetic song) and the romance (four-line song), alabados were introduced into the New World by the Franciscan padres, who taught them to the Indian people as they were teaching them the Bible and converting them to Christianity. In recent times alabados have come to mean any religious hymn sung at wakes or religious ceremonies. Many are very old and the authors unknown, although a few collected in southern Colorado were written by a local singer in the 1940s. Folklorists of the 1930s and 1940s were still able to collect some of these ancient hymns from elderly people who learned them from their parents in the nineteenth century. Juan Rael published one of the first essays on the alabado in 1950, and a recent researcher, William Gonzalez of the University of Utah, calls them “some of the saddest music” (Ingalls B11).
See also Los Penitentes
References Briggs 1988; Brown 1978; Espinosa 1985; Fisher 1958; Henderson 1937; Ingalls 1996; Rael 1950; Robb 1980

Alambrista (Illegal Border Crosser)
Literally, alambre is a wire, and an alambrista is a person who uses alambre. The term has come to mean a person who crosses a wire fence, regardless of the means or method. In this cultural usage the fence is the wire fence along the Mexican-U.S. border, the term is interchangeable with mojado (wetback), which refers to a person who enters the United States illegally by crossing the Rio Grande in Texas. Alambrista is not as common an expression as wetback, but it is used frequently by the media. The Mexican cinema has produced many films about illegal entry into the United States with many characters playing roles as alambristas. An American film with the title Alambrista! The Illegal, written and directed by Robert Young in 1979, deals with the issue of undocumented immigration by portraying the experiences of one man’s journey into the United States and back to Mexico. It is considered a landmark film because of the authentic portrayal of a life of fear and alienation experienced by the main character.
Like the term wetback, this is an expression many Chicanos can identify with since many have family members who have entered the United States through nonlegal means. It is part of the folklore repertoire of Chicano culture since the Mexican-U.S. border is politically and culturally a constant element in everyday life.
References Barrera 1992; Madrid-Barela 1975
All Souls’ Day 
See Día de los Muertos
Altars
An altar is a religious shrine (depending on its size, sometimes called an altarcito, a little altar) established in the home for the personal worship by the family. Home altars are common in many Mexican and Chicano homes. The word altar is derived from the Latin word altare, a combination of altus, high, and ara, altar, referring to a raised structure for worship, one that goes upward toward the sky or heaven. It provides a space where religious people can communicate with God, the saints, or other spiritual beings. Home altars vary in size, from a small shelf with one votive candle and one saint or statue, to a large table altar, with many religious images, La Virgen de Guadalupe, flowers, pictures of saints, candles; a structure that can fill up half a room. Permanent altars can be in a small nicho (niche) in the bedroom, the living room, or even the dining room. Daily devout prayer, such as reciting the rosary or praying to a patron or favorite saint, is a normal occurrence in many families, with the prayers often led by the mother or grandmother. A personal home altar may evolve over a period of years, rather than being constructed suddenly in one day. When the creation is such a gradual process, it can reflect and almost chronicle the happy and tragic events that take place in the family. As family members are born, or die, their picture or a favorite personal item of theirs may be placed on the altar, along with their patron saint, a votive candle, or flowers. Eventually, the altar can become so much a meaningful representation of the family that it will be maintained for years and even generations.
The religious observation of All Souls’ Day, or Día de los Muertos, on November 2, is an occasion for many families to erect altars specifically for a parent or other family member who has recently died. These altars will traditionally have a picture or pictures of the departed with offerings and gifts. Family and friends are invited to visit and add items to the altar, which becomes almost a shrine, and is called an ofrenda. In many U.S. cities Día de los Muertos ritual celebrations have become community affairs that include more than the Chicano community and may entail a procession through the streets ending at a local school or community center. In the last thirty or so years, the creation and construction of altars have become major art programs for museums, schools, and community centers in the United States. The altars are wonderful artistic creations, a form of folk art, with local artists participating and involving children in the making of calaveras (skeletons), papel picado (cut tissue paper), paper flowers, and other decorations.
In Chicano and Mexican culture it is usually women who develop home altars, as expressions of devotion, to pay homage to past family members, and to find a space for daily prayer. It is thought that home altars were created as a result of community isolation from a centralized place of worship. After Mexico gained its independence from Spain, the Spanish friars left Mexico and the Southwest and for many years there weren’t enough priests to visit all of Mexico’s small villages and rural areas. Isolated communities and individual families created their own places of worship. The wealthy or upper classes were able to build small chapels on their ranches, while the poorer classes built small nichos and altars in their homes, in kitchens or other rooms, for private prayer and devotion.
See also Calavera; Día de los Muertos; Folk Art; Nichos; Ofrenda; Papel Picado; La Virgen de Guadalupe
References Carmichael and Sayer 1991; Griffith 1988; Morrison 1992; Sommers 1995; Turner 1981, 1982, 1990, 1999; Viduarri 1991
Americanisms 
See Pochismos
Anglicized 
See Agringado
Anglo 
See Gavacho; Gringo
Arizona Folklore
A large portion of what is now Arizona was once considered part of New Mexican territory. As with Colorado, the folk customs, traditions, and language of Arizona have been closely related to those of New Mexico. The southernmost regions of Arizona, however, have always been more closely related to northern Mexico in customs, language, and folklore. After the U.S.-Mexican War of 1846–1848 and the signing of the Gadsden Treaty in 1854, Arizona experienced the same cultural changes as Texas, New Mexico, and California, although more gradually, since the region was not immediately overwhelmed by an Anglo American invasion as the other areas were. Arizona’s oldest and most important Mexican community has been Tucson, founded by Spanish settlers in 1775. Tucson was the frontier fortification of the Mexican state of Sonora until the Gadsden Purchase transferred it to the United States. It functioned as a cavalry outpost established in response to the many Indian raids of the times. 
Mexicans were a majority through most of the nineteenth century, and Tucson had a bicultural spirit that was unique in the Southwest. A Mexican middle class ran some of the largest businesses, held political offices, became artists or intellectuals, funded private and public education, and created a prosperous Mexican society envied by other communities of the Southwest, with elegant theaters like the Teatro Carmen and Spanish-language newspapers. Tucson’s proximity to Mexico, especially Sonora, permitted Tucsonenses to remain close to their Mexican heritage. According to Thomas Sheridan, “This Mexican elite represented a local florescence of Latin American civilization in Arizona, its society and culture linking Tucson with the finest traditions of both Mexico and Spain” (3). Although there was a strong Mexican middle class, many Chicanos were working class, such as butchers, barbers, and later railroad workers. The railroad arrived in southern Arizona on March 20, 1880, and this changed society in Tucson forever.
There has always been a substantial Chicano and Mexican population in Tucson. The folklore of the region was recognized to be important, and Margarite Collier, an elementary school teacher, organized a Mexican Folklore Club at Carrillo School in Tucson in 1935. An article in the Arizona Daily Star of December 19, 1943, states that the club was “to help the children sustain pride and interest in the traditions, customs and folklore of Mexico and to perpetuate these customs among Spanish-speaking people of Tucson.” Miss Collier taught the children music, art, and folk dances of Mexico. Every year the school organized a Las Posadas procession through the streets of Tucson. The same article in the Arizona Daily Star describes this celebration, with the subtitle of the article stating, “Ancient Mexican Custom to be Encouraged in Ceremonial Here.” The children of Carrillo School carried out this tradition until the late 1970s, and the Mexican Folklore Club continued until well after Miss Collier retired from teaching. Miss Collier worked at collecting songs, games, and other folklore from the children of the school. The Margarite Collier Collection of her private papers is housed at the Southwest Folklore Archives of the University of Arizona library.
James Griffith, a professor at the University of Arizona, is probably the scholar who has published the most on Arizona Hispanic folklore. He has written several works on the traditional folk arts of southern Arizona, a region that also includes the Pimas, Yaquis, and Tohono O’odham Native Americans and borders the Sonora state of Mexico. Griffith writes about the foods of the region, folk art, yard shrines, cascarones (decorated eggshells), religious practices, and the various musical traditions. Folklore collected by Griffith’s students is also housed at the Southwest Folklore Archives of the University of Arizona library.
Patricia Preciado Martin, born and raised in Arizona, has written extensively about the folklore and traditional past of the Mexican people of Arizona. She has collected oral histories and folktales from elderly Mexican Americans, many of them born in Arizona or Sonora, Mexico. These oral histories nostalgically narrate the lives of men and women born at the turn of the century, describing the rural way of life on cattle ranches and the early city life of Tucson.
Thomas Sheridan has written a social history of the Mexican people of Tucson from 1854 to 1941, thoughtfully showing the social and cultural changes that occurred to the Tucsonenses after the coming of the Anglo Americans. The religious and cultural life of the community is carefully researched and impartially presented. A very good description of the foods prepared by Tucson’s Mexican restaurants is provided in the work of Suzanne Myal. An early publication of Arizona folklore is a collection of songs published in 1946 titled Canciones de Mi Padre, by Luisa Espinel. An exhibit at the University of Arizona Museum of Art reviewed by Amy Kitchener shows the continuity between home and community folk arts. A recent article by Josiah Heyman presents a social history of Douglas, Arizona, presented through the oral histories of residents of that city during the first decades of the twentieth century.
References Campa 1979; Espinel 1946; Griffith 1985, 1988, 1993, 1995; Heyman 1993; Kitchener 1997; Martin 1983, 1988, 1992, 1996; Medina 1975; Myal 1997; Sheridan 1986; Sheridan and Noriega 1987; Tales Told in Our Barrio 1984

“Ay Vienen los Yankees!” (Here Come the Yankees!)
This title of a song from early Mexican California vividly expresses fear of the loss of the Mexican culture. The song expresses an aversion to the cultural invasion of the Americans along with a fear that the Mexican women may like the Yankees too much. This song was collected in southern California and according to Hague, the “words date from 1848 or about that time” (109). It is an example of a folk custom the Mexicans used to convey their antipathy toward the Anglo culture. It goes like this: 

Ay vienen los Yankees,
Ay los tienen ya 
Vienen a quitarles, la formalidad. 
Ya las señoritas que hablan el ingles, 
Yankees dicen “Kiss me!” 
y ellas dicen “Yes” 
Ay here come the Yankees, 
Ay they’re coming by
Now let’s all go easy on formality. 
See the señoritas who speak English now, 
“Kiss Me!” say the Yankees, 
the ladies answer, “Yes.” 
References Hague 1917; Schander 1994
Aztlán
According to an Aztec legend, Aztlán was the place from which the Mexica Aztecas came, known as the place of emergence, in some codices identified as the “seven-cave place.” The Mexica Aztecs traveled south under the guidance of the god Huitzilopochtli, who advised them to look for an eagle perched on a prickly pear cactus, devouring a serpent. This would be their new home, they were told, which they were to call Tenochtitlán.
In the late 1960s Chicanos starting calling the southwestern United States, or that portion of Mexico lost to the United States during the U.S.-Mexican War of 1846–1848, Aztlán, in reference to the legend of the wandering Mexica. The concept of a homeland for Chicanos called Aztlán was presented at the First National Chicano Youth Liberation Conference held in Denver, Colorado, in 1969. It was articulated in the manifesto, El Plan Espiritual de Aztlán, a document that outlined an ideology meant to unite all Chicanos of the Southwest. The document is accredited to Alurista, a poet who was already presenting Aztlán in a Chicano studies class he taught in 1968 at San Diego State University. The manifesto stressed the concept of ethnic nationalism and self-determination, and of the need for Chicanos to control their own communities, schools, and political structures. The document proclaims, “We are a Bronze People with a Bronze Culture. Before the world, before all of North America, before all our brothers in the bronze continent, we are a nation, we are a union of free pueblos, we are Aztlán. Por La Raza todo, Fuera de La Raza nada.” El Plan Espiritual de Aztlán was published in the journal El Grito del Norte, Volume 2, 1969. In 1970, a journal was started at the University of California, Los Angeles, titled Aztlán: Chicano Journal of the Social Sciences and the Arts, which is still published today.
The eminent professor Luis Leal states that Aztlán has two meanings for Chicanos: the geographic region of the southwestern United States and “the spiritual union of the Chicanos, something that is carried within the heart, no matter where they may live or where they may find themselves” (Leal 1995, 5).
Aztlán takes a prominent place in murals, folk art, and folklore, and it continues to appear in Chicano literature today, as it has for over thirty years, in poetry, short stories, novels, and essay anthologies. The title of one of Rudolfo Anaya’s novels is Heart of Aztlán, published in 1979; Miguel Mendez wrote Pilgrims in Aztlán first in Spanish in 1974, later translated to English in 1992; and Alurista has a poetry collection titled Floricanto en Aztlán, published in 1971.
Aztlán is the Chicano homeland, especially for those coming of age during the 1960s and 1970s, who wanted to create a cultural space that they could call their own. For Chicanos born in the United States, Mexico is not home, but neither is the United States, so Aztlán is looked upon as the mythical homeland. The affiliation with Aztlán also reaffirms the Chicanos’ identity as mestizos (people of mixed ancestry), as members of the indigenous population of the New World. Chicano writers explore the various meanings of Aztlán in an anthology edited by Rudolfo Anaya and Francisco Lomelí titled Aztlán: Essays on the Chicano Homeland.
References Anaya and Lomelí 1989; Barrera 1988; Bierhorst 1990; Chavez 1984; Leal 1995; Valdez and Steiner 1972










In this chapter, I take up dilemmas that today’s parents face in rearing young children. Throughout this book, we have touched on myriad forces that make contemporary parenting highly challenging. These include one-sided, contradictory messages in the parenting-advice literature; career pressures that impinge on parent involvement in children’s lives; abysmally weak American child-care services to assist employed parents in their child-rearing roles; cultural violence and excessive materialism permeating children’s worlds; schools with less than optimal conditions for children’s learning; and impediments to granting children with deﬁcits and disabilities social experiences that maximize their development. 
Contemporary parents do not just ﬁnd child rearing more difficult; they feel more uncertainty than their predecessors about whether and how to intervene in their children’s activities and behavior. In the pages that follow, I draw on major themes of this book—the power of adult warmth, appropriate expectations, narrative conversation, make-believe play, and teaching in the “zone”—to show how Vygotsky’s sociocultural approach can serve as a guide for resolving a great many child-rearing concerns. 
This chapter answers twenty questions drawn from a survey of over four hundred parents of 2- to 8-year-olds living in a Midwestern city with a population of one hundred thousand. In that survey, I asked parents to list any questions about young children’s development and learning that interested or worried them. The questions I answer here address issues that appeared most often in parents’ responses. Each represents a concern that surfaced in three or more parental replies.
I intend these answers to parents’ questions to reﬂect a way of thinking about child rearing, not a set of recipes for dealing with speciﬁc events. When parents are familiar with principles that are grounded in contemporary theory and research on children’s development, they can better deal with the quandaries generated by the changing home, school, and community contexts in which today’s children grow up. Although adverse cultural trends have complicated and threatened good child rearing, parents—as agents of change, buffers against stressful life circumstances, and gatekeepers of learning opportunities—can do much to protect, restore, and reshape children’s experiences.

My 7-year-old doesn’t think very well of himself. Is poor self-esteem a major cause of learning problems? How can I increase my child’s self-esteem? Should I be praising him more?

When we speak of self-esteem, we refer to the judgments we make of our own worth and the feelings associated with those judgments. People with high self-esteem, although recognizing their limitations, are fundamentally satisﬁed with their characteristics and competencies. Their self-conﬁdence, self-respect, and realistic appraisal of their current skills fortify them in the face of failure, motivating them to try hard to surmount challenges. 
By the school years, individual differences in self-esteem are clearly evident and strongly related to children’s everyday behaviors. That is, most school-age children are quite good at judging their own strengths and limitations. For example, children who agree with such statements as, “I’m good at schoolwork,” tend to achieve well academically; children who concur that “most kids like me” get along well with their classmates; and children who say that they’re “usually the one chosen for games” are more advanced in physical skills.1 Many parents sense this strong link between children’s self-esteem and accomplishment. Consequently, they may try to build their child’s self-esteem with praise and reassuring comments.
Although self-esteem and favorable development are related, high self-esteem does not necessarily cause effortful behavior and achievement. Rather, to help sustain good outcomes, self-esteem must be earned through commitment, responsibility, and mastery of meaningful skills.2 Children whose parents combine warmth with reasonable expectations for mature behavior feel especially good about themselves.3 Warm parenting lets children know that adults believe they can succeed. And ﬁrm but appropriate expectations prompt children to strive for attainable goals and to use those goals as reasonable standards against which to evaluate their behavior.
Parents who deliver praise not based on real attainment actually undermine their child’s development. It does not take long for most children to see through these false compliments and to question their self-worth. For others, this unconditional parental acceptance may contribute to an unrealistic, overly inﬂated sense of self-esteem, which is also linked to adjustment problems. In one study, second and third graders identiﬁed by their teachers as frequently teasing, starting ﬁghts with, and excluding other children were far more likely than their classmates to rate themselves as perfect on a self-esteem questionnaire.4 Their distorted view of their own competence appeared to undermine any motivation to improve their social behavior.
Just as parents can’t solve a child’s motivational and self-esteem difficulties through indiscriminate praise, they also can’t do so through critical, impatient remarks or harsh, forceful tactics, as in “You’re lazy!” “Why don’t you try hard like your sister!” “Do that homework or you’ll be punished!” These strategies spark anger and resentment in children and undermine a positive parent–child relationship, on which motivation and effort thrive. And they destroy self-esteem by conveying a sense of inadequacy to children—that their behavior needs to be controlled by adults because they are unable to manage it themselves. 
Instead, parents can foster high but realistic self-esteem by asking themselves three crucial questions:

•Are the demands I make of my child within his or her “zone”—neither too high nor too low?
•Have I forged a warm parent–child relationship so my child is fueled with the desire to meet my expectations?
•Have I used ﬁrm but encouraging tactics—scaffolding of academic tasks to promote autonomous mastery; narrative conversation about the importance of trying hard to convey strong work-ethic values; and joint participation in routines and duties, such as meal preparation and household chores, to assist in developing responsibility?

Finally, children don’t need to feel great about everything they try. None of us is adept in every area. Rather, during the school years, self-esteem differentiates into an array of self-evaluations. For example, children judge themselves to be good at some school subjects and physical skills but not so good at others. Eventually, they combine these separate self-evaluations into a general appraisal—an overall sense of self-esteem. It remains positive so long as the child feels that he or she is competent at some worthwhile skills.5 
In sum, the route to favorable self-esteem lies in parents’ encouragement of achievement and responsibility. Then children have something worth feeling good about. Praise should be tied to real progress and attainment. Encouraging words are particularly helpful when children are trying their best but gains in performance are hard won. And most children greatly appreciate a parent’s congratulations for a job well done. Positive self-judgments formed in these ways foster continued effort and mastery, which in turn promote high self-esteem.

How much television and what kinds of programs should I permit my preschool child to watch? 

The typical preschool child devotes nearly 13 percent of his or her waking hours to watching television, a ﬁgure that rises to 30 percent by school age. Clearly today’s children spend far too many hours in front of the TV set, a circumstance that restricts time available for joint parent–child activities, play, reading, and other worthwhile pursuits. Television is so pervasive an inﬂuence in children’s lives that I discussed it at length in Chapter 2.
Parents are wise to limit children’s access to TV to about one to one-and-a-half hours a day—no more than 10 hours a week. Following that guideline would cut the exorbitant number of hours children spend watching TV by 50 to 75 percent. Parents also need to prohibit violent TV and orient children toward educational programs that inform them about their world and toward entertainment shows that teach positive values and social skills. In Chapter 2, I explained how readily children can pick up negative attitudes and behaviors from television. Fortunately, children can just as easily absorb worthwhile messages and information from TV, so parental guidance in this area can have great beneﬁts for development.
In Chapter 2, I also noted that it is crucial for parents to model good viewing practices; to watch TV with children, helping them understand and evaluate what they see; and to use televised content as inspiration for make-believe play and other enriching activities. Another suggestion: Try not to use television to reward or punish children. This increases its attractiveness, making children want to watch all the more.

My 20-month-old daughter and husband enjoy going to the Public Broadcasting System website. I’m delighted that they spend time together, but the whole computer concept makes me nervous. Already, my daughter bangs on the keys and uses the mouse. How much is too much and how young is too young? 

More than half of American families own a personal computer, and one-third of these have access to the Internet—rates that are growing rapidly.6 It’s not surprising that even very young children are attracted to the computer—often more so than to television. As one school-age child commented, “It’s fun because you can control it. TV controls itself.”7 Your key-banging, mouse-clicking 20-month-old already seems to appreciate this sense of electronic control!
As I noted in Chapter 4, the computer, like TV, has just as much potential for good as for ill. Hence it’s another alluring device that requires close parental monitoring and intervention—to prevent children from becoming addictive users; from immersing themselves in violent, gender-stereotyped video games; and from accessing websites and web pages with sexual, aggressive, or other inappropriate content.
Undoubtedly, father and daughter are beneﬁting greatly from their time together at the computer. The warmth, exploration, conversation, and fun involved in this and other joint parent–child activities strengthen emotional bonds and foster both cognitive and social development. But such an early introduction to the computer is not necessary. Young children orient to computers because they frequently see adults using these stimulating devices, so they want to do so, too.
Almost all American public-school classrooms have at least one computer,8 and many preschools have them as well. But for the computer to enhance learning in early childhood, adults must guide children in its constructive use and help them acquire computer-literacy skills. Around 3 years of age, children can type in simple commands and play educational games. Although they like the computer, most preschoolers do not ﬁnd it so captivating that it diverts them from other worthwhile activities. 
A common parental worry is that computers will channel children into solitary pursuits and disrupt their social development. To the contrary, children generally prefer to use computers socially. At home, they often like to engage in computer activities with a parent or older sibling because they can do much more with the help of an expert partner. And at school, small groups often gather around the machine to solve problems collaboratively.
How can parents capitalize on the computer’s potential for spurring their child’s development? A variety of educational software is available that permits children to practice academic skills and acquire new knowledge through discovery learning, reasoning, and problem solving. As soon as children begin to read and write, they can use the computer for word processing. It permits them to write freely without having to struggle with handwriting, and they can plan and revise their work easily. As a result, young writers worry less about making mistakes, and their written products are longer and of higher quality.9 However, computers by themselves do not help children master the mechanics of writing, such as spelling and grammar.10 Consequently, they are best used to build on, not replace, other writing experiences.
Beginning in the late preschool years, children can learn to program. Specially designed computer languages, such as LOGO, are available for this purpose. As long as adults provide the necessary scaffold, children beneﬁt greatly from programming experiences. They not only acquire a valuable new skill but master new concepts, become better problem solvers, and think more creatively.11 Also, since children must detect errors in their programs to get them to work, programming helps them reﬂect on their thinking and regulate their own behavior.12
How much is too much and how young is too young? There’s no evidence that computer experiences make toddlers more skilled computer users or thinkers. By kindergarten and primary school, children can gain much from computer activities. As far as how much computer time parents should permit, the answer depends on what children are doing. When they are involved in writing, problem solving, or other educational pursuits, there’s no special reason to be very restrictive. But not all software called “educational” is the same quality, so parents are wise to evaluate what their children are learning. Moreover, parents must ensure that time at the computer does not interfere with the variety of experiences children need to learn at their best. And playing violent video games and freely accessing the Internet should be prohibited.

How many and what kinds of toys does a young child need? My 3-year-old son is attracted to guns and war toys. How should I handle this type of play?

Martha Bronson’s The Right Stuff for Children Birth to 813 is as an excellent resource for selecting play materials that provide children of varying ages with both pleasure and an appropriate challenge. On pages 138 to 141 of Chapter 4, I provided an overview of play-material suggestions for stimulating make-believe and game play in children between 2 and 8 years of age. In Bronson’s book, you’ll ﬁnd additional recommendations, organized into four broad play-activity categories: social and fantasy play; exploration and cognitive mastery; music, art, and movement; and gross motor play.
Children’s rooms and play spaces need not be ﬁlled with every toy imaginable. A modest number of toys is sufficient. Children who have too much typically care little for what they have. When given a chance to acquire something new, they usually don’t react with much excitement or selectivity. For materially indulged children, new toys are such a common event that a complacent attitude sets in. The child comes to think, if I don’t like what I just got, I can always discard it for something else. A bedroom or playroom heaped high with a jumble of toys, many broken and mistreated, also teaches children that possessions need not be cared for and respected. 
Parents often assume that the play materials children choose are the ones that are best for their development. To some degree, this assumption makes sense: If a toy isn’t appealing to the child, the child isn’t going to spend time with it. So it’s important to provide children with a variety of play materials responsive to their interests.
Nevertheless, preference is not the same as appropriateness. Children sometimes choose toys with very limited play possibilities and soon ignore them. Other toys should not be given to children because they encourage undesirable play behaviors. Guns and other forms of weaponry fall into this category. In Chapter 4, I pointed to research demonstrating that these aggressive play materials promote both make-believe and real hostility in children’s interactions with peers.
When thinking about purchasing a new toy for your child, ask yourself these questions: 

•Does my child already have too many toys, and am I adding to this overabundance? 
•Is the toy responsive to my child’s interests, and is it likely to sustain his or her involvement over time? 
•Do I want my child to acquire the values and skills the toy teaches? 
•How will the toy help provide a foundation for my child’s future learning and development?

I’m expecting a new baby. How much is too much information for a 4-year-old about pregnancy and childbirth?

It’s easy to tell preschool and young school-age children too much about pregnancy and childbirth—more than they are capable of understanding. The best approach is to respond to their questions with simple, direct answers. The younger the preschooler, the less likely he or she is to notice the pregnant mother’s growing tummy and to be interested in how the baby got in there. Such questions as, “Where do babies come from?” “Where did I come from?” and “How does a baby get born?” rarely occur before age 5. 
When children do ask these questions, parents vary widely in how much information they are comfortable in providing. Up to age 8 or 9, most children are satisﬁed with such general explanations as it “starts as a little seed inside the mother, which grows into a baby,” “grows in a special space in the mother’s tummy called a uterus,” and “when the baby’s ready to be born, the mother’s uterus squeezes and squeezes, and the baby comes out.” Some parents show their child books with pictures of fetuses, identifying those that are about the same age as the forthcoming sibling and discussing the baby’s development as it progresses. There’s no evidence that this is in any way harmful or that it’s necessary during early childhood; rather, it’s a matter of parental choice.
Eight- to 9-year-olds are ready for more detailed knowledge about how babies are conceived and grow, as children of this age are getting closer to puberty. A variety of well-written and illustrated books are available to help parents discuss love between partners, conception, birth, and rearing of children. Parents need to select carefully, making sure they agree with the book’s values. Two books that I like are How Babies Are Made, by Andrew Audrey and Steven Schep,14 and Where Did I Come From? by Peter Mayle.15 How I Was Adopted, by Joanna Cole,16 is an excellent starting point for discussion with preschool and young school-age children who are adopted.

I don’t believe in spanking. We do time outs, which seem to work for our 4-year-old. How long is time out effective, and what’s the next step?

Although spanking has declined over the past 50 years, the majority of parents in the United States admit to slapping or hitting their child for misbehaving.17 There is good reason not to believe in spanking. A great deal of research shows that it promotes only temporary compliance, not lasting changes in children’s behavior. Children who are repeatedly criticized, shouted at, and slapped are likely to display the unacceptable response again as soon as adults are out of sight and they can get away with it. In fact, children of harshly punishing parents develop into especially disobedient and aggressive youngsters. In a study of a national sample of over twelve hundred mothers of 6- to 9-year-olds, psychologists Murray Straus, David Sugarman, and Jean Giles-Sims found that the more spanking the mothers reported, the more antisocial behavior their children displayed two years later—cheating, telling lies, being mean to classmates, and disobeying teachers.18
Why doesn’t spanking work? First, when parents spank, they often do so in response to children’s deﬁance and aggression.19 Yet the punishment itself models aggression! Second, children who are frequently punished soon learn to avoid the punishing adult. When children evade their parents, they reduce parents’ opportunity to teach desirable behaviors. Finally, as spanking “works” to stop children’s misbehavior temporarily, it offers immediate relief to parents, which rewards them for spanking. For this reason, the parent is likely to spank with greater frequency and intensity over time, a course of action that can spiral into serious abuse.
This does not mean that parents should never express anger at or punish a child. An otherwise warm parent who is disappointed and disapproving lets the child know that the transgression is serious. When children realize that adults regard their misdeed as very important, they listen more closely.20 And punishment is warranted after repeated infractions. 
But parents have far better ways to punish than spanking. One of these is time out—requiring a child to sit aside or to go to his or her room. Another is withdrawal of privileges, such as a visit to the playground or a weekly allowance. These mild punishments derive their potency from warm parent–child bonds. Children of involved, caring parents ﬁnd the interruption in parental affection that accompanies punishment to be very unpleasant. As a result, they want to regain the warmth and approval of the parent as quickly as possible.
An important preventive of misbehavior—and a vital element of effective punishment—is explanation. Pairing reasons with mild punishment (such as time out) leads to a far greater reduction in rule violations than using punishment alone.21 The reason the adult gives the child must match the child’s capacity to understand. At ages 2 to 3, referring to simple, direct outcomes works best, as in, “If you keep pushing Tommy, he’ll fall down and cry.” By age 4, parents can give more complex and subtle explanations. For example, they can refer to others’ intentions (“Don’t yell at Jessica. She was only trying to help”), to others’ feelings (“He’s proud of his tower, and you knocked it down; now he’s very sad”), and to issues of rights and fairness (“That toy belongs to Rudy, so you must ask for a turn”).22
Explaining to children what they did wrong, why it was wrong, and how they should have acted helps them recall the misdeed and relate it to expectations for future behavior. Furthermore, by pointing out the impact of the child’s actions on others, parents prompt children to feel empathy and sympathy—emotions that motivate concern for others.23 And giving children reasons for changing their behavior invites them to judge the appropriateness of parents’ expectations—to see that parents are not being arbitrary or autocratic. Explanations lead children to strive to meet parental standards because those standards make sense.
In sum, when time out is combined with reasoning, it remains effective through the school years. You can tell that your approach to discipline is working when time out and other punishments become less necessary as your child shifts from externally controlled responses to behavior based on inner standards and compassion for others. Typically this shift is well under way between ages 4 and 7.24 
If parents ﬁnd themselves punishing frequently, then they need to reconsider the basis of their discipline. When sensitivity, cooperation, and exchanges of affection are evident in parent–child interaction, children as young as 2 years of age more often follow parental directives.25 Children with an affectionate, mutually gratifying parental tie want to heed parents’ demands because they feel a sense of commitment to the relationship. This reduces the need for punishment, freeing parents to focus on encouraging children’s competent behavior.
Three additional ways to avoid excessive punishment are worth mentioning. First, changing aspects of the environment can reduce children’s problematic behavior. One parent arranged for her younger child to play at a friend’s house during his sister’s birthday party, realizing that the boy wasn’t yet ready to join in the party’s activities and would likely disrupt them. Second, a close look at the reasonableness of the rules can be helpful. Another parent caught herself before yelling, “Don’t roll down that hill!” at her daughter. She realized that the child was unlikely to hurt herself on the gentle, grassy slope and that any grass-stained clothing could easily be washed. With a moment of reﬂection, the parent backed off from an almost-delivered rebuke to allow a pleasurable play activity. Finally, sensitivity to children’s physical and emotional resources helps prevent inappropriate punishment. When children are tired, ill, or bored, they are likely to engage in attention-getting, disorganized, or otherwise improper behavior as a reaction to discomfort rather than as an affront to authority. In these instances, meeting the child’s needs makes more sense than punishing. 

What’s the best way to deal with repeated tantrums in a 3-year-old child who gets so enraged that he hits and throws things at you? How can you calm a preschooler when the situation requires him to listen and pay attention?

When a tantrum occurs, time out is useful—transferring the child to an unstimulating area where he can’t throw things until the emotional storm is over. If he tries to throw anything or to hit you, you need to prevent him from doing so, gently but ﬁrmly. It’s crucial to remain calm and to avoid harsh, coercive tactics, which will only fuel the child’s rage and poor emotional control.
It’s also important to ﬁgure out why these persistent tantrums are occurring. As the often-heard phrase “terrible twos” suggests, many people assume that tantrums are a fact of life for 2- and even 3-year-olds. Once toddlers acquire the ability to follow adult directives, one way they assert their autonomy is by resisting parents’ requests and demands, using the familiar refrain, “No!” And from time to time, toddlers lose control. When frustrated, they haven’t yet developed many techniques for regulating their emotions. But parents who take mental notes for a day on the number of compliant acts versus the number of tantrums are likely to gain a new appreciation for how infrequent their child’’s tantrums really are. For most young children, eager, willing cooperation is much more common than opposition.26
If your child has been emotionally reactive and difficult to soothe since infancy, then temperament is probably a signiﬁcant contributor to his behavior. You’ll also want to consider whether any changes in your family or the child’s daily life might be sparking intense anxiety—marital conﬂict, divorce or remarriage, a new baby brother or sister, starting preschool or child care, or a parent going to work when the child is used to having him or her at home. Parenting practices can modify children’s temperaments and assist them in coping with stressful life events. Protection from family discord; extra parental warmth, affection, and pleasurable time together when the child is behaving well; and ﬁrm, calm, and consistent discipline will help. 
Most children build up to a tantrum gradually. Parents can tell it’s in the offing, and sometimes they can distract the child before it reaches a peak. For example, if the child is about to “blow” while you’re out shopping, try involving the child in the shopping experience—pointing out things of interest to the child; asking the child to help you select and carry purchases; and reminding the child that after the shopping is ﬁnished, you are going to do something the child enjoys. When parents interrupt a tantrum on the rise by redirecting the child’s attention, they provide strategies children can use on their own to regulate emotion. If parents always wait to intervene after the child has become intensely distressed, it’s harder not only for the parent to calm the child but for the child to learn to calm down. And once the child regains emotional control, reassuring the child of parental love with hugs and comforting words restores the parent–child relationship and strengthens the child’s sense of security.
Make-believe play is an effective context in which preschoolers can practice what to do when frustrated. Parent and child can take turns acting out the “parent” and “child” roles. While playing the “child,” the parent can get upset. Then parent and child can come up with ways to help the “child” control intense feelings. Occasionally during make-believe, children send parents clear messages about disciplinary tactics they want and need to quell tantrums. In one instance, Sonja, a mother at wit’s end over her 4-year-old daughter Meredith’s frequent ﬁts of kicking and screaming, consulted a child psychologist. The psychologist had Meredith play the “mother” and Sonja play the “child.” 
When the “child” asked for a cookie, the “mother” said, “No cookies before dinner. You can have a cookie after dinner.”
Sonja the “child” began to mimic her daughter’s tantrums. “I want a cookie. I want two cookies! Gimme my cookies!” she shouted.
“No!” Meredith the “mother” answered, “No cookies until after dinner.”
“I want cookies now!” Sonja the “child” wailed while thrashing about in Meredith’s usual fashion.
Meredith looked on, dismayed by her mother’s unruly behavior. Then she stepped out of the play and instructed, “You’re supposed to say, ‘No cookies ‘til later,’ Mommy.”
When Sonja the “child” continued her screaming and crying, Meredith stated more insistently, “Mommy, say, ‘No cookies! You can’t have cookies before dinner!’”
With the psychologist’s help, Sonja reﬂected on the play episode, realizing that she’d been inconsistent in handling Meredith’s outbursts, sometimes resisting, at other times giving in. As a result, Meredith continued the tantrums to get her way, yet she desperately wanted to stop these explosions and to follow sensible, consistent rules. To do so, she needed her mother to send a clear, rational, and steadfast message that tantrums are inappropriate and ineffectual and that cookies are eaten after dinner.

What suggestions do you have for disciplining a strong-willed, stubborn child? Nothing seems to work, including time out and loss of privileges.

As this question makes clear, some children are far harder to discipline than others. A child’s temperament affects the ease with which he or she will follow parental directives and listen to explanations. In Chapter 5, I indicated that the impulsivity and emotional reactivity of children with ADHD make them very hard to rear and often lead to strife-ridden adult–child relationships, which further reduce children’s cooperation. Willful, stubborn children are also challenging to discipline. They tend to evoke harsh punishment, which heightens their resistance. 
A seemingly stubborn child may feel so little anxiety that parental disapproval and mild punishment do not spark enough inner discomfort to motivate compliance. Consequently, parents of headstrong children must use ﬁrm, consistent discipline and repeatedly explain how to behave and why. At the same time, such parents must resist the temptation to engage in carping criticism, harshness, and force. A warm parent–child bond based on cooperation is especially vital for helping recalcitrant children internalize parents’ standards. It provides the obstinate youngster, who feels little or no anxiety when reprimanded, with an alternative foundation for meeting parents’ expectations: a desire to preserve a spirit of affection and harmony with the parent.27
Because parents’ communication with noncompliant children is often riddled with negativity, it can take time to get the relationship on a better track. Arranging regular times for joint parent–child pleasurable activities is vital. Making sure to notice and praise the child’s favorable behavior also reduces the negative cloud hanging over parent–child interaction. 
Finally, looking for the “silver lining” in the child’s difficult disposition can help parents muster the fortitude needed to rear a child with a difficult disposition. Consider Carl, one of the most obstinate participants in a study of the combined impact that temperament and child rearing have on long-term development.28 Beginning in infancy, Carl rejected many routines and experiences, including baths, bedtime, and new foods. He shrieked, cried, and struggled to get away. Yet his parents regarded his emotional intensity as a sign of inner strength and vigor. They believed that if they were patient and ﬁrmly insistent, Carl would, in the end, adapt positively.
By the time Carl reached school age, he was doing remarkably well. The energies he had previously invested in stubborn rebellion were channeled constructively. He did well in school and became enthusiastically involved in several activities. One of these was playing the piano—lessons that he had asked for but (in his typical fashion) at ﬁrst disliked intensely. Carl’s mother had granted his request for piano instruction under one condition: that he stick to the lessons for six months. She held him to this agreement despite his protests, which gradually subsided. Carl came to love his introduction to music. His parents’ warmth, determination, and consistency had helped him gain control of his behavior and beneﬁt from new learning opportunities.

How can you get an inactive child who loves quiet play to be more active and sociable?

Parents of quiet children often wonder whether their youngster is developing normally. Preschoolers whose play and behavior are typically mature for their age but who prefer solitary, tranquil activities are probably doing just ﬁne, both cognitively and socially. As I indicated in Chapter 3, only certain kinds of nonsocial activity—aimless wandering; immature, repetitive motor action; and anxious hovering around peers without joining in their play—are cause for concern.29 Most play of quiet preschoolers is not of this kind. Instead, it is positive and constructive, consisting of such activities as art, make-believe play, puzzles, and block-building.
Our society places such a high value on sociability that adults often regard quiet reserve as a sign of maladjustment. Yet not all cultures see things this way. Chinese adults, for example, view quiet children very positively—as advanced in social maturity.30 Thai primary-school teachers also value restrained, persistent child behavior, and they regard children who would be average in activity level in the United States as poorly behaved and unmotivated.31 Equating an energetic pace and gregariousness with normality is a Western cultural phenomenon—one that does not match what we know about quiet, nonanxious children. Most are bright youngsters with intense interests who, when they do play with peers, show socially skilled behavior.32
Nevertheless, you might want to encourage a quiet, inactive child to engage in active play from time to time—to ensure healthy exercise and to broaden the child’s experiences. The best way to do this is to join the child in active games, such as tag, relay races, hide-and-seek, and throwing and catching. Creating a “zone” for learning—by ensuring that active play is fun, provides plenty of opportunity to practice physical skills, and is not overstimulating for the quiet child—will increase the success of these efforts. You won’t be able to transform a quiet child into a physical dynamo, but you can help the child learn to enjoy moderate physical activity. Finally, parents of quiet children may be gratiﬁed to learn that a calm, less active nature typically makes a child easier to rear.

How does a parent gain respect from a child who sees the other parent acting disrespectfully toward his or her spouse?

Children learn much about how to relate to others by observing their parents’ day-to-day communication. Marital conﬂict is linked to hostile behavior and poor emotional adjustment in children, including feeling sad and engaging in aggressive acts.33 Hearing one or both parents berate the other leads children to act similarly—toward parents, siblings, teachers, and peers. If disrespect between parents includes physical harm, then children’s difficulties can escalate further.34
Besides modeling destructive forms of interaction, parents who behave hurtfully toward each other generally interact hostilely with their children.35 They also tend to use inconsistent discipline—alternately strict and lax.36 When parents scold children on some occasions but permit them to act inappropriately on others, children are confused about how to behave and engage in especially high rates of disobedience.
In sum, parents behaving insolently to each other are up against a brick wall in getting a child to behave respectfully. They need to repair their relationship. Seeking the help of a marriage and family counselor without delay is the best way to prevent the child’s emotionally despondent and angry reactions from spiraling into lasting adjustment problems. 

Any tips on raising an only child?

The best way for parents to ensure that only children fare well is to engage them in development-enhancing dialogues, to impose reasonable expectations for mature behavior, and to discipline effectively. Overall, parents of only children are quite successful in attaining these child-rearing goals. Contrary to popular belief, only children are not destined to become spoiled and selﬁsh. Instead, research consistently shows that they are as well adjusted and as socially competent as other children. And they form just as close and as rewarding friendships as do children with siblings, suggesting that they can and do learn to share and to be considerate of others’ needs. Furthermore, only children have a more positive sense of self-esteem and do better in school than do children growing up in families with two or more children.37 
A major reason for these positive outcomes is that having just one child generally means a closer parent–child relationship; more time for high-quality parent–child interaction; and greater encouragement for mastery and accomplishment.38 But because only children lose the lifelong beneﬁts of positive sibling ties, parents might take steps to enrich the child’s life with sibling-like relationships—for example, by cultivating warm bonds with cousins or the children of close family friends. In sum, with good parenting, only children fare extremely well.

How can you keep a child’s self-esteem high while still praising a sibling’s achievements and good behavior? When a child “acts out” because of sibling jealousy, what’s the best way to handle it? 

Children display wide individual differences in the quality of their sibling ties. Once again, temperament makes a difference. For example, arguments between siblings increase when one child is emotionally intense and highly active.39 But parents can do much to foster favorable sibling interaction. During the preschool years, mothers tend to be more positive and playful with second-borns than ﬁrst-borns, and they discipline the older child more.40 This differential treatment is understandable, in that older children are more competent and capable, so parents expect more. But being older also means more privileges—for example, being able to stay overnight at a friend’s house or enroll in certain after-school activities and lessons. These advantages may help compensate for an older child’s perception that a younger sibling is receiving better treatment. 
If parents experience intensifying sibling conﬂict, they may want to reevaluate their communication with each child. Warmth and frequent expressions of affection are associated with positive sibling interaction, whereas harshness and coldness are associated with sibling antagonism.41 Once established, this link between parent–child and sibling relationships is self-perpetuating. Warm parenting fosters considerate sibling interaction, which prompts positive parental communication in the future. When parents are hostile and coercive, children act similarly toward their siblings, and parental anger escalates.
The elementary school years are a time when sibling conﬂict can increase. As children get feedback about how well they are doing in school and in other activities (such as sports and music lessons), parents may compare their accomplishments, especially when siblings are close in age and the same gender. The child who feels less valued is likely to resent a sibling whom parents seem to prefer. Therefore, when praising one child, parents should try not to diminish the merits of another. If a sibling expresses jealousy, parents can remind the envious child of an admirable personal trait or a recent commendable performance. But be careful not to give empty praise (not based on real accomplishment), which children quickly come to mistrust. It may fuel jealousy of a sibling, whom the child concludes parents really appreciate.
In sum, parents can foster positive sibling ties through expressing warmth and affection, stressing each child’s positive qualities and achievements, and refraining from making comparisons. When sibling relationships are friendly and sympathetic, they bring many beneﬁts, including gratifying companionship, emotional support, and assistance with everyday tasks.

Should you try to curb bossy behavior when siblings or peers are playing together? If so, at what age?

Yes, you should step in and teach alternative, cooperative modes of interaction—at as early an age as you observe bossiness. A child who has trouble engaging in give and take during play with siblings or peers will quickly become embroiled in conﬂict.
As I noted in Chapter 4, pleasurable, rewarding play depends on attaining intersubjectivity, or shared understanding. Children must resolve differences of opinion and ﬁnd ways to meet both their own needs and those of their playmates. When domineering, uncooperative behavior is extreme, the bossy child is likely to be rejected by agemates. Long-term peer rejection, as I indicated in Chapter 5, not only leads to an unhappy social life but to serious adjustment problems in adolescence and early adulthood.
When a child uses bossy tactics, interrupt the play and ask the child to think of a better way to get others to cooperate, such as making requests and taking into account the playmate’s preferences. If the child can’t think of alternatives, suggest and model several. If bossiness continues unabated, insist that the child leave the play area, explaining why he or she must do so. During times when you’re alone with the child, talk about problems that have arisen in peer and sibling play and help the child think of good social problem-solving strategies. Then act out these situations in make-believe, granting the child plenty of practice in applying effective social skills and showing the child how others are likely to react if bossy behavior returns.

How can a parent identify the difference between a language disorder and normal language development? What resources are available?

If your child’s language development is delayed by several months when compared to norms for early language milestones, then your child might have a language disorder. But keep in mind that children vary greatly in their pace of language learning. For example, girls are slightly ahead of boys in early vocabulary growth, and reserved, cautious children often wait until they understand a great deal before trying to speak.42 When they ﬁnally do speak, their vocabularies grow rapidly. 
Here is a summary of major language milestones for the ﬁrst 2 years:

Approximate AgeMilestone
2 months Coos, or makes pleasurable 
vowel sounds, such as “aaaaa” or “oooo.”
6 monthsBabbles, or repeats consonant–vowel sounds 
in long strings, as in “babababababa.”
6–14 monthsBabbled sounds expand greatly; 
around 1 year, they reﬂect the sounds 
and rhythms of the infant’s language 
community.
8–12 monthsUnderstands some words. 
12 monthsSays ﬁrst recognizable word.
18–24 monthsVocabulary expands from about 
50 to 200 words.
20–26 monthsCombines two words.
27 months and onSpeaks in longer sentences; 
participates easily in a conversation 
with an adult. 

Because of wide individual differences, it’s sometimes hard to tell a language disorder from normal variation in language development. If you’re concerned about your child’s language progress, consult a trained speech–language pathologist. The American Speech–Language–Hearing Association (ASHA) maintains a list of certiﬁed speech–language pathologists for referrals. You can contact the association at (800) 638-8255.
The most common cause of early language problems is a hearing loss. Typically, children with hearing impairments are not identiﬁed until 12 to 25 months of age, when speech and language development is already delayed. Therefore, ASHA recommends that all newborn babies be screened for hearing disorders before they leave the hospital. Newborn testing takes only a few minutes and permits problems to be addressed early, preventing negative consequences for all aspects of psychological development.
Hearing loss can also emerge later. The most common cause during toddlerhood and the preschool years is repeated otitis media, or middle ear infection. Some episodes are painful, so parents detect them, but many are accompanied by few or no symptoms. Children with recurrent otitis media bouts have trouble making out what others are saying. Hence they are distractible, behind in language progress, and socially isolated; and they also achieve poorly in school.43 
When children begin preschool or child care, they are more susceptible to otitis media because of close contact with other children. Therefore, frequent screening for the disease, followed by prompt medical intervention, is vital. Interestingly, verbally stimulating adult–child interaction and high-quality child care help reduce developmental problems associated with otitis media.44 When adults converse often with children and keep environmental noise to a minimum, children with persistent ear infections have more opportunities to hear and respond to spoken language.

I’m trying to decide whether to enroll my 5-year-old son in kindergarten or wait until next year. How can I tell if he’s ready for kindergarten? If he doesn’t do well in kindergarten, should he repeat it or go into a “transition” class?
Many parents struggle with the decision of whether to enroll their child in kindergarten once the child meets the age requirements. Most often, they consider delaying the start of school for boys, who as a group tend to lag behind girls in cognitive and social development. At the heart of parents’ concern is whether their child will be able to meet the academic and social demands of the kindergarten classroom.
Although many teachers believe that a 5-year-old who’s on the young side can beneﬁt from waiting another year before enrolling in kindergarten and advise parents to hold the child out, research has not revealed any advantages for delayed entry. A host of studies indicate that younger children make just as much progress, academically and socially, as do older children enrolled in the same grade. No difference exists between younger and older classmates in achievement test scores.45 
A related dilemma involves whether to retain a kindergartner for a second kindergarten year if he or she is not progressing well. More than a half-century of research has failed to show any learning beneﬁts for children retained in grade, and mounting evidence indicates that retention can be harmful, prompting negative attitudes toward school and a drop in self-esteem and in academic motivation, even as early as kindergarten.46 In one study, retained kindergarten children, despite the extra year of school, scored lower than their classmates in academic achievement after entering the primary grades. In contrast, children recommended for retention but who nevertheless went on to ﬁrst grade were doing just as well as classmates who had been promoted in the standard fashion.47
Yet another alternative is to place a poorly performing kindergarten child in a “transition” class—a waystation between kindergarten and ﬁrst grade. Transition classes, however, are a form of homogeneous grouping that gathers children judged by the school system as less likely to succeed. As with other “low-ability” groups, teachers often have lower expectations for transition-class students and teach them in a less stimulating fashion than they do other children.48 
Notice that each of the options just mentioned assumes that readiness is inherent in the child—that a 5-year-old must have reached a certain level of development to proﬁt from classroom experiences. Consider, once again, the concept of the “zone,” in which teaching leads development. It tells us that children don’t just grow into school readiness. Rather, they acquire the knowledge, skills, and attitudes necessary for successfully participating in classroom life through the assistance of others. This means that readiness is not something we must wait for. Instead, we can cultivate it. Parents, teachers, and school systems can work together to ensure that each child takes the next appropriate steps toward mastering the range of capabilities needed for school success.
The National Association for the Education of Young Children (NAEYC) recommends that every child of legal age start kindergarten. It also recommends against school readiness testing as a means for deciding whether a child should be admitted to kindergarten, be retained in kindergarten, or enroll in a “transition” class rather than a ﬁrst-grade class after completing kindergarten.49 School readiness tests are poor predictors of children’s future school performance and identify many children as unready who are quite ready to handle school experiences.50 
As long as teachers are sensitive to children’s diversity and work with small groups and individual children within their “zones,” there is no reason to hold a child out of kindergarten. Deciding not to enroll a child and opting for an alternative experience is justiﬁable only when the kindergarten environment is so rigid and unaccommodating to individual differences that the child would be frustrated and unhappy and would have an unproductive year. 

My first grader has homework to do several times a week. Should I help her with her homework, and if so, how should I do so?

American parents often express uncertainty about helping their child with homework. They worry that by providing help, they will discourage self-reliance in thinking and problem solving. Vygotsky’s concept of the “zone” underscores that children acquire the many capacities they need to learn autonomously from the assistance of parents, teachers, and other more expert adults. By collaborating with the child on a challenging task, the adult assesses what the child can already do and what the child is ready to learn, providing a support system for mastery.
The metaphor of a scaffold, discussed in Chapter 2, is an excellent guide for how to help your child with homework. Scaffolding involves varying your assistance to ﬁt the child’s changing competence. When the child says, “I don’t understand,” you can adjust the task, breaking it into smaller parts. You can also provide prompts, hints, and explanations, increasing the amount and directiveness of your guidance until the child makes progress. As you do so, you can assist the child in analyzing why certain problem-solving approaches work and others do not, encouraging her to come up with ideas for surmounting difficulties. As she starts to apply the strategies derived from your dialogue, you can reduce the intensity of your intervention, letting her take over responsibility for the task.
Too often, parents imagine that their child’s classmates can do the homework assignment independently. After all, they say to themselves, why would the teacher have assigned it if this weren’t so? This pattern of reasoning leads parents down a counterproductive path. “What’s wrong with my child?” they say to themselves. “She should be able to do the assignment, just like everyone else!” But recall that children of the same age differ widely in their “zones.” And rooted in the very idea of the “zone” is that learning requires teaching! Children in our culture frequently are rebuked for seeking help, a response that promotes dependency, helplessness, and retreat from challenge, not competence and autonomy. 
Chinese and Japanese parents spend a great deal of time helping their children with homework—far more than American parents do. Asian parents also communicate often with teachers about how to help their child learn at his or her best. Rather than being dependent, Chinese and Japanese students develop into well adjusted, excellent students51—at the top in academic achievement in the world. 

When does math become a greater problem for girls than for boys? What can be done to help girls do well in math?

Throughout elementary school, girls get better grades in math—and other academic subjects—than do boys. At times, school-age boys outperform girls on math achievement tests,52 but boys’ advantage in math isn’t clearly evident until secondary school. A close look at children’s performance on speciﬁc test items reveals that both genders do equally well in basic math knowledge, and girls do better in computational skills. Boys’ advantage appears on tests of math reasoning, primarily on complex word problems and in geometry.53
The cause of boys’ late-appearing math advantage is a matter of controversy. Some experts believe the difference is rooted in boys’ superior ability to reason about spatial relations. Gender differences in spatial skills are present by elementary school and persist throughout life.54 Young people who are good at spatial reasoning are, indeed, better at solving complex math problems.55 One conjecture is that male (androgen) hormones may play some role in enhancing boys’ spatial skills. But evidence favoring this idea is inconsistent.56
Although heredity may contribute to boys’ spatial superiority, experience also makes a difference. Children who engage in manipulative activities involving spatial relations, such as block play, model building, and carpentry, do better on spatial reasoning tasks. Also, playing video games that require rapid mental rotation of visual images enhances the spatial test scores of boys and girls alike.57 Yet boys spend far more time at all these pursuits than do girls.
Furthermore, children’s and adolescents’ attitudes toward math and their belief in their capacity to do well at it affect their math achievement. Boys feel more conﬁdent about their math ability, even when their grades are poorer than girls’.58 Why might this be so?
Shortly after entering primary school, children regard math as a boys’ subject—a stereotype that prompts girls to like math less than boys do. Girls also predict poorer math performances for themselves than boys predict for themselves.59 Children derive these views from their social surroundings. They listen to what parents and teachers say about who is “good at math,” and they see more men in math-related careers—from math teachers in the upper school grades to scientists in the wider community.
Also, subtle feedback from adults undermines girls’ conﬁdence in their ability to do well at math. If a parent or teacher believes that a child is not very capable at a school subject, the adult may act surprised when the child succeeds, ascribing good performance to luck by saying something like this: “Gee, you did a lot better than I expected!” And when the child fails, the adult may explain the failure by referring to mediocre ability: “You’re not very good at that, are you?” Girls get much more of this type of feedback than do boys, especially in math.60 In contrast, parents and teachers often attribute boys’ poor performance to misbehavior and lack of motivation. “If only you’d listen and try,” they say, “you’d do much better.”
As a result of these messages, too many girls come to believe that when they succeed at math, their ability didn’t help them. And after failure, they reason that weak ability, not insufficient effort, was at fault. Children who hold these discouraging explanations for their performance often come apart with anxiety when a task is difficult. They say to themselves, “I can’t do this! It’s too hard!” before they have really tried.61 Although eventually young people ﬁgure out that effort can compensate for low ability, girls may conclude that mastering complex math is not worth the cost—extremely high effort.62 So in high school, they retreat from advanced math courses and math-related careers.
Fortunately, parents can do much to foster girls’ self-conﬁdence and achievement in math. Beginning in the preschool years, they can provide girls with toys and activities that promote spatial reasoning and scaffold their mastery of those tasks. And they can assist children of both genders in interpreting their math successes as due to both effort and ability, in understanding that ability accrues from trying hard, and in taking failure as a sign that more effort and better problem-solving strategies are needed. 
A positive sign is that the gap between boys’ and girls’ math achievement is declining. In addition, more girls are enrolling in advanced math and science courses in high school, and slowly but steadily, women are entering male-dominated math-related professions.63 The more parents hold nonstereotyped values about what males and females can and should do, the more likely girls are to sustain their high elementary-school math and science achievement in secondary school.64

Why do boys lag behind girls in reading and writing in primary school? Do they catch up later?

Throughout the school years, girls attain higher scores on reading and writing achievement tests and account for a lower percentage of children referred for remedial reading instruction.65 Part of the reason for girls’ advantage in literacy development is that they undergo a faster rate of physical maturation, believed to promote slightly earlier development of the left hemisphere of the cerebral cortex, where language functions are housed for most people.66 In addition, many types of developmental problems are more common among boys, including speech and language disorders, reading disabilities, and inattention and hyperactivity. Boys’ and girls’ differing genetic makeups probably underlie these gender differences, which affect reading and writing performance.67 
By secondary school, girls’ advantage on tests of general verbal ability is so slight that it is not really meaningful.68 Consequently, boys who are free of reading disabilities have the potential to achieve just as well as girls in reading and writing. Still, girls continue to outperform boys in these subjects. Home and school experiences contribute, although less is known about them than those that underlie boys’ advantage in mathematics. 
Just as children think of math as a masculine subject, they regard reading and writing as feminine subjects. Parents rate daughters as more capable at reading than they rate sons—beliefs that children adopt. 69 Furthermore, traditional primary-school classrooms, in which teacher-directed, whole-class lessons are the major activity, require children to sit still and concentrate for long periods of time on academic tasks that often are irrelevant to their interests. In previous chapters, I indicated that such classrooms are poorly suited to the learning needs of both boys and girls. But boys adapt especially poorly to the regimentation of traditional classrooms because of their generally shorter attention spans, higher activity levels, and less compliant dispositions.Consequently, they often are targets of teacher disapproval, which sparks negative attitudes toward school and dampens their enthusiasm for learning.70
In a recent Australian study carried out by psychologist Freda Briggs, several hundred schoolchildren were asked for their views on school and classroom activities. Many boys between 5 and 9 years of age expressed dissatisfaction with school and said that their favorite activities were recess and lunchtime. But in four classrooms, distinguished by an activity-center curriculum offering opportunities for individual choice, small-group work, and literacy experiences responsive to children’s interests, boys reported strong liking for school. And they named reading and writing as their favorite activities. They particularly enjoyed making their own books, based on themes of sports and hobbies.71
Although more evidence is needed to be sure, perhaps classrooms that create “zones” for learning, with many of the features I described in Chapter 6, spark sufficient enthusiasm for literacy pursuits among boys that they reduce the well-known gender gap in reading and writing achievement. Finally, the trend for boys to learn to read more slowly than girls is less pronounced in countries where reading is not stereotyped as feminine but regarded as well suited to the masculine gender role.72

Is learning and development affected if the father becomes less involved or absent after a divorce? 

Divorce is invariably painful for children, and learning and development can be affected—temporarily and long term.73 Preschool and young school-age children are often profoundly upset. Because they have great difficulty grasping the reasons for their parents’ divorce, they may blame themselves and take the marital breakup as a sign that they could be abandoned by both parents. As a result, they may cry and cling, refuse to go to school, and show a drop in enthusiasm for play and learning. Young children need extra affection and reassurance along with gentle reminders that their parents’ separation is permanent. Of all age groups, preschoolers are most likely to have trouble accepting the reality of divorce and to fantasize that their parents will get back together.74
Many school-age children and adolescents also react strongly to the end of their parents’ marriage, particularly when family conﬂict is high and parent involvement with children is low. Around the time of divorce and for up to several years after, children tend to be emotionally volatile, displaying both depression and demandingness, noncompliance, and aggression.75 Boys in mother-custody families seem to have the hardest time. Research reveals that before the marital breakup, many sons of divorcing couples were impulsive and deﬁant—traits that may have contributed to as well as been caused by their parents’ marital problems. Thus, boys often enter the period of family turmoil surrounding divorce with behavior problems and a reduced capacity to cope with stress.76 Custodial mothers tend to have difficulty handling sons on their own. Both boys and girls show declines in academic achievement during the aftermath of divorce, but school problems are greater for boys.77
Most children improve in adjustment by two years after divorce. Yet for some, emotional distress and poor school performance persist, contributing to lasting problems into adolescence and young adulthood. Adults whose parents divorced during their childhoods tend to do less well in terms of educational, vocational, and economic attainment than their counterparts from stable families.78 Regardless of whether fathers remain salient ﬁgures in children’s lives, the strongest predictor of good outcomes following divorce is effective parenting—combining warmth with reasonable maturity demands, limiting family conﬂict, and using consistent, nonpunitive discipline.79 Fathers who remain involved and who use good child-rearing techniques contribute greatly to the psychological well-being of children of both genders, with boys showing special beneﬁts.80

I have a child with physical disabilities (cerebral palsy) but who’s very smart. Will his intellectual growth continue as long as it’s promoted?

Your child’s intellectual growth will deﬁnitely continue as long as you and other important adults in his life promote it. Chapter 5 of this book is devoted to the development of children with deﬁcits and disabilities. Although I don’t discuss children with cerebral palsy speciﬁcally, the same general principles for fostering continued learning in all children apply to your child. Children—with and without disabilities—acquire new competencies through dialogues with more expert partners, who are sensitive to what the child is ready to master and foster it in culturally meaningful activities.
All too often, children’s disabilities are viewed as entirely biological, much like an incurable disease. Vygotsky’s theory emphasizes that the most serious consequence of a physical or mental defect is not the biological impairment itself but the disruption it causes in the child’s social relationships. You can help your child compensate for his physical limitations through social contact and communication aimed at strengthening the higher thought processes—voluntary attention, deliberate memory, concept formation, logical reasoning, problem solving, and imagination. “The mightiness of the mind,” Vygotsky wrote, “has virtually no limits.”81 
When cerebral palsy results in speech, hearing, or visual impairments, promoting language proﬁciency through alternative means is crucial for enhancing development. Parents and teachers who maximize children’s communicative capabilities, through sign language, ﬁnger spelling, special computer technology, and other symbolic innovations, grant them access to the minds of others and to tools for collaborating with more capable partners in their “zones”—sure routes to realizing their potential.









Two days a week, Kevin leaves his office 45 minutes early to take charge of his 2-year-old daughter, Sophie, while her mother, a university professor, teaches a late class. One balmy spring afternoon, Kevin retrieved Sophie at her child-care center and drove the 15-minute route home. Invited to look in on Sophie’s play, I met the pair at the front door and nestled into a rocking chair from which to observe unobtrusively.
After downing the last bite of her snack, Sophie grabbed Kevin’s hand and led him across the family room to a rug lined on two sides by shelves ﬁlled with books, stuffed animals, and other play props. Sophie moved a toy horse and cow inside a small, enclosed fence that she and Kevin had put together the day before. Then she turned the animals on their sides and moved them toward each other.
“Why are horse and cow lying down?” Kevin asked.
“’Cause they’re tired,” Sophie answered, pushing the two animals closer together.
“Oh, yes,” Kevin affirmed. Then, building on Sophie’s theme, he placed a teddy bear on another part of the rug and offered, “I think Ted’s tired, too. I’m going to start a bed over here for some other animals.”
Sophie turned toward the teddy bear, lifted his paw, and exclaimed, “She wants a lollipop to hold in her hand!”
“A lollipop in her hand? We haven’t got any lollipops, have we?” answered Kevin.
“Laura has!” declared Sophie, glancing at me.
“Has Laura got a lollipop?” Kevin queried.
“Yes! She’s got all of those, and a swing and a table, too!” Sophie remarked, referring to my chair, which rocked back and forth next to an end table.
“Maybe this could be a make-believe lollipop,” suggested Kevin, placing a round piece on the end of a long TinkerToy stick and handing the structure to Sophie
“That’s a lollipop,” agreed Sophie, placing it in the paw of the teddy bear.
“Can she suck that while she’s going off to sleep?” asked Kevin. “Do you think that’s what she wants?”
“It’s a paciﬁer,” explained Sophie, renaming the object.
“A paciﬁer, do you think? The paciﬁer might help her get to sleep,” Kevin conﬁrmed.
“This long, long paciﬁer,” Sophie answered, picking up the TinkerToy structure, looking at its long stick, and pausing as if to decide what to do next.
“Leprechaun is looking pretty tired,” suggested Kevin, laying Sophie’s stuffed leprechaun next to the teddy bear. “What do you think?”
“He wants a lollipop, too!”
“Oh, he wants a lollipop as well. What are we going to use for a lollipop for the leprechaun?” asked Kevin.
Pressing the teddy bear’s and the leprechaun’s arms together and the lollipop-turned-paciﬁer between them, Sophie readily came up with a solution. “He’s sharing,” she affirmed.
“Oh, they’ll share! All right,” Kevin agreed.
This scene is but a small excerpt from Sophie and Kevin’s joint play session, which persisted for more than an hour—a remarkably long time for a 2-year-old to sustain any activity. Yet when the TV set is switched off and children are free to do as they choose, most preschoolers readily become absorbed in pretending. At times, their involvement is so intense that on being interrupted they react with shock and dismay, rejecting an adult who otherwise would be welcomed with joy and affection. One mother reported to me that her daughter Mattie reserved the period after she awoke in the morning for conversing with dolls and other imaginary characters. If a parent entered too soon to help her wash and dress, she dismissed the intruder, proclaiming sharply, “Busy! Don’t stop my dollies!” Only smooth and clever entry into the make-believe activity—for example, inviting the dolls and stuffed animals to get up for breakfast—could lure Mattie into starting the “real” part of her day without protest.
The years of early childhood are often called the high season of imaginative play, and aptly so, since make-believe blossoms during this time, evolving from simple, imitative acts into highly elaborate, imaginative plots involving complex coordination of roles. Eminent child development theorists of the past attached great importance to the role of make-believe play in early development. All were convinced that anything so compelling and engrossing in the life of the young child must be profoundly signiﬁcant.


the role of make-believe play in children’s lives

Among inﬂuential explanations of why preschoolers are so drawn to pretending, Freud’s psychoanalytic theory and Piaget’s cognitive theory held sway for much of the twentieth century. Although each has made valuable contributions to our understanding, a new, more powerful view of the meaning of young children’s play has arrived on the scene, thanks to Vygotsky’s sociocultural theory.

The Psychoanalytic View: Wish Fulfillment and Insight into Social Roles

Freud regarded make-believe play as a form of pleasurable wish fulﬁllment that allows children to act out uncertainties, anxieties, and hoped for outcomes and, therefore, to master frightening and frustrating events. Young children, Freud noted, often revisit anxiety-provoking experiences, such as a trip to the doctor’s office or discipline by a parent, but with roles reversed so the child is in command and compensates for unpleasant happenings. Sophie’s parents, aware of the previous day’s events, might have judged her pretend focus on bedtime, lollipops, and paciﬁers to contain at least an element of wish fulﬁllment. The evening before, they had told her, “Only one lolly from the candy dish,” and she had complained at having to go to bed while her parents continued to talk and laugh with their guests.
Psychoanalyst Erik Erikson built on Freud’s vision, expanding his picture of make-believe. According to Erikson, children draw on fantasy play to ﬁnd out about themselves and their social world.1 In all cultures, children act out family roles and highly visible occupations—police officer, doctor, and nurse in our society; rabbit hunter and potter among the Hopi Indians; and hut builder and spear maker among the Baka of West Africa.2 As they do so, they enter a small social organization whose members must cooperate to achieve common goals. And through observing and emulating admired adult ﬁgures, preschoolers internalize social norms and gain a sense of their future, of what they can become and how they can contribute to society. 
Piaget’s View: Exercising a New Symbolic Capacity

Piaget acknowledged the emotional function of play, and he agreed that through pretending, children become familiar with social-role possibilities. But he is best known for stressing the symbolic nature of make-believe. Pretending, Piaget pointed out, is a vital means of mentally representing the world that, along with gestures, language, and drawings, develops rapidly in early childhood. Through it, children practice and strengthen their capacity to represent their experiences.3 For example, when Sophie pretended to put the animals to bed and used a TinkerToy to stand for a lollipop, she represented in her mind what formerly she could experience only directly—by going to bed or sucking a lollipop. Practicing and solidifying modes of representation, Piaget emphasized, make it possible for the child to free thought from the here and now; create larger images of reality that take into account past, present, and future; and transform those images mentally in the service of logical thinking. 
Nevertheless, Piaget was convinced that by itself, make-believe play does little to advance children’s development. Rather, children merely exercise playfully the symbols they have acquired in other contexts.4 Much like his view of private speech as egocentric and nonsocial, Piaget believed that at ﬁrst pretend play is a solitary activity in which the child uses highly personal symbols that cannot easily be interpreted by others. Sociodramatic play, involving joint make-believe with a partner, Piaget claimed, is not under way until age 3. As with other aspects of Piaget’s theory, the direction of development for make-believe is from purely individual, egocentric symbols to social play and shared understanding.
Yet think back to 2-year-old Sophie’s pretending. Sophie is socially engaged throughout! From the start, she draws Kevin into the activity, explains her pretend actions so he can build on them, and responds cooperatively and appropriately to Kevin’s suggestions, as he does to hers. Vygotsky’s theory has been the wellspring of our recent appreciation of the profoundly social nature of even very young children’s imaginative play—and its wide-ranging inﬂuence on cognitive and social development.

Vygotsky’s View: A Zone of Proximal Development

Vygotsky viewed make-believe play as crucial in children’s learning.5 He regarded it as a unique, broadly inﬂuential “zone” in which children try out a wide variety of challenging skills and acquire many culturally valued competencies. Consider the following frequently quoted remarks, taken from a brief lecture in which Vygotsky eloquently summed up his conviction that pretend play is a central force in children’s development:

[Make-believe] play creates a zone of proximal development in the child. In play, the child always behaves beyond his average age, above his daily behavior; in play it is as though he were a head taller than himself. As in the focus of a magnifying glass, play contains all developmental tendencies in condensed form and is itself a major source of development.6 

Why did Vygotsky say that make-believe play creates a “zone” in which the child is “a head taller than himself”? If we stop every now and then to watch children at play, we can see what Vygotsky meant. Recall how Sophie satisﬁed both teddy bear’s and leprechaun’s desire for a lollipop, when just one TinkerToy lollipop was available. She had them share, a very mature response for a 2-year-old. In everyday life, Sophie, like many Western children her age, ﬁnds sharing to be difficult. 
As another illustration, consider 5-year-old David, who has trouble sitting still during group storytime in kindergarten. He leans over and talks to the other children. In spite of the teacher’s frequent prompting, he can’t stay seated for more than a couple of minutes. But when David plays school with several of his friends, he can sit and pay attention for much longer—perhaps as long as 10 minutes. Play provides the roles, rules, and scenarios that enable David to concentrate at a much higher level than he typically does in nonpretend contexts.


unique features of make-believe play

How do the make-believe scenes just described, and others like them, serve as major sources of development? To answer this question, Vygotsky pointed out, we must identify the distinctive features of make-believe play—those that make it unique among young children’s experiences. 
The widespread belief, originating with Freud, that play is pleasurable wish fulﬁllment characterizes certain playful pursuits—for example, acting out high-status roles, such as doctor, parent, or teacher, and thereby exercising authority over others instead of being directed and controlled. But not all fantasy qualiﬁes as wish fulﬁllment. In the sociodramatic scenarios that young children create, a doctor must have patients to inoculate, a parent must have children to discipline, and a teacher must have pupils to do assignments. Make-believe roles are not equally pleasurable—a feature of cooperation that is as true in everyday life as it is in fantasy play. 
Even when make-believe does fulﬁll a child’s wishes, such pleasure is not unique to play. Many other activities, such as eating a favorite treat, being granted the undivided attention and affection of a parent, and listening to an exciting story, are at least as gratifying and sometimes more so than pretending. Indeed, imaginative wish fulﬁllment can, at times, be counterproductive. In well-known research on children’s ability to delay gratiﬁcation, psychologist Walter Mischel and his collaborators showed preschoolers some delicious marshmallows and told them that they could have one now or several if they waited until later. Children who spent the waiting period in a wish-fulﬁllment mode, thinking about what it would be like to eat those tasty marshmallows, were far less likely to wait patiently and successfully than children who turned their attention away from the treats and thought about other things.7 In this situation and others, being caught up in fantasized wish fulﬁllment interferes with attaining larger, more rewarding outcomes in real life—ones that would have been realized had the child been able to exercise imaginative self-restraint. 
What about Piaget’s belief that through make-believe, young children solidify their new symbolic capacity? A burgeoning ability to use symbols certainly contributes to the emergence of make-believe, and (as we’ll soon see) make-believe does much to extend young children’s symbolic skills. Nevertheless, mental representation is yet another feature that is not exclusive to play. As we have already noted, it also characterizes gestures, language, and artistic pursuits as well as beginning literacy—preschoolers’ ﬁrst efforts to make sense of written symbols.
Vygotsky concluded that make-believe play has two crucial features that distinguish it from other childhood activities. First, the creation of imaginary situations in play helps children separate internal ideas from the objects and events for which they stand. Once young children realize that words, gestures, and other symbols are distinct from external reality, they are well on the way to using those representations as effective mental tools, calling on them to overcome impulses. Second, a careful look at children’s pretend scenarios reveals that make-believe play is, above all, rule-based play. Inspired by experiences in their families and communities, children continually devise and follow social rules in imaginary situations. In doing so, they strive to bring their behavior in line with social expectations and acquire the rules of social life. 
Consider these unique, complementary ingredients of make-believe. The ﬁrst strengthens children’s internal capacity to become civilized and socially responsible. The second provides children with powerful external pressures to act in socially desirable ways. Together, these features make fantasy play a supreme contributor to the development of self-regulation—one that extends the impact of adult teaching and example more than any other early childhood activity. To understand make-believe play’s role in development, let’s take a closer look at each of its unique features.

Overcoming Impulsive Action

Fantasy play makes its appearance in the second year of life, a time when children must start to suppress impulses and accept that certain desires will remain unsatisﬁed. In infancy, most of the child’s wants—for food, stimulation, affection, and comfort—are gratiﬁed quickly. Such prompt satisfaction grants babies the security that their basic needs will be met. As a result, they do not have to be preoccupied with those needs and, instead, can turn their attention outward, toward acquiring physical, cognitive, and social skills. Warm, responsive caregiving also promotes a view of parents as kind and compassionate—an outlook essential for motivating children to emulate and take direction from parents.
Between 1 and 2 years of age, children begin to acquire language, greater understanding of the consequences of their actions, and the ability to comply with others’ requests and directives. Consequently, caregivers’ expectations change. They increasingly insist that children engage in socially appropriate conduct. During the very period in which children must learn to subordinate their desires to social life, imaginative play ﬂourishes. For Vygotsky, this synchrony between socialization and make-believe is no coincidence. Pretend play fortiﬁes children’s capacity to use ideas to guide behavior. The young, immature child runs after a ball that rolls into the street, without considering consequences; drops toys on the spot when another activity engages her; and grabs an attractive object from a playmate, without regard for the playmate’s rights and feelings. Make-believe play, Vygotsky asserted, helps preschoolers conquer these impulses by granting the child repeated practice “in acting independently of what he sees.”8
Just how does imaginative play help children distinguish ideas from the enticing stimuli around them and use thought to guide behavior? According to Vygotsky, the object substitutions that permeate children’s make-believe are crucial in this process. While pretending, children continually use one object to represent another. By making a TinkerToy stand for a lollypop or a folded blanket stand for a sleeping baby, children step back from reality. The TinkerToy becomes a means for separating the idea “lollipop” from a real lollipop; the blanket becomes a means for separating the idea “baby” from a real baby. This severing of thought from objects and actions occurs because, in play, children change an object’s usual meaning. In calling the TinkerToy a lollipop, Sophie conjured up the idea of a lollipop and used it to alter the TinkerToy’s identity. As a result, rather than reacting impulsively to the sight of a lollipop, Sophie relied on ideas to regulate the lollipop’s very existence—and the teddy bear’s, the leprechaun’s, and her own actions toward it!
At ﬁrst, children ﬁnd it difficult to distinguish words and other mental symbols from the objects and actions to which they refer. Parents seem to realize this when, in the presence of their 1- or 2-year-old, they phrase things this way to an adult companion: “After we ﬁnish running errands, let’s stop off for some i-c-e c-r-e-a-m.” Ask parents why they spell rather than say the words, and they remark, “If you say ‘ice cream,’ he’ll want it now. He won’t be able to wait!”
Children’s earliest efforts at make-believe also reveal how challenging they ﬁnd the task of detaching thought from reality. Initially, object substitutions are closely tied to the real things they represent. Toddlers between ages 1 1/2 and 2 generally use only realistic-looking objects while pretending—a toy telephone to talk into or a cup to drink from.9 Once, I handed a 21-month-old a small wooden block, put another to my ear, and called her on the phone: “Ring! Ring! Hello, Lynnay!” She responded by throwing down the block and turning to another activity. Yet when given a plastic replica of a push-button phone, Lynnay readily put the receiver to her ear and pretended to converse.
Around age 2, children begin to pretend with less realistic toys, such as a block for a telephone. And sometime during the third year, they can imagine objects and events with little or no support from the real world, as when they say to a play partner, “I’m calling Susie on the phone!” while dialing with their hands or without acting out the event at all. Between ages 3 and 4, this detachment of make-believe symbols from the real-life conditions they stand for is well developed. Let’s look in on 4-year-old Alison as she draws her father into a make-believe scenario. Notice how Alison’s imagination ranges far beyond the immediate play props before her—a tea set, a toy truck, and an ambulance. In the span of a few moments, she conjures up a fantastic, multicolored house and room and travels to a distant land where she witnesses a cataclysmic event!

Alison: (while stacking multicolored plastic spoons) I don’t need my house painted. It just got painted today!
Father: Just got painted today?
Alison: Yep.
Father: What color was it painted?
Alison: It’s kind of, it’s got brown and red in it.
Father: Brown and red?
Alison: And a little peach color.
Father: A little peach color? What color is your bedroom?
Alison: Well, it’s yellow and orange and red.
Father: That sounds pretty.
Alison: All mixed together!
Father: Oh, all mixed together.
Alison: Well, I have a dump truck. Or—what else would you like? An ambulance? (Picks up toy ambulance and hands it to her father)
Father: Did someone get in an accident?
Alison: Well, yes. (Then, referring to a newspaper report her father had mentioned earlier in the day) This morning, it said (changes to a low-pitched, somber tone of voice), “Two trains crashing—in India.”

Vygotsky maintained that in detaching symbols from objects and actions, make-believe play helps children use thought to choose deliberately among alternative courses of behavior. In play, Alison thinks about paint colors, which need not be the color of her real room. She learns that you can consider possibilities and choose among them, thereby controlling eventual outcomes. 
Imaginative play, Vygotsky noted, also functions as a bridge from the concrete thought of the preschool and early school years to mature “adult thought, which can be totally free of real situations.”10 In helping children disengage thought from reality, pretend play is vital preparation for the much later development of abstract thinking, in which symbols are manipulated and hypothetical ideas are evaluated without referring to currently existing, real world conditions.11 
When imagination eventually combines with the logical, abstract reasoning powers of adolescence, the stage is set for creativity. A truly creative work is both original and sensible; its novelty is culturally meaningful and useful. Almost always, creativity demands a high degree of self-regulation—pulling together previously unrelated ideas, critically evaluating those ideas, and persevering in the face of obstacles.12 In make-believe, Alison experimented with the ﬁrst step of this multistep process when she melded news of the train crash in India with the toy ambulance before her. As we will see shortly, people renowned for their creative accomplishments often report that make-believe play was a frequent, highly inﬂuential aspect of their early development.

Acquiring and Enacting the Rules of Social Life

Had Vygotsky lived long enough to become familiar with Erik Erikson’s psychoanalytic theory, he would have agreed that make-believe play teaches children about social roles and provides them with insights into what they can become in their society. But Vygotsky was far more explicit about just how pretending helps children acquire dispositions that foster eager, willing participation in social life.
Children’s imaginative play, Vygotsky pointed out, contains an interesting paradox. In play, preschoolers seem to do what they most feel like doing, and to an outside observer, their play appears free and spontaneous. Nevertheless, pretend play demands that children act against their immediate impulses because they must subject themselves to the rules of the make-believe scene.13 A child pretending to go to sleep follows the rules of bedtime behavior. Another child imagining herself to be a mother and a doll to be a baby conforms to the rules of parental behavior. And a child playing astronaut obeys the rules of shuttle launch and space walk. 
In this sense, make-believe is not really “free play,” as we often assume it to be. Instead, its very essence is self-restraint—voluntarily following social rules. While pretending, Vygotsky explained, children repeatedly face conﬂicts between the rules of the make-believe situation and what they would do if they could act impulsively, and they usually decide in favor of the rules. When tired, Sophie’s teddy bear and leprechaun don’t stay up late doing just as they please. Instead, they obey their caregivers and go to bed. With only one lollipop, or paciﬁer, to go around, teddy bear and leprechaun share. They don’t quarrel and grab, and if they had done so, Sophie or another make-believe character probably would have intervened and insisted on kind, considerate behavior.
According to Vygotsky, children’s greatest self-control occurs during make-believe play. They achieve their maximum display of willpower when at their own initiative they renounce a momentary attraction in favor of rule-governed behavior.14 The paradox of make-believe is that in everyday life, when children subordinate actions to rules, they usually give up something they want—instead of keeping a treasured toy all to themselves, they share it; instead of continuing to play, they clean up; instead of watching more TV, they go to bed. During fantasy play, however, renouncing impulse and following social rules are central to the fun of playing. Rather than frustrating or disappointing the child, self-restraint is the route to maximum pleasure. 
In sum, subordinating immediate desires to the rules of make-believe scenes becomes a new form of desire15—one that responds to the child’s need to become an accepted member of his or her culture. Indeed, if you watch preschoolers at play, you will see that they rarely violate the rules of their social world. And as they jointly create play scripts and follow social rules with peers, they come to appreciate society’s norms and strive to uphold them. A child playing storekeeper experiences ﬁrsthand the reasons for having customers line up to pay, for making change accurately, and for being polite. A child playing parent in a household scene becomes aware of parental responsibilities and why it’s important for children to follow their parents’ directives. 
In fact, an adult who breaks a rule in make-believe usually brings preschoolers’ profound respect for social order into bold relief! Cara, a demanding but spirited 5-year-old, likes to initiate make-believe with the following transparent role reversal: “Mom, I’ll be the mother, and you be my child 5 years old.” Cara’s mother plays along for a while and then deliberately transgresses, refusing to eat her vegetables or pick up her toys. At the ﬁrst sign of misbehavior, Cara lectures in a tone of voice well beyond her years: “Children must obey their parents because their parents know things they don’t, so the parents must take care of them.” As Cara’s pronouncement makes clear, play creates a “zone” through which preschoolers internalize a basic sense of social responsibility and morality. At the same time, they acquire a wealth of practical knowledge and skills. 
In extreme circumstances, when the organization and predictability of the real world fall apart, young children whose prior lives have been ﬁlled with parental warmth and involvement often call on rules and rituals in make-believe to restore their social world. Recently, I came across the recollections of Alice Cahana, an elderly Holocaust survivor, recounting her days as a child in the death camp at Auschwitz. Alice explained that she and her sister Edith managed despite all odds to stay together. Their secret strategy was never to display any emotion that would give away their relationship, since a major objective of the SS was to break up families. Only at night did they dare to hug, whisper, and play together. 
On Friday nights, they marked the Sabbath in a special way, by imagining that they were at home. They talked about the evening’s events in minute detail to make the image of family life ﬁrm and real. Alice had always had the responsibility of setting the table, and her mother would correct her if she left out even small, nonessential items. In play, Edith would murmur, “Alice, it’s time to set the table. Find the nicest tablecloths, and don’t forget the ﬂowers. Where are the napkins for the guests? You forgot the fork for Father. You really shined the candelabra beautifully this week, better than before.” 16 After their pretend meal, the two sisters would whisper songs.
The rules of make-believe kept alive the integrity of the girls’ lost social world. They kindled hope, or as Alice put it, “an inner light,” fortifying the children with the self-restraint and forbearance they needed to endure the next day. 
from make-believe play to organized games 
with rules

Vygotsky regarded the sociodramatic play of the preschool years as essential for further development of play—speciﬁcally, for movement toward game play in middle childhood. In make-believe, the rules of play are implicit; preschoolers are hardly aware of enacting them. Instead, they are caught up in creating imaginary situations—putting a stuffed animal to bed, driving an ambulance to a train crash, or ringing up a customer’s purchase at the cash register. Winning and losing, team membership and competition, and purposefully laying down rules are not of great interest to preschoolers. Try playing a rule-based game with a 3- or 4-year-old, and you are likely to ﬁnd that the child is easily sidetracked. If, with your prompting and guidance, the child does ﬁnish the game, he or she might say, “I won!” or “Everybody won!” regardless of the outcome.
With age, the imaginativeness of play recedes. In the games that captivate school-age children, rules come to the forefront.17 Six- to 8-year-olds are often preoccupied with working out the rules of a game and making sure all players follow them. They often spend as much or more time on the details of how a game should proceed as they do playing the game itself! Nevertheless, every organized game with rules contains an imaginary situation in veiled form. In Monopoly, children are real estate moguls; in baseball, they emulate Hall-of-Fame idols. Children retain both aspects of play, in changing balances, throughout development.
Increasing emphasis on the rule-oriented side of play extends the “zone” forged by fantasy play during the preschool years. By making children more aware of the goals of their play activities, game play further strengthens children’s capacity to overcome impulse. Consciously striving to reach a goal requires planning—postponing action in favor of thinking out what to do in advance, organizing one’s behavior in accord with the plan, evaluating how well the plan is working along the way, and revising the plan if necessary. 
In the simple games of the late preschool and early school years, the play goal is very clear—in hide-and-seek, to keep the person who is “it” from ﬁnding you; in Chutes and Ladders, to travel a road with as many shortcuts and as few setbacks as possible, getting to the ﬁnish line ﬁrst. Gradually, the goals of children’s games become more distant and complex. Attaining those goals requires more intermediate steps and greater knowledge, skill, and coordination of play actions with those of others—in T-ball and kickball, scoring more runs than the other team while adhering to fair procedures for batting, pitching, and ﬁelding; in chess, moving each type of piece according to its special rule in an effort to checkmate the opposing king. 
Through game play, children receive additional experience in setting goals, in regulating behavior in pursuit of those goals, and in subordinating behavior to rules. And in negotiating rules in peer-organized games, children deepen their understanding of why rules are necessary and which ones work well. In the process, they form more mature concepts of fairness and justice. Indeed, parents and teachers often remark that game play prepares children for the inevitability of real downfalls and teaches perseverance and good sportsmanship.
In sum, the development of play proceeds from make-believe, with an overt imaginary situation and covert rules, to organized games, with overt rules and a covert imaginary situation. The vast yet nearly effortless learning that takes place through pretending makes it, for Vygotsky, “the highest level of preschool development. The child moves forward essentially through play activity.”18 Make-believe play, in Vygotsky’s theory, is the preeminent educational activity of early childhood.


contributions of make-believe play to development

Vygotsky emphasized the development-enhancing, forward-moving consequences of make-believe. Was he correct that pretending in early childhood has a far-reaching impact on development, supporting the emergence and reﬁnement of a wide variety of competencies? Indeed, much evidence ﬁts with Vygotsky’s conclusion. 
Sociodramatic play with peers has been studied most thoroughly. Comparisons of preschoolers’ sociodramatic activities with their social nonpretend pursuits, such as drawing pictures or putting puzzles together in the company of agemates, supports Vygotsky’s view of make-believe as a “zone” in which children enhance their own development. In social pretending, preschoolers engage in lengthier interactions, are more involved, draw more children into their activity, and are more cooperative. In view of these ﬁndings, it is not surprising that 4- and 5-year-olds who spend more time at sociodramatic play are advanced in intellectual development and are judged more socially competent by their teachers.19 Furthermore, pretend play fosters a diverse array of speciﬁc cognitive and social skills, which contribute to these broad-baseed outcomes. Let’s take some examples.

Attention

Attention is fundamental to all human thinking. It determines the information considered in any task and whether the task will be completed. As any parent or teacher knows, young children spend only short times involved in most activities and are easily distracted. Yet attention becomes more sustained over early childhood—a development that equips children for concentrated involvement, which will be essential for success once they enter school.
Under what conditions are preschoolers most likely to display sustained attention? Think back to the examples of Sophie’s and Mattie’s behavior at the beginning of this chapter, and the answer will be clear: during play, especially complex play. In two studies, psychologist Holly Ruff and her collaborators sat toddlers and preschoolers at a table of toys. Children’s patterns of attention changed dramatically with age.20 After playing for a short time with a toy, 1- to 2-year-olds dropped it and turned to another. Their attention was externally controlled by the physical properties of the objects. Hence, they ﬂitted from one toy to another and lost interest as the play session progressed. But once children began to set goals in play, the nature of their attention changed. It became effortful, as indicated by eyes ﬁxed on the toys and a determined facial expression. 
For the youngest children, play goals were often as simple as getting a cap off a bottle. With age, the problems and challenges children set for themselves became more elaborate, such as building an intricate structure out of small blocks or acting out a fantasy scenario. The more complex children’s play goals, the more they displayed focused, effortful attention and the more such attention increased over the play session. And in one of the studies, both construction and imaginative play were powerful predictors of sustained attention between ages 2 and 5.21 With respect to make-believe, when preschoolers create very intricate scenarios, either on their own or with play partners, they generally stay absorbed for a very long time.
Recall the anecdote about David, who remained an attentive pupil considerably longer while playing school than he did in other kindergarten activities. Preschoolers’ sustained attention is more advanced in make-believe than in many real-life pursuits. When permitted to select freely among diverse activities at child care or preschool, young children overwhelmingly prefer fantasy play. Observing in a child-care center richly equipped with play materials, Kathleen Kirby, one of my graduate students, found that 2- to 4-year-olds spent 45 to 50 percent of free-choice periods immersed in make-believe—nearly twice as much time as they devoted to any other activity.22 The rapt attention engendered in pretend play may eventually carry over to nonpretend contexts.

Memory

Fantasy play also strengthens young children’s memories. Preschoolers remember information better in a play context than in a context in which information is isolated from its everyday use and they are told to remember deliberately. 
Psychologist Lawrence Newman permitted one group of 4- and 5-year-olds to play with a set of toys and told another group simply to remember the toys. Play produced far better recall.23 During the “remember” condition, children repeatedly named and touched the objects—a rehearsal strategy that, much like repeating a phone number, helped them hold on to information, but only brieﬂy. In contrast, the “play” condition led to many spontaneous organizations of the toys that enabled children to recall effortlessly. Often these grew out of make-believe—for example, putting the toy shoes on the doll and pretending to feed her the toy banana. Narrating imaginative activities also yielded excellent recall, as in “I’m squeezing this lemon” or “Fly away in this helicopter, doggie!” When children embedded an object in meaningful make-believe, they increased its memorableness.
Furthermore, children acting out stories during pretend play are assisted in mastering the storytelling script, or basic framework of story organization. Preschoolers’ pretend scenarios are often quite storylike, consisting of characters, settings, and plot sequences that include adventure, suspense, surprise, conﬂict, and resolution. Witness the following trip to Sea World, during which Emily and her friends save Baby Shamu from danger:

S: (to Emily) Would you come with us? Let’s go to Sea World.
E: Sea World! Let’s watch Shamu! I’m the mom. (All three children run to one end of the room and sit down next to one another. They gaze toward the other end of the room.)
S: Oh! I see Shamu.
E: It’s starting (presumably the show).
A. J.: Yeah!
E: There’s a little ﬁsh. There’s a big mom.
S: There’s a daddy.
E: Look! He fell on the ice. Look at ‘em. Mommy and Daddy are fell! Oh-h-h-h!
S: (Patting a pretend Baby Shamu) Oh-h-h-h! I know you’re all right. (All make stroking motions on a pretend Baby Shamu.)
E: Look! All better now. (She pretends to lift Baby Shamu back into the water.) 24

Children like Emily, who have formed a sense of story through make-believe, more readily grasp the organization and meaning of new stories and are therefore more likely to remember them.25 Young pretenders also impose the standards of story organization on the way they recall and explain their experiences to others. Their verbal narratives are more cohesive than those of agemates who prefer other forms of play.26 
In helping children grasp the storytelling script (and in other ways we will take up next), make-believe play is wonderful preparation for literacy. Being able to anticipate story organization eases the task of making sense of written prose. It also grants children a ﬁrm foundation for authoring their ﬁrst written narratives.

Language and Literacy

As the ﬁndings just mentioned illustrate, make-believe greatly enriches children’s facility with language. During sociodramatic activities, preschoolers hear speech that describes and comments on actions going on at the moment. This helps ensure that language is understandable because it is in tune with ongoing events. Consequently, when new words arise in the course of a fantasy scene, children can determine their meaning easily from cues in the situation. In this way, vocabulary extends during make-believe as children introduce words they have heard during recent experiences. For example, “I’m going out. I need my cloak,” said 5-year-old Lizzy, mimicking an expression she had heard in a TV movie while grabbing a dress-up raincoat from a hook in the housekeeping area at child care. 
“You mean your coat?” asked Lizzie’s playmate.
“Right, a cloak is a coat,” Lizzie explained. The amount of time preschoolers spent talking with peers while pretending is positively associated with the size of their vocabularies at age 5.27
As children engage in play talk, they not only build their vocabularies but correct one another’s errors, either directly or by demonstrating the acceptable way to speak. In one instance, a kindergartner enacting a telephone conversation said, “Hello, come to my house, please.” Her play partner quickly countered with appropriate telephone greeting behavior: “No, ﬁrst you’ve got to say ‘How are you? What are you doing?’”28
Furthermore, the language skills required to express different points of view, resolve disagreements, and persuade peers to collaborate so play can continue are complex and often subtle. Emily’s success in convincing several classmates to join the make-believe trip to Sea World was partly due to the way she approached them—by asking if they’d like to go. By experimenting with language during play, children can see how others react to various styles of communication and use that information to reﬁne their way of speaking. In this way, play is an ideal arena for mastering all aspects of conversational dialogue.
Opportunities to acquire literacy-relevant skills also abound in make-believe play. In one kindergarten, children transformed the block-building area into a make-believe recycling center with the help of their teacher. Signs were prepared that advertised the new center, its hours, and what it would pay for various goods. As in other friendly businesses, attendants wore nametags, such as “Hi, I’m Charles!” When customers arrived with goods, the attendants had to ﬁll out receipts listing each item, its quantity, and its value. Since many children could not yet spell, they used ﬁrst letters or drew pictures of items. While doing so, they often became curious about how to write the full word and asked the teacher to help them. 
What does research say about the role of make-believe in children’s literacy development? The amount of time children devote to pretending at age 4 is positively related to reading and writing skills after entering kindergarten and ﬁrst grade—speciﬁcally, the extent to which children spontaneously read words on game cards and signs, understand print concepts, and write letters and simple words.29 The more children engage in literacy-relevant play (activities like the recycling center), the more advanced their literacy skills are as well. 
Preschoolers’ commentary about language while pretending, using such verbs as say, talk, tell, write, and explain, is a particularly good predictor of reading progress at age 5. Using language to talk about language happens often as peers jointly create fantasy scenes. Such talk may help children treat both oral and written narratives as objects of analysis; hence its beneﬁts for early reading.30 
With respect to writing, object substitutions and role play seem to have special beneﬁts.31 Frequently using objects to symbolize other objects and transforming oneself into various characters may encourage children to try to make sense of other symbol systems, such as how to express themselves with print. In their ﬁrst efforts to write, preschoolers commonly assume that letters (just like pictures and ﬁrst substitute objects) look like their meanings. In one instance, a child stated with certainty that the word deer begins with the letter O because O is shaped like a deer; then he demonstrated by drawing an O and adding antlers to it!32 Flexibly using make-believe symbols seems to assist children in revising early, incorrect ideas about how print is used to communicate.

Hypothetical Reasoning

During the preschool and elementary school years, thought is largely tied to the here-and-now. Children think in an organized fashion about concrete information they can directly perceive but have great difficulty reasoning about hypothetical situations—ones that do not make sense in the real world. For example, try giving a child between 4 and 9 the following problem: Suppose dogs are bigger than elephants and elephants are bigger than mice. Which one is the biggest: dogs, elephants, or mice? Most will insist that dogs couldn’t possibly be bigger than elephants. “That’s never true!” they exclaim.33
Yet with the help of make-believe, even preschoolers can transcend these limits and reason about situations that defy real-world knowledge. Consider the following “impossible” premises and question: All cats bark. Rex is a cat. Does Rex bark? Psychologists Maria Dias and Paul Harris had one group of 4- to 6-year-olds act out problems like this one, using toys that represented the content of the premises. A second group was told that the events were taking place on a pretend planet rather than on Earth. And a third group merely listened and answered the questions. Children in the two “play” conditions gave more hypothetical responses and also justiﬁed their answers with hypothetical ideas—for example, by saying “In the story, cats bark, so we can pretend they bark.”34
The capacity to adopt a “theoretical” mode of reasoning in make-believe is highly consistent with Vygotsky’s belief that pretending assists children in separating mental symbols from the objects and actions for which they stand, thereby permitting them to manipulate meanings in innovative ways. Reasoning about the nonreal is essential for abstract thinking and for many creative endeavors—that is, for human cognition to reach its highest potential.

Distinguishing Appearance from Reality

After kissing their preschooler goodnight and turning out the lights, many parents are accustomed to hearing refrains like this: “Mommy, Daddy, monsters are in my room again!” To rid the bedroom of scary creatures, pictures and mobiles may have to be removed and a thorough search conducted to assure the child that no monsters are lurking in the shadows, waiting to reappear as soon as the parent leaves. Uncertainty about the relation between appearance and reality also surfaces in other situations. On Halloween, a 3-year-old who eagerly dons her costume may become frightened at the sight of her animal- or witch-like appearance in the mirror. And a father who shaves off his beard and mustache may ﬁnd that his young preschooler reacts with puzzlement and distress to his changed appearance.
Consistent with these all-too-familiar experiences, research conﬁrms that preschoolers are easily tricked by the outward appearance of things. They mistakenly conclude that the way things look or sound is the way they really are. In several studies, psychologists John Flavell, Francis Green, and Eleanor Flavell presented children with appearance–reality problems in which objects were disguised in various ways. The children were asked what the objects were, “really and truly.” Before age 6 or 7, most children took things at face value.35 When asked whether a white piece of paper placed behind a blue ﬁlter is “really and truly” blue or whether a can that sounds like a baby crying when turned over is “really and truly a baby,” they responded, “Yes!” 
Yet in make-believe, children use objects to symbolize things that are very different from the objects themselves—a ball to stand for an apple, a laundry basket for a cradle. They do not judge these imaginary symbols to be real, so clearly they can tell the difference between pretend and real experiences long before they can answer many appearance–reality problems correctly.36 The more 3- to 5-year-olds spontaneously engage in joint make-believe with classmates at preschool, the better they can distinguish the apparent and real identities of disguised objects.37 Pretending with peers may help children master appearance– reality distinctions because it offers repeated practice in transforming a wide variety of objects from their real state to a pretend state and back again.

Understanding the Mind and Its Many Activities

Make-believe play provides a rich foundation for children’s comprehension of the mind’s wide-ranging capabilities. In Chapter 3, I noted that children’s elaborate interactions with imaginary companions foster understanding of false belief and other people’s perspectives. In sociodramatic play as well, opportunities to act out and coordinate various roles probably help children grasp similarities and differences between people in desires, beliefs, and feelings. Recently, a mother recounted to me a make-believe episode initiated by her 2 1/2-year-old daughter, Traci, involving extended experimentation with and reversals of roles, which led to abundant dialogue about mental states. 
One evening, Traci, her two older sisters, and her parents had gathered in the living room to watch a video of The Sound of Music. Although Traci showed little interest in the movie, her ears perked up at a statement in the sound track reporting the death of the mother of the Trapp-family children. Traci began to ask questions, to talk about how the mother must have gotten sick and gone to the hospital, and to repeat that the mother had died. For the next hour and a half, she assigned her own mother and herself at least ﬁfteen different roles—mother, father, baby, sister, doctor, nurse, and more—as she explored the idea of a mother dying: 

Traci: “Here, you’re the baby and I’m the mama. Honey, I’m going to the hospital.”
Mother: “Go to the hospital and have the doctor help you feel better.”
Traci: “No, I’m not going to feel better. I’m going to die!”
Mother: (frantically) “No, no, I don’t want you to die! I’ll be very, very sad.”
Traci: “OK, don’t worry, it’ll be all right.”

Some scenarios (like this one) ended happily; others were ﬁlled with depressing events and ended sadly. In acting them out, Traci imagined and simulated diverse wants, hopes, worries, and strivings of people in her life. 
As this brief vignette illustrates, sociodramatic play is rich in mental-state language, especially references to emotion. As children learn about mental states from conversing and engaging in make-believe with adults, they transfer this knowledge to sociodramatic play with peers. The more 3- and 4-year-old friends talk about mental states during joint make-believe, the better they perform and the more they improve over the following year on tasks assessing their grasp of mental life.38 These include understanding of false belief, identifying the feelings of a puppet acting out emotionally charged situations (such as seeing a parent off on a trip), and explaining real-life causes of happiness, sadness, anger, fear, and mixed emotions (for example, why one might feel both happy and sad about winning a race against a friend). 
Talk between siblings that focuses on feelings seems to play a particularly strong role in the diversity of themes that siblings act out in their joint make-believe. Complexity of play with siblings, in turn, is a good indicator of preschoolers’ understanding of other people’s feelings—more so than is their play with mothers.39 Why might conversing and pretending with siblings make a special contribution to children’s capacity to read others’ emotions? In interacting with their child, mothers spend much time acknowledging and clarifying the child’s feelings. Siblings (as well as preschool friends) frequently articulate how they themselves feel. Therefore, siblings more often expose the child to the inner states of someone other than the child himself or herself. The more affectionate and cooperative siblings’ relationships are, the more sophisticated their sociodramatic play.40 Siblings who get along well are probably better at creating and sustaining elaborate make-believe scenarios—play that contributes to their emotional sensitivity. 
As children build on each other’s play themes, they often refer to their make-believe with mental terms by making statements like these: “Let’s pretend,” “Let’s imagine,” “You act like a pilot, and I’ll make-believe I’m in the control tower.” Some experts believe that this suspension of play to communicate about it marks a major change in understanding.41 Now children do not just represent experiences in play; they display awareness that make-believe is an activity in which the mind creates events. As a result, children become capable of consciously reﬂecting on and deliberately manipulating their own and others’ fanciful representations, and their play becomes even more complex and imaginative.
Researchers continue to debate whether preschoolers actually view pretending as a mental state rather than just a series of actions mirroring real life.42 But there is clear evidence that their grasp of make-believe as a mental activity improves steadily between ages 4 and 8. Over time, they can answer more subtle questions about the nature of make-believe. For example, by age 6 most realize that pretending depends on having prior knowledge about a make-believe role. That is, a person hopping can be pretending to be a rabbit only if he or she knows that rabbits hop.43 Children age 6 and older also recognize that make-believe is something you can do just inside your head, without using your body at all.44
Why is this understanding of make-believe as mental representation so important? When children master this and other related ideas—that people are constantly engaged in thought, even when they have nothing to do; that mental inferences, not just direct observations, can lead to new knowledge; and that prior experiences affect people’s interpretations of new experiences45—they show that they have begun to pay more attention to the processes of thought.46 “Thinking about thought” makes possible a major advance in self-regulation. It permits children to call on what they know about mental life to surmount cognitive and social challenges. The child well aware of the mind’s active, transforming capabilities is more likely to attend to relevant information, to plan, to use memory and problem-solving strategies, and to evaluate and revise his or her thinking to make it more effective. In sum, make-believe in early childhood is among those factors that promote reﬂective thought, which improves throughout the school years.

Self-Regulation

As we have just seen, pretend play, through its impact on children’s awareness of the mind, fosters advanced forms of self-regulation. But what about the self-regulatory capacities that emerge earlier, during the preschool years—self-guiding private speech, willingness to take on chores, and capacity to delay gratiﬁcation for brief periods? Does make-believe foster these early indicators of a self-regulated child? Findings of several studies I carried out with my graduate students suggest that it does.

private speech.  In the ﬁrst of these studies, we reasoned that if Vygotsky is correct that children learn to overcome impulse and manage their behavior through pretend play, then private speech should be especially frequent within make-believe activities. To ﬁnd out, graduate student Kerry Krafft and I observed 3- to 5-year-olds during free-choice periods in two contexts differing sharply in encouragement of imaginative play: the Y Preschool (called this because it is sponsored by the YWCA) and the Montessori Preschool.47 
In the Y Preschool, play formed the basis of the daily program. Children had easy access to a wide variety of toys, games, and books, and each classroom contained two centers especially conducive to sociodramatic play: a block-building area with hundreds of blocks varying in size and shape and a child-sized playhouse brimming with all manner of housekeeping props. The Montessori Preschool, in contrast, actively discouraged make-believe (although not all Montessori schools do so). Spurred by philosophical principles advocating realistic activities, the Montessori teachers set up “work stations” from which children selected. Typical options were puzzles, picture-matching and picture-sequencing tasks, letter tracing, small construction blocks, containers with water for pouring, books, and crayons and other tools for drawing and writing. When Montessori children strayed into make-believe, teachers often interrupted, drawing them back to work-station pursuits. 
Nevertheless, Montessori children did engage in pretending, but it was sharply restricted relative to children in the Y Preschool, who displayed three times as much imaginative play. What happened to private speech? It showed a parallel trend. Children in the Y Preschool engaged in twice as much self-talk as did children in the Montessori preschool. Furthermore, pretend play emerged as the strongest correlate of both fantasy-play private speech and self-guiding private speech. That is, the more children engaged in make-believe, the more they talked to themselves to work out pretend characters’ actions and to guide their thought and behavior during realistic tasks. This latter ﬁnding suggests that private speech, so rich in the make-believe context, may carry over to children’s self-talk when they face real-world challenges.
Recall from Chapter 3 that as children master puzzles and other problem-solving tasks, their self-guiding speech declines. Yet when graduate student Tina Gillingham and I observed preschoolers in a laboratory playroom liberally equipped with fantasy-play props, we found that private speech during make-believe remained uniformly high from ages 2 to 4 and actually increased at age 5.48 Our interpretation of the prevalence of private speech during make-believe is that children continually set challenges for themselves in fantasy play. Consistent with Vygotsky’s theory, they create their own “zones,” frequently calling on self-directed language to work out their imaginings and bring behavior under the control of thought.
socially responsible behavior.  In yet another study, graduate student Cynthia Elias and I addressed the question of whether complex make-believe— speciﬁcally, sociodramatic play involving elaborate communication between agemates—promotes socially responsible behavior.49 During the fall of the school year, we observed 3- and 4-year-olds as they played in the block and housekeeping centers of their preschools and rated the quantity and maturity of their fantasy endeavors. Then we assessed social responsibility by observing the children during clean-up periods, recording the extent to which they willingly picked up and put away toys without prompting and assistance. We made these clean-up observations in the fall and again in the spring so we could measure gain in responsible behavior. 
Our ﬁndings revealed that preschoolers who more often engaged in complex sociodramatic play showed greater improvement in social responsibility over the next 5 to 6 months. And this relationship was particularly strong for children rated by their parents as highly impulsive—that is, who were poorly self-regulated to begin with! In other words, children most in need of enhancing their self-regulatory abilities appeared especially sensitive to the beneﬁts of sociodramatic play.

Imagination and Creativity

In addition to its contribution to many nonplay skills, make-believe can be examined on its own terms: as an imaginative activity that expresses salient aspects of the child’s inner cognitive and emotional life. In Vygotsky’s theory, the drive to fantasize and engage in role play does not fade away with childhood. Instead, he maintained, the imagination of later years is an internalized, condensed form of early childhood make-believe that can be considered play without action. We typically experience it as an elaborate stream of consciousness made up of mental images and silent self-talk that meanders along, remarking on new experiences, reﬂecting on the past, and predicting the future.50
By introducing fantasy elements into consciousness, this inventive private commentary probably helps us cope with the mundane, repetitive aspects of our daily lives. We resort to such ruminations while waiting; during long car trips or meetings; and at other monotonous or idle times. In this way, early make-believe fortiﬁes us with a mental tool that is vital for adapting to everyday life! And from time to time, we apply logical, adaptive thinking to this inner playfulness to harness it for culturally worthwhile purposes. The result may be a creative idea or product.
Was Vygotsky correct that the imaginative mental combinations that form the basis for creativity originate in the pretend scenarios of early childhood? Unfortunately, we have no long-term studies that systematically observed children for the imaginativeness of their play and then tracked them to document their creative accomplishments in adulthood. And even if such studies were available, many intervening events could blur the connection between early play and adult creativity. At present, all we have available to explore this relationship are the recollections of highly creative individuals about their childhoods or the reports of their biographers.
On a recent visit to my local library, I browsed the shelves devoted to biography, selecting several dozen life stories of accomplished writers, artists, and scientists. The accounts were remarkably consistent: For most, pretend play was an inﬂuential aspect of their early years. Often a signiﬁcant person—a parent, an older sibling, or a relative—promoted imaginative experimentation and a sense of wonder by telling fantastic stories, initiating joint pretend, or offering gifts (such as books and puppets) that inspired make-believe.51 
For example, biographical accounts of physicist Marie Curie, co-discoverer of radium and twice winner of the Nobel Prize, invariably make reference to her father’s untiring efforts to provide his children with ideas and games to ﬁll their spare time.52 A chest of colored blocks had special meaning. Marie and her older siblings used the blocks to represent cities, mountains, rivers, countries, and continents. Their father, a high school science teacher, often joined in, capitalizing on play as a way to teach geography. In the home in which Marie Curie grew up, one biographer summed up, “play was learning and learning was play.”53
In poet Sylvia Plath’s childhood, stories and storytelling were pervasive. As a 2 1/2-year-old, Sylvia was intensely jealous of her sickly younger brother for consuming so much of her mother’s attention. While the baby nursed, Sylvia sat nearby on the ﬂoor, impatient and unhappy. Her mother discovered that she could defuse Sylvia’s envy with a game in which Sylvia spread out the newspaper before her, picked out all the capital letters on the page, and pretended, in a very grown-up way, to read—an achievement that attracted much parental admiration. Sylvia’s mother often made up bedtime tales, serialized from one evening to the next. Almost as soon as they could talk, Sylvia and her brother responded in kind with limericks, poems, and fantastic stories of their own. On walks to their grandparents’ house and on long car trips, favorite books invariably came along, offering ready inspiration for the children’s imaginative creations.54 
Filmstar Charlie Chaplin’s mother was herself a talented comedy actress and singer. As a young child, Charlie often accompanied her when she went to work at the theater. As a result, playacting and impersonating became an early focus of Charlie’s pretending. One evening during a performance, his mother’s voice failed. In a pinch, the stage manager, who had seen Charlie at play, led the little boy onstage in her place. Charlie continued his playacting unabated, which included songs, dances, and impersonations from his mother’s repertoire. He was demonstrating the wares of his ﬁrst and best teacher in the art of make-believe, and the performance evoked a roar of appreciation and a shower of coins from the crowd.55
In these and many other similar biographical anecdotes, childhood make-believe engendered imaginativeness that was clearly related to outstanding accomplishment in adulthood. Of course, the scientiﬁc and artistic talents of individuals like Curie, Plath, and Chaplin are rare among us. Nevertheless, as play theorists Dorothy and Jerome Singer point out, all children have “that same potential for playfulness, for trying out possible lives, that is the foundation for a humbler but personally meaningful creativity.”56


adult involvement in children’s make-believe

Piaget’s view of make-believe play, dominant until recently, asserts that pretending emerges spontaneously when children become capable of symbolic thought. He assumed that very young children could not share play symbols with others. Yet in instance after instance, we have seen that adults are central in preschoolers’ play lives, often encouraging and elaborating on their imaginative strivings. If adults are prominent in early make-believe, how did researchers manage to adhere to an image of young children as solitary fantasizers for so long? The reason is that until recently, make-believe was largely studied in the laboratory, in sessions in which children arrived one-at-a-time and had no alternative but to play by themselves. 
Only during the past 10 years have researchers seriously addressed the social context of make-believe. Their ﬁndings conﬁrm that pretending, like other higher forms of thinking, ﬂows from social collaboration. More competent partners scaffold young children’s imaginative play, guiding its emergence and gradual reﬁnement. Once pretend capacities are in place, children forge playful understandings with peers that serve as microcosms of cooperative activity, mirroring social relations and goal-oriented pursuits within the larger society.

Scaffolding Children’s Play

Traci, the 2 -year-old who responded so strongly to the mother’s death in The Sound of Music, often pretends with her own mother, Julie. For some weeks, Traci had been talking about a mysterious creature she called a “maserus.” Traci’s description of the creature convinced Julie that the maserus was an imaginative friendly monster. Congested due to spring allergies, Traci was particularly irritable one morning. Well aware that Traci loves make-believe activities, her mother tried to distract her with a favorite pastime. 
As Traci sneezed and whimpered, Julie spied a half-full white garbage bag in a corner, situated in such a way that it looked like an animal with a snout. “I think I see a maserus!” Julie declared, pointing to the garbage bag. Immediately Traci cast off her irritability and jumped into action. Over the next hour, she and her mother fed the maserus more trash, read books and sang songs to it, and laughed at the monster’s antics. “By the end of our delightful session,” Julie remarked, “I almost felt the bag was alive.” When the activity changed to the more practical concerns of the day, Traci’s problematic irritability resumed.
Recent research reveals that make-believe is, from the outset, a social activity.57 In Western societies, it usually ﬁrst appears between parents and children, although older siblings may participate as well. From these interactions, children derive many play skills that enhance their make-believe in other contexts. 
In one of the most extensive studies tracing the development of make-believe play, psychologists Wendy Haight and Peggy Miller followed nine children from 1 to 4 years of age, repeatedly visiting their homes to make intensive observations of their pretending.58 The researchers found that most make-believe—from 68 to 75 percent—was social across the entire age span. Mothers were the children’s principal play partners from ages 1 to 3. Over time, mother–child play declined and child–child play increased. By age 4, children played about equally with their mothers and with other children—both siblings and peers. 
The dominance of mother–child pretend at the youngest ages, however, was not due to lack of child playmates. Up to age 3, even if siblings and peers were present, children preferred playing with their mothers. Furthermore, Haight and Miller, as well as other researchers, report clear evidence that mothers teach their toddlers to pretend. At age 1, mothers initiate almost all make-believe episodes. They also demonstrate many pretend actions toward objects, thereby showing children how to use one object to represent another.59 Around age 2, mothers begin to talk about nonexistent fantasy objects. In one instance, a mother suggested that an empty bowl was full of juicy oranges, one for each of her son’s miniature zoo animals. This change may help children increase the range and complexity of their play symbols.60
Social Functions and Consequences of Adult–Child Play

Joint adult–child make-believe serves a wide variety of social purposes. Here is a sampling: 

•Teaching. At times, caregivers use pretending as a pleasurable way to teach children real-world skills. For example, Michael’s mother capitalized on make-believe to encourage her 3-year-old to use the toilet. Reluctant at ﬁrst, Michael became an eager learner after being put in charge of toilet training his teddy bear.61 
•Enlivening daily routines. Often children and their caregivers call on pretend play to relieve the monotony of chores and other repetitive tasks. While 2-year-old Molly folded socks with her mother, she put a pair together, held it up, and exclaimed, “Mommy, I made us something to eat!”62
•Defusing conflict. Occasionally, make-believe can defuse persistent caregiver–child conﬂicts. Concerned about 3-year-old Nancy’s use of a paciﬁer, her mother had been trying to get her to give it up. Nancy resisted. As they played with puppets, Nancy announced, “I want a paciﬁer!” Her mother’s puppet responded, “Little girl. You have only a red dot for a mouth. I don’t think you can ﬁt a paciﬁer in there!”63
•Expressing and regulating emotion. Traci’s exploration, with her mother’s help, of what it might be like to have a mother who got sick and died exempliﬁes how parents and children use make-believe to express and manage intense feelings. In pretend scenarios, Traci acted out feeling ill, feeling better, sadness, happiness, worry, love, and caring.
•Inﬂuencing another’s social behavior. Joint make-believe can be an effective strategy for attaining a social goal. When 2-year-old Molly stood at the top of a slide and asked for help, her mother tried to get her to slide down on her own. Molly refused and stepped into pretend: “A shark . . . There’s a shark in the sand!” Molly’s mother immediately helped her down.64
•Having fun. As illustrations of adult–child make-believe throughout this chapter affirm, most of the time parents and children engage in imaginative play just for fun. In fact, some theorists have argued that the earliest expressions of humor emerge out of fantasy play.65 Consistent with this claim, participating in adult–child make-believe seems to precede children’s ﬁrst verbal jokes. One toddler named Ari, having become an avid make-believer, soon showed a corresponding rise in joking. At 20 months, he touched a picture of a sheep in a book his mother was reading to him, exclaimed “Neigh!” and laughed hysterically. At 21 months, while watching his mother wash dishes, he remarked, “Nutmeg [the family cat] drinks water with spoon” and then interpreted, “Funny thing! Ari tell Mommy joke.”66 As Ari’s humor makes plain, pretending is not just a pleasurable activity in itself but brings pleasure to life in general.

That joint make-believe with adults is such great fun is undoubtedly a major reason that 1- to 3-year-olds are so attracted to it. But why is play with adults, at least initially, more engaging than play with peers? While children’s play skills are still limited, adult scaffolding makes play more interesting, surprising, and absorbing. In several studies, 1- to 3-year-olds engaged in more than twice as much make-believe when their mothers were involved than when they were not. In addition, caregiver support led early make-believe to move toward a more advanced level.67 For example, when mothers actively took part, children produced more complex pretend sequences��not just putting the doll to sleep but brushing her teeth, tucking her into bed, singing a lullaby, and kissing her good night. Furthermore, during parent–child play, make-believe themes are more varied, and parents’ verbal commentary is especially effective in raising both the duration and the complexity of play. 
In line with the “zone,” children for whom make-believe is just emerging act more competently when playing with an adult partner than they otherwise would. In Haight and Miller’s investigation, 1-year-olds whose mothers engaged in a great deal of pretending ranked especially high in peer play at age 4. And children of the most imaginative and enthusiastic parents were among the most highly skilled preschool pretenders.

Vital Features of Adult–Child Play

How should parents, caregivers, and teachers go about engaging young children in make-believe? Effective scaffolding of play is somewhat different from scaffolding of nonplay tasks. In fostering play, adults might have explicit goals, such as teaching culturally valued knowledge and skills and promoting self-regulation and imagination. But directiveness and didactic teaching are seldom, if ever, necessary. 
As play theorist Brian Sutton-Smith pointed out more than a quarter-century ago, make-believe enables children who are still acquiring language to represent their everyday lives and inner thoughts and feelings more completely than is possible through any other symbolic means. This conﬁrms Vygotsky’s statement that “in play, the child always behaves beyond his average age, above his daily behavior.” Look back at the vignettes described in this chapter—of Sophie giving a sleepy teddy bear a paciﬁer, of Alison recalling the train crash in India, of Emily traveling to Sea World, and of Traci role-playing a mother getting sick and dying—and note how difficult it would be for 2- to 4-year-olds to construct such well-articulated ideas only in words or in their drawings. Consequently, adults do not need to “tutor” preschoolers in pretending, as they sometimes do when helping them master puzzles or other similar tasks.
Instead, adult participation in make-believe works best when it responds to, guides, and builds on the child’s behaviors with demonstrations and suggestions. In support of this approach, psychologist Barbara Fiese’s observations of mothers playing with their 15- to 24-month-olds revealed that maternal questions, directions, and intrusions (initiating a new activity unrelated to the child’s current play) led to immature behavior in which toddlers merely mouthed, touched, and looked at toys. Relentlessly barraging children with information that communicates “at” rather than “with” them fails to involve them in dialogue and interferes with optimum development of play. In contrast, turn-taking and joint involvement, in which mothers sustained or expanded on their child’s play themes, evoked high levels of pretending.68 
Maternal interactions that suggest play options related to 1 1/2-year-olds’ ongoing activity—for example, saying “Oh, is the doll trying to swim?” as the child puts a doll into a toy cup—continue to predict extended make-believe sequences and imaginative object substitutions at age 3. In contrast, toddlers whose mothers negate and correct—“No, dolls don’t go in cups, they go in the doll house”—tend to become 3-year-olds who spend much time in simple, immature manipulation of toys.69 
Finally, the shared understanding underlying any type of adult–child communication that creates the “zone” is also essential in make-believe. Sensitive and mutually rewarding interaction between mother and baby in the ﬁrst year of life predicts complexity of mother–child pretending and children’s use of mental-state words during play at age 2.70 Parental behaviors that assist infants in “connecting” socially and becoming effective conversationalists seem to enhance their play competence and ability to talk about others’ thoughts and feelings later on. In sum, quality of adult–child social engagement, both within and outside of make-believe play, has much to do with the potential of such play to lead children’s development forward.
enhancing sociodramatic play with peers

At child care, 4-year-old Sammy joins a group of children in the block area for a space shuttle launch. “That can be our control tower,” he suggests to Vance, pointing to a corner by a bookshelf.
“Wait, I gotta get it ready,” calls out Lynette, who is still arranging the astronauts (two dolls and a bear) inside a circle of large blocks, which represents the rocket. 
“OK, all aboard Discovery!” Sammy broadcasts into a small wooden block, his pretend loudspeaker. After Lynette sets up the astronauts, Sammy announces, “Countdown!” 
“Five, six, two, four one, blastoff!” responds Vance, commander of the control tower. 
Lynette makes one of the dolls push a pretend button and reports, “Brrrm, brrrm, they’re going up!”
Among children who have regular contact with peers, sociodramatic play with agemates increases greatly between ages 3 and 5.71 As this excerpt reveals, by age 4 children can create and coordinate several characters in an elaborate plot and weave together intricate role relationships and story lines—factors that, as we have seen, contribute greatly to their cognitive and social competence.
Pretending with peers draws on the diverse communication skills children develop with adults. A secure infant–parent attachment bond, which grows out of caregiver warmth, responsiveness, and sensitive communication, predicts socially mature peer play in early childhood, including cooperation, empathy, and popularity.72 And as I indicated in Chapter 2, the blend of warmth and expectations for mature behavior that make up authoritative parenting is linked to skilled peer interaction as well. Social play with agemates must be responsive and harmonious to result in pleasurable, satisfying, long-lasting play. 
If sociodramatic play with agemates is to serve as a “zone” for learning, shared understanding, or intersubjectivity, is essential, just as it is in adult– child dialogues. In the shuttle-launch episode, Sammy, Vance, and Lynette reached a high level of intersubjectivity as they worked out a division of labor and responded to one another in a smooth, complementary fashion. Of course, children do argue and disagree. Piaget underscored the role of these conﬂicts in getting children to give up their egocentrism and notice others’ perspectives.73 Yet conﬂict is far less effective in promoting sensitivity to others’ beliefs, thoughts, and feelings than is returning to a state of intersubjectivity—by engaging in cooperative dialogues and resolving differences of opinion.74
Intersubjectivity among preschool play partners increases with age. When psychologist Artin Göncü observed 3- and 4-year-olds engaged in sociodramatic pursuits, the 4-year-olds more often considered their partners’ preferences and built on their partners’ play acts—by asking a partner what he or she would like to do, introducing relevant new elements into the play narrative, compromising in instances of conﬂict, and expressing agreement with the partner’s ideas. 75 These features of play reﬂect children’s developing sensitivity to diverse points of view and their appreciation of the value of a meeting of minds for pleasurable, rewarding play.
Research indicates that parents and teachers rarely mediate preschoolers’ peer relations unless intense disagreements arise that threaten safety or (in the case of teachers) classroom order.76 And when adults do step in, they seldom use interventions that help children regulate their own interaction. Instead, adults often resort to directive strategies, in which they tell children exactly what to say and do and therefore solve the problem for them, as in, “Don’t grab. Ask for a turn!” or “Wait until Sandra is ﬁnished.”77
These techniques are appropriate for children who lack social skills and therefore, at least initially, beneﬁt from clear direction. But adults need to modify these strategies to suit children’s play maturity, providing assistance tailored to the child’s “zone.” Sticking with directive interventions does not prompt children to come up with effective solutions to conﬂict as it arises—strategies that work because they take into account both the child’s and the playmate’s desires.
At times, the adult might model a social skill or give the child examples of strategies, as in, “You could ask Paul, ‘Would you let me try it for a while?’ or you could say, ‘May we share it?’” At other times, the adult might encourage the child to generate possible strategies: “What could you do to get Mary and Andrea to let you play, too?” In each instance, parents and teachers select the level of support that best matches the child’s current social capacities and then pull back as the child acquires new social problem-solving skills. 
Many parents and teachers hesitate to mediate children’s play, perhaps because they believe (incorrectly) that children pick up social skills just by spending time with agemates. Vygotsky’s theory tells us that adults are active agents in children’s social development. If they wait until a child’s negative acts become extreme, then their ﬁrst impulse is to assert high control, and sometimes force. The following three suggestions can help parents and teachers select strategies that foster more mature social behavior:

•Intervene soon enough to prevent peer difficulties from escalating, thereby avoiding highly intrusive intervention tactics.
•Focus on developing the skills of each child, not just on quelling disturbances. Ask yourself, “What have I seen this child do in situations similar to this one? How can I help the child communicate more effectively?”
•Think in terms of the support that is necessary without taking over social responsibilities that children can assume on their own. Ask yourself, “How much of my help does the child require to meet his or her goals in this situation? A general prompt? Some suggested strategies? Or a speciﬁc directive and a demonstration?”78

Compared to sociodramatic play, preschoolers ﬁnd it harder to establish a cooperative, shared framework when working together on realistic projects, such as construction, puzzle, and art activities.79 To collaborate on these tasks, they need much more adult instruction and monitoring than they do in make-believe activities. Here, again, children’s social competence is more advanced in make-believe play than in other situations. The social skills mastered in sociodramatic activities gradually generalize, helping children work toward shared goals in nonplay pursuits.


physical contexts for make-believe play

Adults promote children’s make-believe not just through scaffolding their pretending and social behavior but also through arranging a stimulating, appropriate play environment. The physical context of children’s play is important because it shapes play themes and opportunities to interact with agemates. Consequently, it can have a profound impact on what children learn.

Play Materials

Toys and other play props should capitalize on children’s current make-believe capacities while gently spurring children forward, toward a wider range of themes, roles, and characters and increasingly intricate story lines. As children become conscious of the goals of play and more concerned with rules and rule-following, adults can provide opportunities for game play. Then they can extend these understandings by gradually introducing more complex games.
Martha Bronson’s The Right Stuff for Children Birth to Age 880 is an excellent resource for selecting play materials that support development in early childhood. Although it is written for teachers, preschool and child-care center directors, and elementary school principals, it can also guide parents. Here is an overview of changing needs for make-believe and game materials from toddlerhood into the primary grades.

beginnings: 15 months to 2 years.  Toddlers need a small selection of realistic-looking toys to support their beginning capacity to pretend. These include stuffed animals; soft, cloth-bodied or rubber dolls with simple care accessories; a play telephone and housekeeping items to support role play; large hand puppets for an adult and small hand puppets for the child; and transportation toys, both the large riding type and the smaller, hand-manipulated variety. Already, picture books can inspire make-believe, especially when they depict familiar objects and experiences. 
By the end of this period, as toddlers begin to develop the representational capacities and ﬁne motor skills for setting up scenes themselves, they enjoy small peg people that ﬁt in cars, boats, and other vehicles. Soon after, they are ready for more complex scenes—dollhouse, garage, or barn. And some start to dress up, an activity that can be supported by old clothing of family members.

expanding make-believe skills: 2 to 3 years.  Between ages 2 and 3, fantasy-theme repertoires expand greatly. Children take increasing responsibility for initiating and elaborating make-believe scenarios, ﬁrst with adults and older siblings, then with agemates. During this period, they can make use of a wider array of make-believe materials—diverse dolls, from babies to children their own age and with physical and cultural differences they see in their communities; more feeding and care accessories; vehicles of different types and sizes; play scenes with a larger number of peg people, animals, and inanimate props; large and small blocks for putting together pretend structures; and a more varied array of dress-up clothing.
Around this age, placing pretend materials in sand and water-play areas begins to inspire highly imaginative and extended play. Also, books, videos, and TV programs with simple narratives offer models that young preschoolers can act out and embellish in make-believe. With respect to TV’s potential for inspiring play, programs with slow-paced, nonviolent action and easy-to-follow story lines, such as “Barney and Friends” and “Mr. Rogers’ Neighborhood,” lead to more elaborate make-believe play than do those presenting quick, disconnected bits of information.81

blossoming of sociodramatic play: 3 to 5 years.  The mid- to late-preschool years are a time of burgeoning capacity for sociodramatic play, especially group pretend. Children incorporate more detail into their play themes and beneﬁt from increasingly varied and ﬂexible props—hand and ﬁnger puppets; dolls with articulated limbs that can be manipulated; doll clothing with buttons, zippers, and other fasteners; more housekeeping accessories, such as high chairs, bassinets, and cooking, serving, and washing equipment; and diverse play animals, including ﬁsh, reptiles, dinosaurs, and exotic species.
Older preschoolers can comprehend and recall more complex stories, and they like books and videos about children their own age, animals, and everyday life, such as a visit to a hospital, a ﬁre station, or a factory. They also like ridiculous, funny and dramatic, fantastic tales. Often they memorize those they like best and act them out in make-believe.
The years from 3 to 5 are a time of peak interest in play scenes, such as house, school, airport, farm, and zoo.82 In addition to prepackaged scene sets, children can be provided the raw materials—shoe boxes, pipe cleaners, cardboard cylinders, aluminum foil, and art supplies—to create their own scenes. Whereas realistic toys encourage preschoolers to act out everyday roles, nonspeciﬁc materials often encourage fantastic role play, such as pirates or creatures from outer space. Fantastic roles, in turn, prompt more complex peer interaction, especially statements that plan and comment on the make-believe scenario itself, as in “I’ll be the pirate and you be the prisoner.”83 Since fantastic make-believe does not follow highly familiar scripts, children must devote more energy to working out each episode and explaining what they are doing to their companions.
Literacy objects offer another powerful illustration of how play materials mold make-believe content. Early childhood educators Susan Neuman and Kathy Roskos provided 3- to 5-year-olds in a child-care program with literacy-enriched housekeeping, office, and library areas. For example, the housekeeping area included cookbooks, coupons, recipe cards, grocery packages, and pencils and notepads for list-making. Compared to agemates in a control program without extra literacy props, the children engaged in far more complex and extended literacy-related pretending.84 They more often talked about literacy objects, pretended to read and write as part of role play, and transformed literacy props imaginatively, such as calling a cookbook a “magic, genie book” and a piece of paper “directions for ballet lessons.”
Children at the upper end of this age range start to become interested in games. At ﬁrst, simple games that depend on chance rather than strategy or skill are best—lotto, dominoes, and card games based on matching and visual memory (such as Concentration).
advanced sociodramatic and game play: 6 to 8 years.  In the early school grades, children display an even greater capacity to create replicas of the world around them—skills that teachers may build on in extended projects, such as studying a Native American village or the wildlife of a rain forest. Six- to 8-year-olds continue to like role play, and teachers can use it to foster their academic development. One third-grade teacher invented a magic carpet on which her class “traveled” to different countries, integrating all academic areas into the experience—reading, writing, math, science, and social studies.
Around ages 7 and 8, as children become more conscious of the rules of play, they like to act out scripted puppet shows and plays. As informal make-believe declines, game play strengthens. By the end of this period, children formulate and implement strategies and cooperate more effectively in games. They have also become interested in competition. Hence, they are ready for basic strategy games—checkers, chess, fantasy and adventure games, word games, and team sports, such as T-ball and soccer.

Equipping and Arranging the Play Environment

In addition to the appropriateness of play materials, their quantity and arrangement affect the maturity and diversity of themes in children’s make-believe. These features of the environment also inﬂuence the congeniality of peer interaction. 
With respect to quantity, children’s behavior can tell us whether they have too many or too few toys. An excess of toys overwhelms and overstimulates. The child whose bedroom is piled high with all the latest playthings is likely to cherish and play with few of them. Alternatively, poor-quality child-care centers, widespread in the United States, are often underequipped with play materials. In one such program that I visited, the block-building area had only twenty blocks for sixty 2- to 5-year-olds. Although a stove, table, refrigerator, and crib lined the perimeter of the housekeeping area, there were just three dolls, a handful of dishes, one pan, and six dress-up garments to inspire role play. Without adults and play props to engage them, many younger children wandered aimlessly. And rather than becoming immersed in sociodramatic pursuits, older children quarreled over the few toys available. Research conﬁrms that when playthings are in short supply, preschoolers’ conﬂicts increase.85
The power of play spaces to affect the variety of make-believe themes is dramatically evident in preschoolers’ gender-stereotyped toy choices and pretend themes. By age 2, gender differences in play are evident, and they strengthen over early childhood.86 Parents vary greatly in their gender-role attitudes; the more traditional their beliefs, the more gender-stereotyped their toy purchases and the more stereotyped their children’s play.87 In many classrooms, the arrangement of play areas reinforces these sharp gender distinctions. Separate housekeeping and block-building areas—hubs of preschool pretending—result in girls gathering in housekeeping, where they enact domestic roles, and boys congregating in blocks, where they build intricate structures, play energetically with vehicles, and create fantastic and adventurous scenarios.
When graduate student Cheryl Kinsman and I collaborated with a kindergarten teacher to rearrange these play spaces, striking changes in children’s play occurred. We removed the wall of shelves dividing housekeeping from blocks, joining the two areas into one.88 While the shelves were in place, play was highly gender stereotyped. Children largely interacted with peers of their own gender, especially when girls were in housekeeping and boys in blocks. Also, when boys did enter housekeeping, their play was generally irrelevant to the goals of the setting. In one instance, several boys scurried on all fours around the kitchen table, each pushing a large wooden truck while a traffic director stood on a chair, shouting, “Green light, go! Red light, stop!” 
But once the play areas were joined, boys and girls frequently played together. And girls, especially, engaged in more complex play, integrating materials from both areas into their fantasy themes. Finally, negative interactions between children declined after we removed the divider, perhaps because the more open play space reduced crowding and competition for materials. As these outcomes illustrate, play spaces often promote attitudes and practices of the surrounding culture—in ways not evident to teachers and parents. Our intervention encouraged this teacher to think more carefully about the impact her classroom design had on the quality of children’s play experiences.


the transformation of the child’s play world

The make-believe play and games of early childhood offer an inﬂuential route to acquiring cultural values and the self-regulation children need to act in accord with those values. In the heat of the child’s relentless requests for new toys advertised on TV and in the possession of playmates, parents seldom stop to ask the question: What activities will this toy inspire? What values will the activities teach? What social rules will my child learn to follow? A comparison of the fantasy activities of American children with those of children in other cultures spotlights potent lessons of the play world not given sufficient conscious consideration. 
Children’s make-believe places greater emphasis on imaginativeness and autonomy in Western individualistic nations than in collectivist societies. While American preschoolers often conjure up fantastic roles and vie with peers for the most stimulating and inﬂuential of them, children in Asian cultures devote more hours to play in which they perform actions in unison. For example, in a game called Bhatto Bhatto, East Indian children act out a trip to market requiring intricate touching of one another’s elbows and hands as they pretend to cut and share a tasty vegetable.89 On Children’s Day in the Peoples Republic of China, preschoolers gather on lawns outside their classrooms to perform large-group, highly scripted activities for their families. They sing stories conveying social and moral lessons while dramatizing them with complex hand motions and body postures, in which each child acts identically. 
The personal expressiveness and role negotiation in Western children’s play are well suited for developing innovativeness, self-reliance, and social problem-solving skills—traits important for success in Western school and work worlds. Nevertheless, Western children’s play has been transformed into an ever-enlarging culture of conspicuous consumption encompassing a seemingly endless array of costly, fancy amusements. Parents are quick to feel guilty about depriving children of the latest “educational” playthings or jeopardizing their integration into a peer network in which toys and other possessions are a salient basis for belonging. Yet parents’ gatekeeper role with respect to play is as crucial as it is in the realm of TV. 
An important point to note is that many contemporary toys undermine imagination and self-regulation. Aggressive toys are the most worrisome. Preschoolers who transform a stick or block into a weapon are doing little more than exploring a pervasive aspect of their culture. But equipping children with realistic-looking guns, swords, shields, and other tools of warfare is tantamount to setting up a training ground in aggression. Such toys foster both pretend and real hostility among peers.90 Boys’ penchant for high activity, excitement, and risk taking and their view of weaponry as the ultimate in masculinity attract them to war toys. Furthermore, when boys play with action ﬁgures modeled on violent TV and movie characters, such as Power Rangers, Transformers, and X-Men, their play narrows to mimicking the characters’ televised behavior and is generally aggressive and stereotyped. Video games with violent plots in which children advance by shooting and evading the enemy are yet another fantasy pursuit that largely appeals to boys. A growing number of studies conﬁrm that heavy playing of such games duplicates the effects of violent TV by promoting aggression and desensitizing children to violence.91 Furthermore, video games, even more than TV, are riddled with ethnic and gender stereotypes.92 
In watching what happens once fast-action video games have entered their households, many parents express another concern—that their children will become addicted to these violent amusements. About 5 percent, usually boys, develop into “passionate,” or excessive, players during the elementary school years and desperately need parental intervention.93 Compared to infrequent users, children highly involved in video games spend less time productively, more often watching cartoons and less often reading.94 One parent whose son, Joey, spent his early childhood focused on play with Transformers and his school years immersed in video games complained about the boy’s mediocre grades and lamented, “Nothing seems to interest him.” Joey spent so much time with highly stimulating video games that he came to regard slower-paced pursuits that require greater initiative to reach a goal as dull.
Of course, preschoolers—even those as young as age 3—beneﬁt from experience with computers as long as activities are constructive, adults are available to support them, and children are not diverted from other worthwhile activities. But in homes in which family members are preoccupied with the computer, especially the Internet, time spent communicating and enjoying joint leisure activities declines.95 Therefore, the computer’s value for acquiring new skills and information must be weighed against its potential for detracting from adult–child dialogues and other family activities. 
Children’s opportunities to engage in development-enhancing make-believe and game play are at risk in yet another way. Their lives are often heavily organized and scheduled. Many leave preschool, child-care, and primary-school settings, which may not recognize the value of play, for late-afternoon lessons and adult-organized sports leagues. Contributing to the rise in these adult-directed activities is a decline in neighborhood safety, making parents unwilling to allow their children to gather outside without supervision. In many American communities, child-organized games, handed down from one generation to the next—for example, red rover, statues, blind man’s buff, leapfrog, and endless variants on popular sports—are a thing of the past. 
Some experts worry that adult-structured athletics are robbing children of crucial learning experiences that accrue from spontaneous game play. When adults control children’s games, place heavy pressure on them to win, and assign them to speciﬁc roles so they lose the opportunity to experiment with rules and strategies, then the arguments of critics are valid. Furthermore, children who join teams so early—by ages 4 or 5—that the physical, cognitive, and social skills demanded are well beyond their current capabilities usually lose interest and want to drop out.96 And parents and coaches who criticize rather than encourage and do not let players forget about defeat prompt intense anxiety in some youngsters. Eventually, those children may avoid athletics entirely.97
To safeguard children’s learning and enthusiasm, make-believe play rather than organized sports is best for preschoolers. When children are ready for game play, permitting them to select sports they enjoy, to progress at their own pace, and to participate in decisions about team rules preserves the positive lessons discussed in this chapter—in cooperation, fair play, and willingly following social rules. Finally, practice times must be adjusted to children’s attention spans and need for unstructured time with family and peers. Two practices a week, each no longer than thirty minutes, is sufficient for 6- to 8-year-olds.98
By observing children’s play themes, we can discover much about the values and identities that our culture—by way of homes, child-care centers, schools, and community youth activities—transmits to the next generation. As leaders in children’s development, parents and teachers are in a prime position to design and inﬂuence children’s play worlds in ways that shield them from acquiring materialistic and violent attitudes and behaviors and that accentuate play’s cognitive, emotional, and social beneﬁts. Vygotsky’s theory reminds us that as long as we think carefully about the play materials we offer, the style and content of adult–child play, and the social skills we encourage in children’s peer relations, make-believe play can nurture a wide range of capacities essential for academic, social, and later-life success.









Talia and Jim’s fear of helping 7-year-old Anselmo with his homework, lest they create a dependent, immature child, is a peculiarly Western—and profoundly American—preoccupation. American middle-class parents typically regard young children as dependent beings who must be urged toward independence. In response to researchers’ queries, they frequently say that babies should be trained to be self-reliant from the ﬁrst few months.1 Consequently, they place a high value on children’s learning and doing on their own. Repeatedly relying on others for assistance is construed as weakness, uncertainty, and lack of capacity. In keeping with this view, many American parents worry that if their children seek help, they may become dependent. 
A similar view permeates traditional classrooms, where an individualistic value system prevails. Children must “do their own work.” In the most intensely individualistic of these settings, conferring with your neighbor is worse than dependency; it is cheating, and teachers go so far as to set up barriers between pupils, such as upright books and cardboard screens, to prevent it.
This emphasis on independent accomplishment is not broadly accepted around the world. Indeed, adults in some non-Western cultures regard American parents as rather merciless in pushing their young children toward independence—for example, when they insist that infants sleep alone rather than with their parents, or when they take pleasure in the earliest possible mastery of motor skills, such as crawling and walking, long before the child has acquired the reasoning powers to avoid steep staircases and busy roadways.2
Diverse non-Western peoples and American ethnic minorities stress interdependence—that children must feel intimately linked to others to become competent and self-reliant. Chinese, Japanese, Vietnamese, Guatemalan-Mayan, eastern Kentucky Appalachian, and many other cultural groups regard newborn infants as psychologically separate beings whose most important task is to develop an interdependent relationship with their community—an emotional and social foundation that is crucial for survival and learning.3 Witness the following conclusion by a researcher who compared American with Japanese infant rearing practices: “An American mother–infant relationship consists of two individuals . . . a Japanese mother–infant relationship consists of only one individual, i.e., mother and infant are not divided.”4 These contrasting parenting perspectives reﬂect underlying family and community values. Japanese parents and other ethnic minorities adhere to a collectivist worldview, in which people deﬁne themselves in terms of their relationships with others.
Collectivist values also alter the way teachers and children think about classroom learning. Were you to visit a school on an Israeli kibbutz (cooperative agricultural settlement), you would ﬁnd an explicit emphasis on cooperation and avoidance of pupil comparisons, and a far more positive attitude toward children who seek help than is common in American schools. When asked why children look at each others’ work, kibbutz pupils mention the importance of connecting with others to acquire new skills. They explain, “If your picture looks crooked, you would want to see your friend’s paper to learn how to make it straight,” or “If you aren’t sure what you’re supposed to do, then you should check.” To the same question, American and Israeli urban children typically respond, “I would want to see whose picture was the best,” or “I might be wondering whether she got more right than I did.”5 


from interdependency to autonomy

Vygotsky, who studied and wrote about children’s development in Russia in the early twentieth century, was deeply interested in how interdependency—children’s close ties to their community—can pave the way to competence and autonomy. His sociocultural theory has thoroughly collectivist cultural roots. Vygotsky stressed that children need social interaction and meaningful activities to develop, and he regarded high intrinsic motivation and mature, independent functioning as arising from the support granted by cultural experts as children attempt ever more challenging tasks. The child’s mind, Vygotsky pointed out, “extends beyond the skin” and is inseparably joined with other minds. Out of this interconnection springs mastery, proﬁciency, and self-conﬁdence.6
Nevertheless, a deeply ingrained American belief is that satisfying a young child’s desire for social contact and assistance will be habit forming, leading to a clingy, spoiled youngster. Much evidence veriﬁes that this is not ordinarily so.
Consider the early attachment bond that builds between caregiver and baby during the ﬁrst year of life. By age 6 to 8 months, infants single out their parents and other stable, loving caregivers for expressions of joy and turn to them for comfort when anxious and afraid. An overwhelming consensus of research shows that sensitive caregiving—responding to the baby’s cries for physical care and stimulation promptly, consistently, and appropriately—supports the development of a secure attachment relationship.7 Securely attached infants actively seek contact with and are easily consoled by their familiar, responsive caregiver. Yet such infants are not destined to become immaturely dependent! Rather, by the end of the ﬁrst year, their exploration of the physical world is conﬁdent, persistent, and complex. And they are less likely to cry and more likely to use gestures and words to express their desires than are infants whose parents delayed or failed to respond to their calls for help.8 
Sensitive care builds an interdependent relationship between parent and baby—one in which physical and emotional closeness becomes the context for encouraging more mature behavior. Attachment serves as the springboard for a great many capacities that make their ﬁrst appearance in the second year—self-conﬁdence, compliance and cooperation; awareness of others’ needs and desires, and empathy and sympathy (emotions that enable us to feel for and help others in need).9 But the parent who fails to respond promptly and predictably, intervening only after the baby has become extremely agitated, teaches the infant to rise rapidly to intense distress. The baby has learned that only when he is distraught will the parent reliably come to his aid. As a result, he is more dicult to soothe, to encourage to communicate in ways other than crying, and to guide in acquiring other vital competencies.10
An analogous circumstance exists at older ages, as Anselmo’s interactions with his parents reveal. Jim’s refusal to help Anselmo with his homework, in hopes of instilling independence, is counterproductive. Anselmo’s crying and pleading accelerate, to the point that anxiety prevents him from focusing on the task. Denying Anselmo assistance yields precisely what it was intended to prevent—a dependent, doubting child. As Anselmo’s parents refrain from helping, they fuel his anger and demandingness, and ultimately his sense of helplessness. When Talia ﬁnally responds, she does so out of desperation—to stop Anselmo’s agitated appeals, which are about to escalate beyond control. Consequently, Talia assists inappropriately, by doing the task for him.
Anselmo’s resulting disorganized behavior and dependency prompt additional parental vacillation—sometimes refusals to help, at other times maladaptive helping—along with exasperation and criticism. Talia and Jim can be heard saying impatiently, “You aren’t any good at this!” “Can’t you do anything?”11 Soon a barrier forms between Anselmo and the task he had previously wanted to master, and his motivation wanes.
In classrooms, the same sequence of events prevails. Teachers’ communication plays a vital role in children’s eort and learning. Consider a recent study, in which 1,600 elementary- and middle-school pupils were followed over a 3-year period. Those who viewed their teachers as warm and as providing helpful learning conditions—by making expectations clear and checking that the child understood—worked harder on assignments and participated more in class. Eort and participation, in turn, predicted better academic performance, which sustained the child’s willingness to try hard in the future. In contrast, children who regarded their teachers as unsupportive were more likely to disengage, stop trying, and show declines in achievement. These negative outcomes led children to doubt their own ability, which perpetuated their reduced eort.12
How can adults build interdependent relationships with children that foster the development of culturally meaningful skills and mature, autonomous behavior? To answer this question, Vygotsky proposed a special concept: the zone of proximal development. Keeping it in mind can help parents and teachers interact with children in ways that lead their development forward. 


the zone of proximal development

Take a few moments to list ﬁve or six competencies of a child you know well. If you are a parent, do so for your own child; if you are a teacher, choose a child in your class. Perhaps your list looks much like this one, recorded by Jessica, mother of 3-year-old Tyrone: 

Just learned to cut paper with scissors.
Counts to four.
Looks at picture books and names many pictures.
Remembered two of the animals we saw at the zoo last Sunday. 
Puts together puzzles with eight pieces.
Can sort shapes into categories.
Now indicate whether the skills on your list are ones that the child can do by himself, or whether they are ones that the child displays only when assisted by another person. Jessica, like most parents and teachers completing this exercise, limited her list to Tyrone’s already acquired abilities—ones he can do alone. 
Vygotsky pointed out that we are used to thinking of the child’s capacities in static or “fossilized” terms—as ﬁnished achievements. In doing so, we look toward the past. What we should do, he advised, is to move beyond what children can do by themselves to what they can do with expert assistance and, therefore, have the potential to learn. In this way, we focus on the future—on the cognitive processes of today or tomorrow rather than those of yesterday, which are already mastered.13 
Vygotsky deﬁned the zone of proximal development as the distance between the child’s actual development (the tasks the child can do individually) and the child’s potential development, “determined through problem solving under adult guidance or in collaboration with more capable peers.”14 The “zone,” as I’ll call it from now on, is the dynamic region in which new capacities form as children tackle culturally meaningful tasks with a mentor’s assistance. Had Jessica been thinking about Tyrone’s “zone,” she might have framed the items on her list this way: 

Just learned to cut paper with scissors. If I hold the paper while he cuts and prompt him, he can cut along straight or curved lines. He cut out a square and a circle with help today. I asked him which animals we saw at the zoo, and he mentioned girae and zebra. When I reminded him of the bird and pachyderm houses, he remembered a lot more: the ﬂamingos, parrots, swans, elephants, hippos, and rhinos.

For Vygotsky, a crucial aspect of parenting and the central aim of education is to provide children with experiences in their “zone”—activities that challenge them but that can be accomplished with sensitive adult guidance. Consequently, parents and teachers carry much responsibility for ensuring that children’s learning is maximized—for actively leading them along the developmental pathway. Rather than transmitting ready-made knowledge to a passive child or giving a child tasks for which he or she already has the requisite skills, the adult’s role is to engage in dialogue with the child—by observing, conversing, questioning, assisting, and encouraging. During that dialogue, the adult continually assesses the child’s progress and creates the “zone” by keeping the task “proximal”—slightly above the child’s level of independent functioning. In this way, the adult “rouses to life” those cognitive processes that are just emerging in the child,15 sustaining them socially so they can be reﬁned and internalized as part of the child’s psychological world.


creating the “zone”

What features of adult–child shared activity forge the “zone”? Research documents several communicative ingredients that consistently foster development, in children of diverse ages and across a wide range of tasks.

Shared Understanding

For information, ideas, and skills to move from the social-interactive plane to the internal-thinking plane, the adult and child must strive for a common approach to the situation. They must desire genuine communication and work toward attaining it. 
In sociocultural theory, this joint, mutual focus is called intersubjectivity, or shared understanding.16 As the word suggests, each participant in the dialogue strives to grasp the subjective perspective of the other, an eort that results in a “meeting of minds,” in which the partners’ thoughts make contact, connect, and coincide. Intersubjectivity reaches its pinnacle in a love aair, where shared understanding is readily achieved through a glance, a touch, or a comment. Lovers in close psychological contact grasp one another’s meanings quickly because each is on the lookout for and tries to satisfy the other’s needs.17 The opposite of intersubjectivity is total misunderstanding. In a failed love aair, widely divergent views of the same experiences cause people to say, “You don’t understand me. You’ve become a stranger. We can’t ﬁnd common ground. We’ve grown apart.”
The image of lovers communicating helps us appreciate the circumstances in which intersubjectivity is most likely to occur: in close relationships. Children most often attain it with parents, other family members, teachers, and eventually in friendships with peers. Of course, partners in teaching and learning do not need to attain the intersubjective heights of lovers to accomplish their goals. But a certain degree of intersubjectivity is necessary for any dialogue to be successful, and the love aair analogy reminds us that joint understanding, whether established in face-to-face interaction or as individuals work on a common task, combines both verbal and nonverbal cues. Sensitive emotional messages conveyed through gestures, facial expressions, and tone of voice are basic to it.18 
Intersubjectivity is itself a developmental process. Since infants and young children are still acquiring communication skills, the younger the child, the greater the adult’s responsibility for making mental contact and sustaining the interaction. Nevertheless, children of all ages actively join in, striving for a shared view of the world. Their participation results in gains in thought, language, and social skills. Gradually, the child takes increasing responsibility for attaining intersubjectivity, until both parties make similar contributions to the shared mental state that fuels children’s learning in the “zone.”19 Let’s see how, with adult support, the child’s intersubjective competence increases. 

infancy and toddlerhood.  Some researchers believe that the infant’s capacity to share meaning with others is innate. Others think it is learned—that parents respond to infants’ facial expressions, vocalizations, cries, and body movements as if they have meaning, and out of those responses infants pick up the meanings and expressive rhythms of human signals.20 But all experts agree that subtle, sensitive, and mutually rewarding exchanges between parent and baby serve as the earliest context for intersubjectivity. 
From the start, infants are equipped with capacities that draw adults into social exchanges with them. Newborn babies, for example, can make eye contact, and they prefer to look at people and to listen to human voices—especially their mother’s familiar voice, to which they became accustomed during the months before birth.21 Newborns also have a rudimentary ability to imitate facial expressions, opening their mouths or pursing their lips after an adult does so.22 Their responsiveness encourages parents to look at, talk to, and imitate in return. Between 4 and 6 weeks of age, babies begin to smile at people, an irresistible signal that evokes smiles, cuddles, pats, and friendly, gentle verbalizations from their social world.23 As cooing and babbling appear in the ﬁrst half-year, adults again respond in kind, vocalizing and waiting for the baby to vocalize back.
By age 3 months, a complex communication system is in place in which parent and baby each respond in an appropriate and carefully timed fashion to the other’s cues. As a result, babies experience and practice the give-and-take of human conversation. Disrupt this exchange of signals, and young babies’ striving for connection with others becomes crystal clear. In several studies, researchers had the parent assume either a still-faced, unreactive pose or a depressed emotional state. Infants tried all manner of signals—facial expressions, vocalizations, and body movements—to get their mother or father to respond again. When these eorts failed, they reacted to the parent’s sad, vacant gaze by turning away, frowning, and crying.24 American, Canadian, and Chinese 3- to 6-month-olds respond to a parent’s still face identically, suggesting a common, built-in protest response to caregivers’ lack of engagement.25
When parents are attentive, patient, and interested in the baby’s activities, their social signals sustain the infant’s attention, essential for a shared focus. Around 4 months, infants begin to gaze in the same direction adults are looking, although their initial eorts are imperfect. Parents follow the baby’s line of vision as well, often commenting on what the infant sees. This joint attention to objects and events fosters early language development. Mothers who maintain high levels of it during play have infants who comprehend more language, produce meaningful gestures and words earlier, and show faster vocabulary development between 1 and 2 years of age.26
Between 9 and 15 months, the capacity for intersubjectivity takes a giant leap forward. Toddlers use gestures to share their experiences with others. They touch an object, hold it up, or point to it while looking at another person to make sure he or she notices. Or they try to get another person to do something—to hand them an object or help them perform a task—by reaching, pointing, and making sounds at the same time.27 
Look closely at these behaviors, and notice how toddlers intentionally try to establish common ground with another person by combining their interest in objects and events with communication.28 When adults respond to their reaching and pointing gestures and also label them (“That’s a kitty, isn’t it?” “Oh, you want a cracker!”), toddlers learn that using language can quickly lead to a joint focus and desired results—the pleasurable object or experience the child wanted.29 Soon the child utters words along with gestures, the gestures recede, and language is under way.

early childhood.  Spoken language brings vastly expanded potential for attaining intersubjectivity because it allows much greater clariﬁcation of purpose between participants in a dialogue. When a toddler points and reaches but cannot say what he means, the adult may need to search for the child’s meaning, as this exchange between a mother and her 14-month-old son, Jordan, illustrates: 

Jordan: (Points to one of the objects on the counter)
Mother: “Do you want this?” (Holds up milk container) 
Jordan: (Shakes his head “no”; continues to point; two more tries) 
Mother: “This?” (Picks up sponge) 
Jordan: (Leans back in highchair, puts arms down, tension leaves body)
Mother: (Hands Jordan sponge)30
As language competence increases, shared meaning is established quickly, as when the child says, “Get the sponge, Mom. I need to wipe this up!” Then a joint focus becomes the springboard for achieving greater understanding, with children playing a strong, contributing role. This is evident in the impressive conversational skills of even young preschoolers. By 2 to 3 years, children take turns, make eye contact, and respond in a timely and relevant fashion to their partner’s remarks.31
These capacities improve with conversational experience. Children become better at taking the perspective of their partner, especially a partner who adjusts his or her communication to the child’s level and observes the child closely to assess his or her comprehension. By stretching up to grasp the adult’s viewpoint, children acquire new knowledge, the basis for further growth. And with age, children exert greater eort to understand another person, a capacity ﬁrst cultivated in adult–child interaction and then extended to peers. For example, in the following conversation, notice how 4-year-old Sammy assists his friend, Leah, in attaining intersubjectivity:

(Leah tells the teacher that she caught a fish while on vacation, when Sammy enters the conversation.)
Teacher: Did you have to scale the ﬁsh as well?
Leah: No, we eated them. (The child misunderstands the meaning of the word “scale.”)
Sammy: You need to peel them . . . peel them. (Sammy tries to clarify.)
Teacher: (Confirming Sammy’s meaning) You need to take the scales o, don’t you?
Sammy: You can’t do it with your hands; you need a peeler.
Teacher: Or a knife . . . a really sharp ﬁshing knife.
Leah: They peeled the ﬁshes with a fork. (Leah now shares meaning with the teacher and Sammy.)32

Between 3 and 5 years of age, preschoolers increasingly strive for intersubjectivity in dialogues with peers. They more often arm playmates’ messages, add new information to playmates’ ideas, and make contributions to ongoing play to sustain it further.33 They can also be heard making such statements as, “I think [this way]. What do you think?”—clear evidence of a willingness to share viewpoints, which assists preschoolers greatly when conﬂicts arise that must be resolved for play to continue.34 
As the excerpts we have considered illustrate, participants in a dialogue may not attain intersubjectivity on a ﬁrst try, and interaction between most people, whether adults or children, is not perfectly “in sync.”35 But by the preschool years, children can take a more active role in helping a partner reach a state of shared thinking and in correcting “misses” when they do occur.36
The communicative competence inherent in intersubjectivity blossoms within a zone of proximal development in which parents and other signiﬁcant adults are “stimulating, attentive, conﬁrmatory, interpretive, and highly supportive.”37 Parent–child intersubjectivity makes a vital contribution to the development of attachment, attention, language, and understanding of others’ perspectives. These capacities, in turn, ease the task of establishing an intersubjective connection, and that connection provides the platform for the creation of additional “zones,” enabling children to master complex, culturally adaptive skills. 

Building a Support System for Acquiring New Knowledge and Skills

Intersubjectivity makes possible a second essential ingredient for creating the “zone”: a support system that oers new ways of thinking about a situation. The quality of adult support varies with the type of joint activity. As we will see, a helpful parent or teacher interacts dierently when assisting the child with tasks having clear learning goals, such as working a puzzle or mastering a homework assignment; when engaging the child in an open-ended conversation; and when enlisting the child in duties and routines of everyday living. But regardless of the activity, the adult adapts his or her support so the child can make use of it. As the child gains competence, adult support changes accordingly, granting the child a larger role. 

creating a scaffold.  The metaphor of a scaffold has been used to describe eective adult support as children work on tasks that teach culturally valued concepts and skills.38 The learning goal might be built into the task materials, as when a child turns a crank to make a jack-in-the-box pop out, puts together a puzzle, or builds a structure out of blocks. Alternatively, the parent or teacher might specify the goal, as in matching shapes and colors, solving an arithmetic problem, or batting a ball. 
In scaolding, the child is viewed as a building—actively under construction. The adult provides a dynamic, ﬂexible scaold—or framework—that assists the child in mastering new competencies. To promote development, the adult varies his or her assistance to ﬁt the child’s changing level of performance, with the goal of keeping the child in the “zone.” This is usually done in two ways: (1) by adjusting the task so the demands on the child at any given moment are appropriately challenging, and (2) tailoring the degree of adult intervention to the child’s current learning needs.39 
When a task is very new, the child may not yet be aware of its goal and need to be shown what to do, through demonstration. Consider, for example, a 9-month-old infant who has never before seen a jack-in-the-box. At ﬁrst, the adult tries to capture the child’s attention by working the toy and, as the clown emerges, exclaiming, “Pop! What happened?” Gradually, the adult redirects interaction toward how to use the jack-in-the-box. When the infant reaches for the toy, the adult guides the child’s hand in turning the crank and pushing the clown down in the box. As motor, cognitive, and language skills improve in the second year, the toddler intentionally tries to turn the crank, looking at the adult or otherwise beckoning for assistance. The child’s greater knowledge and communicative competence permit the adult to reduce her physical directiveness. Now the adult can help from a distance by using verbal instructions (“Turn, just a little more!”) and gestures, such as a rotating hand resembling a turning motion, while the toddler tries to make the toy work.40 
As children move into the preschool years, scaolding becomes increasingly verbal and takes on the advantages of language—more ready attainment of intersubjectivity; ﬂexible, ecient representation of meanings; and a powerful tool through which minds meet and the child adopts meanings into mental life. To illustrate, let’s listen in as a father assists his 5-year-old daughter, Sydney, in putting together a dicult puzzle:

Sydney: I can’t get this one in. (Tries to insert a piece in the wrong place)
Father: Which piece might go down here? (Points to the bottom of the puzzle)
Sydney: His shoes. (Looks for a piece resembling the clown’s shoes but tries the wrong one)
Father: Well, ﬁnd a piece that looks like this shape and matches this color. (Points again to the bottom of the puzzle)
Sydney: The brown one. (Tries it and it fits; then attempts another piece and looks at her father)
Father: There you have it! Now try turning that piece just a little. (Gestures to show her)
Sydney: There! (Puts in several more pieces while commenting to herself, “Now a green piece to match,” “Turn it [meaning the puzzle piece],” as the adult watches)
Father: Now, Sydney, watch. Suppose I put this piece here. Will that work? (Places a blue piece next to a second blue piece, but the space is too small and the wrong shape)
Sydney: You can’t do it that way. The piece is too big.
Father: What should I do?
Sydney: (Places the piece in the correct space, using both color and shape as a guide.)

Sydney and her father’s interaction contains all the components and goals of eective scaolding:

1. Joint Problem Solving, Aimed at Keeping the Child in the “Zone.” Sydney and her father collaborate in overcoming obstacles that Sydney encounters. In doing so, father and daughter jointly work toward successful puzzle solution. 
Sydney’s father keeps the task within Sydney’s “zone” by temporarily reducing the diculty of the puzzle. He does so by breaking the task into smaller units, focusing Sydney’s attention on the lower section—the part with the largest and most easily matched pieces. Then he assists with a general prompt, “Which piece might go down here?” 
When Sydney’s father observes that this suggestion is not sucient for her to succeed, he oers additional support, “Find a piece that looks like this shape and matches this color” and “Turn it.” His statements contain strategies (attending to color and shape, patiently adjusting pieces so they ﬁt) that Sydney can use in future attempts. When Sydney experiments with the color-matching strategy and succeeds in placing the brown piece, she internalizes the technique. She applies it in subsequent eorts, regulating her behavior with self-directed language resembling her father’s communication during joint problem solving. Consequently, Sydney begins to move toward independent solving of the puzzle.
Notice how, in scaolding Sydney’s puzzle solving, her father adapts the instruction he oers to Sydney’s momentary competence. When Sydney has diculty, he fortiﬁes the scaold, providing increased direction. Once Sydney starts to take over strategies generated during joint problem solving, her father pulls back, reducing the assistance provided.
Scaolding provides parents and teachers with a sensible solution to the often-raised dilemma: Is it better to be directive or nondirective when helping children learn? As the scaolding concept shows, this question has no pat answer. Rather, the intensity of adult support depends on where the task falls within the child’s “zone.” When a task lies at the outer edge of the child’s current capabilities, more direct guidance is necessary to bring it within range of mastery. As the child’s understanding and performance improve, less intervention is required. 
How much assistance a child needs depends not just on cognitive maturity but also on other child characteristics. A temperamentally distractible child, an emotionally reactive child, or a fearful, inhibited child requires an especially sturdy scaold—extra support and, at times, considerable adult perseverance to sustain a joint focus and keep the child engaged. Children who are good listeners, persistent in the face of diculty, socially skilled, and therefore adept at attaining intersubjectivity need less adult vigilance and direction. At the same time, eective scaolding can improve a dicult child’s behavior, since it oers the child knowledge and procedures for solving problems, the security of adult support as long as it is needed, and the satisfaction of overcoming obstacles and mastering culturally valued skills. 
2. Self-regulation. An important goal of scaolding is to promote self-regulation—the capacity to use thought to guide behavior. The self-regulated child follows social rules; makes deliberate, well-reasoned choices and decisions; and takes responsibility for his or her own learning and behavior. Although self-regulation improves gradually throughout childhood and adolescence, early childhood is a crucial period for its development—a time when children learn to overcome impulses by thinking before they act.41 Indeed, self-regulation is so important for children’s cognitive and social development that we will return to it repeatedly in later chapters when we consider how other experiences—children’s self-directed language, make-believe play, and learning in school—contribute to it. 
How does scaolding nurture a self-regulated child? It does so in two interrelated ways: (1) by providing children with strategies for working toward goals, and (2) by relinquishing adult control and assistance as soon as the child can work independently.42 
In scaolding, the adult encourages the child to grapple with questions and problems and, thereby, to contribute signiﬁcantly to the dialogue. In this way, the adult evokes from the child his or her current knowledge and, on that basis, can scaold more eectively. The parent or teacher intervenes only when the child is truly stuck, granting the child as much opportunity to master his or her own behavior as possible. Unless it is clear that the task is so new and obscure to the child that a demonstration would be helpful, the adult refrains from giving immediate answers to momentary diculties. As our consideration of Anselmo and his parents revealed, doing the task for the child severely reduces learning and self-regulation.43
When adults ask children questions and make suggestions that permit them to participate in the discovery of solutions, then transfer of useful strategies to the child is maximized. By introducing language as a mediator of the child’s activity, the adult’s questions and prompts prevent the child from responding impulsively. They encourage the child to step back from the immediate situation and consider alternatives—in essence, to think. 
Look at Sydney and her father’s dialogue once again. When he asks, “Which piece might go down here?” he evokes Sydney’s present strategic thinking, ﬁnding that it is still tied to immediate objects in the situation. Sydney looks for the clown’s shoes but fails to ﬁnd them. Then her father introduces a special form of strategic thinking called distancing. This method helps children move beyond concrete objects by looking for higher-order relationships—in Sydney’s case, categorizing puzzle pieces by color and shape. Once Sydney succeeds in using color, her father encourages further distancing from the most obvious features of the clown image.44 He places a piece incorrectly (by matching only on color) and queries, “Will that work?” In doing so, he helps Sydney analyze an error, consider how to correct it (by matching on both color and shape), and try out her conjecture. Sydney gains practice in applying strategies ﬂexibly—in generating ideas to overcome obstacles. As a result, she acquires reasoning skills and can take initiative when faced with future problems.
3. Warmth, Responsiveness, and Encouragement. To work well, the emotional tone of scaolding must be warm, sympathetic, and responsive. Children who experience warm adult relationships want to preserve that spirit of aection and cooperation—by joining in dialogues with adult partners and acquiring culturally valued skills.45
The standards for maturity parents set for young children vary widely, in ways that reﬂect family and cultural values. For example, Chinese-American immigrant parents report spending nearly ten times as much time as do Caucasian-American parents scaolding their school-age children’s mastery of reading, math, music, and drawing skills46—teaching that is undoubtedly a strong contributor to Chinese children’s high achievement in both academic and artistic endeavors. Inﬂuenced by the Confucian belief in strict discipline to nurture socially desirable behavior, many Chinese and other Asian parents expect a great deal of their children and structure their time extensively.47 But research indicates that their demands are imbued with warmth and caring—with deep concern for and involvement in their children’s lives. 
In a study of parenting in 180 societies, anthropologists Ronald and Evelyn Rohner found that warmth combined with at least moderate expectations for mature behavior and accomplishment is the most common child-rearing style around the world.48 Why do so many cultures mingle concern and aection with guidance and control—a blend known as authoritative parenting in the child-rearing literature? Certainly because they sense its eectiveness, borne out by decades of research. 
Authoritative parenting, whether assessed through direct observation or older children’s ratings of their parents’ communication, is linked to many aspects of competence. In early childhood, it predicts positive mood, self-conﬁdence and independence in mastery of new tasks, cooperativeness, and resistance to engaging in disruptive behavior.49 And in middle childhood, adolescence, and young adulthood, it is related to high self-esteem, social and moral maturity, academic achievement, and educational attainment.50
A major contributor to these favorable outcomes is the fuel that warmth grants to adult expectations. Warm, caring adults oer explanations and justiﬁcations for their demands. In doing so, they invite children to judge the appropriateness of their requirements. When children view demands as fair and reasonable, they are far more likely to heed and internalize them. A warm, involved adult is also more likely to be an eective reinforcing agent, praising children for striving to meet high standards. And when children stray from goals that a parent or teacher regards as important and it is necessary to be ﬁrm and disapproving, a warm adult has a much greater chance of changing the child’s behavior than does an adult who has been indierent or negative. Children of involved, caring parents ﬁnd the interruption in parental aection that accompanies a reprimand to be especially unpleasant. They want to regain their parents’ warmth and approval as quickly as possible.
In sum, scaolding is a warm, sympathetic collaboration between a teacher and a learner on a challenging, goal-directed task that the adult helps bring within the child’s “zone.” Observations of adult–child pairs reveal that the diverse ingredients of scaolding—matching the adult’s assistance to the child’s changing needs, suggesting eective strategies, posing questions that encourage children to think about higher-order relationships, and interacting warmly and praising children for competent performance—consistently relate to children’s task engagement and learning.51

the power of conversation.  The instructional mode of communication inherent in scaolding is well suited for tasks with clearly deﬁned goals. Conversations, in which adult and child reﬂect on everyday events, are more free-ranging. They can dwell on virtually any aspect of experience—of living and working together. This makes them an especially powerful tool for assisting children in building an internal mental life infused with a cultural worldview.
When people converse with one another, they engage in a form of dialogue called narrative—a storylike mode of communicating, composed of a sequence of events with people as main characters. In the narrative, which may be real or imaginary, characters’ roles and mental states—feelings, intentions, beliefs, opinions, and knowledge—are revealed.52 
To illustrate, suppose someone asked you to “tell the story of your life.” In forming a spontaneous autobiography, people link together smaller stories about incidents and occasions, with the self at their center and other inﬂuential people in supporting roles. The narrator arranges the stories sequentially, to conform to a culturally accepted organization of time. And he or she not only recounts, but justifies the stories—that is, makes them comprehensible by explaining why they happened as they did.53 
The mini-stories in our life narratives focus on exceptional experiences—events that stand out against the backdrop of ordinariness in our daily lives.54 For example, a move to a new neighborhood, a ﬁrst date, a high school graduation, an important job interview, a wedding day, the birth of a baby, and special achievements or failings are likely to be included. The various entries are derived from our social interactions, at the time the events occurred and thereafter. When others join with us in celebration, approve or disapprove of our actions, or convey information or opinion that changes our outlook, they bestow special meaning on the events. And so we include those events in our autobiographies, elevating them to lifelong signiﬁcance. 
In everyday conversation, the events discussed resemble the mini-stories of our spontaneous autobiographies. For example, in recent narrative exchanges, I talked with a friend about her daughter’s sudden breakup with a ﬁancé; with my husband about a controversial play we had seen; and with one of my students about how she might handle a troublesome roommate. Each narrative focused on a relatively exceptional personal experience. And in each, my partners and I addressed the legitimacy of characters’ intentions, weighing personal desire against socially acceptable behavior. 
For example, referring to her daughter’s breakup, my friend complained, “It wasn’t that she did it but how she did it. She shouldn’t have promised she’d join him in Chicago and then reneged. His mother called a few days later and said how betrayed the young man feels. You can���t back out like that, with no warning, no explanation, after he had already rented the apartment.” 
“The whole family knew the relationship had problems,” I countered. “She’s paying him for the apartment. Doesn’t that lighten her obligation?” 
During the conversation, my friend and I exchanged a wealth of cultural meanings about how relationships should be and about the maturity and morality of the daughter’s behavior. The telling of the narrative also invited reconstruction of what might have occurred between the daughter and her ﬁancé, thereby placing the event in a wider context of possibilities. In the process, the dialogue highlighted characters’ internal states—the daughter’s motivations, her boyfriend’s feelings, and my friend’s struggle to make sense of the breakup.
Readiness for Narrative. Our narrative dialogues with young children have the same features as do our narratives with adults, only in simpliﬁed form. In these conversations, we arrange events in logical, sequential order, and we focus on explaining unusual, hard-to-interpret occurrences, often by dwelling on characters’ intentions and perspectives.
Even before they begin to talk, children display a readiness to participate in narrative.55 After an adult describes and demonstrates some activity (for example, putting a teddy bear to bed), 1-year-olds who as yet have little language can easily reproduce the main steps in correct sequence with toys.56 When toddlers begin to speak, their main interest is in talking about what people do and the consequences of their behavior. Listen to the two-word utterances that appear between 15 and 24 months of age, and you will ﬁnd many expressions like these: “Tommy hit”; “Get cookie”; “Mommy truck” (meaning “Mommy push the truck”); “Daddy outside”; and “My dolly.”57 At the end of the second year, children begin to label their own and others’ internal states with words, such as “want,” “happy,” “mad,” “think,” and “pretend.”58 These assertions about human action, desire, emotion, and perspective are the stu of which narratives are made.
Early on, children are sensitive to yet another feature of narrative. At birth, they are captivated by unusual events, perking up their eyes and ears when something new and dierent happens. In keeping with this innate bias, the ﬁrst narratives children produce focus on making sense of the atypical. “Look, the sun is sleepy, going to bed,” said 2 1/2-year-old David while watching the sun disappear below the horizon at the end of a day at the beach. At the sight of a woman with her leg in a cast, 3-year-old Rachel remarked, “Mommy, that lady got a big cut. The doctor sewed up her leg.” (Rachel’s brother had cut his leg a few days earlier and returned from the doctor with stitches and a bandage.)
An early armament of narrative tools enables children to quickly and easily comprehend and contribute to the narratives of expert members of their culture.59 In families in which parents and children spend much time together, the ﬂow of stories recreating personal experiences is abundant.60 Through them, adults help children construct increasingly elaborate images of themselves and teach them culturally accepted ways of organizing and interpreting their experiences. As a byproduct of participation, children gain a rich understanding of their own and others’ mental lives—powerful tools in predicting and explaining human behavior and, therefore, in getting along with others. And in enabling children to practice and perfect narrative skills, adult–child conversation provides crucial preparation for literacy. Let’s take a closer look at these diverse beneﬁts of narrative conversation.
Forming an Autobiographical Self. Consider, once again, the narrative task posed earlier, to relate “the story of your life.” Think back to the earliest event you can remember. At what age did it occur?
For the large majority of people, memory for autobiographical events begins around age 3.61 Practically none of us can retrieve happenings at younger ages—a phenomenon called infantile amnesia. What causes this early memory blackout, and how is it that after age 3, certain events dierentiate themselves from a multitude of everyday experiences so they stand out for a lifetime?
Some researchers conjecture that growth of the cerebral cortex and other brain structures is necessary before children can store experiences in ways that permit them to be retrieved many years later.62 Similarly, several psychological explanations focus on changes in the nature of memory during the preschool years—from an unconscious, automatic, and nonverbal system to one that is conscious, deliberate, and verbal.63 Perhaps the second system cannot access events stored by the ﬁrst, making the earliest events of our lives forever irretrievable.
Yet the idea of vastly dierent approaches to remembering at young and older ages has been questioned. Children 1 1/2 to 3 years old can describe their memories verbally.64 And sometimes they even recall events that happened to them as preverbal infants! For example, while walking past a distinctive house with a fenced-in front yard, 22-month-old Lisa said to her mother, “Scary doggy!” Nine months earlier (before the child could talk), the family had taken the same walk. On that occasion, Lisa had seen a ferocious dog barking behind the chain-linked fence. Over time, neither the family walk nor the scary dog will be part of Lisa’s personally relevant memory. Yet the train trip across the country she will take at age 3 1/2 and her ﬁrst day of kindergarten at age 5 may still be memorable when she is 80.
A growing number of researchers believe that rather than a radical change in the way experience is coded into memory, two other milestones lead infantile amnesia to give way to memory for personally signiﬁcant experiences: 

1.A Psychological Self. To build an autobiographical memory, children must have a well-formed sense of self—as a person who, despite changes in appearance (a new haircut, becoming taller and more mature looking), remains the same on the inside over time. Once constructed, this persisting psychological self serves as an anchor for unique experiences, which are retained easily as long as they become personally meaningful.65 A psychological self is not ﬁrmly in place until age 3 or 4. 
2.An Autobiographical Narrative. Besides a ﬁrm sense of an inner self, autobiographical memory depends on organizing personal experiences in narrative form so they become part of a life story. How do children learn to structure memories as narratives during the preschool years? Much evidence indicates that they acquire this skill through conversations with adults.

As early as 1 1/2 to 2 years, children begin to talk about the past, guided by adults who prompt them and expand on their fragmented recollections. At ﬁrst, parents provide most of the content and structure of the story. But very soon, children’s contribution increases, as can be seen in this short excerpt of a mother talking with her nearly 3-year-old daughter about a recent Halloween celebration:

Child: Once on Halloween the kids was over and I had a princess dress on me.
Mother: You had a princess dress on? Did you get any candy? Did you go door to door? What happened?
Child: We went treating.
Mother: You went treating! And who took you?
Child: Andrea’s mother took us. And my mom . . . and we brought a pumpkin too.
Mother: What did you do with the pumpkin?
Child: We lighted it.
Mother: What did it look like? Was it scary?
Child: Uh-huh. Dad made cuts in it with a razor. He made a face too. That was funny.66

Notice how the mother provides details and, by asking “who” and “what,” encourages her young daughter to enrich the narrative. As children participate in these dialogues, they adopt the narrative thinking generated in them and retain many details about past events, made personally meaningful in the context of parent–child conversation.
Observations of parent–child interaction reveal that parents vary in how they engage children in narrative talk. Some, like the mother in the conversation just given, use an elaborative style, in which they pose many, varied questions; add information by building on children’s statements; and volunteer their own evaluations of events, as in “Was it scary?” Other parents use a repetitive style. Appearing rushed, impatient, and inattentive to the child’s comments, they contribute little information and ask the same short-answer questions over and over: “Do you remember Halloween?” “What costume did you wear?” “Do you remember what you wore?” The elaborative style is considerably better at fostering preschoolers’ narrative skill, since 2- and 3-year-olds who experience it produce more coherent and detailed personal stories when followed up 1 to 2 years later.67
Children’s conversations with elaborative-style parents increase in complexity as language development proceeds, creating a zone of proximal development in which narrative competence expands. Between 3 and 6 years, children’s descriptions of special, one-time events—a family excursion, a grandparent’s visit, a ﬁrst trip to the dentist—become better organized and more elaborate. Spurred by adult prompting, older children also add more background information—“when” and “where” the event took place and “who” was present. By including these details, children place personally signiﬁcant experiences in the larger context of their lives. 
Finally, between 4 and 6 years of age, evaluative statements, which help to clarify “why” an event is personally meaningful, become common. Older children more often embellish their descriptions with modiﬁers, such as “My mask was ugly” or “The kite ﬂew high.” At times, they even add drama by intensifying these expressions, as in “The kite ﬂew very, very high” and “Grandma ate a huge bowl of oatmeal for breakfast!” And like the autobiographical and everyday narratives that adults generate, children’s narratives increasingly focus on people’s internal states—their desires, feelings, and beliefs: “She wanted it so much” or “I felt bad.“ 68 Furthermore, the richness of 6-year-olds’ evaluative remarks can be predicted from their mother’s evaluative statements in an adult–child conversation 3 years earlier69—a ﬁnding that underscores, once again, parents’ vital role in creating a “zone” for narrative development. 
In sum, as children share memories, mark them as personally meaningful, and begin to create their life story, the people to whom they are close become vigorous contributors to their self-constructions. From the beginning, the child’s sense of self is not isolated, encapsulated inside the head. Rather, it is shaped by and situated in children’s everyday social experiences—in the dialogues with parents, teachers, and other cultural experts within families, preschools, schools, and communities.
Acquiring Cultural Beliefs and Values. Through dialogues with adults, the child derives not just a self, but a self imbued with culture. The stories, both real and ﬁctional, that parents and teachers relate to or jointly construct with young children are laced with cultural beliefs and values. They have profound socializing implications.70
At times, adults tell children stories that carry important self-relevant lessons. For example, recently I listened in as a father and his 5-year-old son waited in the foyer of a synagogue for a Jewish New Year service to begin. The father wove an animated tale about a boy named Chaim, who had great diculty remaining quiet during the holiday service. Little Chaim had a brand new whistle in his back pocket, and he badly wanted to play it. With great eort, he resisted, turning and twisting in his seat until, ﬁnally, when the Rabbi blew the shofar (ceremonial ram’s horn), Chaim could bear it no longer! A moment later, the clear, high-pitched sound of the whistle could be heard over the Rabbi’s ﬁnal shofar blast. Everyone in the sanctuary turned toward Chaim, who cringed with embarrassment. But much to Chaim’s surprise, all the congregants cheered and thanked him for making the shofar ritual more beautiful than ever. And Chaim’s father praised him for sitting quietly, almost to the end of the service.
Five-year-old Mark listened to his father’s story with rapt attention, asking questions and adding personal comments: “Where did Chaim sit?” “Did he (like Mark) bring a book to read?” “Was Chaim allowed to get up and go to the bathroom?” “Was the Rabbi angry at Chaim?” The story disclosed that adults realize a long service is hard for a small boy to sit through, but exercising self-restraint and participating in communal rituals bring praise and acceptance from the community. The analogies Mark drew between his own life and Chaim’s suggest that he had (as his father intended) experienced the story from a personal vantage point, identifying with its events and applying them to himself.71 
Systematic research reveals both cultural similarities and dierences in adult–child narratives. In an intensive observational study of daily storytelling in two communities—six middle-class Chinese families in Taipei, Taiwan, and six middle-class American families in an Irish-Catholic neighborhood in Chicago—Peggy Miller and her colleagues72 found that preschoolers and their family members routinely narrated past experiences. Most often, they created joint accounts of pleasurable holidays and family excursions—birthday parties, the fair, the zoo, and McDonald’s for the American children; the night market, the zoo, and riding on trains and horses for the Chinese children. Both groups also talked about times the children were ill, sad, or frightened. 
In a smaller set of narratives, the topic addressed—either directly to the child or to someone else while the child listened—was the child’s misbehavior. These stories, more than any others, seemed deliberately aimed at teaching social and moral standards. Chinese parents, however, were far more likely to initiate these tales of misdeeds than were Americans. In fact, 35 percent of Chinese adults’ narratives with or in the presence of 2 1/2-year-old children focused on past transgressions, whereas only 7 percent of American narratives did.73
Furthermore, interpretations of children’s misbehavior diered between the two cultures. Consistent with the Confucian parental obligation, “The deeper the love, the greater the correction,” Chinese mothers’ “misdeed” stories were much longer than those of the American mothers—in fact, the most lengthy and elaborate of all Chinese narrations. Sometimes they occurred right after the child committed a transgression; at other times, they reminded the child of earlier improper behavior. Chinese mothers typically corrected the child repeatedly: “What did you say?” “So, what would you say?” “Then how would Mom have reacted?” And in line with the Confucian reliance on formal stories with moral lessons, these informal narratives often ended with direct teaching of how to act: “Saying dirty words is not good,” and (after the child agreed) an expression of aection—a hug, a tender touch.
In instances in which American stories referred to young children’s misbehavior, mothers frequently deemphasized these acts, attributing them to the child’s spunk and assertiveness. This does not mean that American parents seldom instruct their children in social and moral rules. They often do so, largely through guiding remarks that accompany children’s ongoing actions, as in “Don’t grab. Share the toy.” “Hold hands when crossing the street.” “You hurt Johnny. Say you’re sorry.”
As Miller notes, the way social and moral lessons are integrated into narratives aects children’s frameworks for judging themselves and interpreting their social experiences. Through everyday stories, the Chinese adults personalized moral lessons and stressed obligations to parents and other authority ﬁgures. They also reminded children of the impact of their transgressions on others—an element dramatically illustrated in one mother’s recounting of her 2 1/2-year-old’s disruption of his older sister’s music lesson: “Ai, you made Mama lose face. . . . I wanted to dig my head into the ground. Right? [Child smiles, shakes head]”74 American narratives rarely dwelt on misdeeds and, at times, even recast children’s oenses as strengths—as indicative of quick thinking and an active, spirited disposition. 
Miller describes the generally high self-control the Chinese children in these families displayed—listening attentively to elders and complying without reminders. For example, even at age 2, they waited patiently to open a small gift until a guest had departed—proper etiquette in Chinese culture. Of course, this does not mean that Americans ought to change their child-oriented narratives to be just like those of the Chinese. The socializing impact of a particular narrative style is strengthened by its consistency with a family’s and community’s way of life. Also, the narrative variations we have considered tap only a small slice of cultural diversity in adult–child storytelling. The most important lesson we can take from Miller’s provocative ﬁndings is that when parents and teachers take time to construct narratives with and about the young child, they create a “zone” that spurs children to weave moral and social rules into their self-deﬁnitions and to behave accordingly.
Understanding People as Mental Beings. We have seen that talking about mental states is a major focus of narrative conversation. In narrative, we express the “folk psychology” of our culture—our deeply ingrained assumptions about human desires, emotions, and beliefs, and our judgments of certain ones as more acceptable than others. Indeed, violations of our folk psychology are a major impetus for engaging in narrative.75 Through conversing with others, we try to make puzzling events and behaviors understandable.
Because people’s desires, feelings, and beliefs often dier, conversations are full of social negotiations—attempts to reconcile dierent versions of reality. Recall how I suggested to my distraught friend that her daughter’s breakup with her ﬁancé might have been defensible, given problems in the relationship and the daughter’s willingness to compensate the young man for his monetary losses. Similarly, a 2-year-old who says that the sun disappearing below the horizon is “sleepy” is likely to receive an alternative explanation. And as parents recount the misdeeds of their children, the children gain access to others’ evaluations of their egocentric, inconsiderate acts. 
According to psychologist Jerome Bruner, learning to negotiate diering viewpoints through narrative is a crowning achievement of human development.76 Conversations about personal experiences are prime sources of social stability. When out-of-the-ordinary events occur and we experience clashing views, we often look for a good listener—a friend or a loved one we can talk to. By collaborating with this partner in conversation, we talk out our perspective, seek our partner’s view, search for meaning in seemingly chaotic events, and try to reconstruct a comprehensible world. In these conversations, we may not agree with our partner’s point of view, but we usually acknowledge that we comprehend and appreciate it—and our partner generally does the same. 
By joining in conversation and listening to the narrative dialogues of others, children develop an understanding of their own and others’ rich mental lives. Children with a good grasp of mental life can detect the likely inner causes of another person’s behavior and use that information to anticipate what that person might do next. Such children are also more adept at empathizing—reading others’ emotions and vicariously experiencing them—a response that increases the chances that they will react with sympathetic concern and help others in need.77 As early as 3 to 5 years of age, emotion knowledge—awareness of the circumstances that prompt dierent emotional reactions and the social consequences of expressing one’s feelings—is related to friendly considerate behavior, willingness to make amends after harming another, and peer acceptance.78
Research veriﬁes that the more families talk about inner states, the greater children’s knowledge of them. For example, mothers who frequently label and explain emotions have preschoolers who use more emotion words in conversation. Maternal prompting of emotional thoughts (“What makes him afraid?”) is a good predictor of 2-year-olds’ emotion language. Later in the preschool years, explanations (“He’s sad because his dog ran away”) are more predictive.79 Consistent with Vygotsky’s concept of the “zone,” sensitive parents adjust the way they talk about emotions to ﬁt children’s increasing competence. And in line with what we have said about narrative as a vital context for negotiating diering viewpoints, discussions in which family members disagree about feelings seem particularly helpful in prompting children to step back from the experience of emotion and reﬂect on its causes and consequences.80
Attaining a Subtle Grasp of Mental Life. Around age 3 to 4, children’s understanding of mental life undergoes a profound transformation. Older preschoolers realize that people’s beliefs, not just their desires, aect their behavior. This advance is apparent in children’s awareness that people can hold false beliefs. 81 To test for a child’s grasp of false belief, researchers present situations like this one: Show a child two small closed boxes, one a familiar Band-Aid box and the other a plain, unmarked box. Then say, “Pick the box that you think has the Band-Aids in it.” Almost always, children pick the marked container. Next, ask the child to look inside both boxes; when she does, contrary to her own belief, she will ﬁnd that the marked one is empty and the unmarked one contains the Band-Aids. Finally, introduce the child to a hand puppet and explain, “Here’s Pam. She has a cut, see? Where do you think she’ll look for Band-Aids? Why would she look in there?” Only a handful of 3-year-olds but many 4-year-olds can explain why Pam would look in the marked box: “Because she thinks there’s Band-Aids in it, but there aren’t any.”82
Mastery of false belief shows that children regard beliefs as interpretations, not just reﬂections, of reality. It marks the transition toward a more complex, active view of the mind, which will ﬂourish over the next few years—the realization that people can engage in a great many inner activities, from concentrating, remembering, and understanding to guessing, comparing, and inferring.83 Before age 4, most children assume that physical experience determines mental experience—that if Band-Aids are in the unmarked box, everyone will just know where they are. But preschoolers who grasp false belief recognize that people can, on the basis of prior knowledge and experience, interpret the same event dierently—an understanding that is invaluable for social life. Children who are good at detecting others’ points of view are better at thinking of eective ways to handle dicult social situations.84 Rather than just asserting their own desires, they try friendly persuasion. Or they suggest that a conﬂict be solved by creating new, mutual goals.
Like emotion knowledge, preschoolers’ grasp of false belief grows out of conversations that touch on the mental lives of others. Without those conversations, this level of insight is slow to develop. The Junín Quechua language of the Peruvian highlands is unique in lacking words that describe mental states, such as “think” and “believe,” so Quechua adults refer to mentality indirectly. For example, they use the phrase, “What would he say?” in place of, “What would he think?” Junín Quechua children have diculty with false-belief tasks for years after children in industrialized nations have mastered them.85 Furthermore, clear evidence exists that preschoolers who frequently interact with more competent cultural members—parents, extended family members, neighbors, older siblings, and older peers—are advanced in false-belief reasoning.86 These social encounters oer children many opportunities to hear people refer to their own mental states and those of others and, therefore, to observe dierent points of view. When 3- and 4-year-olds use their newfound capacity to talk about mental states during play with friends, their understanding of false belief improves further.87 
Finally, as children participate in narratives and listen to those of others, they acquire culturally accepted ways for negotiating clashing viewpoints. This equips them with skills for engaging in conversation without confrontation and persistent conﬂict—competencies that are crucial for sustaining warm, pleasurable social relationships. Gratifying social ties, in turn, serve as vital contexts for further cognitive and social development. 
Preparing for Literacy. Most parents hope that during the preschool years, their children will develop the knowledge, skills, and attitudes that prepare them to read and write in elementary school. This interest in literacy is well founded. Reading and writing are not just crucial for success in academic endeavors and later life. They are thoroughfares to vast realms of knowledge, enjoyable leisure pursuits, and contact with others at a distance—even in dierent historical time periods. Once children can read and write, they can explore the insights of countless authors and partake in their rich array of experiences. With those authors, they can forge highly varied and vastly expanded “zones” for learning.
Children can become competent readers and writers without being trained, pushed, or goaded into literacy learning in early childhood. As we saw earlier, preschools and kindergartens that emphasize drill on academic skills are detrimental. This way of teaching induces inattentiveness, restlessness, disengagement from challenging activities, and poorer achievement during the ﬁrst few years of elementary school. Young children who are enthusiastic and self-conﬁdent about learning and who achieve at their best in the early grades have acquired literacy-relevant knowledge informally—through exposure to books and other reading materials at home, in preschool, and in child-care environments; through observing adults reading and writing in everyday life; and especially, through narrative conversation. 
Literacy-related behaviors emerge in these contexts; consequently, early childhood educators refer to preschool competencies that lay the foundation for reading and writing as emergent literacy. Indeed, no clear dividing line exists between prereading and reading. As literacy experts Grover Whitehurst and Christopher Lonigan put it, “Reading, writing, and oral language develop concurrently and interdependently from an early age from children’s exposure to interactions in social contexts in which literacy is a component, and in the absence of formal instruction.”88
Research consistently demonstrates that language development in early childhood is strongly related to later reading competence—and to academic achievement in general during elementary school.89 Furthermore, both language progress and an array of emergent-literacy skills can be predicted by the sheer amount of verbal interaction in the home during the ﬁrst few years of life—a relationship that holds for children of all socioeconomic levels. Conversations with adults are especially powerful contributors to early childhood language proﬁciency and, in turn, to literacy development.90
A strong language foundation is vital for becoming literate because people read to extract meaning. Children can more easily derive meaning from the printed page when their vocabularies are large and they have come to think in ways that resemble the narrative styles on which the large majority of written texts are based. By repeatedly listening to and participating in narrative conversation, children develop mental scripts for the way narratives are typically organized. Then, when they start to read, the organization of text material readily makes sense to them, and they extract meaning more easily. 
One of the clearest indicators of young children’s understanding of stories, and other prereading skills, is the extent to which they can give elaborate, detailed accounts of past events.91 Children sharpen this competency through conversing with adults, who add information, ask questions, and prompt children to increase the sophistication of their descriptions and explanations—in essence, who use an elaborative style of narrative talk. Whitehurst and his colleagues have encouraged parents and teachers of young children to integrate the elaborative narrative style into shared adult–child storybook reading, an approach called dialogic reading.92 
Typically, an adult reads while a child listens—a format that is beneﬁcial to early literacy development93 but that cannot guarantee the child’s attention, involvement, and comprehension. In dialogic reading, the adult encourages the child to become a participant in the narrative, even a storyteller. Using books with pictures that convey a story line but that have limited text so the adult is less likely to revert to straight reading, the parent or teacher has the child relate much of the story. The adult assumes the role of an active listener—querying, encouraging, and expanding on what the child has to say. As in other narrative talk, the adult increases the complexity of his or her questioning to ﬁt the child’s language progress. For 2- and 3-year-olds, questions focus mostly on describing events, actions, and objects. For 4- and 5-year-olds, questions more often address narrative organization (“What happens next?” “How does the story end?”); analyses of characters (“Why did the little girl want a teddy bear?”); and connections between the book and the child’s everyday life (“Have you ever seen a ﬁre engine on its way to a ﬁre?”). 
When parents and teachers use dialogic reading consistently over several weeks to several months, children show gains in language development, print knowledge, and writing progress that are still present six months to a year later.94 Although children dier widely in intrinsic interest in reading activities, shared reading can spark the interest of children who seldom seek out literacy-related pursuits on their own. Aspects of adult behavior—warmth, dramatic quality, and attempts to get the child to participate actively—heighten children’s interest and involvement in reading.95 An interested child is more likely to request shared reading times, notice features of print that are important for reading, ask questions about them, and (later on) read on his or her own. 
As older preschoolers begin to attend to features of print, adults can combine shared book reading with scaolding of children’s knowledge of letter names, letter–sound correspondences, and print conventions (for example, that books are read from left to right and top to bottom of the page, that spaces are used to separate words and periods to end sentences). Adults can also assist young children as they become interested in writing by responding positively to their writing-like creations and helping them attain their writing goals in daily activities and play—printing their name or a message, making a storybook, or adding items to a shopping list. Along with general language and narrative competencies, relaxed informal teaching of basic reading and writing skills—in limited doses and without excessive feedback about right and wrong—fosters emergent literacy and aids the process of learning to read and write after children begin school.96 
In sum, adult–child conversation—in book-reading and other contexts—is the best way to prime young children for becoming interested, accomplished readers and writers. Shared reading with parents is particularly inﬂuential—more so than reading with teachers. In one study, Lonigan and Whitehurst compared shared reading with teachers at preschool, shared reading with parents at home, and a combined condition. All three groups gained in oral language skills compared to children receiving no intervention. But children experiencing home reading improved the most.97 Parents seem to be in the best position to read to their child often and to tailor their dialogues to the child’s interests and abilities.

Other Contexts for Joint Adult–Child Engagement 

When parents and children spend time together, opportunities for scaolding of new skills and for conversation are nearly limitless. Parents who capitalize on these moments ensure that their children internalize the history, values, knowledge, skills, habits, practices, and understandings of their families and communities. We have already seen how academically related tasks, family celebrations, family outings, and adult–child storybook reading are excellent focal points for adult–child engagement. Make-believe play is yet another. Indeed, joint participation in make-believe with more expert cultural members is so important for development during early childhood that I devote an entire chapter to it. Other vital contexts for adult–child engagement include everyday routines and duties, mealtimes, and television viewing. Each of these settings has distinct and highly signiﬁcant developmental beneﬁts, as long as adults take time to enter into them and mentally connect with children. 

everyday routines and duties.  By participating in everyday routines and duties at home and in preschool, children develop a sense of responsible participation in family and community life. At the same time, they acquire practical skills and a wealth of knowledge about their physical and social surroundings. The parent always in a hurry—who says, when the child desires involvement, “There isn’t time,” or who fails to insist that the child join in household tasks in keeping with his or her capacity—severely limits the child’s learning.
In preindustrial times, children spent most of their day alongside parents as they went about housekeeping and earning a livelihood. As a result, children became deeply familiar with adults’ daily activities, picking up many skills through observation and direct participation. (Recall John Ise’s account of family life on a rural Kansas homestead, described in Chapter 1.) Greater parent–child togetherness throughout the day is also common in tribal and village societies, where adults spend less time supporting children’s learning through verbal scaolding because children have so many opportunities to observe and participate directly in the work of adults.98
Because ﬁne-tuned scaolding is seldom required, adult–child participation in everyday routines and duties—preparing a meal, washing dishes, raking and bagging leaves in the garden, buying groceries—oers extra time for conversation, with all its attendant beneﬁts. In addition, many informal learning opportunities arise that will serve children well when they get to school. An astute mother I observed in the grocery store had her 3-year-old son, Ricky, reach for items on the shelf and put them in the cart. When at the checkout counter Ricky became restless and whiny, his mother handed him her credit card and directed him to watch closely for the moment the clerk would need it. As the boy turned toward the register, the mother pointed out how the price of each item appeared on a screen. Ricky alternately named the numbers he recognized and counted items as they passed through the checkout. Awed by the responsibility of handing over the credit card, a task he had seen performed only by adults, Ricky complied eagerly—and also saw numerical concepts in action! Although grocery shopping with Ricky might take 10 or 15 minutes longer than otherwise, it has wide-ranging beneﬁts for his development.
Children, as parents and teachers well know, are not always eager to perform chores that adults set for them. But they are more willing when they see adults engaged in those duties, when adults explain why it’s fair that everyone help, and when their relationship with those adults is warm and gratifying.99 These communicative ingredients motivate children to join in with a cooperative spirit, which demonstrates that they have moved beyond the adult’s position to one of their own—that is, internalized social norms with conviction.100 In doing so, young children demonstrate once again their strong desire to become part of cultural life.

mealtime conversations.  Mealtimes—usually dinner—are special social contexts for families in complex societies. They are among the few occasions in which parents and children regularly gather after spending most of the day apart and in which the main family activity is relating to one another. Hence, mealtime talk overﬂows with opportunities for socialization. 
Mealtimes and similar occasions for family togetherness open special conversational doors. Because all family members are present, dinner talk can convey to children a sense of family coherence and identity.101 Most of us can still recapture the stories our parents told us, in which social and moral lessons were powerful and abundant. Here is one my mother told me, recalled in vivid detail nearly a half century later: “Once, when your grandfather was 16 years old, he came home weeping, his hands all bloody from working in the factory. His mother, your great grandmother, wiped away his tears and said, ‘Don’t cry, one day you’ll own that factory.’ And by the time he was 30, he did.”
Dinnertime recaps of daily events also permit today’s children, isolated from the adult world of real work, to gain access to their parents’ daily lives. I learned much about my father’s experiences as a retail merchant through stories he related to my mother at dinnertime: “Soﬁe, you’ll never believe the customer who came into the store today. She complained so vehemently about a perfectly correct bill that it took two of us to escort her to the door.” 
Family mealtime conversations, whether children participate directly or listen to the exchanges of others, also provide special instruction in discussion skills, since they are among the few routine occasions in which children are permitted to enter an adult conversational world.102 When meals are shared with children, parents can model and teach cultural rules regulating conversation—appropriate topics and politeness (“We don’t say food is disgusting at the table”) and subtle conversational strategies that children become proﬁcient at only after much practice, such as how to enter a conversation and link with other participants’ statements.
Finally, and perhaps most important, mealtimes allow parents to enter into their children’s world and hear about the many facets of their lives, ranging from what the child did at school that day to reﬂections on how to solve peer or sibling problems.103 Consequently, they serve to reinforce not just socialization but parental caring and support. The numerous beneﬁts of this rich communal context are lost when family mealtime rituals diminish or disintegrate into frequent eating on the run or split adult–child meals. 
The importance of family mealtimes is underscored by the fact that the most widely used research instrument for assessing the quality of young children’s home environments asks parents whether the child eats at least one meal a day with a parent.104 Scores on that instrument consistently predict early childhood mental development, no matter what the child’s socioeconomic or ethnic background.105

television viewing.  In Chapter 1, I noted that according to current survey ﬁndings, American adults spend over one-third of their free time—about 15 hours per week—watching TV. Estimates for children are even more ominous. Regular TV viewing typically begins between 2 and 3 years of age, consuming about 10.5 hours per week, or nearly 13 percent of the child’s waking hours. It rises steadily over early childhood until it reaches an average of 28 hours per week for school-age children, or about 30 percent of the child’s waking hours.106 When we consider how much the set is on during school holidays and summer vacations, children spend more time watching TV than they do in any other waking activity, including going to school and interacting with family members or peers. 
These statistics are averages; children dier in their attraction to television. For example, parents who watch a lot of TV tend to have children who do the same. Excessive TV viewing is associated with family and peer diculties, poor school achievement, and serious health concerns—speciﬁcally, overweight and obesity as a result of hours of being sedentary and eating high-fat snacks while viewing.107 Parents with stressful, unhappy lives often escape into television, and their children may do so as well.
It is crucial that parents exercise their gatekeeper role with respect to TV, limiting how much and what young children watch—to about an hour to an hour-and-a-half a day and to programs that are child-appropriate and informative and that teach positive social attitudes and behaviors. In addition, as much as possible, parents should watch with children and engage in joint conversation about televised information, helping them understand what they see. Parental oversight and involvement in children’s TV viewing are essential for two reasons. 
First, preschoolers easily misunderstand televised material. For example, at ages 2 and 3, they do not discriminate TV images from real objects; they say a bowl of popcorn on TV would spill if the set were turned upside down!108 When a child believes that all people, objects, and events on TV are authentic, violence—so pervasive on American TV—becomes particularly terrifying. Although by age 4 children know that not all TV programming is real, they judge TV reality according to whether the images resemble people and objects in everyday life. Not until age 8 do children fully grasp the unreality of TV ﬁction—that characters do not retain their roles outside the TV show.109 
Furthermore, prior to this age, children have diculty inferring characters’ motives and connecting contradictory TV scenes into a coherent story line. They cannot appreciate why a character who at ﬁrst seemed like a “good guy” but later behaves aggressively is really a “bad guy.” They evaluate such characters and their actions much too favorably.110 For example, psychologist Sharon Purdie showed second graders a complex dramatic program in which an accused kidnapper, who had at ﬁrst appeared friendly, tried to shoot a prosecution witness and got arrested during the attempt. Children who failed to grasp the kidnapper’s motive and the reason for the arrest judged him to be “good,” not “bad.”111
Second, weak government regulation of American TV means that without parental controls, child viewers are exposed repeatedly to antisocial attitudes and behaviors. The average American child ﬁnishing elementary school has seen more than 100,000 televised violent acts that provide “an extensive how-to course in aggression.”112 Television also hardens children to violence, making them more willing to tolerate it in others.113 Furthermore, although educational programming for children is highly sensitive to issues of equity and diversity, entertainment programming often conveys ethnic and gender stereotypes—minorities as villains and victims of violence and in subservient roles; men as dominant, powerful, and competent and women as attractive, emotional, and submissive. The more children view, the more likely they are to endorse such stereotypes. 114 Finally, as many parents are aware, television advertising manipulates children’s beliefs and preferences. Although children can distinguish a TV program from a commercial as early as age 3, below age 8 they seldom grasp the selling purpose of the ads.115 Rather, they think that commercials are well-intentioned eorts to be helpful to viewers.
These worrisome ﬁndings are not an inherent part of the TV medium. Instead, they result from the way it is used in American culture. In actuality, television has as much potential for good as it does for ill. For example, TV content depicting acts of cooperating, helping, and comforting encourages these behaviors in children.116 But most of the time, programs mix benevolent and hostile intentions in the same character. Unfortunately, children are riveted by a character’s aggression and miss the caring message. Television promotes positive social behavior in young children only when it is free of violent content.117
Despite widespread public concern about the impact of TV on children’s development, many parents do little to regulate or guide their children’s viewing. When parents do make an eort, preschoolers watch less TV, ﬁnd educational programs more appealing, and more often view shows with their parents.118 Parent–child co-viewing creates conditions in which adults can raise questions about the realism of televised information, assist children in making sense of the story line, and express disapproval of negative on-screen behavior and commercial messages, thereby teaching children to evaluate TV content rather than to accept it uncritically.
Interestingly, parents who are warm, communicative, and ﬁrm but appropriate in their expectations have children who are less drawn to TV, particularly violent TV.119 Very likely, these parents set an example through their own TV viewing, watch with their children whenever they can, and use TV programs in constructive ways, helping children move away from the set into worthwhile activities. A program about animals, for example, might spark a weekend trip to the zoo, a visit to the library for books about animals, or new ways of observing and caring for the family pet. Parents who intervene in their child’s TV viewing so it is in keeping with the “zone” transform the TV medium from a negative to a positive force in the child’s mental life, and they promote favorable cognitive and social development in many other ways as well. 


dialogues with children: larger implications

Compared to two or three generations ago, contemporary parents and children less often engage in the development-enhancing, joint activities discussed throughout this chapter. In 1970, long before parents became preoccupied with the “time bind,” psychologist Urie Bronfenbrenner reﬂected that children “used to be brought up by their parents.”120 Although the family, Bronfenbrenner noted, continues to have primary responsibility for children’s character development, it lacks the strength needed to do the job because parents and children no longer spend enough time together. Ours is a split society—adults in one world, children in another. Too many families have separate adult–child living areas, each equipped with its own TV and other leisure pursuits so that parent–child dialogues seldom take place. When parents and children spend most of their time apart, the result is a profound dampening of parents’ socializing power. 
In the past, extended family members or adults in the neighborhood more readily stepped in when parents, for one reason or another, could not invest enough time in their children’s lives. Today, neighborhood experiences are much more restricted. Housing enclaves where families know each other well and interested adults are available to “mind children’s business” are rare. Children who live close to their grandparents beneﬁt greatly, enjoying aectionate, playful relationships with them at early ages and looking to them for information, role models, family history, and values later on. But greater family mobility means that more children live a considerable distance from grandparents and other relatives. And parental divorce, which will aect 50 to 60 percent of American children born in the current decade,121 lessens contact with the noncustodial parent’s extended family. In childhood, physical distance makes for a psychologically distant relationship.
Remove parents and other adults from active participation in the lives of young children, and the vacuum may be ﬁlled by unsupervised and ill-behaved peers and the moral vagaries of American TV fare. Continued disengagement of adults from children’s lives, Bronfenbrenner prophesied, will result in greater alienation, indierence, antagonism, and violence on the part of young people from all sectors of society—a prediction that came to pass in the form of rapidly escalating youth crime between the 1970s and 1990s, with an increasing number of oenders from privileged homes.122 
As media analysts try to make sense of the most heinous of these acts, including the recent spate of family, school, and neighborhood murders and maimings, parental retreat from a troubled child’s life almost invariably surfaces as a contributing factor. Parents of these youngsters often appear to be good people, having provided their children with material comforts and having responded with anguish, remorse, and attempts to do the right thing in the face of their child’s previous and current grievous behavior. But the cases suggest that stepping in only in at times of crisis cannot compensate for providing the ongoing togetherness and haven of a family. Such togetherness aects a child’s development in countless ways, even through what appear to be triﬂing pursuits—help with homework; outings to the grocery store, the park, and the local library; dinnertime conversations; discussions of exciting or scary TV shows; and bedtime stories. Yet these are the key experiences of childhood, through which children appropriate mental tools from more capable and discerning social partners, become enculturated and, thereby, human—intelligent, responsible, and caring. 
Of course, most youngsters with preoccupied parents do not become antisocial and violent. Yet over and over, commentary in the media and in the psychological literature conﬁrms that too many of our youth are disaected in less intense ways—self-absorbed, disgruntled, and lacking a clear sense of direction and purpose. In the words of psychologist William Damon, they are demoralized,123 a term that suggests a break with their social world, a deﬁciency in internalization of worthwhile values and goals. 
A provocative question is whether a craving for connection with family and community is at the heart of the ﬂoundering of many of today’s youth, manifested in academic problems, poor peer relationships, low self-esteem, depression, angry, acting-out behavior, and—with the arrival of young adulthood—inability to make vocational commitments, attain ﬁnancial independence, and forge healthy intimate relationships. Research documents that these diculties are magniﬁed two to threefold in children and adolescents who have been exposed to marital discord and divorce,124 circumstances in which parents—at odds with one another—all too often are diverted from investing in their children’s day-to-day lives. 
Yet a certain number of children and adolescents, despite exposure to severe family adversity, escape these diculties and adjust well. A common element in the lives of such resilient youngsters, as I noted in Chapter 1, is an unusually warm, positive relationship with at least one parent or a close tie with an adult outside the immediate family.125 What happens within these alternative relationships that shields the young person from problems or restores eective functioning? Although little systematic evidence exists on the precise ingredients of such ties, I recently became familiar with the bond forged between Hannah, a 21-year-old college student, and her Aunt Eva and Uncle Charlie, two of my university colleagues. Hannah’s parents divorced when she was 9 and her older sister Sarah was 15. Hannah related the story of her childhood and the genesis of her relationship with Eva and Charlie, who oered insights as well. What they had to say is enlightening. 
“I can’t remember much family togetherness when I was a kid,” Hannah remarked. “Our parents couldn’t talk things out with each other, and they rarely talked things out with us. Mom took Sarah and me to Girl Scouts, swimming, piano, and other lessons. We enjoyed the activities and the friends we made, but they couldn’t compensate for what was missing: warm, family time. We almost never sat down to a meal together or went places together; we each went our own way. Our dad started going o on vacations by himself when holidays rolled around, so family get-togethers were rare. 
“When our parents split up, we moved with our mom from Arkansas to Seattle. Mom worked all week, weekends, and most evenings. She had to get a career going so there’d be money to live on and to send us to college. Sarah hung out with another family in the neighborhood. A couple of times a week, she had dinner and went to church with them. Looking back, I’d say they were her substitute family; she ‘adopted’ them, and they ‘adopted’ her. I was too young to go o on my own that way. When I didn’t have after-school activities, Mom insisted that I come home and do chores and homework. Sometimes I got to go to a friend’s house to play, but many nights I’d open a can of spaghetti and have dinner by myself. I spent hours daydreaming and looking at old pictures of Mom, Dad, Sarah, and me.”
On ﬁnishing high school, Sarah chose a religiously aliated college of the same denomination as that of her “alternative” family. The year after her college graduation, Sarah married a devout classmate, entering into a culture in which family life was pivotal. Six years later, Hannah started college, but for her the road to maturity was rough. She had diculty concentrating, earned uneven grades, and accumulated so many incompletes in courses that the university prohibited her from reenrolling until she wrapped up her “unﬁnished business.” Frustrated with Hannah’s undirectedness, her mother withdrew ﬁnancial support and insisted that she get a job. Hannah’s full-time waitressing soon became both an obstacle and an excuse for lack of progress in her studies. “I was at sea,” Hannah recalled. “I didn’t have any conﬁdence in myself, and I didn’t think I could do anything. So I started visiting Aunt Eva and Uncle Charlie, who lived three hours away.”
“We hadn’t known Hannah well while she was growing up,” Eva continued, “so we were surprised but delighted when she started coming on weekends. It didn’t matter what we were doing—birthday celebrations, dinner with friends, outings to movies and plays, shopping excursions, or leisurely breakfasts; Hannah hungered to be part of our family. During those times, she asked lots of questions about our work and home lives, and also about her parents, especially their early history: ‘Was my mom close to her mom?’ ‘Did you know my mom and dad when they were in college?’ ‘What was my parents’ wedding like?’ I described these and many other earlier events. We also did our best to convince Hannah that believing in herself grows out of trying hard, taking risks, and following through. We talked about how important it was for her to return to school, helped her think through a change of major, and advised on time management and study skills.”
Hannah completed her degree the following year. In a letter she wrote to Eva and Charlie shortly after her graduation, she attributed her turnabout in motivation and self-conﬁdence to the connection, forged through dialogue, with her aunt and uncle:

Thank you for everything you have provided, the time and eort you shared with me and the conﬁdence you showed in me. It deﬁnitely enabled me to relocate all of that within myself this year and even be pleasantly surprised by how each accomplishment facilitates the next one. This, and you, are among the greatest gifts I have ever received. The change in my ability to focus on my courses and the personal rewards have been immense. THANKS.126 

What factors contributed to Hannah’s turnabout? Shared understanding (intersubjectivity) between adult and child, scaolding of new competencies, narrative conversations prompting a redeﬁnition of self, and joint engagement in culturally meaningful activities—the diverse experiences we have considered that create the zone of proximal development—appear to be at the heart of her success story. Indeed, Hannah’s tale suggests that young children denied these supports can still proﬁt from them later, if such supports are available and they have the fortitude to capitalize on them. But not all young people are as fortunate as Hannah. Some remain profoundly impaired by inadequate adult investment in their childhoods. And even those who fare reasonably well may carry with them inner wounds—a sense of emptiness and regret at having missed self-deﬁning, conﬁdence-inducing early experiences that cannot, in the ﬁnal analysis, be recaptured.
Experts asked to reﬂect on the malaise and problematic behavior of children today repeatedly comment that they lack sucient adult guidance and involvement.127 We have seen that children come into the world marvelously prepared to enter into partnerships with parents and other caregivers. In the course of this chapter, I have had much to say about just how parents and teachers can capitalize on children’s natural propensities. Vygotsky’s concept of the “zone” clariﬁes for us the meaning of true “quality time.” What must we do to keep young children in the “zone,” motivated, involved, and ever advancing to new heights? Here is a brief recap of the communicative principles we have considered:

•Forge an adult–child relationship based on shared understanding, or intersubjectivity—one in which the adult strives to “connect” with the child by “stretching down” to his or her point of view, thereby helping the child “stretch up” to the adult’s more mature perspective. Intersubjectivity is essential for all successful dialogue.
•Oer a scaffold for mastery of tasks that teach culturally valued concepts and skills. Adjust the task to an appropriately challenging level, and tailor teaching and assistance to the child’s changing needs. While supporting the child’s eorts, ask questions and suggest strategies that help the child generate ideas and distance his or her thinking from the immediate features of the task. Turn over responsibility for the task to the child as soon as he or she can master it without assistance. Adult–child collaboration through scaolding promotes self-regulation and independent accomplishment.
•Communicate with high warmth, using a positive emotional tone and providing explanations and justiﬁcations for your expectations. When adult–child relationships are sympathetic and caring, children want to acquire skills and behave in ways that preserve those gratifying ties. They are also more willing to work toward goals that are rational and reasonable. Authoritative parenting, which combines the motivating power of warmth with the guidance inherent in scaolding, predicts many aspects of children’s competence.
•Engage children in narrative conversation about personal experiences, using an elaborative conversational style that poses many varied questions and that expands on the child’s statements. Through narrative, children build an autobiographical self permeated with cultural beliefs and values; come to understand that people have rich mental lives and may view the same events dierently; and acquire negotiation strategies for resolving disputes and getting along with others. Narrative conversation also fosters language development and emergent literacy, which greatly ease the task of learning to read and write when children get to school. 

Through dialogues with children, adults play a formative role in the development of children’s self-conceptions, sensitivity to others, cognition, academic knowledge, morality, social skills, and capacity to use language to gain control over thought and behavior. Can parents and teachers actually witness young children undergoing these social-to-psychological transformations? Let’s turn now to a consideration of children’s inner mental lives, as manifested in the dialogues they carry on with themselves. In the next chapter, I address a question that has long intrigued child development theorists and puzzled many parents and teachers: Why do children talk to themselves?









In my three decades of teaching university courses in child development, I have come to know thousands of students, many of whom were parents or who became parents soon after completing my class. I also served on boards of directors and advisory committees for child-care centers, preschools, elementary schools, and parent organizations. And my research continually drew me into classrooms, where for countless hours I observed and recorded preschool and school-age children’s activities, social interactions, and solitary behaviors, in hopes of answering central questions about how they learn.
As a byproduct of those experiences, parents repeatedly approached me with concerns about how to foster their child’s development in the early years. Their fervent questions, at times riddled with doubt and anxiety, revealed that creating optimum learning environments for young children at home—and ensuring their access to development-enhancing experiences in child care, preschool, and school—have become mounting parental challenges. 
Consider the following problematic situations that parents recently raised with me:

•Bob and Sharon, parents of a 4-year-old: Our daughter, Lydia, could recite her ABCs and count from 1 to 20 by age 2 1/2. When we looked for a preschool, many programs appeared to do little more than let children play, so we chose one with lots of emphasis on academics. To me, Lydia’s preschool seems like great preparation for kindergarten and ﬁrst grade, but each morning, Lydia hates to go. Why is Lydia, who’s always been an upbeat, curious child, so unhappy?
•Angela, mother of a 4-year-old and 6-year-old: My husband and I have demanding careers and need to bring work home in the evenings. I’ve read that it’s the quality of time we spend with our children that’s important, not the quantity. We try hard to give Victor and Jeannine our undivided attention, but they’re often whiny, demanding, and quarrelsome. Many times we end up sending them to their rooms or letting them watch TV, just to get some peace after a long day. What’s the best way to create quality parent–child time?
•Talia, mother of a 7-year-old: My son Anselmo, a ﬁrst grader, constantly asks us to help him with his homework. His father ﬁrmly insists that he do it by himself. Anselmo tries, but he gets so frustrated and upset that I move in and help, even in the face of opposition from his dad. By that time, Anselmo is on such a short string that I do most of the assignment for him. Should we be helping Anselmo with his homework and, if so, how?
•Noah and Suzanne, parents of a 2-year-old: When our parents were raising us, they seemed conﬁdent of their power and inﬂuence. Recently we read that how children turn out is mostly written in their genes; there’s little we as parents can do about it. Does parenting really matter?


baffled, bewildered parents

Despite being well educated, intent on doing what’s best for their children, and enlightened by a vast literature of child-rearing advice, many American parents appear uneasy and unsure of their roles at best, baed and bewildered at worst. As the above sampling of concerns reveals, today’s parents are not just worried about major transitions and traumas, such as the impact of marital breakup or community violence. They agonize over commonplace, recurrent, everyday situations—whether intensive preschool academic tutoring is crucial for later success in school, the meaning of “quality time” with children, and whether and how to help their child with homework. At an even more fundamental level, contemporary parents have begun to doubt their own ecacy in their children’s development. Why is this so?
The reasons, I believe, are twofold. First, rapid societal changes have complicated parents’ task, making child rearing more challenging than in previous generations. Second, information about child development disseminated to parents is increasingly voluminous but at the same time contradictory. It fails to oer a clear, consistent vision of good child rearing to guide daily decision making and practice. Let’s take a closer look at these sources of parental frustration and confusion. 

Societal Changes

Over the past three decades, external forces impinging on the family have transformed parents’ and, therefore, children’s lives. Overall, parents complain that they have less free time to spend with their children.1 Witness a 1995 survey of a large, representative sample of American workers, nearly 25 percent of whom expressed the feeling that the demands of their jobs left them with “no time for family.”2 Compounding their worries, employed parents must, out of necessity, turn over many hours of child rearing to other adults. Yet once their children are beyond their grasp, they are hardly o the hook! Conscientious parents face an added responsibility: monitoring their child’s whereabouts and activities, verifying from a distance that their youngster is physically safe, emotionally contented, and constructively engaged. 
Although many societal conditions heighten parents’ struggle to rear psychologically healthy children, two are especially pernicious, aecting even parents who manage to escape the trials and tribulations of divorce, single parenthood, stepchildren, serious ﬁnancial worries, and other family stresses. The ﬁrst is the dire shortage of acceptable child-care options in the United States, the second is the parental dilemma of “never enough time.” In view of these diculties, it is little wonder that so many American parents express a sense of powerlessness and inadequacy when it comes to aecting their children’s development. 

the problem of child care.  In 1970, 30 percent of mothers with pre-school children were in the labor force, a ﬁgure that increased more than twofold, to 62 percent, by 2000.3 An obvious solution to reconciling parents’ employment needs with young children’s rearing needs is to make high-quality, nonparental care, with characteristics known to promote healthy psychological development, widely available and aordable. In Australia and Western Europe, child care is nationally regulated and liberally funded to ensure that it conforms to standards veriﬁed by research to foster children’s learning, social competence, and emotional security.4 
Without a nationally regulated and generously subsidized child-care system, formal child care in the United States is in much shorter supply and considerably more costly for parents than it is in other industrialized nations. And as our discussion in Chapter 6 will reveal, on the whole, the quality of American child care—whether center-based or home-based—is mediocre to abysmal.5 Indeed, so widespread is poor-quality child care in the United States that Americans have acclimated to it. In a recent survey of parents whose children were enrolled in several hundred randomly chosen child-care centers across four states, over 90 percent believed that their preschoolers’ experiences were far better than experts in early childhood development judged those experiences to be.6 Parents seemed unable to distinguish “good” from “substandard” care. 

the “time bind.”  Like many parents, Angela, who raised the question of quality time, complains of being “torn in many directions.” Often she leaves work in a hurry in the late afternoon to pick up Victor and Jeannine from child care, dashes to Victor’s tumbling class or Jeannine’s piano lesson, then stops at the grocery store to pick up something for dinner. When Angela and her husband, Tom, walk through their front door, they typically head to the phone or fax machine to take care of unﬁnished work while trying to quell Victor and Jeannine’s hunger and irritability with a frozen dinner popped into the microwave and unlimited access to the TV set. Caught in a ceaseless sprint to reconcile job, marriage, and parenting, Angela and Tom feel drained at the end of the day—too tired to grant their children more than 10 or 15 minutes of focused time. When Victor and Jeannine do get their parents’ undivided attention, they are argumentative and unruly, compounding their parents’ fatigue and impatience. 
Angela and Tom represent a growing number of American parents who try to pencil children into busy schedules, much like a business appointment. They love their children, but they also love and need their work, for personal and ﬁnancial reasons. Hence they ﬁnd themselves in a juggling act between the two, with work usually winning out. Tomorrow will be another day for the kids, they rationalize, but a business deal or a professional achievement, if not capitalized on at the moment, may evaporate. Their logic dovetails with the concept of “quality time” for children. In its commonly accepted meaning, quality time refers to an intense but brief contact. The term is a ready salve for the consciences of conﬂicted parents, who squeeze in a few moments with their children, catch-as-catch-can, yet sense deep down that they are robbing their youngsters—and themselves—of something vital.
The expression “quality time” dates back to the 1970s, a decade that witnessed the largest rise in women’s participation in the labor force during this century. The notion was bolstered by observational studies of parent–child interaction. In these investigations, some parents exchanged positive emotional signals with and verbally stimulated their infants, and read to and conversed with their preschoolers. Other parents spent time with their children but were not actively engaged with them. Time and time again, children of the first set of parents developed more favorably, cognitively and socially, than did children of the second set of parents.7
A close look at the research reveals that children who fared well experienced eective interaction over an extended period. In studies following children from infancy into childhood and adolescence, early brief episodes of parental stimulation and sensitivity did not result in more competent children.8 Instead, positive, supportive parenting that endured, even when it marked a change from an early period of parental retreat or negative interaction, was linked to favorable child development, including persistence in problem solving, high self-esteem, socially skilled behavior, closer friendships, and better peer relationships.9 In sum, high-quality involvement with children requires a certain quantity of time—actually, a great deal, as I’ll argue in this book.
In Angela and Tom’s case, sandwiching concentrated time with Victor and Jeannine between work and other obligations, which often took precedence over family rituals, meant that routines that signal parental caring and that are major sources of development went by the wayside. For example, family dinnertimes and storybook reading at bedtime became rare events. So did the sheer enjoyment that comes from relaxed parent–child play; a joint cooking, art, or construction project; and a conversation based on real listening and exchange of ideas. Because these experiences were so few and short-lived, Angela and Tom were deprived of valuable opportunities to observe their children closely and to become intimately familiar with their talents, shortcomings, preferences, styles of learning, and ways of coping with hardship—knowledge that is crucial for helping children develop into mature, competent individuals.
Furthermore, the “time bind” stiﬂes an essential child-rearing responsibility that I mentioned earlier and will return to again: monitoring children’s experiences while they are both within and beyond parents’ immediate reach. This includes frequently touching base with nonparental caregivers and teachers to ﬁnd out what’s happening at child care or in the classroom; looking in on sibling and peer interaction to make sure that it is positive and respectful; and controlling time spent watching TV and playing video games.
In a recent provocative study, sociologist Arlie Hochschild spent months getting to know employees at a large Midwestern corporation she called Americo. Whether clerical workers or executives, the majority conﬁrmed the parental state of mind just described: They complained of overly long workdays and frenetic home lives. A surprising ﬁnding, however, was that few Americo workers had taken steps to make work and family more compatible. For example, even well-paid employees were not taking the annual six weeks of federally guaranteed, unpaid family leave time, although they could aord to do so. Nor were they asking for job share or ﬂextime, prominent company policies aimed at increasing the compatibility of work and home. Hochschild concludes, “Many working families are both prisoners and architects of the time bind in which they ﬁnd themselves.”10 
As homes become frenzied places in which work encroaches on family time and parents are too exhausted or preoccupied to be physically and psychologically available, children quickly become discipline problems. Their disagreeable behavior often causes parents to retreat further into the haven of work. On the job, such parents feel competent and gratiﬁed; home has turned into a place where they are harried, annoyed, and must deal with children who sulk, complain, plead for gifts, and are obstinate until they get their way—reactions that cry out, “Fifteen minutes, here or there, with an essentially distracted parent, is not enough.”
Fortunately, not all reports are as disturbing as Hochschild’s. Psychologist Rosalind Barnett and journalist Caryl Rivers conducted extensive interviews with 300 dual-earner couples in the Boston area and found that despite stress at work and at home, most were highly satisﬁed and found child rearing to be both manageable and pleasurable.11 And in a survey of 6,000 employees at DuPont, nearly half—and only slightly more women than men—turned down upward career moves to remain in jobs that allowed for more family commitment.12 Barnett believes that parents most prone to a time bind in which work robs family life are at higher socioeconomic levels—in more pressured jobs that have less clearly deﬁned limits and in which advancement typically depends on superlative performance. Ironically, she notes, economically less well o parents ﬁnd it easier to establish a viable dividing line between workplace and home.13
Although the precise extent of family–work conﬂict in American culture is not clear, its presence and detrimental impact on parent-child interaction and children’s development are well founded. Consider a series of studies that examined length of maternity leave in relation to employed mothers’ psychological well-being and parenting behaviors. Short leaves of 6 weeks or less (the norm in the United States) were linked to maternal anxiety and depression and negative interactions with babies. But longer leaves, of 12 weeks or more, predicted favorable maternal mental health and sensitive, responsive parenting. 14 
Furthermore, long hours in child care during infancy and the preschool years are linked to less favorable parent–child interaction. One study included repeated observations of more than 1,200 mothers, of diverse socioeconomic and ethnic backgrounds, playing with their children between 6 months and 3 years of age. The more time children spent in child care (which ranged from 0 to 50 hours per week), the less positive and responsive their mothers’ behavior tended to be. Children experiencing less positive interaction were less engaged with their mothers—more negative in mood and less aectionate.15 Yet another study—this time, of 3- to 5-year-old ﬁrstborn sons—suggested that long child-care hours can translate into behavior problems. Mothers and fathers of boys with many hours in child care interacted less favorably with their sons. And such parents reported more noncompliant, deﬁant child behavior. 16
These ﬁndings are not an indictment of maternal employment or nonparental child care. Rather, they underscore the importance of considering the needs of children when making work and child-care decisions. Studies carried out during the 1970s and 1980s on the relationship of maternal employment to children’s development revealed many positive outcomes—higher self-esteem, better grades in school, more positive family and peer relations, and less gender-stereotyped beliefs. 17 But repeatedly, eective parenting mediated these favorable developments. 
Employed mothers of cognitively competent, well-adjusted children value their parenting role and succeed at coordinating it with job responsibilities. Such mothers schedule regular times to devote to their children and combine warmth with consistent expectations for mature behavior. 18 Consider a study of the relationship of maternal employment to ﬁrst graders’ academic and social competence. Children of working mothers were equally or more competent than children of homemakers only if the children frequently experienced mother–child shared activities, such as warm conversation and play. Shared activities were especially crucial for children of mothers who had increased their hours of employment during the preceding 3 years, often from part-time to full-time. When a change in employment status was associated with high mother–child engagement, children fared well. When it led to reduced mother–child engagement, children’s competence suered greatly.19
Fathers’ involvement in child rearing is an additional route to positive outcomes for children. Although women devote more than three times as many hours to child care as men do, fathers’ involvement has risen in recent years.20 Children of highly involved fathers score better on measures of intelligence, school achievement, mature social behavior, and ﬂexible beliefs about gender roles—in short, on all the positive outcomes associated with maternal employment.21 When mothers and fathers support each other and share child-rearing responsibilities, both engage in more eective parenting.22
In sum, increasingly pressured adult lives have contributed to parental diculties in granting children the attention they need. When employed parents spend generous amounts of time engaged with their child, they safeguard the child’s development. Under these conditions, children often reap extra beneﬁts from more equitable involvement of both parents. In contrast, a pressured work life that pulls parents away from child rearing undermines infants’ and children’s well-being—cognitively, emotionally, and socially.
Probably because it reduces work overload, part-time maternal employment is associated with better academic and social development than is full-time employment.23 Unfortunately, most American employers do not provide this option, and many parents—especially, single parents—cannot aord it. Yet as noted earlier, ﬁnancially well-o parents are especially prone to the “time bind” but do not necessarily take advantage of available workplace options aimed at lessening it.

Child-Rearing Advice

Almost all parents—especially ﬁrst-time parents—feel a need for sound advice on how to rear their children. The demand for expert advice is particularly great today, perhaps because parents, teachers, and the general public perceive that children’s problematic behavior has increased. Widespread parent and teacher opinion, gathered from nearly 700 respondents in 1976 and again in 1989, revealed that during this 13-year period, children were viewed as more likely to “do poorly on schoolwork,” “hang around with peers who get into trouble,” and “destroy things belonging to others.” Fewer were seen as involved in worthwhile activities that truly engaged them.24 A 1997 survey of 4,500 American adults, 2,500 of whom were parents, echoed this disheartening trend. Most viewed today’s youngsters as too out-of-control and undirected.25
The call for parenting advice has led to a proliferation of volumes, ﬁlling shelf after shelf in virtually every general-purpose bookstore and public library. The “correct methods” advocated in these books vary widely, with many addressing discipline and communication, thereby catering to rising numbers of parents with undercontrolled, apathetic, non-goal-directed children. Precious few of these parenting manuals are grounded in the explosion of contemporary research on child development that is of signiﬁcant applied value. Rather, a plethora of opinion is available, some of it playing on and exacerbating parents’ self-doubts with such titles as Parenting for Dummies and The Seven Worst Things Parents Do.26 

one-sided views.  Well-known theories of child development—Freud’s, Skinner’s, Gesell’s, and Piaget’s, for example—provide little comfort, since dramatic shifts in favored theories have occurred since the launching of systematic study of children about 100 years ago. Indeed, this waxing and waning of theories has contributed greatly to discrepancies in expert child-rearing advice, which (like the theories) has ﬂuctuated between extremes—swinging, like a rhythmic pendulum, from an adult-imposed, directive approach to a child-centered, laissez-faire approach, and back again. As one recent analyst commented, theories and the popular literature for parents “have done their share to undermine the wavering self-conﬁdence of American parents.”27 The roots of these polarized perspectives can be found in centuries-old, dramatically opposing philosophies about the nature of children and child development.
Adult Supremacy. Writing at the end of the seventeenth century, British philosopher John Locke characterized the child as a tabula rasa. Translated from Latin, this means “blank slate” or “empty container,” a being who can be freely “written on,” or “ﬁlled,” with socially acceptable knowledge and skills—in essence, molded in any way adults might desire through careful instruction, eective example, and rewards for good behavior. Lockean ideas provided the footing for American behaviorism, launched by John Watson in the early 1900s and built by B. F. Skinner into a powerful mid-century theoretical force heralding the supremacy of environment in its belief that behavior is shaped by external stimuli. 
By the 1920s and 1930s, millions of parents had adopted behaviorist procedures in one form or another. The most committed were well-educated mothers, who read about conditioning methods in magazine articles and government bulletins on child care. Heeding Watson’s warnings about the dangers of overindulgence, parents mapped out schedules and routines for their young children and tutored them in all manner of skills and in self-controlled conduct. In preschools and kindergartens, behaviorist tenets were used to justify large-group drill on letters, numbers, and general knowledge as well as repetitive worksheet practice that required young children to sit at their desks for long periods, ﬁlling in blanks, coloring within the lines, and otherwise following teacher prescriptions. 
Parents anxious for their children to display mature behavior were convinced that these experiences would prime them for academic success. But research eventually documented otherwise—that regimented tutoring not adjusted to the child’s interests and capabilities undermines rather than enhances learning, motivation, and self-control. In preschools and kindergartens where much time is spent sitting, listening to teachers, and doing worksheets, children exhibit high levels of stress behaviors, such as wiggling, withdrawal, and talking out. They also show a decline in self-conﬁdence and motivation, expressing doubts about their own ability and retreating from challenging problems. Furthermore, when followed up during the ﬁrst few years of school, children who spent their kindergarten year in a highly teacher-directed classroom achieve more poorly than do agemates who come from kindergartens emphasizing play and hands-on, small-group projects.28
Recall 4-year-old Lydia’s dislike of her academic preschool, described at the beginning of this chapter. Lydia’s negative reaction is certainly consistent with research ﬁndings. The behaviorist presumption that development can be mechanically engineered by social input, guaranteeing brighter, socially more mature children, is not borne out by the evidence.
Child Supremacy. Countering Locke’s image of an all-powerful adult tutor, eighteenth-century French philosopher Jean Jacques Rousseau conceived of the child as a “noble savage”—untamed but naturally good, with an innate plan for orderly, healthy growth. According to Rousseau, adult training served only to thwart the child’s inherently perceptive intelligence and moral sense, which unfolded naturally as children moved through a sequence of developmental stages. 
The Rousseauian view provided the substrate for the twentieth-century counterpoint to behaviorism: a belief in the powerful role of children’s inborn characteristics. At mid-century, Freud’s psychoanalytic theory vied with behaviorism’s reinforcement principles for parents’ and educators’ attentions. In the tradition of Rousseau, the psychoanalysts argued that powerful biological forces channel development through four psychosexual stages. Although psychoanalytic theory embraced a far less benign view of the child’s “instincts” than did Rousseau’s philosophy, Freudian ideas were nevertheless strongly child-centered in declaring that not much could be done about the child’s basic nature. According to this view, the child’s sexual and aggressive urges must be harnessed in the interests of society, but socializing too early or insistently can cause serious inner conﬂict and psychological disorder. Therefore, psychoanalytic experts advised parents to avoid the trauma of heavy adult demands and accept children’s intrinsic dispositions and tendencies.29
The Rousseauian child-centered theme surfaced, as well, in the realm of the child’s intellect. Swiss biologist Jean Piaget, twentieth-century giant of cognitive development, proposed a theory in which an intrinsically motivated child acts on the world, noticing discrepancies between the environment and inner structures, or ways of thinking. Gradually, the child transforms those structures so they better reﬂect reality and permit more ﬂexible, ecient thinking and problem solving. 
According to Piaget, as the brain matures and children’s experiences expand, they move through a sequence of four cognitive stages, or reorganizations of thought: (1) sensorimotor, the stage of infancy, in which babies use their senses and movements to explore the world; (2) preoperational, the stage of early childhood, in which preschoolers use symbols, especially language and make-believe play, to represent their earlier sensorimotor discoveries, but thinking lacks the logic of older children; (3) concrete operational, in which cognition is well organized and logical but limited to coordinating only two or three variables when solving problems; and (4) formal operational, the stage of adolescence, which opens up the capacity for abstraction, permitting young people to coordinate an increasing number of variables and to imagine all possible outcomes in a problem, not just the most obvious.30
In contrast to the behaviorist emphasis on adult tutoring, Piaget believed that since development follows a natural, internally controlled stage sequence, what comes from within the child is paramount in guiding cognitive change. The environment, including the social environment, is available for children to interact with as they make sense of their experiences, but it does not determine the evolution of the child’s mind. Instead, Piaget argued that children are in charge of changes in their own thinking and that biological readiness enables them to capitalize on a wider array of environmental opportunities, both physical and social, in revising inadequate, incorrect mental structures and creating new ones.
Piaget’s contribution to the ﬁeld of child development is enormous. He inspired more research on children’s thinking than any other single theorist. Especially important, Piaget convinced the academic community—as well as many parents and teachers—that children are active contributors to their own development, have their own ways of understanding the world, and must be developmentally ready if teaching is to be successful. 
In the ﬁeld of early childhood education, Piaget’s theory sparked preschool classrooms emphasizing discovery learning through children’s spontaneous interaction with the environment. Rather than teaching didactically, teachers in Piagetian-based settings provide a rich variety of hands-on activities and encourage children’s exploration and experimentation. Educators inspired by Piaget’s work hope that by repeatedly applying cognitive structures in stimulating environments, children will notice and amend deﬁciencies in their thinking. 
In a similar vein, Piaget’s ideas served as a major impetus for the open education movement in elementary education, which rapidly gained ground in the late 1960s and early 1970s. It arose in reaction to the child passivity exacted in traditional classrooms, where pupils sat at their desks, listening to teachers transmit ready-made knowledge, and used textbooks as the main medium of learning.31 A glance inside the door of an open classroom reveals richly equipped learning centers, small groups of pupils working on tasks they choose themselves, and a teacher who moves from one area to another, guiding and supporting in response to children’s individual needs.
Furthermore, children’s progress is evaluated dierently in open education than in traditional education. Rather than tracking how well pupils keep pace with norms, or the average performance of same-age peers, open-classroom teachers evaluate children on an individual basis—in relation to their own prior development. Following Piaget’s lead, this approach accepts the premise that children develop at dierent rates, although it assumes that all follow the same stage sequence. Undoubtedly because open education minimizes the importance of meeting normative standards, open-classroom school-age pupils fall slightly behind their traditional-classroom agemates in achievement test scores. Yet children in open settings display other beneﬁts, including gains in critical thinking, greater respect for individual dierences in their classmates, and more positive attitudes toward school.32
As our discussion already suggests, a central Piagetian tenet is that it is foolhardy to try to speed up development. If children are masters of their own learning, then adult eorts to teach them new skills before they indicate they are interested or ready are doomed to failure. Because Piaget stressed the supremacy of children’s engagement with their surroundings over adult teaching, parents’ and teachers’ contributions to development are severely reduced relative to the child’s. In sum, compared to the behaviorist, adult-supremacy perspective, the Piagetian view stands at the opposite pole.
Despite Piaget’s overwhelming legacy, his theory has been challenged. Recent evidence indicates that Piaget underestimated the capabilities of infants and preschoolers and the direct contribution of adults—both parents and teachers—to cognitive change. To illustrate, let’s look at preschoolers’ responses to Piaget’s conservation problems—the best-known examples of the odd logic of his preoperational stage. Shown two rows of six pennies each, after which the pennies in one row are spread out in a longer line, a 4-year-old is likely to say that the longer row has more pennies. Similarly, after a large ball of play dough is divided into six smaller pieces, a preschooler usually insists that the six pieces have more play dough than the ball, even though none was added during the transformation. Yet a wealth of research reveals that when such tasks are scaled down in diculty (for example, using rows of three or four pennies rather than six or seven) or made relevant to children’s everyday experiences (pretending the play dough is cupcake batter and the six pieces are little cupcakes), preschoolers’ understandings appear closer to those of older children and adults than Piaget assumed.33
Furthermore, in tribal and village cultures without formal schooling, children who are cognitively adept in many ways master Piagetian conservation tasks much later than do children in industrialized nations.34 This suggests that to grasp Piagetian concepts, children must take part in everyday activities, such as transforming the appearance of substances and reasoning about the result, that promote this way of thinking. Older children in preliterate communities who fail Piagetian tasks display other impressive cognitive capacities—ones required by and promoted in their culture. For example, among the Zinacanteco Indians of southern Mexico, girls become expert weavers of complex garments through the informal guidance of adults.35 In Brazil, child street vendors with little or no schooling display sophisticated concepts of classiﬁcation and equivalence as the result of buying candy from wholesalers, pricing it with the help of adults and experienced peers, and bargaining with customers on city streets. Yet when tested for similar understandings on Piagetian problems, these children do poorly.36
Finally, many studies show that children’s performance on tasks such as conservation can be improved with training.37 This, along with the cross-cultural ﬁndings just described, raises doubts about Piaget’s assumption that discovery learning rather than adult teaching is the most eective way to foster development.

absence of a unified vision.  Parents trying to make their way through these opposing theories, and their attendant advice about child-rearing and educational practice, are likely to ﬁnd themselves in a dim forest, without a discernible trail blazed before them. Those who respond with sympathy and patience to their child’s inclinations and demands are as taken to task as those who set clear expectations and relentlessly insist that their child “shape up” and comply with them. 
Parents who throw up their hands in desperation and search through their own parents’ or grandparents’ shelves for a more “tried and true” vision will ﬁnd themselves mired in the same conundrum. They might, for example, run across Arnold Gesell’s books of the 1940s and 1950s—The Infant and Child in the Culture of Today, The First Five Years of Life, and The Child from Five to Ten38—still prominent in many bookstores. Oering a lock-step description of physical, intellectual, and emotional milestones at each age, Gesell aimed to reassure uneasy parents that children’s problematic behaviors were merely a phase—part of a biologically based sequence requiring understanding, not correction. A search of the previous generation’s parenting handbooks might uncover other volumes of this child-centered wave, including In Defense of Children, Children Have Their Reasons, and even Stop Annoying Your Children and Parents, Behave! 
Experts of Gesell’s time complained that he went too far in downplaying the role of parents. His advice was soon overshadowed by Benjamin Spock’s standby, Baby and Child Care, published in 1946 and selling millions of copies over seven editions, the most recent appearing in 1998.39 Providing answers to virtually any question about child rearing that might occur to a parent, from physical care to emotional, disciplinary, and educational issues, Spock seemed, on many fronts, to lean toward parental ﬁrmness and away from children’s rule-of-the-roost. A closer look, however, indicates that even Spock felt torn between the embattled forces of adult and child control. He tried to grant legitimacy to both poles, commenting that perhaps it’s not what you do but how you do it: 

A strictness that comes from harsh feelings or a permissiveness that is timid or vacillating can each lead to poor results. The real issue is what spirit the parent puts into managing the child and what attitude is engendered in the child as a result.40 

Above all, Spock admonished parents to trust themselves, to have the courage of their convictions. Yet many parents “at sea”—in search of a sound child-rearing ideology within the morass of clashing dictates—undoubtedly found Spock’s directive hard to follow.
The past three decades have seen a continuation of this dichotomy of extremes in parenting advice and educational practice. In the 1970s, titles appeared that blew the whistle on permissiveness and child-centeredness, such as Don’t Be Afraid of Your Child and Power to the Parents. As part of this rebound, Thomas Gordon’s Parent Effectiveness Training 41 oered to rescue parents who had allowed their child to ride roughshod over them. In the realm of children’s learning, books in the behaviorist tradition, advocating intensive, early academic training, resurfaced. A prominent example, Siegfried and Therese Engelmann’s blueprint for raising a brighter preschooler, Give Your Child a Superior Mind, appealed to parents bent on boosting their child’s IQ or—even better—producing a genius. In spelling out the theory, the Engelmanns dismissed the legitimacy of biological readiness and proclaimed,

Every single genius at the top end of the IQ scale received early training. Every single one was subjected to an extremely active environment, not one that folded its hands and waited for the child to “mature.” . . . The environment has to be empowered with the capacity to transform the “universal baby.” . . . A child is the product of what he learns. His intelligence, capacity and range of skills reﬂect his environment—his teachers.42

Educational practice followed suit, moving back toward traditionalism. As Scholastic Aptitude Test (SAT) scores of American high school graduates plummeted and concern over the academic preparation of American children and youths became widespread, a “back to basics” movement arose that, by 1980, was in full swing. Academic preschools ﬂourished, and kindergarten and primary classrooms returned to whole-class, teacher-directed instruction relying heavily on workbooks and frequent grading, a style still prevalent today.43 
Bipolar tensions in parenting advice and in educational methods continue to the present day. David Elkind’s book The Hurried Child44 is among the best-known of parenting volumes in the child-centered, Piagetian tradition. Elkind appealed to parents prone to live for and through their child’s accomplishments to give up their vain desire for a superkid, refrain from exaggerating the child’s competence, and stop rushing and pushing the child into adulthood. In keeping with Rousseauian ideals, The Hurried Child advises parents to protect children from the harsh realities of the grown-up world and not to “stress them out” by expecting achievements beyond their biologically based limits. 
As Elkind illustrates, a 10-year-old with many adult responsibilities—such as preparing breakfast, doing housecleaning after school, checking that a younger sibling is all right, assisting with meal preparation, and washing dishes—barely has time for her own personal, homework responsibilities and is in danger of excessive stress from “responsibility overload.”45 Schools, too, Elkind maintains, hurry and stress children by assigning too much tedious work and rushing them from one subject to another, depriving them of time to think and a sense of completion.
Harshly critical of the child-centered tenor of Elkind’s message and pulling in the reverse direction is William Damon’s Greater Expectations,46 an impassioned plea to parents and teachers to eradicate what the author characterizes as a rising, insidious “culture of indulgence” in America’s homes and schools: “Too many children—the auent and the poor alike—are drifting through their childhood years without ﬁnding the skills, virtues or sense of purpose that they will need to sustain a fruitful life.”47
As Damon explains, the child-centered philosophy was a major breakthrough when ﬁrst introduced, in that it made parents and teachers aware that children have unique needs and beneﬁt from warmth and encouragement. But, Damon contends, modern child-centeredness has been stretched to the point of unrestrained child gratiﬁcation, resulting in a youth culture in which children and adolescents are less engaged, less purposeful, less accomplished academically, and more egoistic and antisocial than in previous generations.
Damon acknowledges that economic constraints and other family pressures play a part in this youth disaection. But he places most blame on how contemporary children are reared. Child-centeredness, Damon explains, has become an excuse for a rudderless parenting and educational culture that makes few demands while fostering in children a stress-free, “feel-good” attitude in which children are told, ”You’re lovable,” “You’re great,” “You’re terriﬁc,” regardless of what they do. But because these messages have no basis in meaningful attainment, they are counterproductive. Sooner or later, children see through them, come to mistrust the adults who repeat them, and begin to doubt themselves.
Damon neither endorses the insensitivity of adult dominance nor the tumultuous reign of the child. Instead, he underscores that children are avid, active learners, but adults must cultivate their drive toward mastery. They must induce children to develop talents, skills, good values, and a sense of accomplishment through engagement not just in activities that are easy and fun, but in ones that are meaningful and challenging—that help them sustain eort in the face of diculty, overcome obstacles, and advance to greater heights. 
As Damon’s message suggests, in building an eective vision of child development and child rearing, neither the child’s inner thoughts and feelings nor the role of adult guidance can be singularly extolled or wholeheartedly ignored. To do either leads parents and educators to become trapped in a false opposition, to vacillate, and to think in oversimpliﬁed ways about how best to help children realize their potential to learn and become personally and socially responsible. 

toward a balanced perspective.  The popular parenting literature is notable for lagging substantially behind advances in child-development theory and research. Today, sound theories and educational strategies exist that are neither adult- nor child-centered but, instead, portray both as participating actively, jointly, and inseparably in the process of development. 
On only one point is the popular parenting literature unanimous: the vital importance of getting development o to a good start during the preschool years. The earlier adults begin and the more continuously they engage in eective practices, the more likely children are to sustain eort, achieve in school, develop productive interests, and become responsible, caring individuals. The longer adults postpone and the more unpredictably and inconsistently they behave, the greater the chances that children will develop maladaptive habits and unfruitful interests, doubt their capacities, become dissatisﬁed with themselves, and despair about their prospects for the future. 
After decades of theoretical division and debate, a new, more complex view of child development is coalescing in the ﬁeld, supported by rapidly accumulating research evidence. The fragmented, polarized theories of the past are giving way to more equitable theories emphasizing that the child and the social environment interact and that the contributions of each to development cannot be separated and weighted in a simplistic, one-sided manner.48
Understanding this new view can be immeasurably helpful to parents, caregivers,49 and teachers in providing children with development-enhancing experiences, since it oers a way of thinking about child rearing and education that they can call on to guide decision making in daily life. But a vital prerequisite for enacting this perspective is that parents, especially, must arrange their lives in such a way as to invest time and energy in young children. Indeed, as we will soon see, some children—because of genetic background, biological risk, or previous inept caregiving—require more intensive investment of parental energies than do others. Before we take up this emerging theoretical consensus, let’s address the question of whether greater parental commitment, in the context of today’s demanding and stressful work lives, is possible.


reevaluating the time bind

Parents, as I noted earlier, often complain that they have too little time for children—indeed, too little time to sleep, read, cook, exercise, and socialize as well! Their sense of being overworked and overcommitted, with few moments to spare, must be taken seriously. Feeling constantly frazzled can, in and of itself, interfere with relaxed, patient investment in children.
Yet how pernicious and unique to our lives is this time bind? To gain perspective on this question, I contacted a noted historian of family life,50 who suggested that I consult John Ise’s book, Sod and Stubble, in which Ide chronicles his mother Rosie’s life on a homestead in rural Kansas in the late nineteenth century as she farmed, kept house, and reared eleven children.51
Settling with her husband, Henry, on the land in a one-room cabin, Rosie cooked on a stove so small that she could bake only two loaves of bread at a time, so she had to bake almost every day. She sewed to make the family’s entire wardrobe—her own, her husband’s, and each of her eleven children’s. Keeping up the cabin posed constant diculties. Cracks in the ﬂoor planks and in the log walls permitted various pests to enter, so Rosie battled bedbugs, grasshoppers, and ants, which required frequent searches of the house with a kettle of hot water in one hand and a can of kerosene and a feather in the other. Always, preparations had to be made for the next season—in the fall, for example, cooking enough molasses to last the winter, a task requiring weeks of work.
Outside, Rosie assisted Henry with myriad chores—herding and feeding livestock; making lye from wood ashes to be used in hulling corn for hominy; browning rye for coee; harvesting wheat; and planting and caring for trees, ﬂowers, grapevines, and a vegetable garden. When she was not helping with the crops and the garden, she could be seen washing and hanging out huge baskets of clothes. On rainy days, Rosie grabbed pans from the shelves to catch the water that dripped through the cabin’s sod roof, remaining poised to shift the pans from place to place as new leaks sprang. 
Still, Rosie and her husband Henry had time for their children, as well as time to participate in family gatherings, community events, and learning and literacy societies. While the children were small, they accompanied their parents on outings and during outdoor chores—for example, riding in the rear of the corn-husking wagon, where Rosie and Henry could easily see and talk to them. As they grew older, the children played at adult tasks and soon joined in and helped with many of them. 
Despite grim work lives, Rosie and Henry, who had little schooling themselves, sent nine of their children to college and some to graduate school. They managed to be involved and caring parents, without all the comforts and time-saving conveniences that we now take for granted—a water-tight roof; central heating; fast foods; microwaves; vacuum cleaners; washing machines and dryers; automobiles; telephones; and much, much more.
Though Rosie’s and Henry’s way of life was hard, and we shouldn’t go too far in romanticizing it, their story helps us put the contemporary time bind in perspective. It suggests that many parents who feel overwhelmed by life’s demands ought to be able to free up more time for their children—the ﬁrst step toward high-quality child rearing. Recent research by time-allocation experts John Robinson and Georey Godbey substantiates this conclusion. Although Americans perceive their work hours as excessive, squeezing out other aspects of their lives, a dierent picture emerges when they keep detailed diaries of how they spend their time. Every 10 years since 1965, Robinson and Godbey have gathered daily time diaries from thousands of respondents, representing a cross-section of the American population. They discovered that not only are people’s gross estimates of time per week devoted to work 6 to 8 hours higher than those recorded in their diaries, but free time—time unencumbered by any obligations—has actually increased! 
Americans are working less than they did in 1965—about 6 fewer hours per week for men, 5 fewer for women.52 Diary-obtained estimates of free time average 36 hours per week for employed men, 34 for employed women. Robinson and Godbey note that compared to a generation ago, the free time of Americans is more plentiful but also more disjointed—a half hour here, an hour there. How do they spend it? Americans report that TV viewing consumes nearly 40 percent—about 15 hours—of their unallocated moments. It seems easier to watch the news or an episode of a favorite TV show than to go to a concert, enjoy a leisurely family dinner, or take the children to a museum or the zoo.
Time-diary ﬁndings also verify that time constraints are greater for higher-income Americans. Yet the income gap in free time is not large; ﬁnancially well-o individuals average only 2 to 4 hours a week less free time than do their less economically advantaged counterparts. Weekly free time for privileged Americans with demanding careers is still plentiful. 
If free time is so abundant, why do so many parents say their lives are pressure cookers? The reason, Robinson and Godbey suggest, is that our pace of life is faster. People expect to do more, to live more intensely. Hence, they try to speed up the yield of time, often by doing several things at once—in the case of Angela and Tom, attending to work tasks while ﬁxing dinner, watching TV, and ﬁelding Victor and Jeannine’s urgent pleas for attention. The very activity of squeezing more into the moment exacerbates the belief that time is scarce. This “time-famine” sensation is the wellspring of parental eorts to create quality time in the absence of quantity—a contradiction in terms. 
How can parents beat the “time bind”? Rather than merely cultivating time-saving skills—a remedy that, by itself, may even further compress time spent with children—Robinson and Godbey recommend that parents ﬁnd ways to meld time-saving with time-savoring. When parents have full-time jobs, some time pressure is bound to be present—in getting shopping, laundry, and cleaning done; meals on the table; and children to and from child care, school, and various activities. Yet to grant children adequate attention and involvement, there is no substitute for slowing down and reexamining the pace of everyday life. Parents must ask questions like these: 

•Does my family have a sit-down meal together on most days of the week, free from the distractions of a blaring TV and a constantly ringing telephone? 
•Do I have time on most days to interact one-on-one with each of my children? 
•Do I involve my children positively and usefully in play and recreation and in accomplishing tasks of daily living—shopping, cleaning, gardening, cooking, decorating, and repairing? 
•Do I provide my children with predictable routines; clear, consistently enforced rules; and sucient oversight, while they are both within and beyond my immediate supervision—practices that help ensure that the time I share with them is plentiful, pleasurable, and constructively spent?
Clearly, true quality time for children is quantity time and more! Fashioning time for parents and children to be together is the ﬁrst step toward implementing the ideas and practices I’ll discuss in this book. A second step is an appreciation of the multiplicity of factors that contribute to development—an understanding that spells out parents’ vital role yet clariﬁes how it joins with other forces to aect children’s development and well-being. 


child development: a new consensus

At the dawn of a new millennium, a fresh set of theories of child development has blossomed. The new approaches are numerous—some more concerned with motor skills, others with cognitive competencies, and still others with emotional and social development. Yet they form a consensus, a set of variations on a uniﬁed theme.53 Each borrows features from past perspectives that have withstood the test of time and integrates them with current evidence. The result is a new outlook on how children acquire more complex and eective skills. 

Many Factors Contribute to Development

The new view assumes that many elements, internal and external to the child, work together as a dynamic, synergistic system to aect children’s thinking, feeling, and acting. These elements include the child’s heredity and biological constitution; the people and objects in the child’s everyday settings of home, child-care center, school, and neighborhood; community resources for child rearing (such as family-friendly workplace policies and high-quality, aordable child care); and cultural values and customs related to child development and education.54
Look closely at these ideas—that children are aected by interwoven factors in biology, everyday contexts, and culture—and you will see that contemporary researchers are no longer one-sided in how they view the power of the child versus the adult, or heredity versus environment. Most have turned away from asking which inﬂuence is more important to uncovering how nature and nurture work together to aect the child’s traits and capacities.
In addition, researchers now realize that quite normal children show both similarities and dierences in pathways of change. A common human genetic heritage and basic regularities in children’s physical and social environments yield certain universal, broad outlines of development. At the same time, biological makeup, everyday tasks, and the people who support children in mastery of those tasks vary greatly, resulting in wide individual dierences in speciﬁc skills.55 And because children build competencies by engaging in real activities in real contexts, dierent skills vary in maturity within the same child! Recall the Zinacanteco Indian child weavers and the Brazilian child street vendors, who are advanced in skills relevant to their own culture yet behind on tasks devised for children in Western industrialized nations. They oer a dramatic illustration of developmental variation—both between children and within the same child. 

Heredity and Environment as Inseparable 

Within this dynamic system in which inner and outer forces jointly engender development, each contributing factor inﬂuences—and is inﬂuenced by—the others. Therefore, the roles of heredity and environment, of the child and important people in his or her life, so closely interconnect that according to some experts, their inﬂuence is inseparable.56 To illustrate, let’s take two vibrant, contemporary research topics relevant to young children’s learning: (1) the dramatic growth of the brain during the ﬁrst 6 years, and (2) young children’s temperaments, or genetically inﬂuenced styles of relating to their physical and social worlds. 

brain development. Many people think of infancy and early childhood as a time when the human brain is especially sensitive to experience. In line with this view, although genes provide the code for basic brain structures and functions, heredity goes only so far in aecting the organization of the child’s brain and the rate at which it develops. The environment has a crucial, profound impact.
How does early experience join with biology to aect brain development? The cerebral cortex, seat of human intelligence, undergoes dramatic growth during the ﬁrst few years. Almost all its neurons—cells that store and transmit information—are in place by the second trimester of pregnancy. Once established, neurons begin to take on unique functions by sending out branching ﬁbers, which form elaborate connections with other neurons. Formation of this complex communication system contributes to an enormous increase in size of the brain—from nearly 30 percent of its adult weight at birth to 70 percent by age 2 and 90 percent by age 6.57
As neurons form connections, a new factor becomes vital in their survival: stimulation. Neurons stimulated by the surrounding environment continue to establish new connections, which support more complex functions. Neurons seldom stimulated soon lose their connections as their ﬁbers atrophy. Notice how, for the biological side of brain development to go forward, appropriate stimulation is essential while formation of neural connections is at its peak.58
During early childhood, the brain is highly plastic, or adaptable, in that many brain regions are not yet committed to speciﬁc functions. This means that if a part of the brain is damaged, other parts can usually take over the tasks that would have been handled by the damaged region, provided they are granted the necessary stimulation. In a study of preschool children with a wide variety of brain injuries sustained in the ﬁrst year of life, psychologist Joan Stiles found that cognitive deﬁcits were milder than those observed in brain-injured adults. And by age 5, virtually all impairments had disappeared! As the children gained perceptual, cognitive, and motor experiences, stimulated intact areas of the cerebral cortex compensated for the early damage.59 By age 8 to 10, most brain regions have taken on speciﬁc functions, so brain plasticity declines. Because of rapid brain growth and gradual decline in brain plasticity, the ﬁrst 5 to 8 years of life are regarded as a sensitive phase of development in which appropriate stimulation is necessary for children to reach their full genetic potential.
In describing the close connection between brain growth and experience, I have used the expression “appropriate stimulation.” By this, I mean neither impoverished conditions nor excessive bombardment with sights and sounds but input that the child can absorb, as indicated by his or her approach, interest, and concentration. In Burton White and Robert Held’s classic study of the impact of early stimulation on development, young babies in a barren institution given a moderate amount of stimulation tailored to their ability to handle it—at ﬁrst, a few simple designs on the side of their crib and later, a fancy mobile—reached for and explored objects six weeks earlier than did infants given nothing to look at. A third group of babies given massive stimulation—patterned crib bumpers and fancy mobiles beginning in the ﬁrst few weeks of life—also reached for objects sooner than did unstimulated babies. But this heavy dose of enrichment took its toll. The massively enriched infants looked away and cried a great deal, and they were not as advanced in reaching and exploring as the moderately stimulated babies.60
Much research conﬁrms that overloading children with input leads to disorganization of behavior. Excessive stimulation also causes them to withdraw as they try to shield themselves from a stimulus deluge, thereby creating conditions that, paradoxically, are much like stimulus deprivation!61 These ﬁndings help us understand, from a brain-development perspective, the detrimental impact of excessive adult tutoring on young children, described earlier in this chapter. They also raise grave concerns about the recent proliferation of expensive commercial early learning centers, in which infants are barraged with letter and number ﬂashcards and slightly older toddlers are drenched in a full curriculum of reading, math, science, art, music, gym, and more.62 Rather than optimizing early neurological growth (as proponents claim), these eorts to jump-start young children can inﬂict considerable harm, robbing them of a healthy start on the road to maturity.63
Our rapidly expanding knowledge base on brain development and children’s learning reveals that a genetically inﬂuenced roadmap for brain growth and a developmentally appropriate environment go hand in hand; the impact of each depends on the other. Appropriate stimulation “wires” the brain, prompting it to form new connections and its regions to specialize. As this process goes forward, the brain gradually becomes receptive to increasingly complex and varied stimulation. This fosters further elaboration and specialization of brain structures and ever more advanced knowledge and skills. 

temperament.  From the earliest ages, children vary greatly in preferences, interests, talents—and in temperament, or style of emotional responding, the most thoroughly studied of these sources of individual variation. Temperament encompasses activity level, ability to attend to stimuli, and capacity to adjust the intensity of emotions to a comfortable level so the child can remain adaptively engaged with his or her physical and social surroundings.64 
Temperamental dierences among infants and children are of great interest to researchers because temperament is believed to form the cornerstone of the adult personality. A wealth of research reveals that for children to develop at their best, the experiences adults provide must be adapted not just to children’s general neurological progress, but also to their unique temperamental needs. 
Temperamental traits most often studied include attention span, fear of novel experiences, irritability when desires are frustrated, and quality of mood (positive versus negative).65 Parents can rate their children’s temperamental qualities fairly accurately; their judgments show a reasonable correspondence with researchers’ observations of children’s behavior.66 Teacher ratings are even more precise, since teachers are familiar with many children and therefore have a broader basis for judging whether a particular child is high, low, or intermediate on dimensions of temperament. 
Let’s see how temperament combines with brain development and experience, forming a complex, dynamic system that shapes the course of development. Take Larry, who when brought as an infant to a highly stimulating laboratory playroom, was agitated and upset by all the new sights, sounds, and people. Yet baby Mitch, when introduced to the very same playroom, watched with interest, laughed, and eagerly approached the exciting toys and strangers. Larry scores high on the temperamental dimension of fearful distress. On observing him, most of us would call him a very shy, inhibited child. Mitch, in contrast, scores low on fearful distress and high on positive mood. He is, in everyday language, an uninhibited, sociable child.
To chart the development of shy and sociable children, psychologist Jerome Kagan followed several hundred youngsters from infancy into the school years, repeatedly observing their behavior and measuring their physiological responses to highly stimulating, unfamiliar events. As babies, about 20 percent were easily upset (like Larry), whereas 40 percent were comfortable, even delighted, at new experiences (like Mitch).67 
According to Kagan, individual dierences in arousal of an inner brain structure called the amygdala, which controls avoidance reactions, underlie these contrasting temperamental styles. In shy, inhibited children, novel stimuli easily excite the amygdala and its connections to the cerebral cortex and sympathetic nervous system (which prepares the body to act in the face of threat). The same level of stimulation evokes minimal neural excitation in highly sociable, uninhibited children. Indeed, shy children’s physiological responses to novelty—a rise in heart rate, pupil dilation, blood pressure, and blood concentration of cortisol (a hormone that combats stress)—resemble the reactions of very timid animals and are known to be mediated by the amygdala.68 When neural messages from the amygdala reach the cortex, they lead a shy child to interpret new experiences negatively and a sociable child to interpret them positively. Indeed, brain waves in the cortex dier strikingly for these two types of children.69
Are these early, biologically based temperamental styles destined to last, restricting learning opportunities for shy children while opening new doors for their sociable counterparts? The answer, once again, depends on experience—especially, parenting practices. When parents shield infants and preschoolers who dislike novelty from minor stresses—such as eating and sleeping in a new setting or meeting new people—they make it harder for the child to overcome the urge to retreat from unfamiliar events. Under these conditions, heredity and environment act in concert to maintain the child’s fear, increasing the likelihood that it will translate into long-term adjustment diculties, such as excessive cautiousness, social withdrawal, loneliness, and (by school age) overwhelming anxiety in the face of academic challenges.
This does not mean that a shy child should be forced into new situations with coldness, harshness, and impatience—tactics that magnify their dread of new and unpredictable events. Instead, parents who warmly, but consistently and assertively, require their inhibited child to try new experiences and guide and support them in doing so actually reduce the child’s physiological stress reactions, fostering a more adaptive style in the child. Indeed, adult eorts of this kind are believed to be largely responsible for the fact that about 70 percent of extremely inhibited babies cope with novelty more eectively as they get older (although practically none become highly sociable).
Shy and sociable children also require dierent adult interventions to promote exploration of their surroundings—an activity that (as Piaget pointed out) is essential for optimal cognitive development. Vivacious, stimulating parental behavior, including frequent questioning, instructing, and pointing out objects, is beneﬁcial for reserved, inactive infants; it helps them become interested in and engaged with novel toys. Yet these same parental behaviors interfere with exploration in very active, outgoing children.70 For these youngsters, too much adult intervention is intrusive; it dampens their natural curiosity. Consequently, “appropriate stimulation” varies for these two types of children.
Finally, culture aects the likelihood that parents and teachers will respond to shy children in ways that foster their development. In Western nations, shyness is regarded as a form of social maladjustment—a perspective that heightens the chances that adults and peers will react negatively to inhibited children’s reticence and retreat. In China, adults evaluate shy children positively, as advanced in social maturity and understanding! The high value placed on self-restraint in Chinese culture leads shy children to receive very positive feedback from adults and peers. Consequently, inhibited Chinese youngsters appear particularly well adjusted during the school years—well liked by their classmates and rated by their teachers as academically and socially skilled.71

The Roles of Parents and Other Adults: Agents of Change, Buffers, Gatekeepers, and Conveyors of Culture 

Environmental forces, from adult–child interaction to cultural values, join with heredity to aect the development of children with other temperamental dispositions as well. Throughout this book—and especially in Chapter 5, which addresses the development of children with physical and mental disabilities—we will see many more examples of these synergistic eects. In each, the role of parents and teachers as agents of change is vigorous and profound, although not sovereign and exclusive. Parents cannot erase their child’s genetic propensities, but they can alter many of them in a favorable direction, especially if they have access to knowledge about eective child rearing and they intervene in early childhood, the years of greatest neurological malleability. 
Furthermore, when parents and other adults apply good rearing practices, they serve as buers, or sources of protection, for children against threatening forces in the wider world. A common thread in research on the impact of stressful life events and conditions (including poverty, divorce, abuse, community violence, and wartime trauma) is that a close relationship with a parent, relative, or teacher who introduces aection, assistance, and order into the child’s life, fosters resiliency—mastery of cognitive and social skills that enable the child to withstand and even overcome adversity. To be sure, children who are relaxed, socially responsive, and able to deal with change are more likely to elicit the support of parents and other adults. At the same time, children can develop more attractive dispositions and adaptive skills as the result of parental warmth, attention, and consistent guidance.72
Parents and teachers also act as gatekeepers for young children. Depending on the experiences they oer, they open up or close o a great many avenues for learning. These include toys, books, television, computers, special lessons, weekend outings, time with grandparents and other extended family members, as well as the quality of child care, schooling, and the neighborhood they choose to live in (depending, of course, on the extent to which communities oer viable choices). 
In all the ways just mentioned, parents and other adults are vital conveyers of culture, through direct teaching of attitudes and values and through the pervasive imprint of culture on the settings and activities they provide for children. In the hands of parents and teachers lies the awesome responsibility of conveying to the next generation the intellectual, scientiﬁc, aesthetic, and moral achievements that dierentiate our species from others. From the simplest preliterate society to the most technologically advanced nation, adults are charged with ensuring that children acquire competencies that enable them to assume a responsible place in their society and, ultimately, participate in transmitting its values and practices to future generations. 
Of course, children have an important say in the socialization process. For example, they usually become more expert at those skills that complement their native talents. And depending on their dispositions, the road to maturity may be rockier, requiring greater investment of parental energies and distinct child-rearing strategies. Moreover, without a doubt, peers contribute greatly to socialization—especially by helping children learn to resolve conﬂict, cooperate, share, form deep attachments beyond the family, and otherwise behave in ways that foster social harmony. But the recent, widely publicized claim of Judith Rich Harris, in her book entitled The Nurture Assumption73—that parents are minor players who are overshadowed by children’s genetic makeup and peer culture—is not correct. 
Indeed, many eminent child development researchers have countered Harris’s thesis. 74 Genes and peers do not supplant adult agents, including parents, grandparents, aunts, uncles, family friends, and teachers. Harris draws on evidence suggesting that children’s inherited intellectual and personality attributes lead them to evoke particular responses from adults, which further strengthen the child’s inherited traits. For example, a friendly baby receives more social stimulation than a quiet, passive infant; a cooperative, attentive preschooler receives more patient and sensitive interaction than does an inattentive, distractible child; and a bright, advanced child is praised and stimulated more than a child developing more slowly. Hence, Harris concludes, most children follow a genetically preordained developmental course, regardless of parental inﬂuence.
Although Harris is correct that children often evoke behaviors from parents and others that strengthen their genetic tendencies, research clearly shows that parents can, and often do, uncouple these child-to-parent eects. Indeed, the substantial malleability of temperament in infancy and early childhood is explained, in large measure, by the fact that many parents and other adults are successful in guiding children with maladaptive tendencies toward more eective functioning. Moreover, decades of research on intelligence show that IQ, although not inﬁnitely pliant, varies greatly with the stimulating quality of children’s experiences.75
Furthermore, no conclusive evidence exists for the assertion that the most consequential environment for children’s development is the peer group rather than the family. It is based on an array of selective and equivocal ﬁndings, mustered to convince readers that parenting eects are conﬁned to how children behave in parents’ presence and do not extend beyond the home. I will show repeatedly in this book that just the opposite is so—that parenting practices have much to do with children’s competence at language and communication; sensitivity to others’ feelings and needs; capacity to get along with others within and beyond the family; achievement in school; and guiding values, beliefs, and attitudes.
In fact, this overriding emphasis on peers as a source of positive development is itself a product of our culture. Compared to other nations, the United States is more peer-oriented; it places greater value on gregariousness and being liked by agemates.76 As more American parents with busy, stressed lives retreat from their children, peers take over. Without a constructive link between the values taught at home and the values of the peer group, the consequences of high peer orientation are decidedly negative—a rise in school failure, aimlessness, drug use, teen pregnancy, antisocial behavior, and other youth problems of current concern in the United States.
Downplaying the role of parents—suggesting that they are relatively unimportant in socialization—does both families and society a disservice. It leads parents, like Noah and Suzanne, who are on the cusp of a dramatic period of development in their 2-year-old son’s life, to express grave doubts about their own importance. Harvard University psychologist Howard Gardner notes:

Children would not—could not—grow up to be members of a civilized culture if they were simply left to the examples of their peers. . . . A social science—or a layman’s guide—that largely left out parents after birth would be absurd. So would a society.
Whether on the scene, or behind the scenes, parents have jointly created the institutions that train and inspire children: apprenticeships, schools, works of art and literature, religious classes, playing ﬁelds, and even forms of resistance and rebellion. These institutions, and the adults who run them, sustain civilization and provide the disciplines—however fragile they may seem—that keep our societies from reverting to barbarism.77


sociocultural theory: dialogues with children 

This book takes its inspiration from sociocultural theory, one of the dynamic, synergistic perspectives that has recently captivated the ﬁeld. The central idea of sociocultural theory is that the child and his or her social surroundings join to provide direction to development; participation in social life guides and energizes the child’s mastery of new, culturally adaptive skills. Because sociocultural theory focuses on children’s access to and interaction with cultural experts, it has much to say to parents and teachers about how they can help children develop into responsible, contributing members of society. 
Sociocultural theory originated with Russian psychologist Lev Vygotsky, who carried out his highly innovative research during the 1920s and early 1930s, writing proliﬁcally on the contribution of social experience to children’s learning. After the Soviet Union’s twenty-year ban on Vygotsky’s writings was lifted in the mid-1950s, his major works reached the West. They began to be translated into English in the 1960s and 1970s.78 By the 1980s, many American psychologists and educators—doubting the Piagetian view of development and desiring to account for wide variation in children’s competencies—embraced Vygotsky’s ideas with enthusiasm.79
According to sociocultural theory, cooperative dialogues between children and more knowledgeable members of their society are necessary for children to acquire the ways of thinking and behaving that make up a community’s culture. These dialogues occur frequently and spontaneously as adults and children spend time together—in everyday situations such as household chores, mealtimes, play, storybook reading, outings in the community, and children’s eorts to acquire all sorts of skills. Although interactions that arise between adults and children may seem mundane and inconsequential at ﬁrst glance, sociocultural theory emphasizes that they are powerful sources of children’s learning.
Consider the following conversation between Mel and his 4-year-old son, Ben, as the pair took a summer-evening walk on a California beach near their home. Mel had brought along a plastic bag, as the beach was often littered with trash after a busy day.

Ben: (running ahead and calling out) Some bottles and cans. I’ll get them. 
Mel: If the bottles are broken, you could cut yourself, so let me get them. (Catches up and holds out the bag as Ben drops items in)
Ben: Dad, look at this shell. It’s a whole one, really big. Colors all inside! 
Mel: Hmmm, might be an abalone shell.
Ben: What’s abalone?
Mel: Do you remember what I had in my sandwich on the wharf yesterday? That’s abalone.
Ben: You eat it?
Mel: Well, you can. You eat a meaty part that the abalone uses to stick to rocks. 
Ben: Ewww. I don’t want to eat it. Can I keep the shell?
Mel: I think so. Maybe you can ﬁnd some things in your room to put in it. (Points to the shell’s colors) Sometimes people make jewelry out of these shells. 
Ben: Like mom’s necklace?
Mel: That’s right. Mom’s necklace is made out of a kind of abalone with a very colorful shell—pinks, purples, blues. It’s called Paua. When you turn it, the colors change.
Ben: Wow! Let’s look for Paua shells!
Mel: You can’t ﬁnd them here, only in New Zealand.
Ben: Where’s that? Have you been there?
Mel: No, someone brought Mom the necklace as a gift. But I’ll show you New Zealand on the globe. It’s far away, halfway around the world.
In this dialogue, which lasted only a few minutes, Mel conveyed important social values and a wealth of information to Ben—about responsibility for preserving the environment, about safety precautions, about the wonders of an unusual sea creature, about the beauty and utility of natural objects, and even about world geography.
According to sociocultural theory, as adults—and more expert peers as well—help children participate in culturally meaningful activities, the communication between them becomes part of children’s thinking. Once children internalize essential features of these dialogues, they use the language within them to accomplish new skills and to gain control over their own thought and behavior.80 The young child speaking to herself when tempted by a forbidden object (“Don’t touch!”), solving a dicult puzzle (“Where does this piece go?”), ﬁnding an interesting shell on the beach (“Looks like Mom’s shiny necklace.” ), or acting out a scene in make-believe play (“What would you like for lunch? An abalone sandwich?”) has started to produce the same kind of guiding comments that an adult previously used to help the child think about the world and engage in important tasks. 

A Socially Formed Mind

Sociocultural theory is unique in viewing inner mental activity as profoundly social. The thoughts and imaginings that make us distinctly human are not regarded as independently constructed by the child. Rather, the child derives them from his or her history of relations with other people. 
According to Vygotsky, infants are biologically endowed with basic perceptual, attentional, and memory capacities that they share with other animals. These undergo a natural course of development through direct contact with the environment during the ﬁrst two years of life, similar to the process of exploration and discovery described by Piaget. For example, all babies gradually distinguish objects and people in their surroundings and realize that these entities continue to exist when out of sight. They also merge objects that are alike into categories (such as vehicles, animals, birds, and eating utensils), laying the foundation for mentally representing their experiences and thinking eciently. And they become adept at imitating others, a powerful means for acquiring new skills. These and other infant capabilities set the stage for language, which develops with extraordinary speed after 1 year of age. By ages 2 to 3, most children are skilled conversationalists; by age 6, they have mastered most of the grammatical rules of their language and have vocabularies as large as ten thousand words.81 
The milestones just cited are broad universals of development. They characterize children everywhere, as long as they are biologically prepared to learn and live in stimulating physical and social surroundings. But once children become capable of representing objects and events with symbols, especially language, their ability to participate in dialogues is greatly enhanced. This leads to a crucial change in development. The natural line of development makes closer contact with its surrounding social context, merges with it, and is transformed by it.82 Children’s social exchanges begin to inﬂuence their ways of thinking more profoundly than before, permitting them to acquire competencies in keeping with the requirements of their families and communities.
A basic premise of sociocultural theory is that all uniquely human, higher forms of thinking—including controlled attention to tasks, memory strategies, reﬂections on experiences and ideas, techniques for solving problems, and imagination—are deeply aected by children’s social experiences. For example, when a parent suggests to a young ball player, “Watch me, keep your eyes on the ball!” the adult helps the child control attention, essential for mastering any complex task. When a teacher says, “Let’s write the names of our snack helpers on the board,” or “Put all the animals together and all the vehicles together,” she teaches vital strategies for remembering. And a parent or teacher who asks, “Is Brenda crying because you took her colored pencils? What can you do to become friends again?” encourages children to reﬂect on their experiences and to think of eective techniques for solving social problems.
Vygotsky emphasized that to understand children’s development, it is necessary to understand the social situations adults devise for them. Any higher form of thinking, he pointed out, ﬁrst appears in social communication, between the child and representatives of his or her culture as they engage in a joint activity. Only later does it appear within the child, as an individual capacity or skill.83 The child’s mind, then, is a profoundly social organ. Through social life, it makes contact with and is inﬂuenced by other, more expert minds, permitting transfer of the values, knowledge, and skills essential for success in a particular culture.

The Importance of Language

Because Vygotsky regarded language as the major bridge between our social and mental worlds, he viewed language acquisition as the most signiﬁcant milestone in children’s cognitive development. Language is our primary avenue of communication with others and means through which we represent our experiences. Once children start to think with words, language becomes an indispensable “tool of the mind.” Just as a hammer is a tool used to gain control over and transform physical objects, so we call on language to inﬂuence the thought and behavior of other people and ourselves.84 
Language not only conveys culturally meaningful ideas but is itself deeply imbued with culture. It—along with other symbolic tools, such as gestures, aids to memory, systems for counting, works of art, diagrams, and maps—is the product of the social history of a cultural group, the result of members’ eorts to create a communal way of life. Indeed, the central purpose of language, from its moment of emergence, is “communication, social contact, inﬂuencing surrounding individuals.”85 Then it becomes an individually applied tool for governing our own thoughts and actions.
To illustrate how Vygotsky envisioned this close connection between social interaction and children’s thinking and behaving, let’s look in on another verbal exchange between a parent and a young child. Deb is pulling weeds in the garden while 2 1/2-year-old Maggy follows along, alternately digging with her small spade and holding a toy telephone to her ear. Soon gray clouds appear along the horizon, and thunder can be heard. Maggy, frightened by the booming sounds, whimpers to Deb, “Scary, Mommy. Go inside!”
“That thunder is way up in the sky, far away,” Deb explains, pointing o in the distance. “It can’t hurt you. We need to get these weeds out before the rain comes. Just a little longer, and then we’ll go inside.”
Maggy listens and responds, “Not scary, far far away,” and Deb nods in agreement. As Maggy waits, she paces back and forth near Deb, speaking into her toy phone, “Not scary thunder. Far away. Get the weeds. Not scary, boom boom! Like a big drum.” 
Maggy has taken the communication jointly generated with her mother and turned it toward herself. She uses speech derived from that conversation to reﬂect on the thunder, allay her fear, and help her wait until Deb’s task is ﬁnished and they can go inside. As Maggy “thinks aloud” with words, she converses with herself, in much the same way that she interacted with her mother. Over time, Maggy will start to interact with herself silently, “inside her head.” And as Maggie’s social experiences expand and become more complex, she will continue to weave aspects of them into her inner dialogues, acquiring new, more advanced ways of thinking.
A ﬁnal point about thinking as internalized social interaction: Note that Maggy’s telephone conversation with herself is not a simple copy of Deb’s remarks to her. The sociocultural vision is very dierent from behaviorism, which views development as directly imposed, or shaped, by external forces. Instead, children are active agents, contributing to the creation of their own thought processes by collaborating with more experienced cultural members in meaningful activities. The combination of child and adult leads to the communication between them. Then children actively take over this interaction and gradually adapt it for ecient and eective self-communication, shortening and personalizing it. 
To capture this idea of children selecting from social interaction in ways that ﬁt their goals, some experts like to say that the child “appropriates”—or adopts—tools of the mind.86 Others continue to describe the child as “internalizing” social experience but emphasize the child’s unique contribution to both adult–child interaction and its internalization. Whatever label is applied, active engagement on the part of both adult and child, resulting in a “meeting of minds,” is central to this process.

Purposeful Activities and Culturally Adaptive Competencies

Children learn and practice thinking by participating in purposeful activities, organized by their cultural community. This ensures that they will acquire competencies that are adaptive in their culture. 
At very young ages, when children are just beginning to acquire culturally valued skills, they depend almost entirely on interactions with more expert cultural members to make sense of their experiences. For example, when researchers tested 3-year-olds to ﬁnd out what they remembered about a visit to a museum, the children recalled only information they had talked about with their mothers; everything else had been forgotten.87 
When young children do not understand a concept or how to solve a problem, most often they lack experience in relevant activities with more expert individuals. For example, some ethnic minority children, who grow up in more “people-oriented” than “object-oriented” homes, do less well than they otherwise would on academic tasks because they rarely participate in activities involving “educational” toys, games, and a question–answer style of adult–child interaction (“What color is that?” How many wheels on that truck?”), which prime children for academic success.88 Yet these very same children who do poorly in the classroom can be seen telling complex stories, engaging in elaborate artistic activities, competently watching over younger children, and accomplishing athletic feats in daily life.
The importance of activity contexts reminds us that all children do not face identical tasks. Cultures, and adults within them responsible for socialization, select dierent tasks for children’s learning. As a result, children’s cognition is contextualized; it emerges and derives meaning from particular activities and social experiences. Parents who spend little time in joint pursuits and conversation with their children convey to them a very dierent set of cultural values, practices, and cognitive strategies than do parents who involve their children in constructive play and projects; encourage them to participate in family routines and duties, such as meal preparation and cleaning; and plan parent–child outings. Similarly, teachers who require mostly solitary desk work from children, isolating the skills taught from their everyday use, promote values and competencies strikingly dierent from those cultivated by teachers who embed teaching and learning in meaningful collaborative activities.
The core lesson to be learned from our discussion so far is that development is a matter of children’s genetic/biological potential undergoing a cultural metamorphosis, a process that cannot take place without parents and teachers as thoughtful and committed participants in children’s lives. From the sociocultural perspective, parents and teachers are leaders in awakening children’s minds and fostering their development; children are apprenticed to these experts. 
Hence, to Talia’s concern, posed at the start of our discussion: Should she and her husband, Jim, respond to 7-year-old Anselmo’s pleas for help with his homework? Given what we currently know about how children develop, the answer is a resounding yes. Rather than promoting dependency (as Talia and her husband fear), assisting Anselmo is the surest route to competent functioning, provided parental interaction builds on Anselmo’s current capacities and remains sensitive to his unique characteristics. Now let’s turn to just how parents and teachers can advance children’s knowledge and skills.









Forty years ago, home economics courses in high schools across the country taught cooking, nutrition, and sewing to most schoolgirls. The sewing machine, in its polished wooden cabinet, was an expensive and valued wedding gift. Now the sewing machine, like the typewriter, is fast disappearing. The typewriter is being replaced by the computer, and the home sewing machine has become a small, inexpensive portable unit stored in the closet and used for minor repairs and alterations—if it is used at all. There are many reasons for this shift away from home sewing, including the growing number of women in the labor force. But perhaps the main reason is that production of factory-sewn clothing has become increasingly cost effective. It has taken away a time-consuming and often wearying task from the round of daily chores, providing consumers with a wide array of products and styles at reasonable prices. The popularity of casual-wear items like T-shirts and jeans—quintessentially factory-sewn garments—has also shifted sewing from home to the factory.
The annual number of units of outerwear created in the United States has remained remarkably constant over the last several decades, varying from 12.5 units per capita in 1967 to 13.4 units in 1995,1 while the number of production workers has continued to drop, from 1,098,200 in 1960 to 664,400 in 1997.2 This employment decrease is associated with the impact of casual wear, an increase in worker productivity, and the significant import penetration in garments with high labor content. Casual clothing is not only less expensive to purchase and maintain but also requires less labor to assemble.
Whether the apparel item is casual or formal, the stitching in the garment must accomplish one or more of the following objectives. The primary reason to sew, of course, is to join individual pattern pieces. The second objective is to leave no raw edge of fabric to unravel. This feature is sometimes combined with the joining operation, as in the “felled seaming” on the inseam of jeans or the sleeve seam in men’s dress shirts. The felled seam was first used in work clothing because of its strength and has since migrated to other apparel items because of its visible stitch pattern. Decorative stitching is the third objective of sewing. In the felled seams of shirts and jeans, for example, the visible stitches might be of a color designed to decorate the garment.3 No matter which stitch pattern is being used or which seaming operation carried out, the sewing machine operator must guide one or more pieces of cloth together through the machine. That is the basis of modern sewing operations in manufacturing facilities.
As we have noted throughout, the actual sewing of a garment may take place far away from its design: the translation of that design into a pattern, and the making of a marker of that pattern, which is arranged on layers of fabric for cutting. Consequently, the assembly of that garment often involves sewing together pieces from prearranged bundles sent by the manufacturer. In the contemporary world of contractors, subcontractors, and complicated sourcing decisions, assembly is usually the step in the manufacturing process that is farmed out to lower-cost firms.
Yet just because many U.S. manufacturers rely on foreign contractors for a good portion of garment assembly, it does not mean sewing in a factory requires little or no skill. Only a very few sewing operations involve a machine that is fully automated, in which the operator’s job comes down to stacking parts at one end of the sewing system and re-threading the machines if a thread breaks. Today’s factory sewing machine is generally dedicated to a single operation and most likely will be fitted with specialized fixtures in the area of the stitch plate—to help guide the seaming a fixed distance from the fabric edge, for example, or fold the edge of the cloth under, or with other attachments that feed elastic tape and so on into the seaming operation as needed. More complicated sewing operations require the operator to guide differential stitching, with more fabric in each top stitch than in the bottom one. Regardless of which individual sewing operations are required, the operator must be trained and given practice time to achieve a quality product, at least at the standard production rates.
The time required for a new worker to achieve production standards, while maintaining quality, can range from days for the simplest operation to nearly a year for joining the sleeve to the body of a suit coat. A few sewing operations are so demanding that some operators are never able to achieve the minimum acceptable production rate for them. With different skill levels required for different operations, it is not surprising that piece rates vary with the difficulty of the operation. In this chapter, we will describe what actually goes on in today’s sewing room—the machines used, what operators do, the flow of operations—and how sourcing decisions for replenishable products may affect assembly operations in the future.4
Sewing Machines and Garment Assembly
There are two major types of sewing machines used in garment assembly: the lockstitch and the chain-stitch machine. Each type feeds in separate threads above and below the fabric, and these two threads must be connected in some fashion to form a stitch. Both have one top thread for each needle above the seam and one or more different threads on the bottom below the surface of the sewing table. The primary difference between these sewing machines is in the way the two threads interact.
The Lockstitch Machine
Almost all home machines are lockstitch machines. The top thread comes from a spool or cone of thread above the machine and goes through many thread guides, a thread tensioner, a take-up arm, and, finally, the needle. The bottom thread is wound on a bobbin, a small spool, that is below the needle and the sewing surface. To make a stitch, the needle with the top thread is plunged through the plies of fabric, and a loop of the top thread is formed below the surface of the stitch plate (often called a “throat plate”).5 The loop of top thread is passed over the bobbin and around its thread. The take-up arm then pulls up the top thread to set a stitch. The top and bottom threads are locked together by passing the loop of the top thread around the bobbin.
One part of the art of sewing comes in adjusting the thread tension.6 With a lockstitch machine, when the needle withdraws from the cloth and the take-up arm pulls the top thread tight, the stitch begins to be “locked” or set in place. If the tension on the top and bottom thread is too high, the seam puckers and the seam length becomes less than that of the cloth. If the tension is too low, the seam will be so loose one can see through it when holding up the joined pattern pieces. Indeed, a well-formed lockstitch is smooth and appears the same when viewed from either the top or bottom ply. Note that even if a sewing machine is properly adjusted for sewing a particular weight and color of fabric, it will generally need to be adjusted again if the fabric color changes because the mechanical properties of a given type of fabric can depend on the dye color used. The lighter the fabric weight, the more sensitive seam quality is to machine adjustments and thread tensions as well as to the ability of sewing operators to make necessary adjustments.
In a factory setting, lockstitch machines are used for the decorative stitching that is necessary whenever the undersurface of a garment piece will be seen during normal wear, such as in the collar and cuffs of a dress shirt. The primary disadvantage of this kind of machine is that the bobbin must be small enough so that it can pass through the top thread loop, but it then quickly empties of thread. When this happens, sewing must be stopped and a newly loaded bobbin inserted to replace the empty one. Since the bobbin is reached by sliding back the stitch plate, if a bobbin runs out in the middle of an operation, it might be necessary to rip the seam out from the beginning and start over. Therefore, sewing operators generally keep track of the number of items sewn on a bobbin and stop before the thread runs out. If it were not for the limited thread capacity of the bobbin and the need for the operator to wind thread onto the bobbin, the lockstitch would be more widely used in factory assembly operations.
While men’s dress shirts are normally sewn with white thread, regardless of the fabric color, most apparel items use a thread color to match or contrast in a decorative way with the cloth. This means that after sewing a bundle of items of one color, an operator must not only change the needle thread but also put in a new bobbin for each new color of fabric. If an operator has a choice of thread color for the next lot to be sewn, she will always choose the color of the last bundle. Changing the type of fabric, even if the thread color is the same, generally demands adjustment of the thread tensions and other parts of the machine. Long production runs of the same basic item of apparel, with the same fabric, allow sewing operators to make major machine settings once a day, with only a few additional adjustments required throughout the shift.
The Chain-Stitch Machine
This machine overcomes the bobbin thread limitation and can operate at higher speeds, but it does have disadvantages. In this case, there is no bobbin. Below the sewing surface, the lower thread is manipulated by a mechanical arm called a looper. The looper inserts a loop of the bottom thread into a loop of the top thread that is created when the needle pierces through the fabric plies and begins to withdraw from the cloth. The top thread is then pulled up by the take-up arm. The top thread cannot be pulled through the cloth because it is held below the fabric by the inserted loop of the bottom thread. The bottom thread is formed into a continuous sequence of very small loops by the looper arm. Although the top and bottom threads are not interlocked, as in the lockstitch machine, the stitch is fixed in place and the seam has a bit more flexibility.
Because the bottom thread does not have to be encircled by the top thread, the bottom thread can come from a large cone stored above the machine. A new cone of looper thread contains miles of thread and generally does not have to be replaced more frequently than a few times during a shift. The operator can glance up at the cones of both top and bottom threads and replace them before they run out in the middle of a seam. The disadvantage of this kind of machine is that it makes seams that are not as secure as the lockstitch; in addition, the appearance of the seam from the top and bottom of the fabric is different. If a stitch is skipped—the looper thread is not inserted or may not get caught in the loop of the top thread—then the resulting thread loop could pull the seam out if it were to catch on something. Factory inspectors look for such flaws, but they are hard to find because they end up on the inside of a garment.
Nevertheless, the advantages of the chain-stitch machine far outweigh its disadvantages. A chain-stitch seam is strong and can be produced more quickly than a lockstitch seam. Most of the long seams in factory-sewn apparel are made with a chain-stitch machine or with variations of it. The felled seam commonly used for the inseam of jeans comes from a two-needle chain-stitch machine. Such stitching generally outlasts the fabric of jeans, as one can see from looking at the holey knees of jeans worn by many teenagers.
Other Sewing Machines
A wide variety of specialized sewing machines are also used in factories. There are machines with multiple needles and loopers that attach elastic waistbands to boxer shorts, for example. Knit fleece goods are commonly joined by a seaming operation called over-edging in the factory (and overlocking sewing in home use). The over-edge or overlocking machine automatically aligns the fabric by trimming off the edges of the plies to be joined just before the stitch is made. At least one thread wraps around the edge of the fabric during the stitching process. There are one-, two-, three-, four-, and five-thread overlocking or over-edging machines, each one designed to meet a given requirement of seam, strength, flexibility, and security. Over-edge machines can run at more than 8,000 stitches a minute. At eight or ten stitches an inch, it is possible to seam thirteen to sixteen or more inches a second. In the factory, however, a sewing machine’s maximum speed is generally not what limits production; it is the time it takes to set up the work on the machine and guide the fabric to the needle as the seam is being made.
What the Sewing Operator Does
In a typical apparel factory, a sewing operator is actually sewing only one-quarter of the time. The operator must first select the work to be done, put aside the tickets that indicate she performed the sewing appropriate for those bundles and should be paid at the specified rate for the job, open the appropriate bundles, and position the pieces to be joined on the sewing table in preparation for sewing.7
If the sewing machine is correctly threaded, the operator then lifts the presser foot—a device that comes down on either side of the needle to hold the cloth—and, if the needle is in the up position, inserts the fabric. Otherwise, the operator turns the machine wheel to get the needle in the up position, lowers the presser foot, sews the beginning of the seam, backstitches to lock the seam, grabs the two plies of cloth near where the seam will end, and guides the cloth through the sewing machine. Usually, she will backstitch at the seam end, then cut the thread. Some machines have an automatic thread-trimmer to do this step; if not, then the threads must be cut and the finished work put in an appropriate pile to be tied together when all the pieces of the bundle have been finished.8
Machine-tending, material placement, and off-loading operations are all considered part of a sewing operator’s job. Although none of these operations actually involves sewing, they do take time to complete and are taken into account when determining the piece rate and normal workload for an operation. If a new sewing table or a new sewing machine with programmable features is added at a particular workstation—that is, any device that reduces the time it takes to complete various tasks—then the allowable time and wage rate for that operation must be changed.
These issues aside, there is one other major task a sewing operator performs. She must make the pieces of the pattern fit together at the end of the sewing process. This is certainly not possible if there has been a big mistake in cutting, but it is never easy, even without serious cutting errors. If two plies of flat cloth of identical length are placed on top of each other and sewn together, then the ends of the two pieces will not line up without the intervention of a sewing operator. The two ends of a thirty-inch leg seam on a pair of jeans, for instance, might be a quarter of an inch out of alignment unless the operator takes control. During sewing, the feed-dog on the machine—a part that comes up through two slots in the stitch plate and engages the bottom ply of cloth—will pull the bottom ply under the presser foot and against the pull of the thread. The top ply of cloth is carried along by the bottom ply; hence, one ply is stretched more than the other.
This simple fact of sewing makes it very difficult to automate the process. In reality, the two seam lines to be joined are rarely exactly the same length. Cutting introduces differences from the top to the bottom of the layers of fabric. No matter how good spreaders and cutters are, preassembly operations are never perfect. The sewing operator must overcome all these prior minor variations, as well as the differences introduced by the sewing process, and make the joining seam come out even at the end. She accomplishes this magic by stretching the two plies differently. First, the plies are stretched to get the pattern notches in the two to align; then the ends are pulled together, causing them to align. The operator uses the elasticity of the cloth to overcome minor errors in cutting and prior sewing. Indeed, most trained sewing operators see this defect correction simply as part of their job.
The Sewing Room
The vast majority of workers in the apparel industry are involved in assembly. This is illustrated in Table 9.1 (page 158) for the men’s and boys’ shirt industry. In 1990, 73 percent of all workers in this industry were classified as working in the sewing department; 91 percent were sewing machine operators. Given the predominant share of workers in assembly, organization of work in the sewing room has been the central focus of management attention.
The sewing rooms of most apparel factories are similar in overall appearance. Apparel parts, trim pieces, buttons, zippers, and thread arrive at one end of the room and are separated for each operation, or subassembly. As the last chapter noted, large apparel firms usually operate a central cutting room that provides cut parts to an average of five sewing plants.9 About two-thirds of the production volume of our surveyed business units did their marker-making, spreading, and cutting in a single location. Most would deliver cut goods to sewing plants many times a week; however, when cutting is done hundreds of miles from the sewing plants, weekly deliveries are the norm. Trucks take fresh parts to the plants and return with finished goods for the distribution center.
Sewing rooms are generally arranged in rows of workers, each seated at a machine doing one operation on a bundle of parts. Traditionally, the progressive bundle system assumed that maximum worker productivity could be achieved by breaking down the steps of assembly into a series of discrete operations. Each sewing operator would be trained in the correct approach to one specific task. Through repetition of the task and coaching by experts, the operator would become very productive. Although new work practices are evolving in the apparel industry, many workers still specialize in one operation or at most two. In fact, long product runs in men’s and unisex product lines, such as jeans, have made U.S. sewing operators extremely efficient.
Workers in most plants are paid on a piece-rate basis—that is, they are paid a fixed amount for each seam sewn correctly. If a part must be reworked, it is done on the operator’s own time. This incentive system means that each operator needs to have work-in-process waiting; if there is a machine breakdown or no work waiting, then the operator will be paid at some average earnings rate during the waiting period. But to avoid this, there is always work waiting; for example, in a men’s dress-shirt factory there can be a day’s worth at each sewing station. On the sewing room floor, there are generally piles of items ready to be sewn or moved to the next assembly step. The time it takes for a given item of apparel to pass through a plant is determined by the average hours of work-in-process before each operation and the total number of operations along the critical path.
Work Flow in a Plant
The flow of operations through a typical men’s dress-shirt sewing factory is shown in Figure 9.1 (page 160). The subassemblies for the collars, backs, fronts, cuffs, and sleeves might be on one side of a center aisle down the factory floor and the major assembly steps on the other side. The factory manager needs to keep track of the flow of items through the plant to assure that the subassemblies, such as the sleeves, are ready to join the shirt. A given shirt must have a specified collar size and a given sleeve length. Clearly, the fabric, color, and style must also match. If the cut bundles are sent to the factory once a week, this manager might then put that week’s bundles into carts identified by a flag flying the color for that week. Note that the work in a shirt plant is generally grouped into production lots of 1,500 shirts if the progressive bundle system is used. Shirts are normally counted by the dozen, so a production lot comes to 125 dozen.
Each day, the manager looks over the factory floor to see if any carts with a particular flag color are falling behind the others of that group. Delays in product flow can result from machine problems, worker absence, or if priority is given to special orders. In some plants, the carts may contain up to a day’s worth of work. Although this may appear to be a crude way of keeping track of the work flow, it is simple and generally effective. Still, work almost never progresses in perfect lockstep through a factory. Finding the correct parts for a shirt can often involve a hunt through the plant. For example, a worker might accidentally leave a bundle of unfinished work in the cart when it goes back to be loaded again. Because a worker may have a day’s work in the carts in front of her, it is easy to see how individual bundles of parts can be misplaced—which, in turn, will hold up the assembly of some SKUs. Partially finished shirts and shirt subassemblies will then be in a number of places in the factory.
This shirt factory employs 250 workers. If the shirt in question is rated to require twelve minutes to assemble, such as the one in the figure, a forty-hour work week will produce 4,167 dozen shirts when the factory is operating at standard efficiency. (Of course, many plants may fall below the standard and take longer than twelve minutes to make that shirt.)10 A typical time for a shirt to go through the plant is four weeks, which means the plant will have 16,667 dozen shirts as work-in-process (WIP). The forty operations indicated in the figure may require only twelve minutes if the operators are working at 100 percent efficiency, but any given shirt still takes twenty working days to pass through the plant. To shorten the time significantly, the work-in-process in front of each of the twenty operations listed as part of the critical path would have to be reduced from a day to just several hours. Not all the forty different operations are sequential; the parts assembly goes on in parallel, but the final assembly involves a series of eleven operations that require all the subassemblies to be completed and ready to be mated with the correct parts.
Needless to say, reduction of throughput time is not a simple task. Some of the forty operations require very little time; others are much longer. Hemming the top of a shirt pocket is a short operation, for example, but it takes longer to attach the pocket and longer still if stripes must be matched. If there is one operator for the short operation, then there will have to be several operators for the longer one just to keep the production line in balance. If any one of the several operators speeds up or slows down, the line becomes unbalanced. If the imbalance lasts for more than an hour or so, the factory manager would have to take corrective action. A utility operator skilled in several operations might be brought over from another area to move work past the slow sewing station. Clearly, it is easier for the manager to keep all operators supplied with work, especially since in most cases the work-in-process for each operator is large. The large buffers are designed so that natural daily variations in work rhythm do not cause a major disruption. In fact, a production line is probably never in perfect balance. If it were, when even one worker in the plant changed her pace, the line would drift out of balance.
As work progresses through a typical sewing plant, it is also common for a special order to disrupt the flow. Even if the special order does not require a thread change, as with most dress shirts, someone will have to move the order to the front of the queue at each sewing station and combine the parts for final assembly.
We have visited a top-of-the-line men’s suit plant in Sweden where a special order would go through the plant in four working days, rather than the normal six weeks, just by allowing the work to go to the head of the work buffer at each sewing station. In this suit plant, work was moved from one station to the next by a Unit Production System (UPS). A UPS is a mechanical overhead transport system that moves a unit of clothing from one work station to the next. The mechanical device generally carries all parts of the finished garment. After a sewing operator finishes one step, the carrier is sent on its way to the next. There is a finite mechanical buffer area before each operator; when the buffer fills, the next unit is automatically sent to another operator who does the same operation.
With a UPS delivery system, factory throughput time can be dramatically reduced. But the cost required to install such a system is steep, running to $4,000 or more per workstation. The high cost and lack of production-floor flexibility after the mechanical conveyers are installed have limited the number of factories adopting these systems. In 1992, only 3.5 percent of the output of our surveyed business units was assembled using UPS. A competing approach to reducing plant throughput time involves team-based sewing or modular production, which we will discuss at length in the next chapter. In that case, groups of sewing operators are trained in more than one assembly operation. Workers move from one sewing station to another, guiding the work-in-process through the plant.
The assembly of most items of apparel follows the work flow sketched here. Subassemblies are manufactured in small lines and join the critical path at the appropriate point. But while a T-shirt, for example, might include sleeves made in the cutting room, its collar might be inserted, the sleeves attached, and the garment finished in a sewing room far removed from the cutting room. A suit manufacturer might cut the cloth for the suit in one plant, ship the coat parts to another, and ship the pants parts to yet another plant in another state. Eventually, regardless of where particular operations are carried out, the finished garments return to a central distribution center to be shipped to customers. In the case of the suit manufacturer with plants in different locations, each individual suit is made from shell fabric cut from the same roll and generally the same ply of cloth on the lay table. Matching the coats, pants, and vests is carried out in a special section of the distribution center. The items are then stored in a way that makes them easy to pick for an order about to be shipped.
The Costs of Assembly
The investment per worker in a sewing room is quite modest. A simple new commercial sewing machine may cost $2,000 to $3,000, but a rebuilt machine can run as low as five hundred dollars and still provide a good dozen years of production. The average annual capital investment in sewing machines and attachments per operator in our survey was $720 (in 1992 dollars). Some of the machines in an American men’s dress-shirt plant like the one previously described will cost $20,000 or more, but such automated sewing systems are rare. As we have already noted, the general requirement for return on investment forces expensive capital equipment to be operated under more than single-shift conditions, unless it is essential to produce a given item. The automated sewing systems that create the closely spaced regular stitch patterns used as decorative top stitching on men’s dress shirts, collars, cuffs, and pockets are examples of expensive machines operated for a single shift.
Because assembly operations are driven more by labor costs than capital-intensive equipment, a typical American sewing factory operates just a single shift a day, with an average of about thirty-seven hours of work per week.11 On the men’s side of the industry, factories of up to several hundred workers are common, but smaller loft shops are typical for women’s apparel. Factories are located where the workforce lives. And the infrastructure needed to support a sewing room is relatively modest. Power in the form of electricity, water—especially if items like jeans are to be washed—and a phone are about all that is required. In some developing countries, workers are brought to the factories, which are generally located at the outer reaches of the local industrial infrastructure. These workers often live in dormitories on the factory compound for a period of a year before returning to their villages or moving into the city. Similar worker dormitory arrangements were part of the men’s suit industry in Japan as recently as fifteen years ago.
Apparel Assembly and the Demands of Rapid Replenishment
The traditional system of apparel assembly was designed to minimize the direct labor costs of assembly, not production throughput time. The progressive bundle system, with up to a day’s WIP waiting for each sewing operator was an efficient way of operating when the costs of carrying mountains of WIP did not enter into production costs. Generally, under this system of apparel assembly all production was made to fill an actual order. The risk of inventory was carried by the retailer who placed the order, so apparel operators carried large WIP (in 1988 for our sample an average of 3.65 weeks worth).
But under rapid replenishment arrangements, the inventory risk is now assumed by the apparel manufacturer; consequently assembly time is now very important. As shown in the cases studied in Chapter 7, production-cycle time and inventory carrying costs are two crucial parameters in making rapid replenishment sourcing decisions. When the assembly cycle time is reduced, both the WIP and finished goods inventory levels necessary to meet a given rapid replenishment demand go down.
The possibility of mass customization for some apparel items presents another market opportunity that demands short-cycle production. If a retail customer pays a premium for a custom pair of jeans, dress shirt, or suit, that customer will expect the item to be delivered to her home within days, not weeks or months. We are a nation of last-minute shoppers, and mass customization will have to compete against overnight delivery of apparel items with less than perfect fit from a specialty catalog company. Speed of delivery has increasingly become part of the competitive equation.
There are a number of ways to organize apparel assembly to minimize cycle time. One way is to use a UPS assembly process. Another involves reorganizing the workers themselves through a team of sewing operators responsible for the entire critical path of assembly. In this case, sewing operators achieve production-line balance by moving from one workstation to another advancing the work smoothly through the line. As in life, there are few if any absolutes in methods of apparel assembly. Each method of organizing production has advantages and problems associated with it. Chapter 10 takes up these issues in detail.









The late Joseph Gerber, founder of Gerber Garment Technology Company in Tolland, Connecticut, invented automated fabric cutting and introduced it to the market in 1969. This innovative company went on to create a new industry in automatic-cutting equipment. By the late 1970s, Gerber Garment Technology was supplying the automotive and apparel industries with its GERBERcutter, allowing firms to cut cloth and nonwoven material more effectively. The Gerber system first made it possible for a computer to guide the cutting knife anywhere on the cutting table. Gerber’s automatic-cutting equipment, as well as that of several other international competitors, has continued to improve; cloth from a single ply to layers up to six inches thick can now be cut quickly and accurately.
Gerber is also a major worldwide supplier of information systems for the sewing products industries. Its Product Data Management software provides users with all the information about an apparel product, including design, patterns, markers, sewing instructions, and assembly costs. This single software package can be made available through an in-house local area network or the World Wide Web. Computer data systems like this have enormous potential for the apparel industry. Private-label apparel for U.S. department and specialty stores, for instance, is generally designed in this country and produced by domestic contractors or overseas. Regardless of geographic location, it is always difficult for a contractor to know if it has the latest information on sewing patterns and other construction details. But via a network that allows contractors access, manufacturers’ headquarters can make sure that the information available is the most recent and complete. In addition, video instructions, which do not rely on spoken language, can demonstrate to foreign contractors what is acceptable and what is not.
In previous chapters, we have described the impact of crucial information technologies, such as the use of bar code scanning and electronic data interchange, on the retail-apparel-textile channel. The ability to transmit order information in unambiguous electronic forms between retailers and apparel manufacturers, along with the possibility of sharing point-of-sales information, allow these manufacturers to understand in real time what is happening in the marketplace. It is then up to the manufacturer to use this information in product design and production planning. Indeed, for many apparel firms, speed in the market now means using modern computer tools that make the process of creating a piece of clothing—from conceptual design to fabric cutting to sewing—smooth and efficient. From the first use of computer-assisted pattern layout in the 1970s, computers and specialized information technologies have spread widely in the industry. Such systems have the potential to develop patterns and color fabrics; adapt apparel patterns for custom-made suits, shirts, pants, and other garments; and evaluate production sourcing alternatives to maximize profit while allowing for demand uncertainty.
Yet not every aspect of apparel production depends on new technologies; in fact, automated sewing processes and the use of robots on the apparel shop floor have not turned out to be profitable or effective.1 People do a better job than computers of adjusting fabric alignment through sewing machines and compensating for prior sewing and cutting errors. As a result, the marginal costs for human sewing operators are lower than those of the complex robotic systems needed to guide sewing of limp fabric in most operations.
In discussing apparel manufacturing, it is important to make a distinction between preassembly of garments—design, marker-making, spreading, cutting, and bundling operations that are the focus of this chapter—and garment assembly, the subject of the next chapter. Most of the innovations in production and information technology are taking place in preassembly processes, which can be more readily automated. Although changes in how managers orchestrate production flow through the sewing room are starting to make a difference, shifts in the practices of shop-floor workers have more to do with new human resource policies than equipment.
As most observers of the apparel industry know, contracting out the assembly of garments has become common for American manufacturers, although the use of contracting differs between the men’s and women’s industry. Men’s clothing has generally been made in long production runs with only small variations among styles in a given year and relatively little change from year to year. This has allowed men’s clothing manufacturers to capture the benefits of their own highly efficient sewing rooms through long production runs. Women’s clothing is characterized by great diversity in styles and short production runs. Small contractors’ sewing shops are the norm for most women’s apparel. The use of contractors has grown at the international level in the 1970s and 1980s.
We will examine some of the complex issues related to international sourcing in Chapter 13. But we want to stress here that today’s apparel supplier usually does not produce all of its own garments, from start to finish. Apparel manufacturing can involve many contractors and subcontractors, creating a complex web of supplier relationships. Jobbers—suppliers that may contract out every aspect of clothing production except for design—represent one extreme. Companies like Liz Claiborne and MAST Industries are essentially current versions, although their operations are much larger than those of jobbers in the past.
Many U.S.-based apparel firms, not to mention the apparel union, have long recognized that producing higher quality garments may be the best means for competing against low-cost foreign labor. One way to increase quality is to control fabric purchasing, marker-making, spreading, cutting, and parts preparation in a central facility. The manufacturer can then transport the cut parts for assembly to sewing rooms, which may be either local or out of the country. In fact, HCTAR’s survey indicates that the average cutting room services 4.5 sewing rooms. Quality assembly of garments from pieces of material cut according to a particular pattern involves operations that can be carried out almost anywhere in the world. Whether a unit of apparel is assembled in China or the United States, the overall process is quite similar. The differences from country to country remain in the details—principally in the layout of the pattern on the cloth and in cutting the patterns.
For instance the high-end design of a women’s jacket, made from $300-a-yard cashmere plaid fabric, can still be of very poor quality if the plaids do not match on the lapels, the inseams of the sleeves, or along the seam joining the back panels. Pattern layout may not seem important at first, until one sees a plaid mismatch when this jacket is buttoned. A very small amount of plaid mismatch in cutting can be overcome by a skilled sewing operator, but the essential step in achieving a quality product is to make the pattern parts correctly. This chapter describes the various steps involved before a garment is sewn, focusing on the technical innovations that are having the greatest impact.2 Before looking at preassembly operations in apparel-making, however, we will examine the very beginning of the process—garment design and the creation of a pattern.
The First Step: Apparel Design and Patterns
When most people think of apparel design, they see fashion designers and models on runways. Yet the vast majority of design in the apparel industry has little to do with the way clothing is created in the high-fashion world. Often apparel design and pattern-making are done by department stores, private-label offices, and small manufacturers in addition to major firms. The name designers generally create fashion directions and the next tier of designers fill out the new directions into many levels and for many items of apparel.3 Department stores also have designers at headquarters who prepare designs and patterns for their private-label collection.
Although many apparel manufacturers do have in-house designers, most of the work of garment design comes in adjusting previous -patterns or small elements of existing garments—say, the trim or the fabric—and is more a matter of technical creation than a flight of fancy. Consider the expansion of basic and fashion-basic garments in the U.S. market. For T-shirts, sweatpants, and different types of jeans, the design elements that change annually may only amount to a change of color, fit of the jeans, or the addition of a pocket to sweatpants.
Traditionally, a new apparel design was created by asking the designer/artist to make a watercolor sketch. If the fabric was to have a pattern, there might also be a close-up colored sketch of it. Many designs would be grouped together into a storyboard, which was then presented to managers for final decisions. Next the designs that passed this stage went through a technical design step in which details were added and patterns made. After this step, fabric might be cut and a sample made to see how it would look on a mannequin. If the new garment was a blouse, for example, the designer might wish to see how it looked with skirts planned for the collection. If the designer was not satisfied with the drape of the garment, the fit, or the pattern, he or she might go back to square one. Several iterations of these initial design steps could add weeks or months to the process before production began.
Although some haute couture or high-end apparel designers may still work in this manner, each year more garments are designed using computer technology. In our survey, 40 percent of the business units reported using Computer-Aided-Design (CAD) systems to prepare new products in 1992. Employing CAD was particularly common among the largest business units in our sample. The use of modern design tools and information technology can collapse the design time so that managerial decision-making becomes the longest step in the process—and even the time for that step can be shortened with information technology. The new way allows the designer to work creatively with a computer pen or brush to outline the sketch, which appears on a computer screen. The computer can “watercolor” the sketch and produce the storyboard for presentation. Once past the first steps, these systems let designers drape fabric patterns on sketches or photographs of people on the computer screen. For example, sketches or photos can be draped with material of different colors and patterns. The size of the pattern can be changed and the visual images compared to get a sense of their appeal. And a colored ink-jet printing of the pattern can be made on basic plain fabric to help identify and demonstrate the desired colors in future discussions with textile mills.
Design changes can be implemented in minutes. For example, if the apparel item is a skirt, the proposed material on the computer image can be changed with a few key strokes. Prints can be scanned into the computer and used as the pattern for the visual image. Entire collections can be created in a day with the selected materials draped on a sketched figure or actual photograph of a model. The colors of the blouse can be changed with a few computer steps. The color and texture of the rest of the garments in the photograph can be changed with equal ease. Computerized design systems collapse the time needed to explore new design ideas into hours of work, rather than the traditional work time of days or weeks. The resulting visual images can be shared with other decision-makers in the company wherever they might be, without the need to wait until everyone is in town for a meeting. Computer images can be viewed on the local area network or even put on the Internet in a secure form.
Other development applications allow designers to begin with an actual garment and make appropriate changes to achieve the desired design or construction modifications. In this case, designers pin the garment to a special design table. A computer pen is used to outline a panel of the garment with a sequence of contact points. The computer, on command, then connects the image of the points on its screen with a series of line segments that form the silhouette of the pattern piece. Another computer command adds the seam allowance and, after the desired modifications have been made, a piece of the new design is created. When all the individual pieces of the garment have been modified and entered into the computer system, the final garment pattern is ready to be cut and sewn into a sample garment. Numerically controlled fabric cutters are now available that can rapidly and accurately cut patterns from a single ply of cloth, removing the usual obstacle to sample garment-making. The cutting equipment is driven by the output of a pattern-grading and marker-making program.
Note that this entire design sequence can take as little as part of a day, yielding a sample garment hung on a mannequin. Again, the time it takes managers to reach a decision is what determines the length of this process. However, it may take months to produce a sample garment in a desired fabric simply because that fabric takes months to make.
Design information systems, such as the Gerber Garment Technology software discussed above, can also greatly affect how and when design changes are made. Gerber’s Web version of such a system (WebPDM) allows worldwide access to designated users with information stored on a single host server about relevant apparel products. Naturally, contractors for sewing assembly will not be allowed access to estimates of production costs and information about other suppliers; however, once a change is made in a garment’s design, then everyone involved will have access to and can work from the identical information base. The system can store design, costing, measurements, and detailed construction information, all in multiple languages.
Preassembly: Marker-Making
An order to an apparel factory—whether from a retailer, jobber, or a manufacturer contracting out different stages of the work—specifies the total number of units to be made of a particular design, with a given fabric, and with a certain number of units in each size. Because a retailer normally will have already seen a sample garment before placing an order, the manufacturer therefore will have the pattern pieces for all sizes in-house, with coordinate outlines of the pieces on its computers. The manufacturer might also have the patterns cut out from stiff fiberboard so that the individual pieces can be traced by hand onto a large sheet of paper. But several preassembly processes have to be performed before the cloth can be cut. The order must be broken down into groups of units to be worked on together. Then all the pieces of the patterns must be laid out for the various units so that they can be cut at the same time. The silhouette for each individual pattern piece is generally traced or imprinted on a sheet of paper, which is called a “marker.” Finally, the cloth must be spread in as many layers of thickness as necessary to achieve the number of units requested or as many as can be properly cut at one time.
Each piece of the pattern in a marker has a seam allowance added to the basic outline. This allowance serves two purposes: First, the sewn seam must be made far enough in from the edge of the cloth so that it will not pull free of the cloth; second, the seam allowance provides a region into which small alignment notches can be cut. The notches are the basic instruction to sewing operators regarding where the fabric pieces to be joined should match up or be aligned. In a sense, these notches visually encode the basic sewing instructions into each pattern piece of the garment. This means that skilled sewing operators do not need to be able to read a language to follow instructions. They can -follow the general outline of assembly from supervisors’ or video demonstrations.
Before the pattern layout is made, there is the assortment problem of determining which apparel sizes should be included in a given marker. Because each roll of cloth has a particular width, grouping different sizes together will result in varying percentages of cloth utilization for each width. For example, if one is laying out a marker of men’s pants, there are four large panels for each pair, along with fourteen other small pieces like waistbands and trim.4 Yet the four panels of a pair of forty-inch waist pants will not fit in the typical sixty-inch-wide bolt of cloth. To achieve the 90 percent cloth utilization typical of this kind of production, one needs to combine six pairs of pants into one marker. An efficient marker will have larger sizes of pants balanced with smaller sizes.
A typical marker for men’s pants is shown in Figure 8.1 (page 137). At first glance, it might appear that almost all of the cloth is used in the marker; in fact, only 90 percent has been covered in the layout of 108 individual pieces. Given the basic shapes of the pants pieces, it is unlikely that a substantial increase in marker efficiency can be achieved. At best, experience with different combinations of waist sizes and leg lengths for a given design allows a scheduler to aggregate the units to be made into groups of large and small sizes, which means marker-makers can achieve efficiencies near 90 percent for casual pants. Higher cloth utilization is possible with jeans, but lower levels are normal for blouses, jackets, and intimate apparel (see Figure 8.2).
Making a marker is a complicated task, even with modern computer assistance. Because fabric is generally the most expensive part of finished garments, the skill of the marker-maker is critical for achieving high cloth utilization and lower fabric costs. Marker-making is easier with fewer pieces, but with fewer pieces, overall cloth utilization is generally lower. A typical production pants marker is about 265 inches long and 59.75 inches wide. This marker, over 22 feet long, contains all of the 108 individual pieces of the shell fabric that make up six different pairs of pants. An operator with six months or more of experience with pants markers can take up to ninety minutes to achieve an efficiency of 89 to 90 percent. Manipulation of the arrangement of these pieces, whether on a computer screen or not, is a time-consuming task. It resembles putting a jigsaw puzzle together, except that the cloth pieces do not fit together exactly. The separate pieces can be moved around on a computer screen by the normal drag and drop procedure, but even this involves a complex mixture of trial and error and relies heavily on a marker-maker’s experience. A trial marker might leave the right-hand end very uneven, for example, resulting in low utilization when the cloth is cut straight across the bolt in the standard “guillotine” cut. Such a marker would not be acceptable for production. A marker-maker would have to reconstruct the layout to give it the appearance of those in Figures 8.1 and 8.2.
Computer layout systems also improve the quality of the finished apparel by preventing marker-makers from tilting the pieces by more than a predetermined amount, typically three or four degrees. These restrictions ensure that the weave of the cloth is aligned along the length of the garment. After all, stripes should be vertical—a quality feature of the final product determined when the marker is made, not later in the process. Such quality is difficult to achieve with hand layout and manual tracing of the silhouette onto the marker cloth. When the layout is done by hand through tracing on a sheet of paper, there is always a temptation for the operator to tilt a particular piece a bit more, squeezing it into the marker or “shrinking” the silhouette of some of the pieces to get them all on the marker. Subcontractors who might do cutting as well as sewing are provided with enough fabric to make the order. Any fabric left after the order is completed is kept by the subcontractor, providing an incentive to “squeeze” the pattern pieces more than a designer might want.
When the computer screen layout is finished, it is automatically printed full-size on paper by large computer-driven printers. The paper marker identifies each piece in the layout so that the cloth pieces for individual apparel items can be put together after the fabric is cut. Computer-assisted marker-making can offer large savings with basic garments, like men’s pants or women’s intimate apparel, which may be manufactured repeatedly over several years. The same assortment of sizes might be needed many times in a month, and the finished layout can be called up from computer memory and used over and over again, provided the width of the fabric remains the same. There are, however, small variations of fabric width from bolt to bolt, and from one supplier to another. If the cloth runs wide or narrow, an efficient manufacturer would remake the marker to take advantage of the full width. Variation of just a quarter inch in a sixty-inch width can yield a 0.42 percent change in cloth utilization.
Part of HCTAR’s research effort has resulted in new automatic marker-making software based on computational geometry techniques. The software allows a manufacturer to take existing production markers and automatically “compact” the arrangement of pieces by translation or a combination of translation and allowable amounts of rotation.5 It automatically adjusts for changes in fabric width by moving the pieces to the left and up or down to fill the available width most efficiently. The more pieces in a marker, the more effort required to make an efficient marker of a given width. Therefore, if the cloth of a given bolt of fabric is half an inch wider than the marker, there is a tendency to cut the marker as is. Yet some users of this software have been able to decrease the amount of cloth lost in this way by as much as 2 percent.
The pants marker shown in Figure 8.1 was produced by this automatic layout software and yielded cloth utilization of 89.66 percent. The equivalent production marker made by the manufacturer’s highly skilled operator, using a computer but without HCTAR’s software, achieved a utilization of 89.54 percent, or just a little less than the fully automatic software system. Sometimes a human operator can beat the automatic system by a small amount, but the following example is typical. The production marker for the intimate apparel item in Figure 8.2 was initially laid out by a trained operator with 79.96 percent utilization; the HCTAR software compacted the marker and achieved cloth utilization of 81.54 percent, an improvement of 1.47 percent. One-third of the wholesale price of apparel is typically fabric cost. A 1 percent savings in fabric over the entire production goes directly to the bottom line. Such savings can add up to many millions of dollars for large manufacturers.
Based on our survey results, about two-thirds of the business units in 1992 generated markers by trained operators with computer assistance; when the survey response is weighted by dollars of yearly sales, however, 99.5 percent of the business units’ production came from computer-generated markers. In contrast, apparel operations in developing nations generally do not use computerized layout systems. Markers are made by hand, tracing pattern pieces onto sheets of paper from thick, pre-cut cardboard pattern elements. The primary alignment tool is the meter stick for measuring distances from the edge. It is not hard to imagine a tendency to allow a slight twist in individual pieces to achieve a closer fit between neighboring pieces.
There are also stories of subcontractors, in this country as well as overseas, crumpling a marker up so that when it is laid out again it will be just a little smaller in width and length—a trick to save a fraction of a percent from each piece. The savings can add up for the contractor, since the apparel manufacturer that supplied the cloth might not notice. As far as final quality is concerned, however, such arrangements create the wrong incentive—another reason why it may make more sense for U.S.-based manufacturers to control all aspects of preassembly, including marker-making and cutting.
Preassembly: Spreading
Every meter of fabric destined for apparel production is normally inspected by the textile manufacturer. As a part of this inspection and repair, a detailed map is made that locates any remaining defects; the minimum width of the bolt is measured along with the overall length of the unstretched material. After final inspection, the cloth is wound “without tension” on a roll for shipment. But it is actually impossible to wind the fabric onto a roll without leaving some stresses in the cloth. Variations in storage temperature and humidity also cause changes. Indeed, all the residual stresses in the cloth cause problems when it is spread on the manufacturer’s “lay” table prior to cutting.
Spreading cloth out on a table in a way that leaves it flat but unstretched, without tension in the cloth, is more difficult than one would think. To get the cloth flat, without mechanical help, two workers could hold the cloth by both ends and stretch it out flat, then release just one end. But the friction between the table and the cloth will leave this layer (“ply”) of cloth stretched; just how much will depend on the amount of friction between the two. Putting another ply on top the same way creates an additional problem. The friction between the second ply and the first can create a wrinkle in the first ply. When plies of cloth are piled high—a foot or more is not unusual—there are often wrinkles in the plies after they are cut. This is especially true for knit goods, which are easily stretched and adhere well to neighboring plies in a stack of cloth.
The number of plies of cloth spread at one time depends on the fabric, which, in turn, determines how many are cut at one time. Thirty plies of denim might be cut together, whereas a hundred to three hundred plies of men’s dress-shirt fabric might be cut at one time. In contrast, a men’s dress suit might be cut from a single ply, or from five or six plies of the same or different material.
Spreading the cloth many plies thick without stressing the cloth is, again, one of the quality steps of getting ready to sew. If the cloth has tension before it is cut, then it will contract after it is cut into separate pattern pieces. Because it is easy to stretch many fabrics by up to an inch in a yard, one can imagine the amount of distortion possible in the final garment. But technical innovations have aided the operators. Stresses in the cloth on the lay table can be minimized with the help of mechanical spreading machines, and such devices come in all sizes and costs. The most elaborate allow an operator to ride the machine, which holds the rolls of cloth, so that it can feed the cloth onto the table at a speed that just matches the speed of the machine as it moves along rails fixed to the table. On-board computers compare the location of cloth defects with pattern pieces in the marker. If the type of defect and its location are deemed unacceptable, then the bolt of cloth is cut and a new ply started with enough overlap to ensure that all pattern pieces are whole and without defects. In our sample, business units used some type of automatic spreading for about 39 percent of the volume of goods they shipped.
Simpler spreading machines have no on-board computer, but they do unroll the bolt of cloth “unstressed” and properly aligned with the edge of the ply below. However spreading is done, it is important for the plies to lie directly on top of each other. Misalignment of the edges can ruin many pattern pieces and the final garments for which they were intended. Once a ply is laid down, it is almost impossible to shift it because of the friction between the plies. With simple spreading machines, the operator must look for fabric defect indicators placed in the selvage by the textile manufacturer.
After the cloth is spread, it is ready for the appropriate marker to be fit on top and fixed to the lay of fabric. Sometimes staples are driven through the paper into the underlying cloth. If the lay is made by hand, then the cloth is generally cut directly by hand-guided electric knives that slice through the cloth on the table. If computer-controlled cutting is used, the lay of cloth is pulled onto the cutting table by an underlying paper sheet. In either case, the pattern pieces can now be cut.
Preassembly: The Cutting Room
Since the early twentieth century, the cost to a manufacturer of a cutter’s mistake has been much greater than one committed by a sewing machine operator. Wrong stitching can be pulled out and a seam redone in the sewing room, but a big mistake by a cutter can involve the loss of many yards of cloth—and cloth costs range from one or two dollars a yard for inexpensive fabrics to three hundred dollars for some cashmeres. Even relatively small errors in cutting can degrade the final quality of garments. If the fabric is defect free, the marker efficient, the lay flat and unstressed, then everything else is up to the cutter.6
Some magazine advertisements for upscale men’s dress suits tout hand-cutting by experienced tailors. Occasionally the ads include a drawing of a man with a large pair of scissors. But cloth is rarely cut this way, even when only one ply is cut at a time. An eight- or twelve-inch pair of scissors is an unwieldy instrument, difficult to guide within the 1/32th of an inch of the pattern outline. It is even harder to accurately cut the notches used by sewing operators to align cut parts.
Most often, an electrically driven vertical reciprocating knife is used to cut the fabric. The vertical knife oscillates less than three-quarters of an inch but can cut cloth plies a foot or more in thickness. The knife and motor are supported above the base plate by a frame. The frame also gives the cutter a place to grip the machine for hand-guided cutting. The base plate is a smooth cap with a slit to contain the moving end of the knife. The knives have built-in sharpeners that run a stone up and down the blade every few minutes. In such a “hand-cutting” operation, the operator guides the knife along the outlines on the paper marker fixed to the fabric lay. One hand holds the marker on the lay, the other guides the electric knife. When a pattern piece is cut from the lay, the cutter then makes the notch cuts indicated on the marker. These slits should be about one-eighth of an inch cut into the three-eighth-inch sewing margin around the pattern. The chances are high of making the slit too deep or forgetting it entirely. Computer-controlled cutting machines, on the other hand, do not forget.
Joseph Gerber solved the major problem in cutting—how to hold the cloth while the knife cuts through the material—by putting the entire lay on a vacuum table. The fabric lay with the marker on top is covered with a thin sheet of clear plastic. When the vacuum pump comes on, five pounds of force per square foot push down on the fabric. The thin plastic sheet effectively cuts off the flow of room air through the fabric. The vacuum holds the cloth firmly and compresses the thickness of the lay, typically by half.
Gerber’s automatic-cutting equipment holds the knife on a frame that spans the cutting table and moves back and forth along the table. The location of the knife anywhere on the table can be precisely controlled by a computer, allowing it to cut its way along the silhouette of the patterns. Finally, Gerber’s equipment enabled the knife to slice through all the cloth without hitting the top of the vacuum table, supporting the lay of cloth on a brush between the fabric and the inlets to the vacuum table. The stiff bristles of the brush were made of plastic with flat tops, similar in appearance to a flat-headed nail. The flat tops supported the fabric. The plastic bristles were stiff enough to support the fabric layer under the force of vacuum while remaining sufficiently flexible to deflect out of the path of the knife.
The most up-to-date versions of automatic-cutting equipment, including the GERBERcutter, are even more effective. Cloth is cut by having the knife oscillate up and down while it moves along the silhouette of the apparel pieces in the marker. The knife support tilts to keep the blade erect when going along curves. Software can prevent lines from being cut twice; it can control the touchy job of cutting the apex of wedge-shaped pieces by approaching the point from both sides of the wedge rather than attempting to cut around the tip. The vacuum tables have also become “smart.” One level of vacuum is maintained over the general lay area; a higher level is arranged under the region being cut to keep the cloth fixed.
Yet despite the obvious advantages of computer-controlled cutting, only a minority of the business units in our survey (21 percent) were using this kind of equipment in 1992. Most continued to use manually guided electric knives to do their cutting, including some of the largest business units in the sample. Manufacturers have told us that hand-cutting with skilled cutters is as accurate as computer-cutting. Small factory operations, without sufficient volume to support two shifts of cutting, claim that they cannot justify the capital cost of computer systems.7
Those that do have computer equipment say that the consistency of cutting was their primary reason for purchasing computer-driven cutting systems. The computer cutter does not tire during the day nor forget to cut the notches, and the operator of computer-cutting equipment does not need the skills of a manual operator. As with many new technologies that have developed since the 1970s, adoption of innovative equipment is still occurring in fits and starts and depends on a given firm’s size and mix of products. In the case of computer--controlled cutting, however, there appear to be long-term advantages for manufacturers, especially those that produce large runs of basic or fashion-basic products. Apparel producers providing garments with multiple dimensions—for example, men’s shirts that are sized according to collar, sleeve length, and often torso length—require much more consistent cutting than suppliers whose apparel is sold only in small, medium, and large sizes.
Knit material, which is easily stretched, poses other challenges for cutting. Tubular knits are often cut in a die-cutting press. With most tube T-shirts, for instance, the die-cutter serves the twin functions of pulling the knit material into the machine and centering it under the die before cutting. The machine then presses the die down on the fabric, cuts through the fabric, and unloads the machine. The centering operation is important because the diameter of a knit tube varies slightly along its length, and it is necessary to reference cutting from the midline of the tube. Some die-cutting operations allow for a number of knit tubes to be centered, placed on one another, and then cut.
Like computer-controlled cutting equipment, large-capacity knit die-cutting presses are expensive machines; they can cost up to $400,000 and are generally found only in factories of the largest producers. The die is a razor-sharp steel outline of the desired item to be cut. Like a cookie cutter, it is pressed down on the fabric and, if all is aligned, a replica of the die is cut from the tube. To change the size of the item to be cut, the die must be removed and a new one installed. The machines are massive in size because they must be rigid to achieve cutting along the entire silhouette. Die-cutters are much safer when fully automated, but building computerized loading and unloading features into the machine adds cost. Therefore, such machines are used only where long production runs of a given size of T-shirt or sweatpants will allow a payback of their capital costs through round-the-clock or multi-shift operations.
One other technical innovation deserves mention here, partly because it illustrates why the most sophisticated equipment is not always appropriate for factory operations. Laser-cutting of fabric remains a little used technique in the United States and abroad. The HCTAR survey indicated 0.6 percent usage among responding business units in 1992 and, if the survey results are weighted by the dollar value of production, then the use drops to only 0.0002 percent. We have seen such equipment working in a production setting in a knit goods manufacturer’s facilities; however, we believe that its immediate potential use is limited for several reasons. Laser-cutting equipment must be totally enclosed to be safe for human operators. A high-energy light beam vaporizes a very narrow path around the silhouette of the patterns to be cut. The enclosure contains the vapors and conducts them to an exhaust outlet as well as prevents human access to the cutting region. A laser beam can seriously harm humans, and people may not notice the small-diameter beams of light in an industrial environment.
Twenty or more years ago, when lasers were first used to cut cloth, a mixture of polyester and wool as well as 100-percent polyester cloth was common. Attempts were then made to cut several plies of cloth at the same time. The light beam did cut through the plies, but it melted the polyester fibers at the sides of the burn and fused the edges of the cloth together. No matter what is done, the beam affects the edge of the cut. With the lower-intensity laser beams of the past, the bead of fused material at the edge of the cut formed a rough edge and was unpleasant to touch. Some over-edge sewing operations common with knit goods actually trim the edges of cloth just in front of the needle; in these cases any fused material from the laser cutting could be trimmed away. But, if nothing else, the temperature effects on fabric, combined with the cost of installation, appear to limit the use of this technology to those applications in which the connection between plies before sewing could be an advantage.
The great advantage of laser-cutting is speed. Modern laser-cutters, developed both in this country and Japan, leave the laser fixed in position and move the light beam around simply by computer-controlled tilting of the mirrors that guide the beam along the desired path. With high-powered lasers, the beam can be moved quickly and still cut through the cloth. There may come a day when the demand for single-ply cutting and the economics of continuous laser-cutting will allow this technology to be more cost effective. Until then, it will not be widely used in the garment trade.
Bundling the Parts
When cutting is completed, the pieces are removed in stacks and arranged in bundles for sewing. For many, if not most, applications, each ply in a bundle is marked with a sticker to indicate the actual garment to which the piece belongs. This can be an important step in men’s dress-suit assembly. Each suit is ideally made from pattern pieces cut from the same ply of cloth and the same region of material. This is done to avoid cloth matching problems, especially if the shade of the cloth varies along the roll. The point is to make sure that even very slight shade variations will not be apparent in the final assembly. It is also necessary to identify the individual pieces in order to assemble the correct pieces for a garment of a given size. As we have already noted, garments of various sizes are often grouped together on each ply of cloth.8
Some stacks of parts are further broken down into smaller bundles of parts so that sewing operators can use the same thread for everything in a bundle. Suits and pants require thread colors that match or blend with the shell fabric, and it is important to reduce the number of thread changes the sewing operator has to make. A work ticket is attached to each bundle of cloth, indicating the garment style, size, and all other necessary parameters. The main tag generally has subtags or tickets that the sewing machine operator collects to indicate that a sewing operation has been completed.9
This final preassembly step and those that precede it affect the assembly operations that follow. As we will see in Chapter 9, work processes in the sewing room have been designed to minimize the direct labor content in a garment. To ensure that sewing workers remain busy and operate at high productivity, apparel manufacturers traditionally carry large ready-to-sew cut goods in front of their sewing lines. In 1988, business units carried a median of twenty-four hours (three days worth) of such goods. However, our sample also reveals that some manufacturers began to adjust to the new demands of lean retailing: By 1992, the median dropped to ten hours, reflecting their desire to reduce the amount of work-in-process at this beginning stage of apparel assembly.
Mass Customization
The percentage of the population wearing factory-made apparel has grown steadily since the nineteenth century. Some still rely on custom-made clothing, especially those who have to go this route because of their size and shape or those with the money to afford custom tailoring. Although many might like to have customized clothing, few consider it a realistic option. It is only recently that “mass customization” may make sense for both consumers and apparel-makers.10
Mass customization involves a number of preassembly innovations. When somebody orders custom-made clothing, his or her measurements are taken by a fitter in a store and, three to six weeks later, the garment appears. In this case, how was the suit, shirt, pants, or pair of jeans made? Were all the preassembly steps followed or did an individual tailor cut the cloth and make the entire garment? The answers depend on the garment as well as on just how “custom-made” it really was. Regardless of how customization was done in the past, consumers paid more for the end product. Mass customization, however, has the potential to make “tailor fit” at least somewhat less expensive, as new systems combine features of the efficient factory system with attention to at least a few critical customer measurements.
There are two different approaches under way. The first modifies an existing apparel design in a few dimensions to improve its fit for an individual customer. Levi Strauss, which is currently offering custom-fit jeans for women in some stores, provides the best example of this kind of mass customization. Many women have a difficult time finding a pair of jeans that fits to their satisfaction. Buying jeans is based on both style and fit; for many people this means trying on several different brands and finally making compromises. Jeans-makers have tried to satisfy the majority by making many different styles and sizes, but for some customers there still are not enough choices.11 Fit for a given style involves at least four different measurements. Obviously, waist and hip measurements are important, but where the waist should be also matters and, once that is determined, there is inseam length.12
A customer for Levi’s custom jeans is asked to try on the style that comes closest to the fit she wants. The store sales associate then takes the four key measurements: waist, hips, where the waist should be, and inseam. These measurements, along with the style of jeans and the type of fabric, are sent to a sewing plant where they are cut, sewn, and then mailed to the customer. Levi’s uses proprietary software to make these modifications, but other software systems are commercially available for modifying standard patterns and producing a marker to guide fabric cutting.13
The actual making of custom jeans or any other item of custom apparel is slightly more complicated than making an equivalent item under standard production conditions. The pattern pieces for each individual pair of jeans must first be modified. Then a unique marker must be created that combines different orders using the same fabric. Under these conditions, a marker will not be as efficient as the standard production markers shown in Figures 8.1 and 8.2 (page 137) because the amount of cloth that can be saved for a single ply does not justify the time required to reach high levels of cloth utilization. Indeed, fabric-cutting costs are higher for custom clothing than for mass-produced items simply because just one item of apparel is cut at a time.
Mass customization of this sort also means that a single garment must pass through the sewing room at a time. Apparel assembly is described in the next chapter, but for now it is enough to say that all the pieces for a custom garment must be kept together during assembly. If the sewing room is making garments one at a time, it is probably not using the progressive bundle system. Instead, items will be assembled by teams of a few workers, who will do all the assembly operations. Such a short-cycle production system adds to the cost of customized apparel.
You cannot make a completely customized item of apparel with just four measurements. The Levi’s process merely adjusts the pattern pieces of a basic style of jeans with these measurements. If a customer wants more areas or features customized, many more measurements are necessary. Achieving consistent measurements presents a major problem because two trained fitters will generally come up with important differences in the body measurements of the same person. No matter how the measurements are taken, most people being measured in this way have a difficult time standing up straight and holding in their stomachs.
The second approach to mass customization attempts to overcome some of these problems by optically scanning the customer with light beams in a private area of the store. In this case, the person needs to be dressed in appropriately tight (form fitting, but not form modifying) athletic shorts and a top. The computer-processed results of such a scan are shown in Figure 8.3 (page 148), with a sample of the extracted body dimensions in inches printed on the right side of the figure. For reference, some of the measurements are highlighted and presented as darkened lines on the processed image.
The optical system that produced this image was developed by [TC]2 and is now ready for commercial demonstration.14 This system will probably cost $100,000, and a demonstration in a shopping mall is currently under way. When in place, customers will be scanned at a central location in a mall. They would then take their body measurements to any of several participating retailers, who pass the information on to their apparel suppliers and have the clothing custom-made.
Computer-generated body measurements are just the first, if most important, step in achieving success in fit for customized apparel. The measurements must still be transmitted to a CAD system that will automatically alter the pattern to conform to specific body measurements. From that point, the pattern must be laid out, cut, and sewn by a group of sewing specialists.
The technology now exists to do mass customization, whether that involves a pair of jeans based on four measurements or a garment custom-made from a whole body scan. Five U.S. firms, including [TC]2, offer 3-D scanners, and there are at least two firms with systems that can adjust basic patterns to conform to individual body measurements. Custom clothing may therefore be financially available to a wider audience in the future, opening a new market in which domestic apparel manufacturers can compete. The general public interest in the possibilities of mass customization is evidenced by a recent article in The New York Times describing the techniques and reporting that representatives of several apparel firms expressed interest in exploring the public willingness to pay for better fitting clothing.15
From Preassembly to Assembly
Mass customization represents an innovative combination of new technologies in information, design, marker-making, and cutting. For the short term, its impact will be on a relatively small niche market. However, lean retailing and product proliferation place much more general pressure on suppliers to decrease time and cost per SKU associated with the design and preassembly steps we have described.
In many American apparel plants, central spreading and cutting rooms abut the area of fabric inventory. Finished goods distribution is often a part of the same complex. Centralization of this kind makes financial sense because trucks that take out cut parts to a firm’s sewing rooms or contractors can return with finished goods for inventory. Having spreading, computer-cutting, fusing, and inspection in the same areas also allows teams of cross-trained workers to prepare the order for sewing, finishing, final inspection, and packaging. This is one place in apparel manufacturing where teamwork has been quite successful. In many cases, it has shortened the cycle time from order to ready for sewing by half. In addition, computer-cutting or die-cutting makes the team less dependent on the skill of a manual cutter and allows all team members to operate automated-cutting equipment.
These centralized spreading and cutting facilities generally operate at least two shifts per day and, in some large companies, around the clock. The equipment is capital intensive, especially if computerized or die-cutting machinery is used; therefore, plant managers try to keep these lines producing as much as possible. We have visited a large knit goods manufacturer that combined final fabric finishing operations in the same building with cutting and initial automated sewing, all of which operated around the clock. Although automation of sewing operations is generally not cost effective, these innovations have made some inroads in particular segments. T-shirts, which are consumed in the United States every year by the billions, are a good example. A commercially available machine can automatically make the sleeves of T-shirts. This machine picks up cut material from a carousel at one end and delivers finished sleeves at the other. One operator can tend to the needs of two such machines. Yet because the investment per worker is several hundred thousand dollars, it only makes sense if the equipment is used nearly continuously.
Sewing factories, in contrast, are not capital intensive and are rarely operated for more than one shift. Because of this, most expensive automation equipment is concentrated in preassembly, drawing on multi-shift operations. Marker-making, fusing processes, sleeve-making for T-shirts, die-cutting, and computer-driven knife-cutting fall into this automated “getting ready to sew” category. As always in a world of lean retailing and rapid replenishment, the need for faster production is what drives these capital-intensive technical innovations. Because some U.S. manufacturers have found that centralizing preassembly operations also improves the quality of products, this may provide another edge for American apparel-makers in the future.
Our survey indicates that the average length of time it takes to get a garment ready for sewing, from issuing the order for a given marker to having the pieces cut and otherwise prepared, is 4.9 working days. The cut parts are then sent to sewing areas or other factories. If the sewing room is in the same building as the cutting room, then cut goods are sent over many times a day. If the sewing factory is far away, then a shipment once a week is typical. Reducing the time from placement of the order to cut goods in the sewing room requires decreasing both the time it takes to complete preassembly and the wait for delivery to the sewing room. Indeed, logistical considerations enter assembly well before garments are finally sewn together. Time really is money in today’s apparel industry, a theme we will expand on in the next two chapters.









Retailers’ calls to apparel manufacturers about late delivery are the basis for many a tall tale at retail conventions. In the past, the standard reply to a query about what had happened to an order was “It’s on the loading dock.” Information systems at apparel factories were primitive. If all the SKUs for an order were not in the warehouse, substitutions of the same style in a different size would be offered to the retailer. Or retailers might not even notice if an unplanned substitution had been made because their information systems were equally as primitive. If there were insufficient SKUs of the requested style, the order would be shorted or a phone call made to the retail buyer to negotiate a solution to the problem. If no SKUs of the order were in the finished goods warehouse, then the search of the factory floor—where there might be tens of thousands of partially completed items to look through—would begin.
Then along came lean retailing and the need for rapid replenishment—manufacturers are now expected to replenish products in less than a week. At first, only a few retailers required this, and apparel manufacturers tried to meet these needs with minimal changes in their internal practices. Often, this was done at the expense of a manufacturer’s non-lean retail customers. For example, the CEO of a men’s dress-shirt supplier reported to us in 1992 that its finished goods warehouse was divided into two areas. A locked section contained finished goods reserved for orders from Dillard’s, Inc., this manufacturer’s biggest customer and its only one with stringent rapid-replenishment requirements. The rest of the warehouse held inventory for all other retailers. If the locked section had insufficient inventory for a Dillard’s order, product from the rest of the warehouse could be picked and sent to Dillard’s, but no retailers could receive products from the locked section reserved for Dillard’s, no matter how severe their needs. This arrangement worked well from Dillard’s perspective; it found this firm to be one of its best rapid-replenishment suppliers, with high order-fulfillment rates and on-time deliveries—the main criteria for success. For the manufacturer, it meant a larger finished goods inventory and worse service for its other customers.
As long as only one or two retailers required rapid replenishment, manufacturers could get away with this type of solution. But it didn’t take long before most retailers wanted orders for basic apparel items replenished this way and they became very demanding. As an increasing number of suppliers are dancing to the demands of rapid replenishment, they are finding it a complex tune. Manufacturers suddenly have much more to do than just make clothing—they are being asked to do work previously done by the retailer, such as picking and packing the order for each store from the retailer’s warehouse. Each store’s order has to be put in a separate carton, labeled with its own bar code, and accompanied by an advance shipping notice. Moreover, retailers want an order to arrive at their distribution center at an exact time. If the truck is late, the driver often has to wait until the end of the day to unload, if allowed to do so at all. Deliveries made a day late are sometimes refused and sent back.
Such retail requirements have certainly put substantial pressure on apparel manufacturers to change their own practices. Chapter 5 described some of the basic changes many manufacturers are making to stay in the game with lean retailers. But even if lean retailing has led to suppliers’ wide-scale adoption of bar codes and EDI-related capabilities, divergent production strategies among suppliers have emerged. Conceivably, two business units could each meet the same lean retailing requirements yet have very different internal practices and performance. One could raise finished goods inventories substantially (like the dress-shirt manufacturer described above); the other could make crucial operational changes to reduce manufacturing lead times. However, in light of the growth of rapid replenishment, our research predicts that the performance of these two units will vary over time, with the supplier that has implemented flexible planning and short-cycle production processes coming out ahead. By investing in these practices, apparel suppliers have the potential to satisfy lean retailing performance standards without bearing the costs of greatly expanded inventory in their own operations. From our standpoint, holding high inventories to meet rapid replenishment demands is strictly a short-term strategy for manufacturers.
The increasing emphasis on rapid replenishment raises a related question: can offshore manufacturers meet retailers’ requirements for such short delivery lead times and so many services? More specifically, what are the characteristics of products for which inexpensive, long lead-time production is preferable to more costly production with extremely short lead times? The models and analyses presented in this chapter help shed light on this critical question.
We begin this chapter with an overview of the impact of demand variability on a manufacturer’s own inventory and production planning processes. Next, we describe how apparel manufacturers can use statistical analysis and simulation to gain insight into inventory planning and production scheduling for products they offer in their rapid replenishment collections. The first of two case studies illustrates how demand uncertainty affects a firm’s target inventory levels. The second case study demonstrates how short-cycle production translates into inventory reduction for a manufacturer, thereby radically reducing the increased exposure to inventory risk a manufacturer would otherwise face to meet lean retailers’ demands. The chapter concludes by emphasizing the relationships among demand volatility, manufacturing lead times, and inventory levels, addressing a critical decision apparel manufacturing firms face today: Given two different apparel sources, with different variable production costs and lead times, how does a firm decide which products to make in each of the two plants?
The Key Role of Demand Variability
The most important thing we are doing is “consumerization,” to be the best in the business in delivering products customized for what the consumer wants. All of our initiatives are to drive consumer value. And as we reduce costs, we reinvest those savings in improving our consumer responsiveness.1
—Mackey McDonald, President and CEO, VF Corporation, 1998
Because being responsive to consumer tastes is central to lean retailing, dealing with variability in demand has become crucial to suppliers competing in a lean retailing world. Even for basic products, demand varies from day to day and week to week. Thus, if a retailer follows the simplest strategy of ordering at the beginning of each week exactly those items that sold during the previous week, manufacturers must be prepared to ship an unknown number of items each week. Very few manufacturers can produce items in production quantities in the limited lead time retailers allow for replenishment and consequently they must fill such orders from finished goods inventory. And, as one would expect, the higher the variation in week-to-week demand, the more inventory a manufacturer must hold to meet a retailer’s high service expectations.
Because weekly demand variability is a key determinant of the finished inventory a manufacturer must hold, each firm should conduct an assessment of the demand variability of each item in the product line.2 Retailers require orders to be filled at the SKU level, so such demand variability analyses should be conducted at the SKU level as well.
We conducted such an analysis of weekly demand for a U.S. manufacturer of men’s coats, suits, and blazers. Figure 7.1 depicts the weekly demand for one SKU—a single-breasted coat in one of the firm’s most popular sizes (46-regular)—during the first twenty-four weeks of the year. Each week’s demand has been divided by the average demand over the twenty-four weeks; therefore, the average weekly demand is simply equal to 1.0 on this normalized scale. (The important features of demand for scheduling coat production are contained in demand data presented in this normalized fashion. Normalizing the data also allows us to keep this manufacturer’s actual demand volume confidential without obscuring the central information contained in the data.)
Plotting the data in this way allows us to focus on the deviation of the weekly demand from the average weekly demand. Figure 7.2 depicts the weekly demand for a different SKU—the same single-breasted coat—but this time in a less popular size (43-regular). Again, the normalized data highlights the weekly deviation from the average demand. In this case, there is greater week-to-week variation than for the more popular size.
The amount of variation in weekly demand exhibited in Figure 7.2 is quite remarkable, especially if we consider that the manufacturer’s demand is based on the total sales of this SKU in over a thousand retail outlets each week. It is important to note also that this product was not promoted at retail with discounted prices at any time during this period, so the variation is not due to consumers preferring to purchase a product when it was “on sale.” In addition, the demand peak for the 43-regular occurs in week 10, which was only an average demand week for the 46-regular.
It is useful to outline the ordering and manufacturing processes on a weekly basis to see how this manufacturer’s inventory policies might differ for the two different sizes. Suppose that, as described in Chapter 6, the retailer consolidates POS data for the previous week’s sales each Sunday night and places a replenishment order with our manufacturer. On Monday, the manufacturer (1) processes the order; (2) picks and packs the desired items from finished goods inventory and ships them to the retailer; and (3) places a factory order to manufacture those items that it shipped that day. Assume that the manufacturing lead time—the amount of time required to go from a production order to a product ready for shipping to retail—is less than one week. Then, by the following Monday, the items ordered the previous week would be completed at the factory and available in the manufacturer’s finished goods inventory. At this point, the manufacturer’s inventory is restored to the “target” level it had the previous week and is ready to fill the next week’s retail replenishment order.
For the popular 46-regular coat, weekly demand never exceeds twice the coat’s average demand. Thus, as long as the lead time for producing more coats in size 46-regular is less than a week, the manufacturer could hold two weeks’ worth of inventory and be able to fill—immediately—retail orders that replenish the previous week’s demand. That is, it could set a target stock level of two weeks of finished goods inventory and be able to provide a very high customer service level (defined here as order-fulfillment rate) to retailers.
However, for the low volume 43-regular, the maximum weekly demand is about four times the average. To provide the same service level to retailers for both sizes, our manufacturer must hold twice as many weeks of demand of finished goods for the 43-regular than for the 46-regular. Note that we are comparing the inventory levels in terms of weeks of average demand, which measures the ratio of the units of finished goods to average weekly sales. In fact, the actual number of units of finished goods inventory would be higher for the popular 46-regular than for the low volume 43-regular. The point to keep in mind here is that, compared to a product’s average demand, more popular products required relatively less finished goods inventory than less popular ones. Bear in mind that the actual sales of our manufacturer’s coats showed no seasonal variation. If a product has seasonal sales trends, then the manufacturer’s inventory must rise to meet customer demand during peak seasonal demand. Furthermore, if the manufacturing lead time exceeds one week, the manufacturer faces more demand risk and therefore must hold even more inventory.
As explained in previous chapters, variation in weekly demand can be characterized by a standardized measure, the coefficient of variation, or Cv. Formally defined as the standard deviation of demand divided by average demand, the coefficient of variation can be considered a measure of variation that is normalized; it allows us to compare the variation of demand for different products, even if the average demand of the two products is quite different. The value of the coefficient can vary from zero (if demand is exactly the same every week) to numbers much greater than one for wildly fluctuating weekly demand. In our analyses of demand patterns for different apparel products, we have found that the most predictable items have Cvs in the 0.4 to 0.6 range. But in most situations in which a firm provides a wide range of goods to customers, some of its products will have low or moderate demand variation, while others’ demand will vary a great deal. As illustrated in the previous examples, high volume products often have lower coefficients of variation than low volume products. (In Figure 7.1, the high volume 46-regular has a low Cv of 0.55. In Figure 7.2, the lower volume 43-regular has a Cv equal to 1.0, which means the weekly demand departs much more from the average.) This is a result of the familiar “demand pooling” argument, which shows that the total variation for the sum of many customers’ demand is less than the sum of the variation in individual customers’ demand.3
The same argument can be used to explain why growing product variety has increased demand variation at the SKU level: As variety grows, demand is distributed among an increasing number of SKUs, thereby reducing the pooling effects of demand aggregation. Take the single-breasted coat of our manufacturer, which is sold through more than a thousand retail outlets. The total yearly sales of all SKUs of this kind of coat are in the tens of thousands. Yet sales of some of the less popular sizes, such as the 43-regular, are only a few hundred a year. When considered on a weekly basis, this translates into average weekly demand across all retail outlets of less than ten units. Therefore, even a small swing in demand from week to week translates into high relative variation—that is, into a high coefficient of variation.
Figure 7.3 (page 114) plots the coefficient of variation for men’s single-breasted coats. The graph shows that the SKUs with the lowest total yearly sales have the highest Cv values (the largest variation in week-to-week demand). The coat manufacturer will have to hold relatively more finished goods inventory of the low volume SKUs than of the high volume SKUs.
Taking demand variability into account becomes even more important given recent trends toward product proliferation. Over time, suppliers must manufacturer more and more goods that have the joint characteristics of low volume and high variability. As a result, product proliferation represents a shift in the curve relating sales volume and variability (see Figure 7.4).
High demand variation similarly occurs during the beginning and end of a product life cycle. This variation is due in part to the lower demand volumes during those periods relative to the middle of a product’s life, but such fluctuations also occur because of the inherent uncertainty during the ramp up or ramp down of a product’s life.
Demand variation plays a central role in determining a manufacturer’s finished goods inventory levels. In the following case studies, we describe how demand variation can be used to determine a firm’s production and inventory planning processes. These cases offer a rational approach to inventory management for manufacturers, one that is premised on receiving accurate POS information from retailers and maintaining good working relationships with all channel players—for example, retail orders are not placed at the last minute and textile suppliers come through when they say they will. Reality is messier of course: retailers and suppliers often “surprise” manufacturers, and the POS data are rarely perfect or may not even be available. Yet these nagging problems do not negate the need for a new approach to inventory management; they merely indicate how complicated supplier relationships have become.
Case 1: Inventory Control at a Men’s Coat Manufacturer
Our first case study examines the inventory management practices at the men’s coat manufacturer previously described. This manufacturer’s standard approach to rapid replenishment requests was simply to carry large inventories. The firm treated all SKUs alike; it held the same number of weeks of demand for each SKU. Specifically, our manufacturer checked inventory of every item each week. If the inventory of any item was ten weeks of demand or less, the firm would place a production order for that item so that the current inventory plus the planned production was equal to fourteen weeks of demand. (This manufacturer essentially followed an (R, s, S) policy as described in Chapter 6, with R = time period between orders= seven days, S = target inventory level = fourteen weeks, and s = reorder point = ten weeks.)4
Note that this response is not unusual. Many manufacturers do not explicitly track and use information like weekly demand variation for different SKUs. Currently, no manufacturer we know of has implemented all the changes described here and in the following chapters. In that respect, this men’s clothing supplier is representative of the industry.
In our initial assessment, we found that this manufacturer was in stock for most SKUs most of the time—a pretty good result. However, we also noticed that the firm was out of stock for some items, especially those with the most variable demand. Managers first thought that was true just for its largest sizes, but further analysis revealed that the company had the same problem with some small sizes as well as with some less popular styles. The firm was stocking out of the low demand items, which, as described above, suffered from relatively high demand variation. This is illustrated in Table 7.1, which shows the average order-fulfillment rate for products with different levels of demand variability, assuming the same level of average demand is held for each SKU.
The data suggest that when a manufacturer chooses the same inventory policy for all products, its order-fulfillment rate for highly variable products is usually worse than for low variation products. Such a policy rarely maximizes profits; the manufacturer stocks out, thereby losing the margin on the sale, and the retailer, which typically desires a consistent (or at least predictable) order-fill rate across items in a product group, is unhappy. Simply increasing inventory for all SKUs would be a poor allocation of investment, further increasing the order-fill rate for those SKUs for which service levels are already high. Thus, for most manufacturers, tracking weekly variation for different SKUs is essential and will help to guide a firm in setting appropriate inventory targets for each SKU. To do this, firms need a planning tool that translates demand variation into inventory targets by weighing, for each SKU, the opportunity for more sales against higher inventory carrying costs.
Once demand variation for each SKU was determined for our men’s coat manufacturer, its managers faced the question of how to manage the inventory of the items in its rapid replenishment collection while maintaining a smooth flow of products through the sewing room. Using traditional sewing operations, it typically takes eight weeks to produce a coat, from the time an order is issued for cutting to the moment the finished goods are hanging in a manufacturer’s distribution center. Two weeks are spent in the cutting room, where the cloth is spread, cut, inspected, and has backing material fused to appropriate parts of the outer (“shell”) fabric. Four weeks are spent in assembly processes. The last two weeks involve final inspection, repairs if necessary, shipping to the distribution center, and hanging the finished coats so they can be picked to fill individual orders for a given store.
A men’s suit coat or a blazer requires more than a hundred assembly operations (compare this with only forty operations for a men’s shirt); it is one of the most complicated and expensive apparel items to make. Although the number of operations partly determines how long it takes to get a garment through production, other factors come into play, including the firm’s policy about how many finished coats should be allowed to build up in work-in-process and finished goods inventory. Given this manufacturer’s policy of ordering production only when inventory levels dropped below ten weeks, with the production quantity set to restore the inventory to fourteen weeks, the minimum production quantity for each item was four weeks of demand. Thus, at least four weeks of demand—a large quantity for most products—of the same style and size could move through the sewing plant at one time, minimizing setup costs for thread changes and the like.
The diagram in Figure 7.5 depicts the production process, including all product and information flows relevant to the inventory decision. In general, to maximize operating profit, a manufacturer must know the factory’s overall cycle time, work-in-process carrying costs, finished or hanging goods carrying costs, unit production costs, and unit selling price, as well as the Cv for each SKU of a given style. The manufacturer in this example effectively had limitless capacity to produce the single-breasted coat, since only approximately 30 percent of the plant’s total capacity was devoted to producing a variety of rapid replenishment items. This capacity could be invoked when necessary by putting aside the lower priority products made in the factory.
Our approach to the problem was to use operations research techniques and computer simulations of demand to explore the appropriate inventory levels, taking into account the statistical nature of the weekly demand for each of the SKUs for a style. In our approach, we assumed that an unfilled order was a lost sale with a lost profit. Table 7.2 reports the recommendations derived from the method.5 Setting a target inventory level for each SKU that maximizes profit is the first step; we did this using a computer simulation. As expected, the target inventory levels depend on a product’s demand variation. The larger the variation is, the higher the inventory level should be for an item to satisfy demand, as shown in the fourth and fifth columns of Table 7.2. The second and third columns of the table indicate our manufacturer’s standard approach to inventory and are included to allow comparison with the optimal policy.
The optimal policy is one for which marginal increases or decreases in chosen inventory levels will not confer additional profits. For example, when demand for an item was quite variable, with the highest Cv of 0.90, the optimal policy called for placing a production orders when inventory dropped to twelve weeks of demand, rather than the lower standard level of ten. Put in a different way, increasing the amount of inventory from the company’s uniform level to the optimal level raised the manufacturer’s order-fulfillment rate to more than 97 percent for all SKUs, which raised profits more than it cost the manufacturer in terms of added inventory carrying cost. As a result, overall profits increased because of the change in inventory policy.
Following this strategy, it is true that a manufacturer will carry more inventory for certain items. Yet the percentage of time (97.6 to 99.5 percent in our simulation) that the firm is in stock for these SKUs translates into more sales and fewer stock-outs, which increases gross margin and, ultimately, operating profit. Because margin is primarily determined by the difference between the selling price and manufacturing and materials costs, if the margin for a unit is high, it pays to be almost always in stock. The resulting profit accrues, even after the higher finished goods carrying cost associated with larger inventory has been considered.
This view of production and inventory planning also provides a manufacturer with a more sophisticated tool for balancing alternative plant operating choices to maximize profits. For example, consider whether a manufacturer should cut fabric and assemble garments in smaller lots. In order to make this decision for a SKU with a given level of demand variation, this firm’s managers should weigh the increased unit costs arising from manufacturing smaller lots against the benefits this might create in shortening production lead times, which would reduce the amount of inventory the firm must hold for that product. Similarly, the impact of alternative methods for reducing plant cycle time depends not only on the direct costs of changes, but also on the reductions in inventory levels allowed by shorter lead times.
Fundamental to any resulting scenario is the idea of coupling inventory carrying costs to other manufacturing costs in order to make optimal production planning decisions. This allows manufacturers to balance the potentially higher operating costs associated with decreasing lot sizes (the minimum number of units in a production run) with the opportunities to reduce inventory carrying costs and increasing sales. The failure of most suppliers in the apparel industry to make inventory carrying costs an explicit part of their decision-making process remains a significant impediment to enhanced profitability. On the flip side, the performance results presented in Chapter 14 indicate that moving toward this more sophisticated method of handling production decisions can yield significant competitive advantages.
Case 2: Multiple Plants and Production Planning
Of course, a firm that relies on multiple production plants has a more complex problem than the example just presented. Not only must it set inventory levels and schedule production for each product, but it must choose which products to assemble in each plant. In many cases, the choice is between a more expensive plant—probably located close to the market—that provides shorter lead times and a more distant supplier that takes longer to make items but does so at a lower unit cost. Under the traditional retailing system, suppliers filled an order by carrying out assembly in the least costly plant, as long as its quality was adequate for the market for which the product was destined. In a lean retailing world, however, factors other than the direct costs of assembly and transportation need to be considered.
Caught between lean retailers’ need for immediate replenishment and the high risk of carrying inventory for products with uncertain demand, a manufacturer today must go beyond traditional direct costs and also include manufacturing lead times and inventory carrying costs in its sourcing equation. Most production managers instinctively believe that having at least some manufacturing capability close to the market adds value to the company, but expressing that value in dollars and cents, and making specific allocations of products to plants, are difficult.
Manufacturers—whether of suits, CDs, office products, or pasta—generally classify products in terms of product lines. Planning, therefore, is done for fall fashion lines, jazz ensemble CDs, yellow legal pads, or fettuccine pasta products. Even if this method of categorization is important from a marketing perspective, it often glosses over what is, in fact, common to many products that seem different and different about products that seem the same. Once again, demand variability is key. For our men’s suit manufacturer, the men’s size 43-regular coat may have less in common with the size 46-regular coat in the same size and color than with a fashionable boy’s blazer.
To set an optimal policy for a multi-plant or multi-source setting, the first step is to determine the coefficient of variation for each SKU and then to arrange the SKUs into groups that have similar variations in weekly demand (i.e., the same Cv). Figuring out how to assign products to plants rests on two findings explored in this chapter. First, the previous case study suggests that SKUs with large demand variance (high Cvs) will require larger amounts of inventory than low variance SKUs to provide a high order-fulfillment rate to the retailer. Second, we argued earlier that reducing manufacturing lead times can lower the amount of inventory needed. The combination of these factors suggests that high variance SKUs are the best candidates for a plant with short lead times—the higher direct costs of production are balanced by the reduction in inventory carrying costs resulting from the shorter manu-facturing lead times.
The Two-Plant Model
Our second case study is based on a prominent apparel manufacturer that acted as one of our research sites. Here we will show how a decision tool can be used to make the transition from general intuition to specific decisions about (1) which products to make in each plant and (2) how to schedule the time and quantity of production for each product.6 This analysis can help manufacturers allocate production among existing facilities. It also illustrates what plant characteristics a close-to-market production facility must have to be competitive with low-cost, offshore suppliers. For this analysis, we assume that that the two facilities already exist—that is, we do not evaluate the option of building a new plant or modifying an existing plant (i.e., we are seeking a solution to a short-run optimization problem.)
A simple depiction of the production situation is presented in Figure 7.6. Block diagrams represent this manufacturer’s plants and distribution center as well as the retail stores involved. There are two production lines or plants; in the “quick-line” plant, it costs more to produce an item of apparel but it does so more quickly than in the “regular-line” plant. The flow of goods is shown in solid lines, and information flows are represented by broken lines. Both plants are capable of making the same set of products. We assume that once a week, orders from all retail stores selling the product are received, picked, packed, and shipped to the retailers from the manufacturer’s distribution center. On receipt of the weekly orders, production managers total the quantity of each SKU ordered and determine production needs to restore each SKU’s distribution-center inventory to its target level. The total production quantity for each SKU is allocated between the two plants. The cost to produce a unit and deliver it to the distribution center is known for each plant, as well as the time it takes.7
For confidentiality reasons, the actual costs and weekly sales volumes for our manufacturer are disguised; however, the cost numbers and sales volumes that appear in this case are reasonable numbers for, say, an upscale dress-shirt manufacturer. Let’s assume that we have a single style of dress shirt and that the shirt can be made in one of two plants. In the plant with the “regular” production line, the average direct cost of producing one shirt is $13.15: $7.15 in materials costs (including all buttons, thread, and lining material) plus $6.00 in labor and transportation costs (including direct labor at the plant level; transportation costs for fabric and other supplies shipped to the sewing plant; the cost of transporting finished goods to the manufacturer’s distribution center, any customs fees or insurance associated with transportation, and any other costs associated with producing an acceptable unit of finished goods). The other plant (the “quick-line” plant) has production costs that are 10 percent higher than for the regular line, but the manufacturing lead time from the time a production order is placed until a shirt is available in finished goods inventory is two weeks, compared to eleven weeks for the plant with the “regular line.”
The question a manager faces in this situation can be stated as follows: For which dress shirts is it more profitable to pay $13.75 per shirt ($7.15 materials plus $6.60 production costs) but have a two-week production lead time, rather than $13.15 with an eleven-week lead time?
If this case involved traditional production strategies in the apparel industry, there would be no problem to study. Managers would just decide to make all these dress shirts in the regular plant because its unit production cost is lower. But in the world of lean retailing, the decision becomes more complicated. Now the unit wholesale selling price, assumed to be $22.00 a shirt, is relevant to the decision because managers must weigh the cost of carrying shirts in inventory with the foregone revenue if they stock out of shirts in the distribution center.
In addition, these managers need to know weekly demand variation as well as average weekly demand for each SKU. In this case, we assume that total weekly demand for all of our SKUs averages 10,000 shirts a week. We classify the SKUs into three categories: those with high demand (averaging 5,700 units a week) and low demand variation (Cv=0.6), those with medium demand (averaging 3,000 units a week) and medium demand variation (Cv=0.7), and those with low demand (averaging 1,300 units a week) and high demand variation (Cv= 1.3). These particular volumes and Cvs were chosen based on the values shown in Figure 7.3 (page 114). 
Finally, to allocate production appropriately, managers need to know the inventory carrying cost for carrying work-in-process and finished goods inventory. The inventory carrying cost should reflect not only the cost of capital tied up in inventory, but also the risk of holding that inventory. One indicator of risk is the cost of markdowns manufacturers must make to clear inventory that retailers are not willing to purchase at full wholesale price—if at all.8 For example, the HCTAR survey found that an average apparel business unit discounted its products to retailers by 24 percent in 1992.
Determining Optimal Allocations
Next, the manufacturer must determine what percentage of its total capacity should be allocated to the quick line (we call this percentage the quick-line capacity ratio), with the remainder allocated to the regular line. Once this decision is made, specific SKUs must be allocated between the two plants on a weekly basis. As in the first case study, we assume that the retailer places an order every Sunday night and that the order must be filled during that week.
We have developed a software package that solves this problem by using computer simulations of the weekly demand and production that determine the consequences of different quick-line capacity ratios and production scheduling policies for the manufacturer’s inventory and service levels (order-fulfillment rate) to the retailer. For a given quick-line capacity ratio, the computer program searches for a target inventory level for each SKU and finds the values of the target inventory for each group of SKUs that maximizes profit. The number of computer searches necessary is very large, but with a fast desktop computer and by using special search reduction techniques,9 the computations can be carried out in just hours.
The results of a search for the maximum profit in this two-plant case appear in Figure 7.7 (page 124), which shows how the quick-line ratio increases as the inventory carrying costs increase.10 As we would expect, if the cost of carrying inventory is very low, the quick line is not used; that is, the quick-line capacity ratio equals zero. As inventory costs rise, the percent of units allocated to the quick line increases; eventually, when the annual inventory carrying cost approaches 30 percent, the ratio equals one—that is, all the production is allocated to the short-cycle plant. With higher values of inventory carrying costs, it is more profitable to shift more production to the quick-line plant to allow reduction in work-in-process and finished goods inventory.11
The major point here is that inventory carrying cost is a critical variable in making such plant capacity decisions. A 24-percent annual inventory carrying cost amounts to approximately 2 percent a month. For the long-cycle plant, work-in-process and finished goods inventory will cover about sixteen weeks on average before the unit is sold. At 2 percent a month, this results in an inventory carrying charge of just 8 percent of the cost to assemble (plus materials). This 8 percent charge against materials and production should be compared with the 24 percent of wholesale selling cost our survey reported as the average markdown needed to clear inventories.12
Figure 7.8 shows the full relationship between inventory carrying costs, lead times, and the quick-line production ratio. Again, our earlier intuition is confirmed. The decreasing lead time of the quick-line plant makes it competitive at a lower inventory carrying cost. The short-cycle plant becomes more competitive for two reasons: (1) there is less work-in-process; and (2) the finished goods inventory level necessary to satisfy retail demand for each SKU is less because the short-cycle plant can respond to actual demand more quickly.
In this figure, the cycle time of the slower plant has been set at eleven weeks; the short-cycle line can make our products with three different times—namely, two, three, or four weeks. In this case, the cycle time for the long-cycle plant represents the number of weeks typical for offshore production. Note that some outsourcing of production for fashion items is done in Pacific Rim countries and flown directly to distribution centers in the United States. For example, executives at The Limited have often claimed that its firm can produce an item offshore in a thousand hours—or just six weeks—using air-freight delivery to its center in Columbus, Ohio. But most firms that use foreign plants take longer, which is why we have chosen eleven weeks as the cycle time of the slower production line. Figure 7.8 shows the curves for the various lead times listed in the legend on the right-hand side.
Both components of total inventory (work-in-process and finished goods) decrease as the most profitable production shifts to the short-cycle plant. Less finished goods inventory is required because finished goods can be rapidly replenished after a peak selling week.
Therefore, the amount of finished goods in the manufacturer’s distribution center needed to satisfy weekly demand for all SKUs depends on the cycle times of the plants supplying finished product, and what fraction of production is made in each plant. In the single-breasted coat example of the previous section, there was only one plant involved, which made the most profitable target inventory level a single number for each SKU.13 Increased profit came from missing fewer sales by being in stock a higher percentage of the time. In the second case, the finished goods in the distribution center are generally a blend of the output of two plants and the target inventory level varies with the quick-line capacity ratio. Most important, when a manufacturer considers two sourcing options, the one that offers the lowest direct cost is not always the most profitable.
The Manufacturer’s Dilemma in a Lean World
This chapter shows that suppliers must take additional dimensions into consideration when they make decisions about sourcing. To maximize profits, a firm must consider the complete set of benefits and costs of production decisions. The disadvantage of lower cost, slow production today is that it is necessary to risk large inventories to provide reasonable levels of service to retailers. The omission of such costs from sourcing decisions—as well as the failure to consider the benefits a supplier gains by being in stock on certain items—will reduce a manufacturer’s profitability as well as its ultimate ability to compete.
This dilemma in a lean retailing world is summarized in Figure 7.9. Exactly how a manager divides production between plants with different production costs and cycle times depends on the details of the situation, such as those presented in the cases above. However, at least one general rule emerges from the cases we have studied: The cycle time of a fast production facility can be no more than a week or two. Needless to say, a local, more expensive production line with long cycle times cannot compete with slower, low-cost producers, even when allowances are made for late deliveries, markdowns, and the like.14 But as Figure 7.9 suggests, a manufacturer can pay somewhat more to make certain units—those with high weekly variation in sales—in quick production lines and still reap a better return than it would by making all of the product in a less expensive, slower plant.
Balancing these production alternatives clearly has implications for foreign competition and the current transformation of the U.S. apparel industry. It also requires changes in internal processes, including manufacturing innovations and the sophisticated computer tools necessary to do this kind of production planning. Although many U.S. apparel-makers are only beginning to incorporate these changes into their operations, lean retailing practices will continue to push suppliers in this direction.
The next two chapters examine apparel operations, starting with a look at the use of information technologies and automation equipment in the preassembly stages of garment-making (Chapter 8) and then the sewing room (Chapter 9). Chapter 10 considers how new human resource practices that allow for short-cycle production, in concert with the use of information technology, can positively affect the performance of suppliers.









William Dillard’s simple maxim1 succinctly captures the central—and perennial—inventory challenge facing retail managers. To make a sale, a retailer must have “on its wagon” the product the customer wants. Absence of an item often translates into a lost sale and reduced revenues and profits. The magnitude of such lost sales for retailers can be significant. For example, in 1994, roughly 25 percent of customers who entered a Macy’s store left without making a purchase because the product they were seeking was not available.2 On the other hand, the retail “wagon” should not be too full, since stocking retail shelves with unpopular items also results in excess costs—the cost of capital tied up in unwanted goods, the opportunity cost of the space that could be used for products that customers would buy if present, and, ultimately, lost margin when retailers must resort to price markdowns or product disposal to clear languishing items from their shelves.
The main goal of retail inventory strategy is to maximize profitability by managing the inherent tension between stocking too much and stocking too little. Retail buyers of old grappled with this problem as they do today. But as product variety has increased and product life cycles have shortened, this tension has become increasingly acute, prompting inventory management practices to evolve in recent years to meet rapidly changing market demands. Although a seemingly mundane, tactical aspect of business, a firm’s inventory strategy reflects its approach to managing risk. Indeed, the inventory strategies chosen by firms in a supply channel—and the congruence of those policies across channel partners—have enormous implications for the channel’s speed, flexibility, and profitability.
Conceptually, retail inventory management is straightforward enough: Forecast demand for a product; order the product in the appropriate quantity; stock it in the right retail locations; keep track of its sales and the resulting inventory levels; and replenish its store inventories if possible (either from the manufacturer if it offers replenishment services for that product or from the retailer’s central warehouse if the retailer had purchased a large quantity of the product in advance of the selling season). In practice, however, retail inventory management is fraught with challenges, such as long and uncertain order-fulfillment lead times, and errors in product identification and record keeping. Consider, for instance, how many store clerks still scan items incorrectly at the register. A customer may purchase three similar polo shirts in different colors or sizes, but because the price is the same for all, the clerk may simply scan one of them three times—-losing important information about consumer color and/or size preferences. Even without such obvious errors, forecasting demand at the SKU level has become difficult, as an ever wider array of products cycle through stores. Many lean retailing practices are rooted in retailers’ attempts to deal with growing demand uncertainty. In this environment, ordering large quantities of products far in advance of the selling season is simply too costly. Retailers now prefer to place relatively small orders before the season and then observe consumer response to the product offering before ordering more. As we described in Chapter 4, many have transformed their warehouses into modern distribution centers to facilitate the receipt and distribution of these smaller orders.
The forecasting and inventory models presented in this chapter are not new; they have been recommended for years by statisticians and operations researchers.3 However, until the 1990s, retailers had neither the data collection and computing capabilities required to execute these models effectively nor the tremendous impetus to implement them that lean retailing has precipitated. Because the effects of lean retailing are sweeping across many industries, it is imperative that everyone involved understand how inventory policies have been affected. This chapter covers the key steps in retail inventory management: forecasting demand, choosing appropriate stocking strategies, and determining order quantities and frequencies. Although few retailers have embraced the complete set of forecasting and inventory models described in this chapter, lean retailers are moving in that direction.
The Retail Forecasting Challenge
We first turn to the problem of forecasting sales in retail stores. Imagine trying to predict how many women will walk into a particular downtown Boston store next week prepared to pay $48 (full price) for a size-8 pair of Levi blue jeans, with “long” pant length, “loose” fit, stonewashed finish, and a pleated waist—in other words, one particular SKU out of thousands. How will that compare to the number who would buy the same product but with a “short” pant length? How does a retail buyer even begin to approach the problem of making forecasts at such a minute level of detail?
The buyer might start by trying to get historical data on the weekly sales of those Levi jeans in the store. But wait—should that be on the sales of those jeans throughout the Greater Boston area? Should the buyer base her prediction on sales of only this particular size and style or would it be more accurate to look at the sales of all jeans in this style and then multiply by the percent of all jean styles sold that were size-8 long? Maybe she should restrict herself to this year’s data to ensure that it is as current as possible. On the other hand, one would hate to lose the information that might be contained in past years’ selling patterns.
The complexity of the problem, even for basic blue jeans, is staggering. Now consider the same exercise for a new dress style not previously available at retail—perhaps a style that gained attention when worn by a controversial film star at the most recent Academy Awards ceremony. How many of these dresses will sell this season? Specifically, how many will sell in a dark-peach tone in size 14?
If the challenge of making such predictions for this season’s sales is not sufficiently daunting, try predicting how many of each item will sell during a given period next year.The impossibility of making -accurate predictions of demand long in advance of the selling season—especially at the SKU level—is clear. But because products are manufactured and ordered by SKU, some attempt must be made to forecast demand at that level. Most retailers have to make demand forecasts for products in two different categories: existing products for which historical sales data are available and new products with no selling history. The following section discusses the first category and provides general background on the elements of a demand forecast. It is followed by a short discussion of new product forecasting.
Forecasting Demand for Products with a Selling History
Creating a forecast for a product that the retailer has sold in the past starts with collecting and analyzing historical selling data. Those data provide insight into historical trends and suggest how the product’s sales are related to other factors like weather, holidays, special advertising campaigns, general economic indicators, or simply the passage of time. Air conditioners sell in greater quantities during summer months, for example, neckties just before Father’s Day, and consumer electronics when the economy is booming. Once these relationships are understood, predictions of future sales can be made, although a high level of uncertainty is always involved. Before discussing how one might analyze the trends in historical data, it is important to recognize three often overlooked aspects of demand forecasting.
Three Caveats About Forecasting
First of all, a product’s selling history is only representative of future sales if the product is sold in a stable environment. For the blue jeans discussed above, the selling environment will remain stable as long as competitors do not introduce competing products that draw from Levi’s demand; fashion preferences do not change; a new, more desirable type of denim is not introduced that customers prefer; and the economy does not dip into a recession. However, even for a basic product like blue jeans, it is unlikely that all these assumptions will hold. Given the volatile nature of demand in many industries, an assumption of stability is suspect, meaning that forecasts based on historical sales data may be less accurate than the historical data suggest. Consequently, lean retailers prefer to forecast demand, set target inventory levels, and place orders on a weekly basis, because the selling environment is much more likely to be stable into the next week than months into the future.
Second, most firms gather sales data, not demand data. Customers rarely inform the sales clerk in a typical retail store if a desired product is out of stock; they either buy a different product or leave the store without making a purchase. Direct-mail firms, such as catalog companies and those that sell via television or the Internet, are important exceptions. Because the customer must write, call, or e-mail these retailers with a specific purchase request, these firms are able to capture actual consumer demand rather than sales numbers alone. Such retailers can also gather data about customer demographics, past purchases, and responses to potential substitute items, all of which add up to a gold mine of information about consumer preferences.4
In fact, the value of such data may induce traditional store retailers to offer incentives for customers to share their demand preferences, even when the product is not available in stock. In the mid-1990s, Nordstrom ran newspaper ads promising, for certain products, that if the size or color of an item the customer wished to purchase was not in stock at the store, Nordstrom would locate the desired item and mail it to the customer at no additional cost—both the item and its delivery were free. (Not surprisingly, Nordstrom limited this offer to a small number of basic styles and sizes and to one item per customer.) The only thing a customer had to do was tell a sales clerk what he or she wanted.
This approach has benefits on three fronts: the retailer avoids a lost sale and its associated margin; a potentially dissatisfied customer is delighted by the store’s additional service and free product; and last, but certainly not least, for a very small fee—the wholesale cost of the product and shipping fees—Nordstrom gains critical information about consumer demand. Without such programs, retailers may find it difficult to judge how demand is faring after a product stocks out at the retail site and therefore may have trouble making sensible reordering decisions.
The third caveat to bear in mind is that a “point forecast” (a single number) alone has relatively low value. If a buyer forecasts that customer demand for size-8 Levi jeans next week in one of its stores will be ten pairs, what does that mean? Will exactly ten pairs sell? Is ten the most likely number to sell—or will at least ten pairs sell? A forecast consisting only of a single number provides no indication of the degree of uncertainty.
Indeed, the purpose of the forecasting process is to provide a basis for deciding how many units of a given product should be shipped to a store to minimize the costs—that is, risks—of over- and undersupply. But risk exists precisely because retailers are uncertain about what demand will be for their products. Therefore, to provide a useful basis for making decisions that minimize risk, a forecast should include an explicit assessment of the relative likelihood of different demand levels occurring. Our buyer might capture this information by saying that there is a 90 percent probability that weekly demand for size-8 jeans in the store will fall between two and seventeen units, with an “expected value” of ten units. She might add that there is a 50 percent probability that demand will fall between six and thirteen units. Figure 6.1 shows a demand distribution having these properties. (Note that there is a 95 percent chance that demand will be less than seventeen units next week—thus, if our buyer decides to stock seventeen units at the beginning of the week, the store should be able to offer a 95 percent order fulfillment rate on this SKU.) It is only with such probabilistic forecasts, which explicitly characterize uncertainty, that retailers can make inventory stocking decisions that minimize risk.
Four Components of Historical Demand Data
With these caveats in mind, let’s assume our store buyer has representative historical demand data for blue jeans for the last few years. She will first analyze the historical data by separating the causes of past changes in demand into the following categories: (1) trend, (2) seasonality, (3) cyclicality, and (4) random fluctuation.5
The trend in demand data describes a medium- to long-term growth or decline. Such trends occur in all industries and can be steadily increasing, steadily decreasing, or varying over time. Seasonality describes within-year trends that are associated with the season of the year and that occur year after year. For example, Figure 6.2 shows weekly demand for men’s dress shirts at a particular retailer: There are seasonal peaks in demand at Father’s Day and Christmas, when many shirts are bought as gifts. Cyclicality in demand describes longer-term, gradual rises and declines that are typically associated with aggregate business activity. For example, demand for new automobiles tends to increase during times of economic prosperity and decrease during recessionary periods.
The final component of a demand distribution, random fluctuation, is perhaps the most critical; it is also the most difficult to assess and incorporate into inventory planning. Essentially, random fluctuation in demand cannot be explained by trends, seasonality, cyclicality, or other factors like advertising and new product introduction. Examine Figure 6.2. In addition to the seasonal trend associated with major holidays, random fluctuation in shirt sales occurred from week to week. For our purposes, note that high demand fluctuation decreases one’s ability to forecast demand accurately.
Building a Demand Forecast
After completing an analysis of how different factors relate to past demand fluctuations, our buyer can draw inferences about what future demand for women’s blue jeans might be in her store next week.6 In this case we assume a stable environment: specifically, that past relationships among variables are representative of future relationships among those variables. Although this may not be a realistic assumption for many situations, it makes it easier to understand the fundamentals of demand forecasting here.
Let’s assume that the store’s demand for the size-8 Levi’s jeans last week can be described by the distribution in Figure 6.1. Let’s also assume that the average demand each week has been growing at a rate of about 1 percent, so that the average demand for the next week should be 10*(1.01) = 10.1 units, for the following week about 10*(1.01)2 = 10.2 units, and so on. Then the expected (average) demand is the solid black trend line shown in Figure 6.3.
The buyer could incorporate demand uncertainty into the forecast by indicating different possible values of demand, and the likelihood of that actual demand will fall within those values. For example, in Figure 6.3, the lines directly above and below the solid trend line indicate a range of demand for which the likelihood of demand falling within that range is 50 percent. The lines further from the trend line indicate the range with a likelihood of 90 percent. Thus, for week 1, there is a 90 percent probability that demand will be between two units and -seventeen units, exactly as depicted in Figure 6.1. Predicting what -customers will do when they walk into the store will always be challenging, but the buyer can be confident that if she stocks seventeen units at the beginning of the next week, she has a 95 percent probability of meeting all consumer demand on this product.
Forecasting Demand for New Products
Of course, when a product has just been launched and no historical data exist on which to base a forecast, retailers confront additional challenges. In this case, most companies resort to informal forecasting methods. A common approach is to forecast “by analogy,”using data for similar products that have been on the market previously. One might assume, for example, that sales for this year’s new fashion will be similar to those for last year’s new fashion. This is clearly a subjective call; but once made, it gives retailers a basis for predicting demand patterns for a new product.
Obviously, forecasting demand for new products accurately requires a broad understanding of consumer preferences and market trends. Fisher, Hammond, Obermeyer, and Raman have introduced a method that proved successful in predicting demand for new fashion skiwear as part of an “Accurate Response” forecasting and planning approach.7 This approach combined individual forecasts by members of the company’s Buying Committee, creating a probabilistic forecast whose uncertainty was determined by the level of agreement among forecasts made by individual managers. Statistical analysis showed that those garments for which the Buying Committee had the greatest disagreement were indeed those with the greatest demand uncertainty. The skiwear firm has credited the Accurate Response approach with increasing its profits by nearly two-thirds.8
The Impact of Product Variety on Forecast Uncertainty
The forecasting challenges retailers confront have been amplified in recent years by product proliferation in almost every category. As a result, demand forecast uncertainty has grown substantially, thereby increasing the level of inventory that must be held to meet customer service requirements. High demand uncertainty, previously associated only with fashion products, is now pervasive, characterizing even those items once regarded as basics—such as power tools, industrial seals, men’s dress shirts, and blue jeans.
A good rule of thumb for understanding how product proliferation affects demand uncertainty is that the demand uncertainty for a product category increases as the square root of the number of products in the category (assuming that the total demand for the product category remains unchanged and that the individual items in the category have demand distributions that are statistically independent and identically distributed). A common standardized measure of demand uncertainty, the coefficient of variation (Cv)—defined as the standard deviation of the demand distribution divided by the mean of the demand distribution—for a specific product is proportional to the square root of the number of products offered.9 For example, increasing the number of products offered in a category by a factor of four (say from fifty items to 200) without increasing total demand in the category would increase the coefficient of variation for each individual product by a factor of two. And, as we’ll see in the next section, doubling the demand uncertainty roughly doubles the amount of finished goods required to provide the same level of product availability in the store.
Therefore, product variety is costly due to the increased demand uncertainty associated with each unit. Retailers thus must either limit product variety or change their way of doing business so as to minimize the impact of high variety. Lean retailing is the major such change that retailers are adopting to reduce significantly the costs associated with product variety.
Setting Inventory Levels in the Store
After completing the process of developing a demand forecast for each SKU, a retailer must determine how much of each item to stock on the shelves of its stores. Retailers have an incentive to stock high levels of inventory: They want both to provide sufficient display stock to attract customers—empty shelves are not inviting—and to have products available for those who wish to purchase them. Yet carrying inventory is expensive: Retailers pay capital costs for having their money tied up in inventory, for the physical floor space necessary to store goods, and for handling, managing, and monitoring the inventory.10 Most important, they pay a “risk premium” for carrying products that might become obsolete, either because they are damaged or fall out of fashion.
A retailer’s decision about what to stock will depend on a variety of considerations, including the demand forecast for the product, the level of product availability it wishes to provide to customers, the frequency with which it will place replenishment orders, and the lead time to acquire replenishment units. We’ll describe later in this chapter how these factors affect retail inventory policy. A number of other straightforward costs are associated with any inventory stocking policy, such as the cost of ordering and transporting product; the cost of determining inventory levels; and the impact on purchase price of any quantity price discounts.
In order to evaluate the performance of different inventory options, it is important to emphasize the less straightforward costs involved. Take the two primary types of inventory “errors” a firm can make: stocking too much of an item the customer does not want and stocking too little of something the customer does want. Although the categories for the costs of mismatched supply and demand are simple in concept, in reality they are difficult to measure accurately. Evaluating forced markdown costs is hard, for example, because one must separate markdowns made for promotional reasons from those made to liquidate stock that cannot be sold at full price. The difficulty of measuring these costs is further exacerbated by the fact that a given product may be attractive to different consumers at different prices, so determining the appropriate “full price” for a product is not an easy task.
Stock-out costs are also complex. To determine the magnitude of a stock-out cost for a unit, one must understand consumer behavior. Will the customer buy a substitute item if a particular item is out of stock or return to the same store at a later date to purchase the item when it is again in stock? In these cases, stock-out costs are minimal. But the customer may leave the store because a desired item was not in stock, thereby not purchasing anything else; that means the stock-out cost would equal the margin on all the products the customer would have otherwise purchased. In the most extreme case, a stock-out might cause a customer to switch retailers, costing the lifetime value of that customer and others who might defect due to negative word-of-mouth.
In addition, it is useful to divide the items retailers order into two groups: those for which additional units can be obtained from the supplier during the selling season for that product and those that cannot—that is, replenishable products versus nonreplenishables. This distinction matters, because inventory management differs for products in the two categories. All else being equal, a retailer would prefer to have replenishment opportunities for every product. Lean retailers’ rapid replenishment arrangements radically reduce the risk of undersupply—the retailer can essentially “correct” for those items that it ordered too little of prior to the start of the season—and of oversupply, since the retailer orders smaller initial quantities. In contrast, orders for nonreplenishable products must be placed in full prior to observing consumer demand for the product. The retailer “rolls the dice” and makes its entire order commitment based on preliminary demand forecasts, considerably increasing the risk of over- or undersupply.
Inventory Models for Nonreplenishable Products
When a retailer has no ability to replenish a product, the inventory decision is reduced to a single question: How many units of the item should a buyer order to maximize that product’s profitability? Retailer managers are relying less and less on their “gut” and past experience; lean retailers are increasingly using more sophisticated statistical models, even in the risky realm of nonreplenishables, to help guide stocking decisions. In this section we review briefly the well-known “news-vendor” problem to illustrate the basic trade-offs retailers must make when determining inventory stocking levels.11
To determine the optimal quantity for a SKU, the retailer finds the number of units to order so that the expected marginal cost of stocking an additional unit and not being able to sell it equals the expected marginal cost of not stocking that unit when it would have sold if available. Mathematically, this relationship translates as follows.
Find the optimal inventory stocking quantity, Q*, that satisfies the relationship:
[Probability the unit cannot be sold)](Co) =
[Probability the unit could have been sold](Cu),
that is [Prob(D<Q*)](Co) = [Prob(D≥Q*)](Cu).
where Q* = the optimal order quantity
D = demand for the product
Co = cost of oversupply
Cu = cost of under-supply
At the simplest level, the optimal stocking policy for nonreplenishable goods is to stock the quantity (Q*) that satisfies [Prob(D<Q*)] = (Cu)/(Cu+Co). For example, suppose a retailer can purchase a dress for $200 that it sells for $440. Suppose also that if the retailer stocks too many of these dresses, it can only sell the leftovers for $120 each. In this case, the cost of oversupply comes to $80 = $200 – $120 because the retailer loses that much on every leftover dress. Conversely, the retailer loses $240 = $440 – $200 whenever it stocks out of a dress that a customer would have purchased at full price. According to the model, the retailer should purchase the quantity Q* that will yield [Prob(D<Q*)] = 240/(240+80) = 240/320 = .75—that is, a 75 percent probability that demand for the dress will be less than the quantity purchased.
With this analysis completed, the retailer must next forecast demand for the dress at the SKU level. A sample demand forecast for the dress appears in Figure 6.4. The buyer should order 250 units, since there is a 75 percent probability that demand will be less than this. Note that this buyer would be ordering more than she expects to sell (the mean value of the distribution, 180 units). This makes sense, because the margins on these dresses are high relative to the cost of buying additional dresses and having to dispose of them below cost.
Inventory Model for Replenishable Products
Although determining an inventory policy for nonreplenishable products continues to be an issue for retailers, inventory decisions that involve replenishables have undergone the most change with the advent of lean retailing. Indeed, many products sold in retail outlets, particularly basic and fashion-basic items, can now be replenished after the start of the selling season. The jagged heavy line in Figure 6.5 (page 100) depicts a typical inventory pattern for a replenishable product like our blue jeans in size 8. Note that the inventory level drops gradually as consumers purchase the item. Once a week, this retailer places a replenishment order with its supplier and receives a shipment. On July 17 and 24, the replenishment order arrives in time to restock the inventory before selling out; however, during the week of July 24, high demand led to rapid depletion of stock, so the retailer stocks out of the product prior to the end of the week.
To understand this product’s inventory requirements, it helps to divide the inventory into two separate components: cycle stock, which is held to cover expected demand for the product; and safety stock, which is held to cover higher than expected demand. Figure 6.5 breaks out these two components of stock. The straight dashed lines show the inventory pattern that would result if there were no variation in demand—that is, if exactly the same number of units were bought each day. Specifically, the dashed lines indicate the inventory pattern that would result if demand each day were equal to the average, or expected, demand. In the figure, cycle stock is the amount of stock necessary to meet average demand. Below the cycle stock sits the safety stock, a buffer that is held for those weeks (such as the one following July 24) in which demand exceeds the average. If there were no uncertainty in demand, this retailer would need no safety stock. But the higher the demand uncertainty, the more safety stock is required to ensure a low probability of stocking out.
As Figure 6.6 shows, the safety stock needed to achieve a given customer service level is proportional to the standard deviation of the demand forecast.12 Simply put, the less certain retailers are of the demand for their product, the more safety stock they must hold to meet consumer needs. In the figure, we assume that the order-fulfillment rate equals 97 percent and the order-fulfillment lead time is three weeks. The parameter choices for the figures, although based on data from actual apparel firms, are for illustrative purposes only. By reducing order-fulfillment lead times, lean retailers are able to reduce the level of safety stock required to deal effectively with a given level of demand variation.
Because safety stock is directly dependent on demand uncertainty, increasing product variety increases retail safety-stock requirements. For example, when the coefficient of variation increases from 0.5 to 1.0—which would happen if the number of products offered increased by a factor of four—the amount of finished goods required to provide the desired service level doubles. Formally, one determines safety-stock levels by weighing the costs of having too much inventory (overstocking) with the costs of having too little (understocking), in much the same way as we did for nonreplenishables.
From the retailer’s point of view, the only way to mitigate the effects of increased demand uncertainty is to have frequent replenishment opportunities, in which replenishment orders can be filled by manufacturers with very short lead times. Chapter 7 examines what this entails from the manufacturer’s perspective. At this point, however, we will introduce the standard inventory model that many retailers use for rapid replenishment items, considering the implications of demand uncertainty raised above.
(R, s, S) Models: Traditional Inventory Policy for Replenishables
A standard inventory policy for a retailer proceeds as follows: At the end of every week, check the inventory of your product. If the inventory has fallen below a stated amount, s, termed the reorder point, place an order for more units. The amount ordered should be sufficient so that the number of units on hand plus those that are on order equal some “maximum” stocking quantity, S.13 For a particular item, our store buyer may reorder when the inventory level falls below s equals 4 units, in a quantity that brings the current inventory up to S equals 8 units. With this policy in place, if at the end of a day she notes that inventory has dropped to 3 units, she would order 5 more, as shown in Figure 6.7. The parameter R in this model refers to the length of the time period between inventory status checks; in this case, the buyer checks inventory weekly, so R is 7 days.
Note that there is a short delivery lead time from the time the order is placed: one day during the first two cycles shown in the figure, two days for the third cycle. Because units typically are sold during the delivery lead time, the actual inventory in stock rarely reaches eight units. Instead, at the time of ordering, inventory in stock plus that on order equals eight units. But if order lead times are long, the buyer must order up to a larger number S to meet demand during the replenishment lead time. Once again, if lead times are uncertain, retailers must hold additional safety stock to meet demand in the event of an unusually long lead time. It can be shown that high variability in lead time means higher costs for retailers than somewhat longer, but more reliable lead times; that is, it may be better to have a longer reliable lead time than an unpredictable one with a shorter average duration.14 The lean retailing policies described previously attempt to reduce both average lead times and lead-time variability through the imposition, for example, of penalties for late deliveries.
We noted earlier that a retailer’s decision about how much to stock depends on the demand forecast for the product, the level of product availability it wishes to provide to customers, the frequency with which it will place replenishment orders, and the lead time to acquire replenishment units. Let’s see how these factors would combine to create a stocking policy for our size-8 blue jeans. We continue to assume that this SKU has the weekly demand distribution shown in Figure 6.1 (page 92). Assume that the retailer wishes to provide a 95 percent order-fulfillment rate for this SKU, that the retailer checks inventory once per week, and that the manufacturer’s lead time to deliver replenishment units is overnight. (This last assumption is unrealistic in many situations15; we choose it only to simplify the exposition. It is not difficult to extend this analysis to the case in which the replenishment lead time is longer.) Finally, we assume that like most retailers, our retailer replenishes each week exactly the number of units that sold the previous week. (Formally, this translates into an (R, s, S) policy with s = S – 1: that is, if the current stock is S – 1 or less, the retailer orders S – s.)
Given the desired 95 percent service level, the retailer should set a target stock level of seventeen units. Thus, the retail replenishment system would check the stock of these jeans every Sunday night; if the current stock is thirteen pairs of size-8 jeans (meaning that four pair sold the previous week), then it would automatically order four more pairs, bringing the amount of this SKU up to its target level of seventeen units. This order would be combined with other replenishment orders for Levi jeans destined for the same store, thereby reducing shipping costs.16
Periodic Versus Continuous Review
The policy described above involves what is known as periodic review. After a fixed period of time (e.g., every week), the retailer checks the inventory level. If the level of inventory is less than the specified reorder point s, the retailer “orders up to” the specified level S. This is still the most common practice today.
An alternative approach offers continuous review—or an (s, S) model—in which the retailer continuously checks the inventory level. The moment the level hits s, the retailer orders up to a specified quantity S. Unlike a periodic-review policy, in which retailers may order when the inventory level is less than s, with a continuous-review policy, they always order when the inventory equals s. Thus, under a continuous-review policy, retailers always order the same quantity (Q = S – s) but after a variable amount of time since the last order was placed. Conversely, under periodic review, they order after a fixed length of time, but the quantity differs because it depends on the amount that is in stock when inventory was checked each period. Use of continuous review allows retailers to achieve a higher service level with a lower amount of inventory. By monitoring the inventory continuously, they ensure that it never falls below s before placing an order.
The choice of which model to use depends on a number of factors. Prior to the use of bar codes, implementation of a continuous-review policy at retail was nearly impossible because it was extraordinarily difficult to keep track of actual inventory levels on a continuous basis.17 Today bar codes and retail information systems allow access to stocking levels on a continuous basis, but most retailers choose to use periodic review systems to restrict ordering activities to set times of the week; that way, they can save on transportation and other costs by ordering multiple products from the same vendor at the same time.
Finally, a complete economic analysis of the appropriate parameters for an (s, S) or (R, s, S) policy must include consideration of some of the “softer” costs and benefits of inventory. A retail buyer may choose to stock more of a product than indicated by an economic analysis because she believes that more stock is necessary to attract the customer and sustain the desired level of sales. In recent years, many retailers have been hampered in their efforts to reduce in-store stocking levels by the size and shape of the fixtures in which their products are displayed. If the fixture was designed to hold ten shirts of a particular color and size, for instance, it is both wasteful of space and visually unappealing to put only three shirts out—even if an economic analysis recommends the lower quantity. In fact, many stores have introduced new fixtures with smaller slots for each SKU (or flexible slot sizes) that can hold a more economically desirable quantity of stock without sacrificing pleasing appearance.
Vendor-Managed Inventory
One of the most significant changes in retail inventory management in recent years has been the introduction of vendor-managed inventory (VMI) programs, also known as Continuous Replenishment Programs (CRP) or Continuous Product Replenishment (CPR). These programs involve having either the retailer, the manufacturer, or the retailer and manufacturer together determine desired inventory stocking levels for the manufacturer’s product in the retail store. After these “model stock” levels are set, data about product sales and current retail inventory levels are transmitted electronically to the manufacturer. The manufacturer then decides how much to ship—and, in many cases, when to ship—to the retailer in such a way that its own costs of manufacturing and shipping are minimized while still meeting retail inventory policy requirements. Typically, these programs result in the frequent delivery of small quantities of items to the retailer—it would not be uncommon for a blue jeans manufacturer to ship a carton of one dozen blue jeans of mixed styles and sizes to a particular store.
The benefits of such policies are significant. In the grocery industry, the implementation of VMI programs has been shown to increase retail inventory turns from 50 percent to 100 percent over those achieved prior to implementation, even if the retailer and manufacturer had previously used electronic data interchange for communication of retail orders.18 The advantage of using VMI programs stems from the retailer and manufacturer working together to determine a flow of shipments that optimizes the economics of the two parties as a system. Otherwise, the two parties make independent decisions that myopically optimize their own profits, without complete consideration of the impact these decisions may have on other players in the channel.19
A few caveats are in order, however. According to HCTAR’s survey, the incidence of retail model stock programs increased significantly over the 1988–1992 period, from 7 percent to 16 percent of total volume shipped by the business units in our sample (see Figure 5.1, page 73). But there was a much smaller increase in the prevalence of model stock programs governed by apparel suppliers, reflecting the dominance of retailers in instigating new channel relationships as well as the reluctance of most retailers to allow suppliers to control merchandise on the shelf. As in all cases where partnerships might benefit the various parties involved, real-world considerations—who has the most power, who is responsible for instigating change, who will make the initial investments—often slow integration.
Managing Inventory in a Lean Retailing Environment
The new world of rapid replenishment implies additional capabilities for both the retailer and manufacturer. The retailer must be able to gather and synthesize point-of-sales data quickly to determine what has sold and then update its demand forecast for the product accordingly. The manufacturer must deliver the ordered product quickly to the retailer. As we describe in Chapter 7, manufacturers have essentially two choices in supplying replenishables. They can hold finished products in inventory, thereby reducing their processing requirements during the replenishment lead time to picking, packing, and shipping the order. However, this approach increases the risk to the manufacturer: It has to commit to holding finished goods of a product for which it has little or no consumer demand information.20
The alternative is to adopt quick-response manufacturing strategies that allow items to be produced to order. But given the increasingly short lead times dictated by retailers (often just a couple of days), most manufacturers cannot produce in this way.21 Therefore, it is not surprising that most replenishment products are basics or fashion-basics with relatively stable demand: Manufacturers are unwilling to hold speculative stock to meet replenishment requests from retailers for fashion products because the risk of holding those fashion goods in finished goods inventory is too high.
Ironically, replenishment capabilities would be of most value to the retailer for fashion products, but because of their short product lives and the unpredictability of demand, fashion products are typically not offered on a replenishment basis. From the apparel supplier’s perspective, that’s a good thing—at least for the time being. As the next chapter will make clear, the demands of lean retailing have already created plenty of inventory challenges for manufacturers.









In 1911, John Wanamaker opened his flagship store in downtown Philadelphia. The twelve-story building, with its forty-five acres of floor space, was the largest of its time devoted to retail merchandising. Its central “Grand Court” had marble arches that rose 150 feet and was capped by a dome. Major physical innovations were hidden behind this visual wonder: sixty-eight state-of-the-art elevators; the latest in fireproofing; a large power plant devoted entirely to the store; and sophisticated heating, ventilating, and sanitation systems.
Wanamaker had been in the forefront of retailing for more than thirty years by the time he opened this store. His goal was to provide the elegant shopping experience of major European boutiques while satisfying the American desire for product diversity. At the same time, he based his retailing system on four fundamental principles: one price for a product (no haggling); prices guaranteed to be “10 percent lower than the lowest elsewhere”; acceptance of cash payments only, in order to keep prices low; and cash refunds or exchanges for unsatisfied customers. With these fundamental principles in hand, he became one of the leading retailers of his day.1
Sixty years after the opening of Wanamaker’s Philadelphia store, another entrepreneur synthesized a set of existing technologies and, along with a number of other retailers, began another revolution in the industry. Sam Walton started small in the 1970s, but Wal-Mart rapidly became the largest retailer in the United States, with total sales in fiscal year 1995 equaling the combined sales volumes of Kmart, Sears Roebuck and Co., and the supermarket chain The Kroger Co., the next three largest American retail organizations. Walton’s successful innovations placed enormous pressure on other mass merchant retailers to alter their practices along similar lines. By the late 1980s, a growing number of retailers had started changing the way they did business.
As we have emphasized, the current retail revolution—involving new information technologies, new product labeling, and new methods of distribution—has driven changes in the apparel and textile industries as well. Yet this revolution didn’t happen overnight; nor was it the brainchild of a single entrepreneur. In fact, the retail systems of both Wanamaker and Walton integrated a variety of innovations that had already been pioneered by other retailers. For example, Wanamaker’s “one-price” policy was initially adopted by wholesaler Arthur Tappan in the 1820s and experimented with by Lord & Taylor in 1838 and Rowland Macy in the early 1850s. Similarly, bar codes and electronic scanning—key building blocks of new retailing practices—began in the grocery industry. Kmart became the first major nonfood retailer to employ them as a means of tracking inventory in the early 1980s, several years before Walton made this technology a core building block of his distribution system.
This chapter will examine the differences between the traditional re-tail model and lean retailing. We explore how the set of practices that traditional retailers drew on to merchandise and distribute products became increasingly costly. Then we return to why retailers—-Wal-Mart, Kmart, J. C. Penney, Dillard’s Inc., Federated Department Stores, and others—adapted technologies and management practices to handle demand uncertainty, product proliferation, and complex sourcing decisions.
The Retail Challenge
Imagine the problems faced by a typical department store. It must cater to a diverse clientele: men, women, and children, with varied tastes, disparate income levels, and a wide range of physical measurements. It must deal with seasonal changes that affect the type of clothes offered—is it winter or summer? The beginning of the school year? The holiday season? If the company operates stores in different geographic regions, its product offerings must also reflect regional differences in style, weather, income, and culture. In addition to these factors, consumer tastes often shift rapidly, sometimes within a single season. These long-standing causes of variation in consumer demand have been further compounded by accelerating product proliferation in all segments of the apparel industry.
The combination of different sizes, colors, styles, fabrics, price lines, and consumer groups means that a retailer must carry an enormous range of different products. The more diverse the consumer base of the retailer, the larger the number of individual products typically measured in stockkeeping units (SKUs).2 This variety is portrayed in Table 3.1, which shows the number of SKUs provided annually by different types of retailers over the course of a year. The number of SKUs can range from just 10,000 for a discount food store like Costco, which offers a limited number of products sold in large quantities, to more than two million different items in an upscale department store.
Today retailers must manage this profusion of products. At an operational level, this means deciding what types and how many of any one good it should stock to maximize sales per square foot of available space—one of the most critical measures of retail performance. If all goes well, retailers allocate space to different goods efficiently, responding to shifts in consumer tastes (stocking the hits and discontinuing flops); setting pricing policies (markups and markdowns) to deal with both the direct cost of goods and the nature of consumer demand; and controlling inventory to reduce exposure to risk. Further, the contemporary retailer has to keep track of sales and inventory accurately by SKU.
The Elements of Traditional Retailing
The early twentieth-century success of Wanamaker’s and other department stores illustrates that the keys to effective retailing are providing customers with a variety of desirable products, procuring those products at a low enough cost to make a profit, marketing them well, and charging prices that reflect customers’ willingness to pay. As we discussed in the last chapter, large retailers were able to implement this strategy in the late nineteenth century because the falling distribution costs afforded by a national railway system, as well as new information links arising from the telegraph and later the telephone, provided economies of scale and scope. Other technological innovations, including steel construction, plate glass, and the Otis elevator, allowed retailers to expand multi-story floor space without purchasing more real estate, providing for a more varied collection of products. The creation of a national highway system in the 1950s further fostered the development of mass retailing by opening vast new spaces in suburban malls.
Under the traditional model, retailers ordered desired products far in advance of the selling season because their apparel suppliers charged less for large runs and long lead times with long periods of advance commitment. Retail buyers, assigned to a specific product line, purchased products based on their best guesses of what would sell. They would then apply rules of thumb to allocate volume across styles and sizes. These transactions typically occurred eight to ten months before the goods appeared on the retailer’s selling floor. The success of buyers therefore turned on their ability to predict what consumers would want and to obtain those products at the lowest possible cost.3 Although the order would specify a delivery time far closer to the season, once the buyer placed the order with the apparel manufacturer, it typically remained unchanged until delivery to the retailer’s warehouse or individual stores.
As portrayed in Figure 3.1, the typical shipment between an apparel manufacturer and retail customers was large and of low frequency—usually once a season. Once delivered, the retailer held the products in central warehouses or as inventory in individual stores’ “back rooms.” When the desired time of display and sale arrived, workers stocked the product on the selling floor and replenished from store or warehouse inventories as the selling period progressed. Inventory control relied on painstaking, manual comparisons between sales records (paper receipts) and physical counts of items on the floor, in the back room, and in warehouses.4 Overstocks at the close of a season were then marked down for clearance, warehoused in inventory for future sales, or sold to a secondary market supplying discount retailers.
Those who could predict, or in some cases create, markets for new products clearly were at an advantage. Not surprisingly, fast tracks in the traditional retail world started with buyers, and many apparel CEOs successfully demonstrated their “feel” for the market early in their careers. This list includes John Wanamaker and Marshall Field in the early era of the department store; Stanley Marcus of Nieman Marcus and Millard S. Drexler of The Gap are more recent examples of “buyer” CEOs.5
The best traditional retailers were also good at merchandising. Effective merchandising requires matching the retailer’s product mix to the tastes and incomes of its targeted customers. Establishing the target customer base is therefore a critical first step in any merchandising strategy. Although this may seem obvious today, Wanamaker shook up the existing retail world in the 1870s by seeking to understand his customers’ preferences as a basis for making merchandising choices.6
A century later, retailing success is often attributed to combining effective marketing with an understanding of consumer tastes. The growth of private-label programs among retailers in the 1980s exemplifies this trend. In private-label programs, retailers create a distinctive product line under their exclusive name and license. If successful, a retailer’s private-label program can capitalize on the same type of strong brand recognition that has yielded profits to companies like Levi Strauss or more recently Tommy Hilfiger. For example, the success of The Gap’s jeans, J. C. Penney’s Arizona line, and Sears’s Canyon River Blue line has led to erosion of the market share held by the two leading jeans manufacturers, Levi Strauss and VF Corporation.7 According to Standard & Poor’s, “In the 1980s the standout performers in retailing developed a sustainable competitive advantage by differentiating themselves in the eyes of the consumer....The winners have either created new markets or revitalized old businesses with a price and product mix geared toward a narrower market.”8
In addition to effective buyers and merchandising, successful traditional retailers relied on a third element: purchasing products at low costs through buying power (volume or cash position), or via access to the cheapest domestic and international sources for apparel. As we’ve already noted, international sourcing has become increasingly prevalent. Beginning in the 1970s, retailers expanded their offshore sourcing efforts, especially after quality standards improved, establishing sourcing offices and relationships in low-wage countries, particularly in Asia.
The Growing Costs of Traditional Retailing
Nevertheless, large-scale retailing came with its own risks. Through their buying power, traditional retailers could dramatically lower the direct costs of procurement and, in the process, usurp the role of wholesalers in the apparel distribution system.9 Purchasing in large quantities for their stores, however, subjected retailers to the attendant risk of selling “perishable” products like apparel. The absence of business systems capable of adjusting to real-time demand information, as well as the lack of information between the time when orders were placed and the actual selling season, meant that early order commitments could not be amended pending new information.10 In terms of the retail bottom line, this risk appeared in the indirect costs associated with holding inventories of unwanted products and stock-outs of popular items.11
Two trends over the past twenty-five years have compounded the problems inherent in the traditional retail model. First, product proliferation has vastly increased the number of products retailers are required to manage in their stores. Second, the total amount of retail space in the United States has expanded dramatically, even while consumer expenditures on apparel items have declined as a share of total expenditures. Some analysts deem this “the overstoring of America.” Since the early 1980s, retailers have faced the growing costs associated with holding inventories of a wider variety of goods in a world increasingly characterized by industry overcapacity. Low-cost international suppliers helped fill the gap for a while, but the traditional retail model can no longer hold its own without information integration and other innovations.
Product Proliferation
In Chapter 1, we introduced the fashion triangle, which includes the three types of goods commonly sold by apparel retailers: fashion, fashion-basic, and basic products. Although product variety in apparel has historically been associated with the fashion end of the industry, the number of products available to U.S. consumers in almost every apparel category has grown significantly over the past two decades.
Consider men’s shirts. Throughout much of the post–World War II era, the majority of men’s shirts sold in the United States were white dress shirts. But today a shirt manufacturer’s “basic” collection typically includes solid white, blue, and a white/blue weave, as well as white with color stripes in pure cotton, cotton/polyester blends of various mixtures, and other fabrics like 100-percent cotton oxford, pinpoint oxford, and several qualities of broadcloth.12 Most of the collection will come with a choice of collar styles, and some will include a French cuff option. There are also common cuts (“silhouettes”), such as regular, athletic, loose fit, and long. In addition to these dimensions, there are quarterly collections of different fabrics. Each shirt corresponding to a combination of these characteristics—for example, a 16–35 blue, button-down, pinpoint oxford shirt with French cuffs cut long—has its own pattern of demand that varies considerably over the course of a year.13
For a retailer, a larger number of SKUs raises the level of uncertainty regarding what product will sell or not sell in any period. In practical terms, this means that a retailer carrying a broader array of goods faces increased costs both for carrying goods in inventory that will not sell (overstocks) and running out of a good that sells beyond expectations (stock-outs). The costs associated with demand uncertainty, which were previously connected primarily with fashion products—that is, the problem of selling a highly perishable item—have grown enormously for apparel retailers. Apparel retailers are not alone: The variety of products offered has increased considerably in most consumer product sectors, from most segments of the retail food industry to home building products to personal computers.14
Increasing product proliferation was clear among the business units in our survey, as vividly portrayed in Figure 3.2. The average number of SKUs per business unit rose from an average of 3,871 in 1988 to 6,304 in 1992. This overall increase is mirrored by growth in the average number of new SKUs introduced per year by apparel business units, which increased from 2,368 in 1988 to 3,688 in 1992. Meanwhile, the number of discontinued SKUs rose from 2,057 to 3,050. This means that a large portion of each apparel firm’s product line consists of new products. The consequent “churning” of products adds further uncertainty to the retailer’s or manufacturer’s already difficult tasks.
Retail Overcapacity
Construction of retail centers, particularly shopping malls, boomed in the 1980s. Rapid expansion of retail space arose from a simple formula that had traditionally proven successful: Add more stores and revenue growth will follow. The early age of retailing was marked by the expansion of stores within major metropolitan areas, but in the early 1960s, retailers started flocking to large, enclosed suburban malls and non-enclosed “strip malls.” As a result, between 1972 and 1992 the annual rate of new shopping-center construction outpaced the growth in population and potential consumers.15 The size of retail establishments also grew during this period because of two important trends.16 First, the number of independent department stores—usually a single-site enterprise of relatively moderate size—declined dramatically in the 1980s. Second, many multi-enterprise retailers either built large new stores or expanded the size of existing ones.17
Far outpacing the overall growth in population, retail space per capita rose from 5.3 square feet per person in 1964 to 9 square feet in 1974 to 16 square feet in 1988. By 1996, it had grown still further, reaching close to 19 square feet.18 In comparison, per capita retail space in a developing country like Mexico is estimated at .3 square feet.
The growth in consumer expenditures did not rise commensurately with the boom in retail space. The apparel and upkeep share of household expenditures in the Consumer Price Index fell from 10.6 percent in 1963 to 5.5 percent in 1995. Per capita expenditure for apparel and related services declined from $1,710 in 1992 to $1,698 in 1994 (in current dollars).19 And these downward expenditure trends occurred in the face of growth in the average number of outerwear garments consumed per capita: from 14.3 garments in 1967 to 28.7 garments in 1995.20 In other words, the amount of money spent by an average consumer per garment fell over this period, reflecting in part more casual workplaces, which allow people to spend less on clothing for work, and intense price competition. Retailers with more and more floor space were chasing fewer and fewer apparel-consumption dollars.21
The Retail Fallout
Increasing product proliferation, retail overcapacity, falling relative per capita expenditures on apparel, and the constant pressure to provide lower prices to consumers created an unforgiving competitive environment for retailers. Overall margins for the industry (particularly for specific retail segments like department stores) declined between 1977 and 1987. By the mid-1980s, a number of the most prestigious retailers were faltering, with some filing for bankruptcy or being acquired by other retailers.
Department stores proved to be one of the most adversely affected retail sectors.22 Their inability to adapt to changing consumer tastes and the emergence of new retail channels that targeted specific consumer segments—specialty stores (especially so-called “category killers”), catalog stores, and mass merchants—led to erosion in market share. Although in the 1960s and 1970s the majority of apparel sales occurred in department stores, by 1990 they accounted for only 29 percent of all sales.23 Venerable giants like Macy’s, Gimbels, Saks Fifth Avenue, Federated, and Wanamaker filed for bankruptcy in the late 1980s and early 1990s.24
Product proliferation coupled with industry overcapacity revealed the costs inherent in the traditional model of retailing. Three types of costs were particularly high under the old model: forced markdowns to clear out unsold goods; lost sales from stock-outs; and the costs asso-ciated with holding inventory. In 1985, the losses associated with -markdowns, stock-outs, and inventory carrying costs for U.S. retail-apparel-textile channels were estimated to be $25 billion.25 An estimated 56 percent of these losses, $14 billion, arose from the need to mark down unsold products, either through store sales and promotions or through the use of the sizable secondary market for items purchased by discount retailers for sale to other consumer segments. Product stock-outs accounted for 24 percent, $6 billion, of the losses, and the cost of inventory carrying itself constituted the remaining 20 percent, $5 billion.
Price reductions from the beginning to the end of the season also increased dramatically over the period from 1948 to 1988, one in which there was considerable growth in product proliferation. Consequently, the difference between early season and end-of-season prices for women’s apparel from the late 1960s to 1988 grew substantially.26 Although these losses were borne throughout the entire channel to some extent, a disproportionate share, 65 percent, fell on retailers. This is not surprising, given the traditional retailing strategy under which retailers commit to purchases well in advance of the selling season.
Despite its high costs and negative impact on the bottom line, being left with unwanted apparel products—or running out of fashion hits—was viewed by most traditional retailers as a cost of doing business. With neither timely information on the state of sales at the store, nor the capability to use that information, little could be done to resolve this source of uncertainty and excess cost in the channel. This historical constraint only began to change with the advent of the current retail revolution.
The Lean Retailing Alternative
The whole point is speed and clarity of communications. With this new technology, buying procedures that used to take weeks have now been cut to days—and sometimes even hours. That has greatly enhanced our response to new trends, reduced turnaround times and increased the flexibility of all those involved in the buying process.27
—William Howell, Chairman, J.C. Penney, 1995
If lack of information provided a regrettable but unavoidable cost of doing business in retailing before the late 1980s, access to information has become crucial to competitive success in the 1990s. The ability to gather, transmit, and use information regarding sales at the cash register has created a new way of offering products to customers. It has created the lean retailer.28
The leveraged buyouts, mergers, and corporate restructuring of the 1980s left many of the historic retail powerhouses in a vulnerable condition, with a number of the strongest traditional retailers—Macy’s, Saks, Sears—in an extremely weakened state. But this industry landscape also left the field open for the emergence of a new kind of retail competitor, one able to harness information as a central component of its competitive strategy.
A number of retailers filled this role, becoming the vanguard of the lean retailing revolution. Lean retailing represents an amalgam of technologies and management practices adopted and refined by various companies. Although no single retailer pioneered or adopted all the innovations that compose lean retailing, we focus here on those in three segments—mass merchants, national chains, and departments stores—that played important roles in initiating the larger transformation.
Mass Merchants: Wal-Mart
Wal-Mart is the most well known of the early lean retailers.29 Traditional mass merchants sought cost advantage through economies of purchasing scale. Given limited information on sales, this meant that these retailers purchased large inventories of goods that they would then “push” to consumers, often by means of price reductions and sales promotions. Beginning in the late 1970s, Wal-Mart sought to reduce its costs by using emerging information technologies to track consumer sales at the checkout counter, monitor its inventory of goods within and across stores, and then supply its stores on an ongoing basis via highly efficient, centralized distribution methods. By capitalizing on “real-time” information on sales and inventory position, Wal-Mart increased its ability to let consumer demand “pull” its orders. As a result, it could reduce the amount of inventory it needed to hold for any given product and focus its resources on stocking those goods that were being purchased by consumers.
The Wal-Mart strategy required and fostered the development of a company-wide computer system to track incoming and outgoing shipments to the various stores. Through the use of its own proprietary standard, Wal-Mart gathered and exchanged information among its stores, distribution centers, and the main office in Bentonville, Arkansas, to monitor sales, place orders based on those sales, track shipments to the distribution centers, and coordinate the flow of materials and information throughout the system.30 By the early 1980s, the company’s investments in this information system—including satellite links to handle its immense amount of daily data—totaled more than $700 million.31
Wal-Mart reaped the full benefits arising from its extensive information systems when it shifted its focus from internal purposes to a means of interacting with suppliers. In 1987, Wal-Mart began its first major experiment in changing its relationship with a key supplier, Procter & Gamble, by establishing the “Wal-Mart Retail Link” program. This program provided Procter & Gamble with access to Wal-Mart’s point-of-sales information, allowing the supplier to track sales of its products on a real-time basis and manage its inventory accordingly. In the words of Lou Pritchett, Procter & Gamble’s vice president of sales at the time, “P&G could monitor Wal-Mart’s inventory and data and then use that information to make its own production and shipping plans with a great deal more efficiency. We broke new ground by using information technology to manage our business together, instead of just to audit it.”32
The Wal-Mart/Procter & Gamble partnership has been often cited by the business press. The program began through an informal discussion between Sam Walton and Procter & Gamble’s Pritchett. Although the effort has been characterized as a partnership, senior executives at Procter & Gamble have also noted that the initial impetus came from Walton. The partnership required Wal-Mart to switch from its internal proprietary standard to a more widely adopted electronic data interchange (EDI) standard, as well as to bar codes that were already in use by other retailers, particularly Kmart. Although Kmart was the first major retailer to experiment with EDI, Wal-Mart led the way in structuring supply relationships and its overall competitive strategy around information exchange. The program soon expanded to other vendors, including apparel suppliers, who entered their own “trading partnerships” with Wal-Mart. Thus, what began as a system focused on efficient distribution eventually evolved into the modern system of lean retailing.
National Chains: J. C. Penney
J. C. Penney built an internal data communications network well in advance of its use with suppliers.33 Point-of-sale terminals first appeared at its stores in the mid-1970s, allowing the company to capture information on store-level sales. Penney was also one of the first retailers to adopt scanner technologies. Although early forays into electronic data management relied on mainframe computers, between 1988 and 1991 the company installed 45,000 cash registers equipped with microprocessors and storage capabilities.
These store-level investments were accompanied by major capital investments in central computer processing capacities, continuing development of store- and corporate-level software systems, and improvements in distribution operations. In the late 1980s, Penney drew on these systems to allow corporate buyers in its Plano, Texas, headquarters to display potential products to geographically dispersed individual store merchandisers who, with store managers, had considerable autonomy within the company. This information infrastructure proved most beneficial when it gave Penney’s major vendors access to sales data via direct broadcast satellite. There was initial resistance, however. Despite the company’s offer to provide suppliers with EDI downloads, many declined because of their inability to process the data. It was only when Penney provided aggregated reports via fax to account executives that a thousand vendors agreed. By 1993, Penney was using EDI for processing 97 percent of purchase orders and 85 percent of invoices with 3,400 of its 4,000 suppliers. Nonetheless, many small suppliers did not have electronic links with the company.34
It is no accident that such innovative information and distribution relationships with key suppliers emerged through Wal-Mart, Kmart, and a national chain like J. C. Penney rather than among department or specialty stores. The larger size of these mass merchants facilitated adoption of rapid-replenishment practices as a result of economies of scale in inbound and outbound transportation, information technology, and distribution center operations. Indeed, the adoption of these distribution innovations parallels the emergence of department stores and mail-order houses a century earlier.
Both mass merchants and national chains cover a more narrow range of products—primarily basic apparel items—than department stores. Basic products are prime candidates for lean retailing because such a product style remains in a retailer and apparel company’s product line over much of the selling season and often over several years. That makes it easier to use information acquired during the selling season for replenishment during the same season or for forecasting future demand. Basic items also represent a major percentage of all apparel goods sold. In our 1992 HCTAR sample, 45 percent of all shipments by business units, weighted by sales volume, could be classified as basic. Therefore, given their scale and product mix, it is not surprising that Wal-Mart, Kmart, and J. C. Penney were among the early pioneers of lean retailing.
Department Stores: Dillard’s and Federated
Although providing consumers with low prices for a limited range of goods underpins the strategy of mass merchants and national chains, department stores (going back to Wanamaker) rely on offering consumers a diverse and exciting collection of goods. The focus of department stores tends to be on the middle and higher portion of the fashion triangle; consequently, lean retailing came later to this segment of the industry.
Dillard’s was a pioneer in the use of information technology for tracking and responding to sales. Dillard’s became one of the first department stores in the late 1980s to build a centralized inventory-tracking system to provide its headquarters in Little Rock, Arkansas, with real-time information on sales, by both store and item.35 This entailed buying and then adapting early scanning technologies for use at sales counters and for point-of-sale data collection. Dillard’s also purchased computing capacity for individual stores and its headquarters office, along with the necessary equipment to connect stores to the head office via electronic data transmission.
With these systems in place, it began to develop distribution centers capable of being efficient intermediaries between its suppliers and stores. Finally, like the mass merchants and national chains, Dillard’s started insisting that its suppliers invest in corresponding technologies to allow electronic reordering and to meet its increasingly stringent service requirements. But unlike a mass merchant that typically manages over 125,000 separate items in a large store, the Dillard’s system uses this information to manage over one million SKUs in one of its flagship stores.36
Federated originated as a decentralized “federation” of well-known stores like Rich’s and Bloomingdale’s, with wide variation in both its merchandising and back-room activities. Like Dillard’s, its stores carry a vast array of products: a typical department store may have 800,000 items; its flagship Macy’s in midtown Manhattan offers more than two million separate SKUs. During the 1980s, however, the amount of inventory held by Federated ballooned while it faced bankruptcy.
Under CEO Alan Questrom, the company addressed these problems by attempting to increase its inventory turns (the number of times a year that goods turned over in its stores) and reduce its exposure to losses from excess inventories. This entailed instituting aggressive markdown policies in the short term to remove large inventories that had built up in many divisions and stores. At the same time, the company began to redesign its logistics system—the method it used to move goods from suppliers, through warehouses, and to delivery at stores.
The size of Federated’s logistics challenge can be captured by the following figures. In 1997, the company moved over 700 million units from its suppliers to its stores, requiring an average of 500 truck deliveries per day, which amounted to thirty million miles for deliveries per year.37 Like Dillard’s, J. C. Penney, and others, Federated spent millions of dollars on installing scanners, adopting bar codes and EDI to communicate internally and with suppliers. Given the size of its logistics challenge, Federated also chose to redesign its methods of moving goods from suppliers to stores. With the establishment of an independent operating unit, Federated Logistics, this retailer reduced the amount of time required to process merchandise in distribution centers by 60 percent, to an average of two days.
Meanwhile, the company sought to maintain the strengths of its divisions—Macy’s and Bloomingdale’s, in particular—in merchandising. It created, among other innovations, a “team buying” system that centralizes certain buying functions to benefit from potential economies of scale while taking full advantage of divisional expertise regarding different customer groups within Federated’s stores. Yet a tension exists between its desire to provide customers with a changing variety of apparel fashions and the need to increase its capacity to replenish a higher percentage of products, thereby taking advantage of its expertise in logistics.38 Increasingly, a department store must be successful at both pursuits. We discuss the trade-off arising from providing new products with little information on consumer demand (fashion products) and replenishing items on the basis of sales (historically limited to more basic products) in detail in Chapter 6.
Although Wal-Mart’s rapid climb has created the most sound and fury, a variety of retailers adopted and adapted different pieces of lean retailing in the early 1990s. Note that the push toward rapid replenishment, reduction of lead times, and what has often been called “quick response” came predominately from retailers rather than from their apparel suppliers.39
The next chapter analyzes the building blocks of lean retailing, drawing on the retailers described above as well as others. Chapter 5 discusses how the retail revolution has led to a tremendous shift in bargaining power within the channel—away from manufacturers and suppliers and toward lean retailers.









The emergence of textile, apparel, and retail enterprises in the United States is full of fascinating twists. In 1790, for instance, an act of industrial espionage is said to have launched the domestic textile industry, if not American manufacturing in general. At that time, Samuel Slater, a skilled mechanic, built the first successful water-powered yarn spinning mill in Pawtucket, Rhode Island. Yarn was in short supply in the new country and much in demand in households that did hand weaving as well as in workplaces with looms that produced sheeting, shirting, and stockings for commerce. Some of the American states and improvement societies had even offered generous rewards for the establishment of water-powered combing and spinning, especially those based on state-of-the-art English Arkwright operations. But British law strictly prohibited the export of drawings, plans, or models of these new technologies. It took somebody like Slater—an indentured apprentice for over six years at the Arkwright and Strut’s plant in Milford, England—to ferry the plans to America.1
Slater was interested in the financial rewards to be had in the new world while still in England. Mindful of British prohibitions, he committed to memory the design and construction of the spinning mill where he worked. Arriving in New York in late 1789, he was referred to Moses Brown in Providence, a prominent merchant who had established a company, Almy and Brown, to develop “frame or water spinning.” Brown responded on December 10, 1789, to Slater’s initial inquiry, saying Almy and Brown certainly wanted the assistance of a person with Slater’s skills because an experimental mill had failed, “no persons being acquainted with the business, and the frames imperfect.”2
Once in Almy and Brown’s Pawtucket plant, Slater found the existing machinery totally unsatisfactory. He entered into a partnership with Almy and Brown to erect “perpetual card and spinning” machines, otherwise known as the Arkwright patents. By 1793, the firm of Almy, Brown and Slater was operating a seventy-two-spindle mill, producing high-quality yarn. From the Pawtucket mill, the American cotton-spinning industry was launched.
The Slater mill not only copied British technology but recreated that country’s arrangement of family labor, which included young children, six-day weeks, the minimum twelve-hour day, Sabbath schools, and payment of wages partly in goods and partly in cash. The form of ownership and management also followed British lines—one partner financed the venture, while the other furnished the technical know-how. For these accomplishments, Samuel Slater has been called “the father of American manufactures.” His story underscores the international role of textiles and apparel, their impetus in national economic development, and their place in conflicts over domestic production and imports—a theme that recurs throughout U.S. history. For example, from the outset of the new nation, President George Washington and his Secretary of the Treasury Alexander Hamilton wanted to encourage U.S.-based industry. Indeed, Washington wore a dark brown suit, entirely made in America, for his first inaugural on April 30, 1789.3
In this chapter, we will concentrate on the past hundred years, outlining major changes in American retail, apparel, and textiles that occurred before the 1980s. The industrial transformation of this earlier period, which affected far more than these three industries, echoes today’s enormous shifts in supplier relations, manufacturing operations, and human resource practices. The changes now going on have their analog in the last century, when technological innovations of the day like railroads, telegraph, and steam power—developed for purposes far afield of retail, apparel, or textiles—helped transform the mass distri-bution of goods and information.
Alfred Chandler described the last industrial transformation in his well-known book The Visible Hand. The use of everything from railroads to an improved postal service, according to Chandler, created enterprises with internal administrative structures that coordinated the flow of goods from many individual producers to many more consumers. This administrative coordination reduced “the number of transactions involved in the flow of goods, increased the speed and regularity of that flow, and so lowered costs and improved the productivity of the American distribution system.”4
The parallels with the information integration now occurring in retail-apparel-textile channels—this time driven by advances in computer and related technologies—are striking. In fact, another industrial transformation is under way, one that rivals the earlier revolution in organizational structure and management. The first three sections of this chapter summarize the emergence of the U.S. retail, apparel, and textile industries over the past century, including a number of human resource issues. The fourth section looks at their channel relations prior to the mid-1980s, before some enterprises started interacting with each other in new ways. This brief historical survey highlights not only the crucial developments that still undergird these industries but also the systems and work practices from an earlier era that no longer match today’s competitive requirements.
Retail: From General Stores to Mass Retailers
In urban centers, there have always been small shops with goods for sale. Often the owners of these shops produced the goods themselves, such as the cobblers and silversmiths of old. At farmers’ markets, families would display the vegetables they grew or sell eggs from their chickens. At most, a town might have a general store with a motley array of dry goods, based on a limited distribution system—one that relied on local producers and faraway supply houses with extremely long lead times and spotty delivery. The old system didn’t begin to shift until the mid-nineteenth century, with the advent of a new kind of middleman. Alfred Chandler writes,
In the 1850s and the 1860s the modern commodity dealer, who purchased directly from the farmer and sold directly to the processor, took over the distribution of agricultural products. In the same years the full-line, full-service wholesaler began to market consumer goods. Then in the 1870s and 1880s the modern mass retailer—the department store, the mail order house, and the chain store—started to make inroads on the wholesaler’s markets.5
Until the emergence of mass retail, the wholesaler-jobber dominated the distribution of consumer dry goods to general stores: clothing, upholstered furnishings, hardware, drugs, tobacco, furniture, china, and glassware. Unlike traveling peddlers of the past, who carried everything with them, these salesmen could ride the rails into town with no more than a trunk of samples and catalogs. The new infrastructure created by the railroads and telegraph contributed to the growth of wholesale houses. Retailers no longer needed to carry such large inventories, the risk of losing shipments was reduced, and delivery was more certain on a specified schedule. Increased volume cut unit costs and enhanced cash flow, reducing credit needs. Moreover, these salesmen provided a flow of information to their headquarters on changing demand in -various localities as well as the credit ratings of local storekeepers and merchants.
Wholesaler-jobber enterprises of the time, such as Field, Leiter and Company in Chicago (which later became Marshall Field and Company), required both a purchasing organization and an extensive traveling sales force to sell to the scattered general stores in smaller cities and country towns. These buyers and their assistants each handled a major product line like hardware or dry goods. They typically determined the specifications of the goods purchased, the volume purchased, and the price to be charged to customers at retail. These buyers became the most important managers in wholesaler-jobber companies, foreshadowing the key status of the buyer in later retail organizations.
The wholesaler-jobber distribution system peaked in the early 1880s. It was subsequently supplanted by mass retailers in the form of department stores in large urban cities and by mail-order houses focused on smaller communities and rural markets. As Chandler recounts,
Mass retailers displaced wholesale-jobbers as soon as they were able to exploit a market as large as that covered by the wholesalers. By building comparable purchasing organizations they could buy directly from manufacturers and develop a higher stock-turn than the jobbers. Their administrative networks were more effective because they were in direct contact with the customers and because they eliminated one major set of middlemen.6
Other factors drove the development of mass retail as well. The rapid growth of urban cities and access to their downtown areas, initially with horse-drawn streetcars, encouraged mass retailers. Department stores, with a wide range of goods arranged in “departments,” provided one-stop shopping, both novel and appealing to consumers of the period. The increase in women seeking ready-made clothing and home furnishings also contributed to the rise of the department store as did newspaper advertising. Although small specialty shops were limited to a few items, such as those found in a traditional dressmaker or milliner’s shop, department stores offered fixed prices and the convenience of returning purchases for exchange or cash. They sold goods at a lower markup than specialty stores and, above all, concentrated on achieving a high level of stock-turn (or the number of times products turn over in a given year).
Many of the first department stores have names that are still familiar: Macy’s in New York, Marshall Field’s in Chicago, John Wanamaker in Philadelphia. Chandler points out that the stores founded in the 1860s and 1870s accounted for almost half of the leading department stores in New York a century later. In addition, he writes, “Because sales were made on the store’s premises rather than through traveling salesmen, buyers had an even larger role than they did in the wholesale houses.... They had direct charge of the sales personnel who marketed their lines over the counter.”7
Then there was the parallel growth of mail-order sales. With the help of new transportation and communications systems, the first company to market a wide variety of consumer goods exclusively by mail and parcel post was Montgomery Ward, formed in 1872. The Grange, the largest organization of farmers, supported the company. By 1887, its catalog of 540 pages listed 24,000 items. But Sears Roebuck and Co. outstripped Montgomery Ward in the 1890s. As with the wholesaler-jobber and the emerging department stores, the buyers at Sears had full autonomy. Chandler notes, “Each merchandise department was a separate dynasty, and the buyer was in complete charge.”8
Department stores and mail-order houses (and later chain stores in food distribution) dominated mass retailing after 1880 through large volume, high inventory turnover, lower prices, payments in cash that reduced the need for credit and debt, and the crucial role of the buyer. Although wholesaler-jobbers had faded from the scene, the policies, practices, and administrative organizations of many mass distributors were derived from them. Other buying practices came from small shops. Each retail merchandise department, particularly in multi-store organizations, became a separate fiefdom, with the buyer in charge of product selection, scale, timing of orders, and pricing. Up until the mid-1980s, the buyers’ personal network of contacts and “feel” for what customers wanted determined marketing policy. And although the wages of nonsupervisory workers in retail have been and still are quite low,9 the compensation system for buyers provided substantial rewards for favorable results.
Consequently, for decades the decisions of buyers in retail organizations directly affected apparel and textile suppliers. The distribution system that emerged after 1870 would not be challenged until more than a century later. Only in the 1980s, with the development of another system of mass distribution that includes new technology, new management methods, and new links to manufacturing—lean retailing—did the role of the buyer significantly diminish.
Apparel: From Home Work to Modern Manufacture
In colonial days, housewives typically did spinning, weaving, and tailoring for the family. The well-to-do purchased imported cloth and had apparel made by itinerant tailors or those in small shops. The ready-made garment industry grew out of altered rejects and secondhand clothing that were then sold to the poorer classes in the cities. In 1832, a 50 percent import duty curtailed clothing primarily from England and increased the demand for American home industry.10 By 1850, the U.S. Census reports that there were 4,278 establishments with 97,000 workers—63 percent of them women—in the ready-made clothing industry.11 Cloth was cut and assembled into bundles in these establishments, given out to workers to take home to sew, and returned for finishing operations.12
With the invention of the sewing machine by Howe, and its perfection by Singer in 1851, a new era began in the manufacture of clothing, when more work became concentrated in shops. The Civil War and the consequent need for uniforms stimulated the factory system, and the introduction of standard body-size measurements facilitated ready-to-wear clothing. When Hart, Schaffner, and Marx, for instance, opened its doors in 1879, only 40 percent of men’s suits were ready-made. By 1920, most men wore suits that came from a factory. In this period, a number of key technological changes appeared: sewing machines that made many more stitches a minute, long knives instead of shears for cutting, and pressing machines.
From the nineteenth century on, enterprises in the apparel industry have taken one of three general forms: the manufacturer with an inside shop; the jobber; and the contractor with an outside shop, which can supply either manufacturers or jobbers. The jobber, a form characteristic of women’s apparel, does not produce in a plant that it owns. Jobbers may purchase cloth and materials; design or purchase design of garments; and cut or contract out cutting of fabrics. They turn over sewing and assembly to contractors, and their main role is to merchandise finished product.
The jobber-contractor system developed to address many of the issues that still concern apparel-makers. It provided great flexibility in coping with fluctuations in style, season, and economic conditions; at the same time, jobbers did not take on the substantial costs of plant, equipment, or employees that “inside shop” manufacturers did. This system also separated and specialized the functions of production from the purchase of materials and the selling of finished products—developments that greatly influence women’s and children’s apparel today, including the complexity of the regulation of labor conditions.
Regardless, apparel operations in both the men’s and women’s segments have always been labor intensive; even with continual technological innovation, the work still comes down to cutting cloth and sewing pieces together into a garment. Although union organization has not been so extensive in retail or textiles, unions have been important players in apparel manufacturing. At the same time, apparel manufacturers have pressed for ever greater productivity on the shop floor, hoping to cut labor costs in a variety of ways. These two related historical issues—the ascendancy of a particular system of clothing assembly and the role of unions—have a direct bearing on what is now happening in retail-apparel-textile channels.
Development of the Progressive Bundle System
For the most part, in-plant production methods for apparel have been organized around the way in which cut parts of garments are distributed to operators for sewing and then assembled into the completed garment. From the outset of the factory system in woven apparel, after cloth has been laid out and cut in the configurations of patterns for various sizes, the cut parts have been grouped by parts of the garment—fronts, backs, sleeves, patches for pockets, collars—and tied together into bundles for operators, who sew together individual parts—hence the term “bundle system.” Each worker specializes in one, or at most a few, sewing operations.
By the early 1930s, two systems of sewing and assembly emerged in the men’s segment of the apparel industry: the progressive bundle system (PBS) and the straight-line system (SLS).13 The ascendancy of PBS in the men’s industry, where it remains by far the dominant system even today, illustrates how product market competition—specifically intense price-based competition—gave rise to distinctive human resource practices.14
PBS refined the traditional bundle system by organizing individual sewing tasks in a systematic fashion. It entails better engineering of specific sewing tasks, including some specialized sewing machines, to reduce the amount of time required for each task. A worker receives a bundle of unfinished garments. She performs a single operation on each garment in the bundle. The completed bundle is then placed in a buffer with other bundles that have been completed to that point. Machines are laid out in a manner that speeds up shuttling a bin of garment bundles from operator to operator. With its roots in Taylorism, each PBS task is given a target time or “SAM” (Standard Allocated Minutes). Time-study engineers calculate the SAM for an entire garment for an experienced worker as the sum of the number of minutes required for each operation in the production process, including allowances for worker fatigue, rest periods, personal time, and so on.15
The straight-line system (SLS) also attempted to apply Tayloristic notions to apparel but in a way that had more in common with scientific management techniques used in other manufacturing industries. SLS breaks down tasks into simple sewing operations, just as PBS does. Unlike PBS, however, SLS uses the single garment rather than the bundle as the unit of production. As a result, SLS operates essentially without bundles or extensive buffers; operators pass garments directly to the next worker, thus allowing for single or a few apparel items to move through the assembly process rapidly.
In its limited adoptions in the 1930s, the SLS sewing room was organized in short rows of sewing machines based on the sequence of operations for the garment. Even more than under PBS, sewing tasks were broken down in minute detail, both as a means of increasing speed and decreasing skill requirements. Engineers designed operations to take similar lengths of time to achieve line balancing. When a specific task took longer than the surrounding operations, multiple workers were employed on the slower task to achieve balance. Each operator’s workstation was connected by a bar or chute that fed the garment directly to the next worker.
Yet line-balancing problems bedeviled SLS operations. Laying out a production line required exact calculation of the number of workers required for a given step to keep single garments moving through the operation continuously—much as a car moves down an assembly line. The lack of buffers for bundles made the system vulnerable to day-to-day fluctuations in the performance of individual operators, whether because of fatigue, health, mood, absenteeism, substitutions, or intentional slowdowns. In a competitive market that placed a premium on price/cost competition and little value on time to market, the small reduction in direct labor cost did not justify the high potential costs and risks that arose from SLS downtime. In contrast, PBS provided apparel manufacturers with a means for improving labor productivity along with adaptability to day-to-day variations in shop-floor conditions.
In 1938, virtually all assembly in the men’s shirt industry, for example, was done on the basis of bundle systems of production. By 1956, 41 percent of production workers were classified as operating under the traditional bundle system; 55 percent assembled shirts through PBS, and less than 4 percent used the line system. By 1961, the percentage using traditional bundles had fallen to 26 percent; PBS had risen to 69 percent of all production workers, and line systems remained uncommon at 5 percent. By 1990, PBS had become virtually the only assembly system used in men’s and boys’ shirt production, with less than 4 percent of production accounted for by SLS and others systems.16
The dominance of PBS affects current developments in apparel manufacturing and employee management for two reasons. First, the system depends on buffers between assembly operations to minimize downtime. Standard practice is a one-day buffer between operations.17 With a pair of pants assembled through roughly forty operations, a large amount of in-process inventory is created. More important, a given pair of pants takes about forty days to move from cut pieces to final product. Now that apparel manufacturers face more stringent order-fulfillment requirements and are expected to provide a much wider range of products to retailers, the costs of large amounts of in-process inventory have grown tremendously.
Second, PBS is not set up for large-scale modifications of assembly. Although this system has never had as many problems with line balancing as SLS, creating sufficient buffers between assembly steps to keep everyone in the sewing room occupied remains a challenge. Under PBS, a balanced line is a function of the workers’ rate of speed at each of the steps; the total volume moving through the system; the current incentive rates; and such daily uncertainties as turnover and absenteeism. Because introducing changes at any step may unbalance the system as a whole, technological innovations have not easily found their way into the sewing room—which may be out of sync with what an integrated retail-apparel-textile channel requires.
The Role of Labor Organizations
Apparel workplaces have historically been located in major metropolitan areas—New York, Chicago, Philadelphia, Rochester, Baltimore, Cleveland, St. Louis—and drawn on successive waves of immigrants. In the production of both men’s and women’s clothing, immigrant labor provided a continuing secure labor force that often already had the requisite skills. In 1930, three out of five workers were foreign born, and a large percentage of the native-born were of foreign parentage. The union in the men’s clothing field at the time issued official publications in eight different languages. Practically all the manufacturers were first-generation Jewish immigrants.18 More recently, apparel manufacturers, seeking lower labor costs, have moved to the American South and California. But a disproportionate number of domestic apparel workers are still immigrants.
Given access to a large pool of immigrant labor in urban centers, the jobber-contractor system in women’s apparel led to the wide-scale presence and abuses of sweatshops. Sweatshops at the turn of the century encompassed a range of workplaces in which, as one commentator noted, “Congestion, unsanitary quarters, lack of restriction on child labor, absolutely unregulated hours, and miserable pay combine to create a condition which endangers the lives not only of the workers, but of the purchasers of their products.”19 A study in 1893 of the “sweating system” estimated that one-half of the clothing manufactured at that time came from factories, while the other half originated in home work or was subcontracted in small shops often adjoining homes.20
Organizing a relatively low-skill immigrant workforce presented great challenges to unions in the garment industry. Employer resistance to unionization, arising from the highly competitive conditions in apparel markets and the significant percentage of total costs arising from labor, further compounded the problem. This difficult environment shaped the organizing and representation strategies of the two major unions—the Amalgamated Clothing Workers of America and the International Ladies’ Garment Workers Union (ILGWU)21—as well as their relations with employers through collective bargaining arrangements.22 Both unions established a foothold in the industry because they represented strategic workers in the apparel production process: the skilled cutter working inside manufacturers’ plants. Cutters required substantial training, and the withdrawal of their labor could quickly shut down all sewing and pressing operations. Because cutters worked on multiple layers of fabric at one time, their errors were likely to be costly. Not surprisingly, cutters were the highest paid workers receiving day rates.23
By organizing cutters first, unions gained the leverage with which they could then organize and represent the much larger, but less skilled, group of sewers who worked in factory settings, particularly in the men’s industry, or in the small shops that characterized the women’s industry. The principal architects of this approach, Sidney Hillman, founding president of the Amalgamated, and David Dubinsky, long-time president of the ILGWU, were cutters and came out of this craft-group.24
Given this union foothold, collective bargaining in apparel focused on the standardization of labor in a market area and a product line. This was done because of the organization of work in clothing shops; the low capital costs and high proportion of labor costs, especially in women’s wear for contract shops; the intense product competition among manufacturers within and among geographic markets; and the diversity of products and changing styles. The unions drew on several different methods to standardize wages and conditions within the markets. For the ILGWU, standardizing wages required regulation through collective bargaining of the network of contractors and “submanufacturers” working for jobbers and manufacturers. Emphasizing the potential role of the union in this regard, ILGWU President Dubinsky commented on the difficult conditions of the 1920s:
The employers in the stable shops with employees whom they were anxious to keep suffered as much as we did because the union was weak. They had to pay decent wages and maintain decent conditions, but they also had to compete with the fly-by-nights and chiselers. They began to recognize that the union was a necessary stabilizing force. They could not meet conditions if their competitors were free to ignore them.25
Employers who signed the major collective bargaining agreements with the ILGWU in the women’s industry (primarily manufacturers) not only agreed to abide by wage and working conditions for their own employees, they also pledged to use only contractors “designated or registered” with the union and the employer association.26 These contractors, in turn, agreed to abide by the terms laid out by the collective agreement. The collective bargaining process aimed to control contractors by making the manufacturer responsible in the area-product agreement for its suppliers’ behavior and payment of wages and benefits.27
Both unions also sought to standardize wages by setting piece rates for assembly work. At the shop level, this was expressed in union involvement in piece-rate setting through union experts.28 At the manufacturer’s level, collective bargaining sought to standardize direct wage and benefit costs for product lines (such as women’s coats, suits, dresses, and intimate apparel) through various joint boards. To support these activities, the apparel labor unions created in their national offices industrial engineering departments to seek improvement in work practices and experiences.29 The unions and their employers also became pioneers in establishing neutral umpires and arbitrators in the handling of labor-management disputes.30
Over time, major growth in imports and traditional price/cost competition have reduced the strategic leverage of the apparel unions and their chosen methods of wage stabilization. (The Amalgamated and ILGWU merged in 1995 to form the Union of Needletrades, Industrial and Textile Employees—or UNITE!). On a labor-cost basis alone, U.S. workers cannot compete with foreign apparel assembly operations in developing countries. At the same time, the problem of sweatshops persists, despite government regulation of minimum wages, overtime, child labor, and safety issues. In fact, regulation has increased significantly since the 1930s, and Secretaries of Labor continue to be concerned about sweatshops and violations of labor standards in apparel.
Textiles: From Fiber to Cloth to Finished Product
The basic processes of the textile industry—the spinning of fibers and the weaving of cloth—go back to ancient times. The early phases of the Industrial Revolution in England were closely linked to the mechanization of the textile industry and its transfer from the home to the factory. Textiles have also led the industrialization process in many recently developing countries.
For the United States this brings us back to Samuel Slater, “father of American manufactures.” By 1810, the Pawtucket, Rhode Island, enterprise begun with Slater’s cunning had spawned a vibrant cotton-spinning industry throughout New England. The next step in developing a U.S.-based industry was to bring the machine that took yarn and transformed it into finished cloth—the power loom—across the Atlantic. This feat was accomplished in much the same way that Slater brought cotton spinning to the United States, through the agency of a crafty Boston merchant, Francis Cabot Lowell. As business historian Robert Dalzell notes,
[T]he crowning glory of Britain’s textile technology ... remained beyond the reach of American manufacturers. Until, that is, Lowell scored his triumph. Leaving the British official who twice searched his luggage none the wiser, he managed by meticulous observation to memorize the principal features of the power loom well enough to produce his own version of it on his return to Boston.31
A full-blown textile industry therefore blossomed in New England, fostered by the region’s access to abundant water power, capital, mechanical skills, and a hardworking labor force. But the adoption of steam power in New England was delayed until the 1850s and 1860s, at which time most of the significant water-power sites were already in use. The efficiency of steam engines had by then been greatly improved through the use of better materials, and their operating costs reduced by cheaper transportation of coal.32 Southern manufacturers had already adopted steam engines for textile production, along with newer and more productive technology. As a result, after 1880 the industry began to expand south, particularly in North and South Carolina, Georgia, and Alabama. By 1920, over half of the spinning and weaving capacity was in the South, leading industrialization there. By 1980, little of this basic part of the textile industry remained in New England.
The U.S. textile industry has taken advantage of economies of scale in production to serve large, expanding, and, for much of the century, protected markets for textile products. It has become an industry adept at producing high-quality products in large runs competitively and its strengths and limitations must be understood in this context.
Capital Intensity and Economies of Scale
Primary textile manufacturing includes both the spinning of raw cotton and other fibers into yarn and the weaving of yarn into “greige goods,” or unfinished cloth. Although there have been specialized spinning and weaving mills, the great majority of output is produced in enterprises that engage in both operations. In fact, Lowell and his associates established the first incorporated manufacturing operation when they set up an integrated mill, from cotton to finished fabric.33 The cloth produced in weaving mills requires further finishing—such as bleaching, shrinking, dyeing, and printing—before it is ready for sale to the apparel industry, to retail distributors, or to industrial consumers. To undertake such a comprehensive set of activities, of course, requires significant capital investment. From the outset of the Industrial Revolution, spinning, weaving, and finishing have called for substantial investments in plants, power, and equipment.34
Because of this capital intensity, the textile industry has been driven by economies of scale. American plants have largely succeeded through making huge runs of a limited range of products and, since the 1950s, technological changes on the floor—much quieter machinery, for example, or removal of the ubiquitous cotton dust (now required by the Occupational Safety and Health Administration) that used to affect both worker performance and the quality of cloth—have dramatically improved industry performance. Further, the knitting machine has been a key development in manufacturing technology. Knitted goods are an essential and growing segment of the textile industry, a trend that reflects the increasing demand for casual wear. The knitting machine produces cloth as the loom does but uses a different method. The warp knitting machine produces a flat fabric much like woven cloth, while the circular knitting machine creates a tubular fabric. The most important knit goods products are hosiery, knit underwear, and knit outerwear—popular casual wear items like T-shirts, polo shirts, and sweatpants. Knitting mills now account for almost 30 percent of production employees engaged in textile manufacturing.35
Continuing integration of the industry also contributed to the rise in productivity. Although small, family-owned and operated companies were the norm in traditional textiles, in the early 1950s leaders like Burlington Industries and Milliken undertook vertical integration to handle textile products from fiber to finishing.36 Historically, finishing operations were often undertaken by separate firms known as converters, which played a large role in the design of finished goods. Companies like Burlington integrated forward by bringing converting operations in-house, while a number of converters extended their operations backward into primary textiles.
Beyond restructuring for materials flow, the industry has experienced substantial horizontal integration. As a consequence, some segments of textiles, such as spinning, weaving, and knitting, became more concentrated by the late 1970s. The industry underwent another substantial restructuring in the 1980s, and product lines became even more concentrated.37 Much of this happened because less efficient firms, using older technologies, went under or were absorbed by larger survivors. Between 1977 and 1987, the number of textile establishments declined by 11 percent, from 7,202 to 6,412, and industry employment fell by nearly 25 percent. At present, the four largest firms control about 40 percent of weaving and yarn mills output, although many finishing and dyeing companies and knitting firms remain small.
Human Resources and Productivity Growth
The drive to gain advantage from economies of scale and the role of manufacturing technology in textiles have also affected the people who work in the industry. Ever since garment-making entered the factory system, the textile industry has been much more capital intensive than apparel. Today we estimate capital per worker in apparel at $2,000, while the figure for basic textile operations is several hundred thousand dollars. As a result, human resource practices in the two industries differ considerably.
For one thing, the textile industry’s machine operations involve a large number of distinct job classifications defined by the technology and production process; they fall within a narrow range of compensation, with the classifications of loom fixers, weavers, maintenance electricians, and machinists above that range. Because the textile industry has become so capital intensive, there are fewer jobs than in the past—but the people who remain are, on average, paid more than apparel workers; some lower-skill jobs, such as the picker tender opening bales of fiber, have now been automated out of existence. In 1950, average hourly earnings in textiles were $1.23 an hour compared with $1.24 in apparel. By 1980, textile hourly earnings had risen to $5.07 compared with $4.56 in apparel; in 1997, textile workers earned an average of $10.02 an hour, 21.5 percent more than the $8.25 an hour of those in apparel.38 Currently only 48 percent of textile employees are women, while women constitute 77 percent of apparel workers.
Labor organizations have historically had a small proportion of the textile industry under collective agreements. As the textile industry moved south to the Piedmont states, it drew on a rural and small community workforce, largely made up of native whites.39 Textile mills at their outset often provided the principal employment in the locality. The first unions were formed among some of the skilled craftspeople, such as loom fixers, weavers, spinners, and slasher tenders, particularly in New England. With the advent of the CIO, industrial unionism sought to organize more workers in the industry, and the Textile Workers Union of America merged with the established Amalgamated Clothing Workers Union in 1976. However, organization met fierce opposition from southern textile employers.40 Currently, about 15 percent of the textile production and nonsupervisory workforce is organized compared with 25 percent in the apparel industry.41
The combined impact of these factors is captured by the following trends. From 1950 to 1996, U.S. production of textiles increased almost threefold. Over the same time period, the number of production workers decreased by almost half. And the rate of textile productivity over this period far outpaced that for the manufacturing sector as a whole. (We discuss the performance of the textile industry extensively in Chapter 13.) Although U.S. apparel firms struggled in the 1980s, competing with foreign producers on labor costs, the domestic textile industry fared much better. Successful exploitation of economies of scale, favorable international trade agreements such as the MFA, and special arrangements for apparel imports made of U.S. textiles—even the clout of certain southern senators, looking after the firms in their states—mean the U.S. textile story has not been determined by import penetration.
Even so, lean retailing practices pose both new opportunities and challenges for the textile industry. Supplier relations in retail-apparel-textile channels are shifting. Textile manufacturers no longer simply supply apparel-makers with cloth; they may also sell a variety of household goods, such as sheets and towels, directly to retailers or serve industrial users with a wide range of products. Because product proliferation is the order of the day in all these markets, textile firms are being asked by their customers to provide many more products in smaller lot sizes and with shorter lead times. In the new competitive arena—where demand uncertainty and time to market have become important factors along with price—textile firms are being forced to adapt to information-integrated channels, rather than just drawing on the economies of scale that led to their success in the past.
Historical Relations Among Retail, Apparel, and Textile Firms
For most of the last century, companies in one of these industries related to those in another through markets as sellers and buyers. The business enterprises that emerged in the American retail, apparel, and textile industries were, for the most part, separated. They weathered diverse competitive conditions; they differed markedly in their capital structures, costs of entry and exit, size and scale of operations, the proportion of direct labor costs, unionization, geographic locations, and so on. There was almost no vertical integration across retail, apparel, and textiles. For example, only a few major manufacturers in men’s apparel have also entered into the retail business—Bond Stores in the World War II era, Hart, Schaffner, and Marx more recently—although Levi Strauss, a manufacturer of jeans, has opened some retail operations. As for retailers, most mass distributors have focused on buying and selling rather than manufacturing products.
No textile producer of woven goods has been a significant apparel manufacturer. One company, Burlington Industries, sells directly to organizations that purchase uniforms for airlines, police, and fire personnel. It specifies in the sale that, regardless of the apparel firm used to fabricate uniforms, Burlington’s cloth must be used.42 Another major textile company, Milliken, has a degree of common ownership with a retail business, Mercantile, although these arrangements remain unusual.
Textile firms, however, have been players in multiple supply channels. There are three major categories of sales outlets for these manufacturers: (1) woven goods and some knit goods destined for clothing, in which materials are sold to apparel-makers for fabrication and assembly; (2) home furnishings—such as sheets, bedspreads, towels, and some knit goods—in which the textile firm sells directly to retailers; (3) industrial products, from automobile seat covers and rugs to commercial fishing nets, in which a textile firm sells materials to a car company or other nonapparel manufacturer. Thus, there are at least three kinds of relations among the industries, and multiple textile channels are on the rise. Although apparel uses dominated textile consumption in the past, by the early 1980s apparel’s share of fiber consumption was only 37 percent; home furnishings was about 38 percent; and industrial textile products consumed over 20 percent.
Textile companies like Springs have taken advantage of these new outlets—for example, producing Disney-character sheets for retail—but a new dynamic is also developing with apparel-makers, who want shorter runs of materials much more quickly from their textile suppliers. Historically, the textile-apparel relationship involved long lead times or advance commitments to secure the necessary cloth in the right style, texture, and patterns. This occurred not only because of the greater concentration of businesses in the textile industry, but because textile companies generally plan to run their expensive capital equipment at full capacity around the clock. Our research indicates that the relationships between firms in the textile and apparel industries remain underdeveloped, with new competitive forces driving both sides to change.
Even if integration efforts in the past have been uncommon, information flows, transport, and inventory have always been decisive factors in shaping the relations among retail, apparel, and textile firms. As Alfred Chandler and other business historians have made clear, successive changes in information exchange and transport over the last century have reshaped relations among industries, as well as the internal organization of these enterprises. Chandler notes,
Significantly, it was in several of these [labor-intensive] more fragmented industries—textiles, apparel, furniture, and some food processing—that the mass retailer (the department stores, mail-order houses and chain stores) began to coordinate the flow of goods from manufacturer to consumer. In those industries where substantial economies of scale and scope did not exist in production, high-volume flows through the processes of production and distribution came to be guided—and the resulting cost reductions achieved—by the buying departments of mass retailers, retailers who handled a variety of related products through their facilities.43
And so we arrive at the new information technologies of the 1980s. These have begun to create integrated channels among enterprises in the three industries, facilitating even more product proliferation and stimulating changes in merchandising, inventory management, internal production practices, and methods of using human resources. When it comes to the driving force behind the late twentieth-century industrial transformation, lean retailing is at the forefront of that revolution.









More than a century ago a major wave of innovations in distribution and production led to the modern department store, the mail-order house, and the chain store, and reshaped their suppliers. The present transformation of retail and manufacturing engendered by new information technologies, production methods, and management practices also fundamentally alters the manner in which industries and firms take raw materials, turn them into a profusion of products, and deliver them to consumers. Although these developments are very much a work in progress, information-integrated channels of production and distribution are emerging.
Such channels are not unique to retail-apparel-textile relations but have arisen in a wide variety of consumer product industries in which retailing practices are undergoing similar changes. The developments reported here offer a prototype of the new links among manufacturers, other suppliers, retailers, and consumers.
In fact, the transformation has been gradual and is still under way. Only as recently as the mid-1990s has integration risen to critical levels, providing a clear picture of what channel relations will look like in the future. Information integration has reshaped much of the retail-apparel-textile channel, yet further transformation is likely in the decade ahead, not only for these linked industries, but for consumer product sectors in general.
In this final chapter, we step back to survey the ways in which information-integrated channels will affect the public and private sectors. The pervasive changes arising from lean retailing challenge the conventional wisdom about the future of international trade, labor standards, employment, and even macroeconomic fluctuations. At the same time, these changes alter the nature of competitive strategy for businesses that supply lean retailers in apparel, textile, and other industries.
Trade Issues: The New International Economics
[W]e estimate that national income would improve if quotas and tariffs were eliminated because the cost to the economy of protecting each worker with import restraints exceeds the wage the worker is paid ... [F]or textiles the cost per job protected is $40,200 while wages are $20,000; for apparel the cost per job is $37,500 while wages are $14,000.1
We want the world to know how strongly we oppose NAFTA expansion and fast track.2
—John J. Sweeney, President, AFL-CIO
These quotations aptly reflect the continuing controversy over international trade policies. The apparel and textile industries have played a central role in trade discussions since the inception of the United States, just as they have in other developing and developed countries throughout the world. These industries have often been chosen as the means for building manufacturing capacity in the developing world; at the same time they have been the recipient of trade protection in developed economies. More to our point, information integration has added a new dimension to these long-standing controversies.
The textile and apparel industries have often been intertwined in public policy discussions about international trade, the Uruguay round of trade negotiations, the role of World Trade Organization, NAFTA and its labor side-accords, the renewal of fast-track negotiating authority, imports from China and human rights standards, and so on. This stream of general debate, however, is seldom related to a detailed study or analysis of the impact of such developments on the U.S. textile or apparel industries.
From the time of Adam Smith and David Ricardo down through the writings of Hechscher-Ohlin, economic analysis has been devoted to the consequences of trade restraints in the form of quotas, tariffs, and nontariff barriers on output, employment, and prices. Traditional international economics attributes trade to comparative advantage, relative labor costs, and the relative costs of logistics and transportation. A “new international economics” in the past decade has stressed that much global trade actually reflects, as Paul Krugman puts it, “National advantages that are created by historical circumstance” rather than natural resources. “Because comparative advantage is often created, not given, a temporary subsidy can lead to a permanent industry.”3 Note that these economic analyses and policy prescriptions have been applied generally and are not focused on particular industries like textiles or apparel.
In any case, since the 1970s, such debates about the impact of international trade policy have been placed in a new economic context. Increasingly, analysts and public policy makers discuss trade issue in terms of the emergence of a significant and growing inequality in compensation between production and nonsupervisory workers, on the one hand, and managerial, supervisory, or exempt employees and professionals on the other. These differences include a larger disparity in compensation between those highly educated and those who are not, particularly high school dropouts. In addition, there has been an appreciable growth in relatively unskilled immigrants in some localities such as major metropolitan areas around the country.4 The 1997 Economic Report of the President, reporting a colloquium of experts at the Federal Reserve Bank of New York, attributes the growth of inequality to the following: technological change (45 percent), international trade (12 percent), a decline in the real minimum wage (10 percent), rising immigration (8 percent), and other factors (15 percent).5
Although such analysis and policy discussions have not singled out specific industries, the nature of the occupational structure and workforce in textiles and apparel—particularly the latter sector—makes the general discussion relevant to these two industries. It would appear that neither the market imports of textiles nor the immigration of low-skilled workers has had an appreciable negative impact on the wages of the textile industry or its major sectors. The average hourly earnings of U.S. employees in textile mill products (SIC 22) went from $4.66 in 1979 to $10.02 in 1997—an increase of 115 percent and more than the increase in all manufacturing or nondurable manufacturing. This relative wage increase in textiles took place despite its concentration in a low-wage region—the southeastern Piedmont states—the low level of collective bargaining, and the higher-than-average percentage of women workers.
But the experience in apparel is less categorical, especially because of the differential impact on various branches of apparel and other textile products (SIC 23). In 1997, the average hourly earnings of apparel workers were $8.25. On the high end, automotive and apparel trimmings (SIC 2396) averaged $11.36; on the low end, women’s and misses’ blouses and skirts (SIC 2331) averaged $7.01. Correspondingly, employment in automotive and apparel trimmings increased 71.4 percent from 1979 to 1997 while in women’s and misses blouses and skirts it declined by 60.6 percent in the same period. Bear in mind, however, that blast furnaces and steel mills (SIC 3312) declined in employment from 478,500 employees in 1979 to 163,300 in 1997. This 65.9 percent decline from 1979 to 1997 compares with a 31.3 percent drop for textile mill products and 37.6 percent for all apparel workers.
Still, there can be little doubt that in a sector like women’s and misses blouses and skirts, in which employment is concentrated in small contract shops, import competition from low-wage developing countries and unskilled immigrants have contributed to its deterioration. Moreover, the failure to comply with federal and state employment statutes relating to minimum wages, overtime rates, and child labor, uncovered in periodic enforcement forays, have contributed to the decline of this sector.
The general analysis of the consequences of trade and immigration in the textile and apparel industries clearly requires a much more focused application to detailed sectors to provide reliable conclusions. Moreover, and as this volume indicates, the offsetting influences of lean retailing and short-cycle production in comparison with low foreign labor rates must be evaluated by product demand variability, rather than simply making generalizations about aggregate trade and immigration. For instance, the information-integrated channels in retail-apparel-textile are having some of their most significant impact on sourcing among suppliers, domestic and foreign. The low labor costs for sewing and short time to market from Mexico and the Caribbean countries, and the provisions of the Harmonized Tariff Schedule (formerly Section 807 and 807a, or currently 9802.00.80) that establish duties only on the value added to U.S.-produced materials sent out for assembly, all favor sourcing of apparel from south of the U.S. border rather than Asia. According to the U.S. International Trade Commission, “U.S. imports of textiles and apparel from China and two of the traditional Big Three Asian suppliers—Hong Kong and Korea—continued to decline in 1996, when these countries together with Taiwan, accounted for 23.4 percent of total sector trade, compared with 38.5 percent in 1991.”6
The information-integrated channels developed in the United States, which are now influencing sourcing patterns from Mexico and the Caribbean Basin, have begun to affect the textile and apparel sectors worldwide. For many fashion apparel products—defined as those planned to last only one season—the practice of sourcing on the basis of lowest labor costs may be expected to continue. Indeed, much of Asian sourcing has been devoted to such items, with production shifting within Asia away from regions where wage levels have risen. But for basic and fashion basic apparel products, for which frequent replenishment orders are becoming the norm, the practice of sourcing some of the assembly and sewing operations from nearby lower wage regions and countries is emerging. At the same time, design, distribution centers, marketing—even cutting—as well as some short-cycle assembly remain in the market region.
As we pointed out in Chapter 13, regionalization of apparel production in three main areas has started to occur. In the U.S. market, most sewing operations take place in Mexico and the Caribbean Basin; in Europe, sewing operations go to North Africa, Turkey, and Eastern Europe; and in Japan, sewing operations go to various East Asian regions. The formal analysis in Chapter 7 specified the factors that determine whether production of items under rapid replenishment policies should be done domestically or outsourced to low wage countries.
For textiles, with their high capital costs, lower labor content, and emphasis on high quality and finishing operations, the concentration in the southeastern United States, Korea and Japan, and industrial Europe may be expected largely to continue. But the longer term viability of American textile centers will depend on the development of infrastructures capable of supporting advanced textile production in countries close to the U.S. market, such as Mexico and elsewhere in Latin America.
Macroeconomic Implications: Inventories, Business Cycles, and Price Levels
In an information-integrated channel, the historic market relationships between buyers and sellers change significantly. It is true that textiles firms still sell to apparel-makers, which in turn sell to retailers, which ultimately sell to consumers. Markets certainly have not disappeared, but these relationships have been transformed. Different channel players now share detailed information on daily sales; investments in technologies mutually benefit both retailers and suppliers; and because of the effective use of information and manufacturing technologies, risk has been reduced across the entire channel. The adoption of standards in the supply channel, such as those that specify packaging, labeling, and marking of products, have reduced further time to market and enhanced efficiencies; this expedites transit and ensures floor-ready merchandise for consumers at the end of the channel from suppliers. As a result, the traditional boundary lines between firms are blurring as the cost of transacting business within and across industries falls dramatically.7 Note that the technologies and standards that made these information-integrated channels possible were a product of private-sector activities—individual enterprises, trade associations, and consulting firms. The fundamental standards of product identification through bar codes and related technologies have become compatible worldwide without the prescription or regulation of a Bureau of Standards or government regulatory agencies.
Falling transaction costs between sectors allow an economy to increase the total output of goods and services it can produce for a given set of resource inputs.8 The dramatic decrease in transaction costs across many sectors parallels the wide-scale changes at the end of the last century, which, in the words of Alfred Chandler, reduced “the number of transactions involved in the flow of goods, increased the speed and regularity of the flow, and so lowered costs and improved the productivity of the American distribution system.”9 Yet it often takes time for an economy to reflect the impact of such fundamental shifts. In fact, the current combination of changes in information technology, management practice, and manufacturing strategy may be one of the places where the impact of computers on the economy has been hidden until recently.10
The falling costs of conducting business between retailers and their suppliers may also explain why there has been relatively little vertical concentration across industries in the channel—no textile firms have gone into the manufacture of apparel or retail and few apparel firms have set up their own retail outlets.11 Indeed, an effective information-integrated channel probably works against vertical integration. Sharing information and current knowledge of the market across channel players achieves some of the same objectives—at lower cost—of formally reaching forward or backward into markets. Enterprises in different parts of the channel can therefore concentrate on their business strengths.
Lean retailing and the restructuring of manufacturing supply have also affected the economy as a whole in the area of inventories. Lean retailing itself implies a dramatic reduction in the amount of inventory held by retail enterprises. Chapter 14 documents the large inventory reductions of apparel suppliers that draw fully on information technology in concert with new managerial and manufacturing practices; in some cases they have decreased inventory levels by half.
The impact of these new policies on retailing and manufacturing sectors may have begun to show up in economy-wide measures of inventory. The overall ratio of inventories to final sales of domestic business fell considerably in the past decade, from 2.78 in 1987 to 2.34 in 1997.12 It has long been known that inventories at the macroeconomic level affect the depth and length of business cycles.13 The connection between recent changes in inventory policy and the business cycle have only begun to be studied in a systematic fashion.14 As noted in the 1988 Economic Report of the President,
Adoption of just-in-time inventory management by manufacturers also represents a significant development, since changes in inventories have often been an important source of business-cycle fluctuations. Whether just-in-time inventories will be able to dampen future business cycles, however, remains to be seen.15
Our work on apparel supplier adjustments to lean retailing suggests that an economy characterized by an increasing level of modern manufacturing and retailing practices should experience lower levels of inventories relative to sales. Because a reduction in the I/S ratio means that changes in sales will be matched by a smaller change in inventories, a lower ratio also implies lower inventory volatility. This is important because aggregate inventory volatility has historically made up a significant portion of the volatility of Gross Domestic Product (GDP). If the effects documented for retail-apparel-textile channels are more pervasive across other sectors similarly affected by channel integration, these changes could imply lower GDP volatility. This macroeconomic link may prove to be the most profound implication of the adoption of firm-level information technology and manufacturing practices.
Fundamental changes in inventory policies in retail and manufacturing may significantly affect price levels as well. The increased volatility of producer and consumer prices in a number of sectors since 1995 has been attributed in part to the adoption of new inventory polices related to lean retailing.16 Some have suggested a connection between these policies and price fluctuations.17 According to one view, an information-integrated channel may lead to increased volatility in aggregate prices because the impact of shifts in supply and demand is more rapidly reflected in consumer prices without the buffering impact of inventory. Competitive information-integrated channels may also reduce aggregate price levels, as expressed by price markup policies that in the past have reflected the incomplete information of channel participants.18 Whatever the effect, the more widespread adoption of information-integrated channels documented in this book raise a central question for future models of industry- and macroeconomic-price movements.19
Labor Standards: The Problem of Sweatshops
The most effective weapon used by American capital in weakening the power of organized labor has been to hire immigrant workers....[I]mmigrants are cheap and controllable. The conditions they toil under make a mockery of the already low American labor standards—the most regressive among the advanced industrial nations.20
For more than a century, the U.S. federal and state governments have investigated sweatshops in the garment industry, including the role of immigrants, and have adopted legislation to ameliorate their impact on workers and consumers. At the turn of the last century, unsanitary conditions, in addition to low wages, long hours, and child labor, were the biggest concerns. State inspectors were authorized to attach a “tenement-made” tag to garments produced by violators. The Consumers’ League, organized in 1899, adopted a voluntary label to be attached to garments made by manufacturers that abided by labor standards—that is, they obeyed state factory laws, manufactured on their premises, employed no children under 16, and used no overtime work.21
In 1938, the Fair Labor Standards Act (FLSA) for industry generally specified minimum wage rates, overtime after forty hours of work per week, and a prohibition of child labor. The so-called “hot cargo” provisions of the statute, Section 15, made it illegal to transport or sell goods in commerce produced in violation of the provisions of the Act.22 Despite these strict legislated standards—with wage levels updated from time to time—widespread violations in apparel workplaces have become commonplace in the 1990s. Labor conditions have deteriorated for a number of reasons: the decline in the coverage of collective bargaining agreements with their provisions for regulation of contract shops; the difficulty of policing contributions for health and pension funds from employers in this sector; the increase in immigrants, legal and illegal, concentrated in certain areas; the intense competition from imports; and the sharp drop in employment in apparel in some markets.23 Sweatshops, it seems, have always been with us.
The El Monte plant in southern California, with immigrants working behind barbed wire, caught the nation’s attention in 1996. Federal investigators reported in 1997 that two-thirds of the establishments in New York City’s garment industry violated overtime or minimum wage laws.24 The U.S. Labor Department reports that independent surveys, as well as federal and state compliance data, show minimum wage and overtime violations of the FLSA occurring in 40 to 60 percent of investigated establishments. The policy question is what, if anything, can be done to control or eliminate sweatshops and noncompliance with statutory standards in the United States? And what can be done to ameliorate sweatshop conditions in developing countries that produce and export half of the apparel purchased in this country?
Historically, U.S. governments have employed three general approaches to the problem of sweatshops. First, the federal and state governments used powers of enforcement to seek compliance with labor standards. For the federal government, the Fair Labor Standards Act and its regulations specify the standards and enforcement procedures.25 But sole reliance on traditional government enforcement activities has serious limitations.26 The Department of Labor has fewer than 800 investigators to enforce employment statutes for 800,000 apparel industry employees in about 24,000 establishments, not to mention the other 122 million employees in 6.5 million workplaces around the country. Monitoring compliance with wage and hour provisions and pursuing violations is an extremely complicated and time-consuming process.
A second method has involved mobilizing public pressure on consumers, retailers, and manufacturers to raise the incentives for voluntary compliance with labor standards. For example, the Secretary of Labor has used his or her “bully pulpit” to call attention to the problem, urging the public, retailers, and manufacturers to avoid purchasing products made in workplaces that do not meet the standards.27 Various reports have also publicized government enforcement actions to deter contractors, jobbers, manufacturers, and retailers from violating the standards, such as the release of a series of government reports on the extent of violations and the penalties assessed against violators.28 In yet another example, Duke University’s adoption of a code of conduct to ensure that apparel items bearing the university’s name are not made in sweatshops has received public support.29
Indeed, efforts to use public concern, and at times outrage, to tackle the sweatshop problem go back to the early part of this century. The most famous case involves public reaction to the fire at the Triangle Shirtwaist Company on March 25, 1911, in which 146 women died. The fire started in a loft of the factory during the workday. The women and girls working in the factory could not escape because the company had locked the doors to the stairs from the outside, ostensibly to prevent theft by employees. The lack of fire extinguishers within the factory and the inability of fire ladders to reach the windows made escape impossible. In this case, public outrage led to early workers’ compensation and factory inspection legislation.
But, in general, the effectiveness of focusing public attention on sweatshops and poor labor conditions has been limited by the difficulty of keeping consumers, voters, students, or other groups working on this issue for sustained periods of time. Such avenues are at best a means for focusing the attention of key parties in order to build longer term mechanisms that remain even after public attention wanes.
Finally, voluntary agreements among channel participants to ensure compliance—which sometimes have arisen from efforts to increase public pressure—have been employed at various times. For instance, in 1995, the Labor Department sponsored the Apparel Industry Partnership, in which a number of U.S. apparel manufacturers, UNITE!, the National Consumers League, the Interfaith Center on Corporate Responsibility and others agreed to monitor compliance with labor standards of contractors.30 Yet these initiatives also have limitations. It is difficult to select an organization to do the monitoring, establish the procedures to be followed, and determine who should serve as outside or independent monitors.31 Voluntary compliance measures and agreements in the United States, outside of collective bargaining, have thus far had a history of short-term viability and limited effectiveness.
Policies to reduce repugnant workplace conditions—by U.S. standards—in developing nations that export apparel to the U.S. involve an even more complex range of issues. What are the appropriate labor standards? Is one only to apply the standards and regulations of the exporting country or are some higher international standards to be used? How are such standards to be established, recognized, and enforced?32 One approach would be to extend the conventions and standards established by the International Labour Office (ILO) and to enhance the effectiveness of its enforcement. The ILO held a convention on child labor in June 1998 and is considering a proposal for an annual “global report” on countries that have not ratified certain core workers’ rights, such as freedom of association, abolition of forced labor, nondiscrimination and equal remuneration, and minimum age.33 Even with such international standards adopted by the ILO, the task of enforcement remains daunting.
In the United States a number of programs have been adopted that seek to change labor practices in workplaces overseas. The Department of Labor provided $500,000 to the International Program for the Elimination of Child Labor in a joint effort with the ILO to end the use of children in the manufacture of soccer balls in Pakistan. (In 1994, 35 million soccer balls were produced there, one-quarter by children.)34 Mattel, Nike, and Kathie Lee Gifford exemplify manufacturers, brand names, and celebrities who have adopted programs for overseas inspections to mitigate criticism of their possible sweatshop imports. The Council on Economic Priorities has established a global, variable “social accountability standard” that companies can follow to prove they adhere to an array of labor standards and pay their workers a sufficient income.35 The U.S. and European Union, through the Secretary of Labor and Commissioner for Employment and Social Affairs, have sought to develop among labor and management an acceptance of international standards to assure consumers that the products they buy are not made in sweatshops.36
In a significant sense, such efforts to deal with labor standards in apparel production simply illustrate the larger issues of trade, labor, and environmental standards that are likely to be a focus of international economic discourse over the decade ahead. In fact, it is doubtful that these issues can be separated to the extent they have been over the past decade. There are sharp differences in the United States between organized labor and business and in the political arena as well. Persistent efforts in the labor standards field indicate that separating trade, labor, and other social issues will no longer be as acceptable in the era ahead. The fact that U.S. Secretary of State Madeleine Albright took up the issue of global sweatshops is a striking example of this reality.37
The complexity of sweatshop problems makes any “silver bullet” solution as unlikely now as it has been throughout this century. Nonetheless, our analysis suggests a number of steps that might be taken to improve compliance with U.S. labor standards in the presence of information-integrated channels. Given the inherent resource limitations in U.S. government enforcement, inspections must be carefully targeted to yield maximum impact. One method for improving targeting would be to require each garment to include a bar code label that shows the place and time of fabrication. This would take advantage of the same technology that has been so fundamental to the changes examined in this book. Information from the bar code could more directly be used by the Wage and Hour inspectors to sample compliance and more rapidly isolate violations. Such requirements could arise either as a result of voluntary agreements among retailers and apparel suppliers or be mandated through regulation.38 Past experience suggests, however, that in this field voluntary measures need to be reinforced by regulatory authority.
The viability of collective bargaining as a means, once again, to regulate sweatshop conditions largely depends on the ability of UNITE! to rebuild its collective bargaining and membership base in a smaller and more efficient industry responsive to lean retailing.39 Efforts by the union and apparel employers to link compliance with wage and working condition standards to efforts to improve the competitive viability of the industry offer promise such as through sponsoring training of apparel managers or by helping to build more responsive networks of apparel contractors to deal with retailers. But these initiatives are still at an early stage of development.40
Finally, the central role played by retailers in development and operation of the channel points to the fact that any measure—whether taken by the government, through voluntary compliance programs or via collective bargaining—must include their participation and support. The reliance of lean retailing on the promulgation of standards of performance has been well documented in this book. A logical extension of those practices might be the adoption of procedures or systems related to labor standards in domestic or offshore sourcing operations.
The Coming Competitive Landscape
Since the end of World War II, textile-mill products and apparel have both been characterized by substantial reductions in employment; at the same time these sectors show substantial increases in output, including shifts to higher-value products and higher productivity. Total employment in U.S. textiles is projected to continue its decline, reaching 588,000 workers by 2006, with apparel down to 714,000 at the same date. Meanwhile, outputs are projected to increase 22 and 4 percent, respectively, in the 1996–2006 period.41
These are scarcely moribund industries, with inflexible product and labor markets. The textile industry, in particular, has been characterized by rapid technological changes and automation; shifts to large-scale establishments; restructuring and consolidation of enterprises in spinning, weaving, and knitting; substantial capital investments in these activities and finishing operations; and a shift to products with expanding markets. Wages have risen relative to the average of all manufacturing or nondurable manufacturing. Exports have been within a few billion dollars of imports in recent years.
The economics of these channels depend on the costs of the separate steps and transactions—from manufacture, including inventory costs, through distribution costs, retail, and sales, including markdown and stock-out costs. The costs of time to market also matters. This view of costs examined throughout this book yields quite different estimates from the traditional resort to comparative direct labor costs of manufacture as a sole basis for supply-choice decisions. Previous chapters have demonstrated that the lowest purchase price from a supplier does not necessarily yield the lowest costs at the point and time of sale or the largest profit. An established channel in which the various parties focus on time to market results in markedly different supply decisions and dynamics than those dictated by conventional direct labor costs of supplies. Given these crucial changes, the following sections review the competitive “horizon” for each of the industries that make up the channel.
The Retail Horizon
Information-integration is one of the major factors contributing to increasing concentration in the retail sector. Previously, manufacturers and suppliers to a number of retailers were often in a better position, compared with any one retailer, to report on shifting styles and tastes and estimate market direction. In many situations, they chose SKUs and set volumes for retailers. Now point-of-sales information provides retailers with reliable information on market developments and hence gives them more leverage in dealing with direct suppliers and others further from ultimate consumers. In other words, direct measurable information of consumer behavior translates into market power. The lean retailer can also transfer to its suppliers the functions (and costs) of creating floor-ready merchandise, activities that traditional retailers handled in the past. Bear in mind, however, that the information-integrated channel requires substantial investment in technologies by retailers. Although small-scale retailing continues, it is clear that an increasing proportion of retailing will be concentrated among a decreasing number of larger enterprises.42
The Internet has been often cited as an alternative to retailing and, presumably, a potential challenge to the dominant role played by lean retailers. In this regard, Tracy Mullin, President of the National Retail Federation (NRF) notes:
The NRF fields a deluge of calls each week about the Internet’s impact on retailing. The most common question we get from reporters: “How long will it take for the Internet to completely replace physical retailing?” We have observed that traditional retailers are taking a cautious approach to the Internet. Yet most understand its great potential, even if they openly admit they don’t have all the answers.43
A limited number of retailers are currently experimenting with the Internet, although only 9 percent of those surveyed in 1998 indicated that they currently sell products this way.44 Retailers are currently reluctant to go on-line both because they believe that their products are “ill-suited for Web sales” and are concerned about specific technical limitations, such as the security of electronic financial transactions.45
A number of developments, many linked to issues we have discussed, indicate both the potential and limitations of electronic retailing. In one sense, the Internet offers opportunities akin to mail-order retailing for playing a very lean game. For example, Lands’ Ends became an early leader in adopting certain lean retailing elements into its catalog operations and has aggressively entered Internet retailing. This retailer launched its Web site in 1995, the first major apparel retailer to do so. Its site incorporates an encryption system to protect customers against credit-card thefts.46
The Internet provides some of the advantages of mail-order sales with even lower transaction costs. However, the obstacles to virtual retailing remain formidable. Product offerings are limited in Web retail sites—the Lands’ End site, for example, offered only 500 products in 1997. In addition, just as in other areas of modern retailing, a company must have a distribution system capable of getting products out efficiently on an order-by-order basis, either through internal resources or use of third-party consolidators. The economics of distribution for Web retailing, like catalog retailing, are therefore quite different from those developed even by advanced in-store lean retailers.
Finally, measurement, fit, color, and texture remain central components of apparel sales. In apparel—unlike the sale of goods via the Internet such as computers, software, or tools—people want to see, feel, and try on the products. These aspects of selling apparel items do not fit well with “virtual retailing.” The mail-order business already contends with this problem, and these retailers cope with returns that sometimes go over one-quarter the value of sales in a given year. Consider Lands’ End once more. In 1991 (well before its entrance to the Internet), it was forced to cope with returns of 132,000 shirts. Each return was associated with a processing cost roughly equivalent to 25 percent of its value.47 Thus, although Internet retailing will certainly grow as a channel of distribution, the most essential longer term developments will involve the expansion of lean retailing principles to a wider and wider variety of goods sold by a decreasing number of major retailers.
The Apparel Industry Horizon
A central feature of information-integrated channels—indeed, the basis for our term “lean retailing”—is the effective management of inventories at the SKU level. Throughout the modern channel, lean inventory management reduces the risk of selling “perishable” products, thus enhancing profits. The capability to compete increasingly depends on an enterprise’s ability to manage operations according to the logistics of time and flow of product, reducing time to market and the costs of holding inventory.
We have made clear that holding inventory can be expensive to a supplier, whether it manufactures or sources its products, in several ways. These include capital tied up in work-in-process or finished goods; the costs of facilities used; the risks of failure to sell; and price markdowns to dispose of products. At the same time, the inability to supply product to retailers or customers is another costly risk.
These risks and costs may be minimized and profits enhanced by using a combination of short-cycle and longer-cycle production lines. The short-cycle line turns out products faster but usually at a higher unit cost. The long-cycle line takes longer to produce items, but at lower costs. Balancing these lines by establishing for each SKU the precise pattern of expected variability in demand and point-of-sale information provides the means for maximizing profits. Our research suggests that the cycle time of a fast production line should be no more than a week or two to be an effective alternative for the lower costs of a long-cycle line or plant.
The balancing of short-cycle and long-cycle production alternatives has direct application to the choices manufacturers and retailers face between domestic sources with potential short cycles and foreign sources with longer ones. The future of the domestic apparel industry rests on those items made using short-cycle production, which are often those with high weekly variations in sales. Such short-cycle production necessarily requires methods like modular or UPS assembly rather than the lengthy progressive bundle system. At the same time, it requires an ability to use incoming information on sales in a sophisticated manner to allocate production in this way.
In a related vein, the future of domestic producers also relies on their development of capabilities for supplying fashion products on a replenishment basis. Once again, this requires a combination of practices; by using advanced forecasting methods and innovative production techniques, apparel-makers may be able to respond in very short periods of time to point-of-sale information regarding sale of products with higher fashion content. In addition, as we discussed in Chapter 8, suppliers attempting mass customization of apparel products such as jeans will need similar capabilities.
The Textile Industry Horizon
Textile markets in the United States no longer depend primarily on apparel as they did in the past. Currently, no more than approximately 35 percent of textile shipments are for apparel items. Textile firms now furnish a range of household products (such as sheets, bedding, towels, and rugs) and some knit products (T-shirts) directly to retailers. Such channels have adopted the information-integration described earlier as textile products have been upgraded from greige goods in a brokers’ market to those that involve complex finishing operations and extensive product proliferation. A number of integrated channels have therefore been developed among textiles, retailers, and their customers.
Significant markets have also grown for industrial textiles in a wide range of industrial enterprises, such as automobile interiors and tire cord. The range of industrial products is expanding, including knapsacks, tea bags, tents, fishing nets, hammocks, air bags, and parachutes. Even if textile products flowing to apparel sewn in this country (or in Mexico and the Caribbean Basin, where contractors assemble garments using U.S. textiles) decline, it is realistic to assume that some U.S. textile exports will increase in the near term and that there will be substantial increases in domestic industrial markets.
Still, at least one feature of textile markets warrants attention in their relations to apparel. The size of many orders preferred by the apparel industry is considerably smaller than that preferred by textile firms. Apparel-makers confront frequent changes in styles and new SKUs, while textile manufacturers seek long runs to keep capacity operating round-the-clock. In the retail-apparel-textile channels, there is a need for an information-sharing integrated system—some form of packager—to assist in ameliorating these differences. Once again, the development of Web sites to undertake some of these connections represents an important first step in this direction.
The Future of Information-Integrated Channels
As we have stated throughout, textiles and apparel remain significant sectors of the U.S. economy. In 1997, together they provided more than 1.4 million jobs, and in 2006 they are projected to have combined employment of over 1.3 million—nearly 8 percent of all projected jobs in manufacturing. These sectors are far too vital to their communities and the country, and have proven sufficiently vibrant, to be dismissed by the conventional doctrine of comparative labor costs.
Indeed, rather than turning the future more bleak, the introduction and the widespread adoption of lean retailing by all participants in the retail-apparel-textile channel provides new opportunities for the textile and apparel industries, at least in some segments. We see a viable future for these industries—with a few caveats. These revived opportunities do not apply with equal effect to all branches of apparel or all parts of the fashion triangle. Garments amenable to rapid replenishment principles have the most potential for U.S. production.
Our less pessimistic view of the future of these industries should not be misinterpreted. The textile sector appears more promising because it has become more directly connected to retailers and industrial users. Yet survival in both sectors belongs only to the fittest adopters of the new order of retailing and the channel. Employment levels are not projected to turn around. Instead, employment will gradually decline in both industries, while output and productivity increase—the best that any industrial sector can expect over time in the modern economy. The new order in apparel places more of a premium on scale and size, along with investments in the requisite technologies. The traditional contractor shop and small enterprise will have a smaller and even less secure role unless linked to sophisticated intermediary agents in the channel.
In short, the paths these industries follow will be determined by their interconnection with one another. Providing a stitch—or a package of pasta, a home computer, an automobile—in time requires a growing degree of integration among business enterprises within and across industries. Whether it is Federated Department Stores’ or Home Depot’s use of point-of-sales information for inventory control; Levi Strauss’s or Black and Decker’s efforts at customizing products to suit very specific consumer groups; or VF’s or Dell Computer’s innovations to provide product diversity more efficiently, channel integration is driving the current industrial transformation—and will continue to do so in the period ahead.









The beauty of automatic replenishment is that the buyer is really the customer. She is telling us what she wants and needs in the future. Quite frankly, of all the buying we do, letting our customer make the choice seems to make the most sense.
—Tom Cole, Chairman and CEO, Federated Logistics and Operations
Our goal is to replace the product on the retail shelf as quickly as possible, because that’s where the consumer buys it.
—Jeff Kernodle, Vice President for Replenishment, VF Corp
Many of the popular accounts of quick response, rapid replenishment, and supply-chain management assume that all parties—consumers, retailers, and suppliers—win as a result of these policies. Consumers have definitely benefited because these practices afford them a greater choice of products at lower average prices.1 It is safe to say that lean retailers have also come out ahead, given their rapid growth in relation to, and at the expense of, traditional retailers in many different retail channels. But have suppliers benefited from entering into relations with lean retailers? Have such firms improved their competitive position along with the retailers they supply?
The short answer to these questions is “It depends.” Although it is certainly true that a supplier gains from successful customers, the degree to which such a company actually benefits has much to do with its internal manufacturing choices. A supplier that has done little to change its internal practices may end up simply “holding the bag” of a retailer’s inventory. Alternatively, an adept supplier who uses information for planning, production, and distribution may well share in the competitive advantages derived from better information on the true state of final customer demand.
This chapter examines the reasons that different suppliers win and lose, reviewing many of the innovations we have discussed throughout.2 Drawing on the HCTAR survey, we first look at the way apparel suppliers adopt combinations of information and manufacturing practices in response to lean retailing.3 We then show how supplier performance, ranging from the degree of inventory risk to profitability, is changed by their information technology investments and the sequence in which they are adopted. The chapter concludes with a more general discussion of what suppliers in information-integrated channels must do to succeed.
Clusters of Supplier Practices: One Innovation Is Not Enough
Lean retailing allows department stores, mass merchandisers, and other retail outlets to capitalize on information, allowing them to minimize their exposure to demand uncertainty. Retail adoption of these strategies, in turn, means suppliers must invest in a basic set of technologies to provide the information links necessary for rapid replenishment. These investments consist of the capacity to receive and transmit information electronically—the minimum set of practices required for working with lean retailers.
In addition, apparel suppliers must invest in technology and capital improvements to package, label, route, and move products rapidly from their production operations directly to the retailer. Once again, these capital expenditures represent a basic cost of doing business in a lean world. As detailed in Chapter 5, our research indicates that the prevalence of information technologies, advanced distribution and logistics operations, along with the other related services apparel suppliers provide to retailers have grown dramatically since 1988, particularly among business units that supply a large percentage of lean retailers.
Last but not least, responding to lean retailing requirements ultimately necessitates much more sophisticated demand forecasting, production planning, and manufacturing strategies than the practices employed by traditional suppliers. At one extreme, a manufacturer can simply hold inventory for lean retailers and make few changes in its internal practices. At the other end of the spectrum, a manufacturer can alter its internal design, planning, procurement, and manufacturing operations and respond rapidly to demand changes through the use of flexible manufacturing or sourcing practices.
Determining the degree to which a supplier benefits from its technological investments is the real issue. Although there are no easy formulas, it does appear that the specific combinations of information technology and assembly methods drawn on by the supplier make a difference in responding to lean retail requirements. In order to study performance we must first examine how different manufacturing practices fit together for suppliers. In this section, we will discuss the interaction of four information and manufacturing practices related to apparel suppliers’ ability to provide products in a lean retailing world. These key practices affect how apparel suppliers acquire and use information concerning demand at the SKU level.
Note that the information and manufacturing practices examined here are not specific to the apparel industry—in fact, most were originally introduced in other sectors—but are applicable to a wide variety of consumer product industries. We focus on the retail-apparel channel because HCTAR’s surveys provide extensive evidence for the ways in which apparel suppliers are changing. Even if suppliers in other businesses will not make the specific operational changes of an apparel-maker, an increasing number are establishing information links with other channel players and combining information use with technologies and work practices to speed up order processing. For example, textile firms that supply retailers directly with their own products may have to combine equivalent information technologies with manufacturing innovations in finishing lines that shorten production cycles in order to gain competitive advantage. Much of what we have learned about the determinants of success for apparel suppliers can be applied to comparable situations faced by businesses in other retail-driven industries.
Key Practice 1: Bar Codes
The adoption of the Uniform Product Code (UPC) provides unique, optically scannable bar codes for identifying products at the SKU level. The availability of a standardized system of classification gives companies the means to input, store, transmit, and access information concerning demand inexpensively. Use of the UPC bar code system has the potential for significantly decreasing transaction costs with customers. Adopting bar codes, of course, requires a variety of technological investments by business units—in bar code readers and writers, hand scanners, computer hardware and software—and conventions, such as those promulgated by the Uniform Product Council. Even so, use of bar codes has become the norm for apparel-makers and retailers; to date, few channel partners have failed to make this change.
Key Practice 2: Electronic Data Interchange
The second basic practice involves the use of electronic data interchange (EDI) as a means for transmitting data on orders between apparel suppliers and retailers. Like bar codes, the use of EDI requires a set of investments by suppliers and customers in computer technologies capable of sending and receiving data rapidly. It also depends on conventions that standardize the system of data interchange, including payment mechanisms. While many channel players have adopted EDI, it also represents an area of evolving practice; the amount of information that can be transmitted between retailers and suppliers has grown at the same time that the costs of transmission have fallen.
Key Practice 3: Standard Labeling of Shipping Containers
Marking cartons and containers for shipment according to channel-wide standards can speed up distribution. Modern distribution centers are capable of rapidly identifying and sorting incoming shipments from all suppliers—whether apparel-makers, textile producers, or grocery manufacturers—through the use of scanning systems, automated sorting and conveyer systems, and computer controls. At the same time, these systems use the information on container labels to process and reconcile invoice information on incoming and outgoing shipments. This means incoming shipments must adhere to a set of technological and process standards regarding the use of bar codes for labeling cartons in addition to other standards for packing, labeling, placement, shipping, and display of products.
Key Practice 4: Modular Assembly
Finally, apparel manufacturers can make innovations in the assembly stage through modular, or team-based, production. Instead of breaking up sewing into a long series of small steps, modular production entails grouping tasks and assigning them to a team to reduce the elapsed throughput time required for assembling a given product. Adoption of this assembly technique involves altering the physical layout of sewing machines as well as human resource changes in training requirements, compensation systems, and methods of supervision. As Chapter 7 stressed, modular production need not be adopted for all assembly; it makes most sense for products that require rapid replenishment, where the capacity to engage in short-cycle production matters. In particular, retaining some short-cycle capacity may be advantageous for production of SKUs with higher levels of demand variation, whether because of fashion content or uncommon size—that is, for garments that have unique design elements or are in a size few consumers wear.4
Combining Key Practices
Firms responding to frequent purchase-order requests from retailers benefit from combining these practices.5 At the simplest level, the benefits of adopting a uniform system of production identification are reinforced by the presence of EDI transmission of information, which lowers the cost of moving data between channel partners. Business units adopting both bar codes and EDI are therefore able to reduce the transaction costs for processing information about sales and orders.
When bar codes and EDI are combined with advanced shipping practices, the benefit of each practice is enhanced; order processing occurs more rapidly, accurately, and with less paper. The standardized shipping container marker—which is possible only because of the existence of bar codes in the first place—provides a scannable description of a carton that can be electronically associated with data files containing specific information on the individual products shipped to the retailer. This information, sent via EDI, can then be used to check incoming orders against purchase orders and authorize payments to suppliers. It can also rapidly identify discrepancies between invoices and actual shipments, once again lowering the cost of the transaction for both parties.
Meanwhile, modular production allows apparel suppliers to reduce the time required for a given product to move through the assembly process. For instance, by substantially reducing work-in-process buffers in assembly, throughput time on the modular lines of business units in the HCTAR sample dropped to just two days, compared with nine days for standard assembly methods. But the benefits of throughput-time reduction cannot be fully realized unless firms are rewarded for their ability to replenish rapidly. Rapid replenishment, in turn, requires the availability of detailed demand data and its frequent and accurate transmission. Finally, suppliers must be capable of using this data to allocate production capacity between short-cycle (modular) and standard (progressive bundle system) production lines. In this way, modular assembly systems only yield real advantages in the presence of the other three practices.
In particular, advanced practices in distribution and modular production interact with each other because they both reduce throughput time. The time saved in production can be lost if the distribution method is slow, or if there are other impediments to the movement of products from the apparel-maker to the retailer. Alternatively, distri-bution operations that efficiently process finished products reinforce the benefits of a team-based assembly system. One extreme case illustrates the importance of fit between these performance elements. A men’s trousers manufacturer in the early 1990s invested in modular production in some of its lines to reduce throughput times. Yet it left its distribution practices unchanged. The plant required that trucks be filled before making deliveries, which often meant two weeks of production would build up. In other words, the savings created in throughput reduction in assembly were lost on the shipping dock.
What Clustering Looks Like in the Real World
According to the HCTAR survey, apparel suppliers do seem to invest in clusters of practices arising from the joint benefits of adoption. Table 14.1 shows that combinations of practices increased quite dramatically between 1988 and 1992.
For example, in 1988, joint adoption of bar codes and EDI systems was uncommon: Only 25.2 percent of business units had adopted both, while 46.8 percent had adopted neither. By 1992, three-quarters of the business units had implemented both bar codes and EDI technologies, while only 8.0 percent had neither in place. Similar patterns of increased adoption can be seen among other combinations of these practices in Table 14.1.
The mere fact that two practices have been adopted, however, does not tell the whole story. The changing organization of the retail and apparel industries also suggests that there is a particular sequence for adopting the four key practices. To begin with, the adoption of bar codes came before rapid replenishment arrangements because retailers required a low-cost means of collecting information at the detailed product level for their own use—that is, they first developed an efficient method for scanning prices at the check-out register and tracking products for internal inventory purposes. Only after a common convention for bar codes had been established and in use for several years did retailers turn to such systems to transmit and receive data from suppliers.
Indeed, the use of bar codes, followed by implementation of EDI systems, provides the basic foundation for subsequent investments in efficient logistics management in retail distribution centers. Retailers do not get much out of investing in advanced distribution technologies, such as shipping container markers, if they lack a means for electronically identifying and using information concerning the contents of incoming shipments or of connecting that information back to suppliers for invoicing purposes. And suppliers get little return out of providing customers with standardized shipping container markers if neither of these channel players has made previous investments in bar codes and EDI.
As we detailed in Chapter 10, changing the method of production to reduce manufacturing throughput times also makes little sense if a business unit has not first invested in the necessary information links for carrying on rapid replenishment relationships. From an apparel supplier’s perspective, the benefits of adopting shipping container markers and modular production are much higher once bar codes and EDI are in place.
In fact, our analysis of the HCTAR data shows that the probability of adopting shipping container markers and modular production significantly increases if both bar codes and EDI have already been implemented.6 The probability of adopting shipping container markers in 1992, given that bar codes and EDI had been adopted in 1988, was 77 percent compared with only 47 percent if bar codes and EDI were not both present. Similarly, the probability of adopting modular systems in 1992 was 54 percent compared with 30 percent if bar codes and EDI were not both present.7
From Supplier Practice to Performance Results
Once these manufacturing and information practices have been adopted, it should come as no surprise that they affect the performance of business units. Based on our survey research, we found that implementing a combination of the four key practices—bar codes, EDI, advanced shipping systems, and modular assembly—increases business-unit performance because these practices interact with and reinforce one another. This is sometimes described as “complementarities” between practices. The specific sequence of adoption should also affect performance outcomes.
Two types of performance measures are of interest in this regard. The first pertains to operational performance, or the ability of a supplier to respond to lean retailing replenishment requirements. Successful performance includes providing high levels of order completeness, short lead times for new products, and rapid response to requests for replenishment. However, operational performance measures do not necessarily provide a direct financial return to the supplier beyond allowing that firm to continue supplying a retailer with these service requirements. A second set of outcomes relates to the financial performance of the business unit itself. These include impacts on its revenues (prices and sales), cost structures, and profitability. Financial performance encompasses the impact of the supplier’s manufacturing investments on its inventory levels, which directly affects the business unit’s costs and the degree of risk it bears from holding high finished goods or work-in-process inventories.
From the perspective of operational performance, two business units with different degrees of investment in the four practices may do equally well in the short run. But their financial performance, as measured by inventory levels or profitability, may differ substantially. As we have emphasized in earlier chapters, an apparel manufacturer that meets a lean retailer’s replenishment requirements while optimizing the level of inventories it holds per SKU will be exposed to less risk than one that meets retailer requirements by simply holding larger stocks of inventories.
Retail Replenishment Performance
Lean retailers now have much higher standards than they did in earlier years for the accuracy and timeliness of order fulfillment. Our studies of business units with differing levels of the four practices indicate that firms with the complete set of practices achieve similar or slightly better performance in regard to the percentage of goods delivered complete and on time, although these differences between business units are not very dramatic.8 This is to be expected, given the high penalties faced by suppliers for violation of these standards,9 and the fact that retail standards may be met without extensive changes to internal apparel production practices.
In contrast, more innovative business units—those that have adopted three or four of the key practices—are able to replenish products more rapidly than less innovative ones. We have observed this in a number of different ways. In 1992, the mean response time for replenishing products that the supplier had agreed to provide on this basis was 2.9 weeks among those business units that had adopted none of the four practices. But the average replenishment interval was only 1.3 weeks for those that had adopted all the key practices. These performance differences persist even after controlling for other characteristics of business units, such as size and product mix, which might also be associated with replenishment speed and technology adoption.10 The results are particularly striking, given that only the most demanding lean retailers in 1992 required replenishment within two weeks of order placement.
Lead times provide another measure of supplier responsiveness. Lead time is calculated as the number of days required for an apparel manufacturer to procure textiles, manufacture, and deliver a typical product in its collection. The total time includes the number of days it takes a supplier to order and receive fabric, make the marker, cut the fabric, sew the pieces, press and package the product, ship it to a distribution center, and, finally, process it at the center. The shorter the lead time, the more quickly a firm is able to deliver products to retail customers. Based on our 1992 survey, we estimated lead times for two different scenarios: “standard” lead times that represent performance for a typical product in the supplier’s selection and “shortest” lead times that indicate a supplier’s best practice. Both measures were for products manufactured domestically.
As shown in Figure 14.1, those business units that invested in a more complete set of innovative practices had significantly shorter lead times for standard products. The total elapsed standard lead time for business units with little innovation in practice averaged 172 calendar days compared with only 117 days for those that had invested in bar codes and EDI. Even more striking, lead time dropped to just 66 days among those units that had adopted all four practices.
Figure 14.1 suggests that the most innovative firms are able to produce and deliver their products in less than half the time of the least innovative apparel suppliers. Of course, other firm characteristics, such as business-unit size or product type, might also be correlated with adoption of innovative practices and performance outcomes. Even after we control for these factors using multiple regression techniques, the number of innovative practices adopted by business units have a statistically significant positive effect on lead time.11
Inventory Performance
Throughout, we have argued that reducing the substantial risk presented by inventory, particularly in the presence of ever-increasing product proliferation, is essential for improving a manufacturer’s performance in integrated retail-apparel-textile channels. That means inventory performance measures are crucial to determining the impact of information technology and flexible manufacturing. In this case, we draw on a unique, matched data set that combines the HCTAR sample results with detailed microdata collected by the U.S. Department of Commerce.12
Specifically, we matched data from the HCTAR survey to corresponding establishment-level data from the Department of Commerce’s Longitudinal Research Database (LRD). The LRD provides longitudinal data for establishments included in the Bureau of the Census Annual Survey of Manufacturing.13 To understand the relationship between technology adoption and inventory levels, we matched survey data on adoption decisions in 1988 with inventory observations for the 1988–91 period and adoption decisions in 1992 with inventory observations for the 1992–94 period.
One common way of measuring inventory is to calculate the I/S ratio—that is, the ratio of total finished good inventories to total sales. This measure allows one to compare inventories in firms with different sales volumes. We calculated the I/S ratio for suppliers in our matched sample and then compared those with the ratios of suppliers that used different combinations of the four manufacturing practices. Figure 14.2 illustrates the impact of manufacturing practices on average inventory levels.
The average I/S ratio fell considerably as business units adopted more of the four key technologies during both time periods under study. In the 1988–91 period, firms that adopted none of the four technologies had an average I/S ratio of 1.9, while those that implemented bar codes, EDI, and either advanced shipping container markers or modular assembly—or both—had an average I/S ratio of only 1.1.14 What is more, these differences between low- and high-level adopters grew dramatically by the 1992–94 period, in which the low-technology firms had more than twice the inventory/sales ratio—2.46 compared with just 1.22 for the high-level adopters.15
A reduction in the I/S ratio means that changes in sales will be matched by smaller changes in inventories. Therefore, a lower I/S ratio implies lower inventory volatility or variation.16 This, in turn, suggests that firms with more of the key technologies in place will have total inventories that are less volatile. One method of capturing volatility is to look at the standard deviation of each establishment’s inventory level and I/S ratio for the two time periods.17 Based on this measure, inventory volatility did not decrease with more technology adoption between 1988 and 1991. However, by the 1992–94 period, firms with all four technologies had lower standard deviations in total inventories compared with less technically innovative ones.This impact on volatility is even more striking when examining variation in I/S ratios for the 1992–1994 period (see Figure 14.3): Standard deviations in the I/S ratio of business units with low levels of adoption were 1.22 compared with only .50 for the suppliers that had implemented all the manufacturing practices by 1992. Note that the I/S standard deviations control for differences in firm size. And these results remain even after controlling for other factors, such as product diversity, that may be related to both inventories and the adoption of modern manufacturing practices by suppliers.18
Adopting more of these practices also decreases the growth of inventory levels. Figure 14.4 shows the comparative growth rates in inventories from 1992 to 1994 for business units with low, medium, and high technology levels. Adjusting for inflation and other factors that affect inventory growth, we found that establishments with low levels of technology adoption in 1992 experienced far higher annual growth rates in total inventories and I/S ratios than those with a more complete set of innovative practices. This confirms the fact that apparel suppliers investing in both information technology and short-cycle production capacity can move to lower inventory levels more quickly.19
The implications of these findings are significant. A supplier attempting to meet the rigorous standards of a lean retailer—whether a shirt manufacturer for Wal-Mart, a pasta-maker for Ralph’s Food, or an electronic drill supplier for Home Depot—must hold a far larger amount of inventory if it has not invested in a comprehensive set of information technology and short-cycle production capacity. As the next section demonstrates, holding larger inventories to service lean retailing demand translates into diminished profitability.
Impact on Profitability
Imagine two men’s dress-shirt suppliers. One still operates traditionally, except for the implementation of basic information links to receive orders from lean retailers. The other maintains extensive information systems, which allow it to send, receive, and process information on retail demand, orders, and shipments; advanced information technology also helps it plan manufacturing capacity so that the firm can engage in short-cycle production. Although the first shirt supplier can respond to retailers’ weekly orders in a timely manner, its costs for doing so are high, both in terms of the internal expense of transacting frequent orders and its increased exposure to the risk posed by holding inventory. It costs the second supplier less, however, to transact weekly business with retailers because of the electronic systems it has in place. In addition, its capacity to use information on the state of demand allows it to set inventory levels on a SKU basis that balances the benefits of having a product available against the costs of holding work-in-process and finished goods inventories.
As a result of these differences, we expect that the second dress-shirt supplier’s financial performance will be decidedly better than that of the first over the long run. Our survey evidence confirms this expectation. Consider the frequency with which suppliers reduce the price of their product for retailers during the selling season. Apparel suppliers in our survey that had adopted all four of the key information and manufacturing practices reported fewer price markdowns by retailers than those with few or none of the practices.20 Therefore, retailers that work with suppliers employing a more complete set of information, distribution, and manufacturing innovations need not eliminate as many of their unsold products at the end of season via price reductions.
Manufacturing markdowns to retailers provide more direct evidence of the benefits of these innovative practices. Those business units that had adopted all the practices reported an average discount provided to retail customers of just 4.3 percent, compared with an average discount of 22.2 percent among suppliers that had implemented none of them. Although these differences cannot all be directly attributed to the adoption of the practices per se, they do suggest—especially when combined with the significant inventory performance results reported previously—how important it is for manufacturers to be adept at using incoming information from lean retailing customers.21
The real question, then, is how do these factors together affect the bottom line? And do business units with the more complete set of innovative technologies have higher profitability? Here the answer is a definite yes. Profitability is measured as operating profit margin—revenue minus costs of goods sold divided by revenue. Figure 14.5 shows our basic results in regard to average profit margin for different levels of technology adoption. Business units that did not adopt any of the four key practices earned the lowest profit margins, about 3 percent in 1992. The most innovative firms were approximately four times as profitable, achieving average profit margins of 11.7 percent.
Even after controlling for the independent effects of firm size, product mix, and distribution channel on performance, we found that the most innovative firms were significantly more profitable than those that had adopted fewer of the key practices. In our sample, adding shipping-container markers to established bar code and EDI practices increased operating profits by 2.2 percent—that is, from about 6.2 percent in average profit margins to 8.4 percent; adding some modular assembly capacity to these three practices increased operating profits by about the same amount.22
Since HCTAR’s 1992 survey, informal case evidence suggests that these disparities in operating and financial performance have only grown larger, as lean retailing continues to sweep across distribution channels. The least innovative apparel suppliers are seeing their chances for survival dwindle every year. In contrast, suppliers that have continued to innovate and expand their use of the four practices, as well as other activities described in previous chapters, keep outperforming the industry as a whole.
Management Practice: The Final Ingredient in Enhanced Performance
The upshot of all this is that manufacturers need not hold the bag for lean retailers if they adopt a set of technologies and practices that allow them to collect and process demand information, incorporate it into planning, and use traditional and short-cycle production strategically. Simply doing business with lean retailers in no way confers competitive success. In fact, a supplier that attempts to provide rapid replenishment without any other innovations may end up performing poorly from the perspective of its retail customers. More important, it will sustain higher costs in inventories, face a greater need to mark down the prices of its products, and therefore earn a lower profit margin than those establishments that have invested in comprehensive changes.
Of course, becoming an advanced manufacturer is not just a matter of buying more information technologies or setting up a short-cycle assembly line. The essential force behind the performance impact of these practices is their effective integration with one another. Integration does not arise from hardware or software purchases. It comes from successful management.
We have already described some specific ways that managers can think about integration of new information technologies and manufacturing practices. Chapter 7 presented two production planning cases. The first indicated how managers must assess a product line according to the variance in demand for particular SKUs in setting inventory policies. The second case developed how suppliers must use this new perspective on demand to plan production or sourcing strategies. Both cases illustrate the necessity of creating managerial practices that explicitly link the data arising from information technology with changes in manufacturing practices to take full advantage of these innovations.
A contemporary apparel-maker, handling on average 15,000 SKUs in its collection, faces the challenge of replenishing weekly numerous retail customers at high satisfaction levels with a constantly shifting subset of its goods. Managers of such a firm must do so by drawing on information from the past weeks’ sales as well as explicitly factoring in the impact of uncertainty. They need real-time information regarding what goods their plants have in finished, work-in-process, and material inventories. They must know the lead-time requirements for procuring textile products and establish relationships with at least some textile suppliers that allow the apparel-maker to procure fabric in smaller quantities and with shorter lead times. This supplier must draw on production lines and sourcing arrangements that provide it with a range of response times, from short-cycle production capacity for products with high demand variability to lines or sourcing arrangements that create larger production runs at lower costs for items with low demand variability. But most important, it must have a managerial system capable of coordinating these elements on an ongoing basis.
Based on our observations of apparel suppliers, coming up with the money for new technologies and practices seems to be less of an impediment than altering basic management conceptions about using these technologies for planning and production. Many of the business units in our sample have adopted specific practices without changing their approach to using them together to compete in an integrated channel. They continue to draw on traditional conceptions of planning, production, and sourcing—in other words, they still think in terms of large orders of their products, placed months before delivery is expected. Needless to say, these business units have not fully benefited from the investments they have made.
Suppliers in most consumer industries now face lean retailing pressures or its equivalent. Many are taking steps to adapt to the changed requirements placed on them. One example is the restructuring beginning to appear in automobile distribution. Traditional auto retailing focuses on selling product lines in production quantities that were largely determined in advance of distribution. The system therefore placed tremendous pressure on auto dealers to sell the enormous finished goods inventory found in a car lot. In contrast to this traditional retailing model, BMW announced in 1997 an effort to restructure its U.S. dealers by allowing consumer customization of car purchases through the use of multimedia computer systems. By allowing customers to design their own cars, BMW dealers hope to reduce their finished goods inventories.23
Note that this system poses production questions for BMW similar to those faced by apparel suppliers. The company will need to decide which auto SKU (or subassemblies) to produce using traditional assembly techniques and which to produce with short-cycle production methods. BMW will also need to combine information technologies, planning and forecasting methods, and production techniques to implement such strategies.24 Similar pressure to innovate automobile distri-bution and production is also increasing because of the emergence of new retailers like Car Max Auto Superstores and the United Auto Group, which operate under principles more akin to lean retailing.25
Two examples from the computer industry further illustrate supplier approaches that integrate information technology and manufacturing decisions. In the early 1990s, facing product proliferation and replenishment requirements for its laser-jet printing products, Hewlett Packard redesigned its manufacturing process for printers. It did so by separating those subassembly processes that were standard across products from those that were distinctive to specific laser-jet products. By using incoming demand information in concert with this subassembly and assembly redesign, Hewlett Packard can now assemble different products with shorter lead times in response to actual information concerning demand; at the same time it continues to take advantage of scale efficiencies in production. The resulting inventory and production policies allow Hewlett Packard to balance the costs of stock-outs with those of unsold inventories.26
In 1997, Compaq Computer, the world’s largest producer of personal computers, announced a plan to change relations with its distributors. Compaq’s main competitors, Dell Computer and Gateway 2000, sell directly to consumers through mail-order and Internet operations. In contrast, Compaq sells its products through computer dealers. Technological advances and rapid diffusion of older technologies make personal computers extremely perishable—much like apparel with a fashion content—and subject to almost constant price markdown pressure. Because Compaq, like other personal computer manufacturers, provides its distributors price guarantees on purchased inventories (i.e., it reimburses the distributor if it must mark down prices in response to falling memory or other costs), its inventory carrying costs are significant.
Rather than continuing to increase inventory, Compaq announced that it would only assemble its new line of personal computers as its retail customers ordered them. And, instead of providing an open-ended guarantee on prices to its distributors, the company would guarantee the price for only two weeks after purchase by the distributor, refusing to take back computers unless they malfunctioned. By changing its method of distributing products, Compaq hopes to reduce the level of dealer inventory across product lines to two weeks’ worth and in the process save $1 billion or more a year. These cost savings will be used to reduce prices and compete more aggressively with Dell and Gateway 2000 that do not work through distributors.27 Therefore, Compaq’s competitive strategy arises from its efforts to advance information-integration forward in the channels in which it operates.28 Note also that if Compaq seeks to take full advantage of these changes in distribution, it must also adjust its production strategies to account for differences in demand variability across the computer maker’s product lines.
In fact, companies in myriad sectors are grappling with the same managerial challenges and opportunities of those in the American apparel and textile industries. Rethinking how to service stringent retail replenishment requirements for ever broadening product lines in more selling seasons has become a central business challenge.
The implications of these changes do not end here. An economy consisting of lean retailing and corresponding “lean” suppliers operates in a fundamentally different manner from one based on traditional retailing and supply practices. The industrial transformation currently in progress encompasses international trade issues, competitiveness, labor regulation, and macroeconomic policies. Accordingly, the last chapter of this book is devoted to our reflections on the impact of channel integration on certain public policy issues.









In the late 1940s, Bond Stores, the largest men’s clothing chain at the time, created a sensation in New York City by offering a wide selection of suits with two pairs of pants instead of one, reintroducing a level of product choice not seen since before the war.1 When the line of hopeful buyers at its Times Square store stretched around the block, Bond had to impose a limit of two suits per customer. During World War II, the apparel and textile industries had been converted to supply field jackets, overcoats, and uniforms to the U.S. and Allied Forces. But in the years immediately following the war, returning soldiers, the end of rationing, and pent-up customer demand meant apparel was in short supply.
Fifty years later, it is hard to imagine a retailer—be it a high-end department store, mass merchandiser, or catalog service—limiting an individual customer’s clothing purchase. Retailers collect detailed point-of-sales information that reflects the real-time demand for goods by consumers. Through new computer systems, they share this information with suppliers who, in turn, can ship orders within days to automated distribution centers. The contemporary equivalent of Bond Stores now has a much better chance of avoiding stock-outs of popular items and the inventory gluts that lead to costly markdowns. By the same token, the overall risk associated with fickle consumers, numerous selling seasons, and segmented markets—along with fierce overseas competition—has currently made this a tough arena for American retailers and manufacturers.
The most surprising aspect of this story is that today’s U.S. apparel and textile industries—left for dead by business commentators and economic analysts in the 1980s—have begun to transform themselves, reaping new competitive advantages. Although Bond Stores’ customers were thrilled by a suit with two pairs of pants, contemporary customers want and expect a huge range of choices, and the consumer desire for limitless variety has kept the American apparel industry alive. In 1995, for instance, American consumers purchased 28.7 outerwear garments (all coats, jackets, shirts, dresses, blouses, sweaters, trousers, slacks, and shorts) per capita; in China the estimated number of such garments was only 2 per capita.2
The transformation of U.S. clothing and textile manufacturing is very much still in progress and has by no means been successful for every company; but these industries have entered a renaissance of sorts, one that reflects new information technologies and management practices as well as the new economics of international trade. This book describes what has happened since the postwar era in three related industries—retail, apparel, and textiles—and what such companies must do to improve performance. We cover the histories of these industries, including the information technologies that have transformed these enterprises, manufacturing processes, inventory management, the new role of logistics, and global trade implications and policies.
The story is a complex one, involving many individual cases and specifics. This study began with a focus on apparel manufacturing, but we soon concluded that apparel production must be viewed as an integral part of a channel. A channel is the set of all firms and relationships that get a product to market, including the original acquisition of raw materials; production of the item at a manufacturing facility; distribution to a retailer; sale of the finished item to the customer; and any installation, repair, or service activities that follow the sale.
A retail-apparel-textile channel typically includes the companies that manufacture synthetic fibers; produce, gather, and refine natural fibers; spin fiber into yarn; weave or knit yarn into fabric; manufacture buttons, zippers, and other garment components; and cut and sew fabric into garments. It also includes the retailers who sell garments to end consumers. The retail link often involves services or instructions to suppliers about fabric and garment design, packaging, distribution, order fulfillment, and transportation. And it is in some of these areas, particularly distribution and order fulfillment, that channel dynamics have undergone substantial change during the last decade.
Supply channels are not new, of course; for centuries, fabric-makers have sold their wares to those who cut and sew garments. But, until recently, most channels in the textile and apparel industries have been characterized by arm’s-length relationships among relatively autonomous firms. It is only since the mid-1980s that a number of market and technological changes have encouraged companies to enhance the links among different stages of production and distribution. Indeed, retailers like Wal-Mart Stores, Kmart Corporation, and Dillard’s Inc. have been the driving forces behind changes in manufacturing and logistics systems in a way that was unheard of in Bond Stores’ time. For instance, entrepreneur Sam Walton built a retail juggernaut that began with thirty-nine Wal-Mart stores in 1971 and grew to almost three thousand by 1996. He did so by insisting that suppliers implement information technologies for exchanging sales data, adopt standards for product labeling, and use modern methods of material handling that assured customers a variety of products at low prices.
We contend that this revolution in retailing practices will determine future competitive outcomes in retail-apparel-textile channels. These new practices—which we call lean retailing—have compelled apparel producers to reorganize the manner in which they relate to retail customers, undertake distribution, forecast and plan production, and manage their supplier relations. Lean retailing has also changed the way the textile industry relates to both apparel producers and retailers. Most important, because the apparel industry has been one of the first to face the full brunt of the retail revolution, its story illuminates pervasive changes under way in the entire economy.
In many respects, our findings defy the conventional wisdom. When we began our research, we were advised by American industry participants to establish better performance measures—for example, how many minutes does it take to make a shirt? The traditional view holds that because manufacturing performance is determined by the labor time required to produce an item, then what applies to cars, for example, can also apply to clothing; therefore, U.S. apparel manufacturers might be able to save themselves by improving assembly operations.3 Yet after years of studying hundreds of American apparel firms, we have found that direct labor content is not the primary issue. The companies that have adopted new information systems and management practices, participating in a well-integrated channel, are the ones with the strongest performance today—not those that have simply improved assembly operations.
The changes we examine in retailing are not only profound but rippling through a growing segment of the American economy. They have already transformed channel relations in such industries as food and grocery, home-building products, personal computers, and office products. The retail revolution is affecting the automobile, health care, and pharmaceutical industries as well. Now that manufacturers of power tools and ball bearings talk about their products as “fashion” items, the apparel industry—always subject to the whims of fashion—has much to say to any industry that involves retailing. Every channel has its particular history, elements, and dynamics, and retail-apparel-textile channels are no exception. A Stitch in Time uses the U.S. apparel story to highlight the transformation of retailing and manufacturing across the board.
Five Decades of Change
When Bond Stores had customers lining up around the block to buy suits, “casual wear,” as we know it today, did not exist. Even in the 1960s, men wore suits, ties, and hats to the ballpark, and women were clothed in dresses and millinery. As recently as 1969, the dress code at Harvard required undergraduate men to wear a collar, necktie, and jacket in the dining halls; women had to wear a dress or a skirt and blouse. It wasn’t until the 1970s that these vestiges of formality gave way to blue jeans and T-shirts—the casual wear uniform. The 1980s ushered in yuppie brands, and in the 1990s history repeated itself as baby boomers’ children adopted the bedraggled grunge look. Many business firms have “casual days” for office attire. Now six out of ten U.S. employers now have casual days in their workplaces, all but a few establishing this practice during the 1990s. About seven out of ten organizations with dress-down days permit employees to wear polo shirts, jeans, and sneakers.4
The U.S. apparel and textile industries, like the clothing and other products they produce, have undergone tremendous changes over the past half century. From 1950 to 1995, domestic production of apparel doubled, while textile production, less vulnerable to imports, increased almost three times.5 Yet since World War II, shifting tastes in clothes, rising real incomes, and domestic and foreign competition within the textile and apparel industries have markedly reduced the proportion of consumer budgets expended on apparel and its upkeep (laundry and dry cleaning). In December 1963, apparel’s share of the Consumer Price Index was 10.63 percent;6 by December 1995, that percentage had fallen to 5.52 percent of average household expenditures.7
Meanwhile, structural changes in the retail industry have influenced how and where clothing is sold. The growth of the highway system around central cities and the rapid expansion of suburbs created new opportunities for shopping centers, malls, and other outlets closer to a growing number of two wage-earner families. The metropolitan suburbs increased housing units in the 1950s through the 1980s far faster than the inner cities or the rural suburbs.8 Because inner cities retained a high proportion of lower income families, increased purchasing power for shelter, food, and clothing shifted to the suburbs. That means the large department stores traditionally based in cities, such as Macy’s or Marshall Field and Company—served by mass transportation and marketed through newspaper advertisements—suffered from the competition of mass distributors like Wal-Mart and specialty shops in new locations.
The enterprises that compose the apparel and textile industries manufacture a wide variety of products, and the mix has also changed since the postwar era. Over the past thirty-five years in the textile industry, the number of workers employed for carpet and rug production has doubled and is projected to expand further over the next decade. In the apparel industry, more than a quarter of all workers now produce nonclothing items like curtains, draperies, house furnishings, and automotive trimmings; once again, employment since the 1960s in these areas has doubled, while it has dropped off dramatically for actual garment-making.
These changes are related to new technology and foreign competition. Exhortations to buy the “union label” or “Made in the U.S.A.” have done relatively little to stem the tide of clothing assembled overseas. For example, the per capita number of outerwear garments purchased in the United States increased from 14.3 to 28.7 in the period from 1967 to 1995.9 Imports, however, provided half the total in 1995, leaving domestic production with only about the same per capita number of outerwear garments as three decades earlier10—all this, even though apparel and textiles in the United States have long been characterized by special import regulation. Tariffs on their imports have remained higher than many other manufactured goods. Since the 1960s, national policymakers have sought to moderate the growth of imports, primarily through agreements with other governments. The Multi-Fiber Arrangement (MFA), a network of bilateral agreements negotiated with participating nations which became effective in 1974, established quotas for imports largely related to estimates of the growth of the U.S. domestic market. The stated purpose of the MFA was to provide for the “orderly” growth of trade in these products among countries on a negotiated basis. Advocates emphasized that “textiles and apparel offer proportionately more jobs, including entry-level positions, to less well educated, more disadvantaged groups in the United States than most other sectors of the economy.”11
Yet with the signing of the agreements that grew out of the Uruguay Round of international trade negotiations that concluded in 1994, the MFA has now been replaced; textiles and apparel trade are to be integrated into the General Agreement on Tariffs and Trade (GATT) over a ten-year period that ends January 1, 2005. Many American industry participants and policymakers believe these changes could deal a fatal blow to the U.S. apparel industry, which will become even more exposed to global competition. The impact of these trade changes remains uncertain, and national policies that take them into account are still evolving. But if one did not consider the shift in retailing practices that is also recasting the apparel industry—and turned some American companies into unexpected leaders—it might indeed look like “Made in the U.S.A.” was a lost cause.
A Dying Industry—or Not?
For many commentators, a book about the future of the U.S. apparel and textile industries is still an oxymoron. The conventional wisdom paints a grim picture of where these industries are headed. Low-cost labor overseas and the increasing penetration of imports have certainly undercut American apparel manufacturers; apparel imports grew rapidly in most categories starting in the mid-1970s. If we measure import penetration in physical units (rather than dollar value),12 import penetration for men’s and boys’ suits, for example, went from just 10 percent in 1973 to 43 percent by 1996. A similar expansion in imports occurred for men’s and boys’ trousers, women’s and girls’ dresses, and women’s slacks and shorts.13
As one consequence, the number of business failures among U.S. apparel manufacturers climbed from 227 in 1975 to a high of 567 in 1993.14 Not surprisingly, employment in the apparel sector during this period declined appreciably. And the U.S. Bureau of Labor Statistics projects a further reduction in the domestic apparel industry during the period 1996 to 2006 from 864,000 workers to just 714,00015—this from an industry that employed about 1.2 million employees in 1950 and reached a peak of 1.4 million employees in 1973.16
The conventional wisdom explains the industry’s decline in this way: Apparel, particularly women’s apparel, is driven by price-based competition among generally small manufacturing and contracting establishments.17 Labor costs represent a significant portion of cost for many garment categories,18 and U.S. wage levels far exceed those of competitors in countries like the People’s Republic of China and Mexico.19 Although the magnitude of these differences varies as exchange rates fluctuate, under any realistic exchange-rate scenario, the labor cost differential is sufficiently high to put U.S. manufacturers at a very significant competitive disadvantage.
The manufacture of men’s shirts provides another illustration. Throughout much of the post-World War II era, the majority of men’s shirts sold in the United States were white dress shirts, primarily through department stores. Shirts with stripes, patterns, and uncommon colors constituted less than 30 percent of all dress shirts sold through the 1960s.20 In this environment, low fashion content and limited product variety made demand for individual shirts relatively predictable. Store buyers succeeded by striking deals with apparel manufacturers for large shipments of white shirts at the lowest possible price and with long delivery lead times. Unlike the women’s industry, where style has always mattered more, relatively large men’s apparel manufacturers such as Haggar; Hart, Schaffner, and Marx; Fruit of the Loom; Arrow Shirt Company; and Hathaway Shirt emerged, seeking to capture economies of scale.21
But hourly compensation levels have increasingly hurt U.S. apparel-makers, if performance is principally determined on a price/cost basis. For example, because of wage differentials between the countries, U.S. apparel-makers would need to be 2.5 times more productive than firms in Hong Kong to be “competitive.” As a result, U.S. shirt manufacturers lost enormous market share to offshore producers. And employment in men’s and boys’ shirts between 1972 and 1996 declined an average of 3 percent a year.22
There is just one problem with these accounts. Although the production of basic white dress shirts may lend itself to a price/cost analysis, this “staple” good, like many staple goods, now constitutes only a small proportion of all shirt production: by 1986, little more than 20 percent of men’s dress shirts were white.23 This one-time staple has been replaced by shirts of dizzying diversity in fabric, design, and style, providing the final consumer with a huge assortment of shirts while exposing retailers and manufacturers to increased risk of holding large volumes of unsold goods. Classical economic assumptions about market competition are not directly applicable in this situation, even in a “mature” industry like apparel.
As shown in later chapters, manufacturers that invest in advanced information technologies and use them to change their methods of planning and production can significantly reduce the amount of inventory they hold, thereby reducing the need to mark down or write off unsold products at the end of a season. These manufacturers also earn twice as much in profits than suppliers that continue to operate along traditional lines. Yet the distinguishing feature of such high performers is not their success in shaving off labor costs in the assembly room; it is their effort in changing basic aspects of the way they manage their enterprises.
Although it is true that the American apparel industry could have given up in the early 1990s, with only distribution centers and designers remaining in this country, it did not. Instead, manufacturers have developed, or have been compelled to develop, a competitive service for retailers; best practice American producers can now deliver orders with just a few days’ notice, something overseas suppliers have difficulty achieving. These U.S. firms do so through electronic data interchange (EDI), automated distribution centers, and sophisticated inventory management—a triumph of information technology, speed, and flexibility over low labor rates.
The Channel Perspective: Five Propositions
So what has changed the prognosis for American apparel and textiles and provided new opportunities for these industries? The answer is not to be found simply in the clout of a few retailers or the use of bar codes or EDI. To understand why the apparel industry is a prototype for others, we need to look at the underlying dynamics of demand and its impact on manufacturing practice. Consider once again the contemporary customer’s appetite for variety. Increased rates of product introduction, product proliferation, and shortened product cycles mean that companies have to respond much faster to rapidly changing markets.
For our purposes, we can represent growing product diversity in the form of a “fashion triangle” (Figure 1.1). Apparel items at the very top of this triangle include dresses from Paris, Milan, and New York runways, which represent a very small share of apparel sold. The majority of fashion products also have a short selling life—usually one season—but are produced for a broader market. At the triangle’s bottom are basic products that remain in a retailer’s or manufacturer’s collection for several years, such as men’s white dress shirts or underwear. Basics -historically constituted the majority of apparel products sold. In the middle of the triangle are fashion-basic products, typically variants on a basic item but containing some fashion element (such as stonewashed jeans or khaki pants with pleats or trim). This expanding center of the fashion triangle indicates where the industry is headed. Because a growing percentage of basic apparel items have some fashion content, fashion-basic products are driving product proliferation.
Product proliferation and shorter product cycles, reflected in ever-changing styles and product differentiation, contribute to general demand uncertainty for both retailers and manufacturers, thereby making demand forecasting and production planning harder every day. In a world where manufacturers must supply an increasing number of products with fashion elements, speed and flexibility are crucial capabilities for firms wrestling with product proliferation, whether they are retailers trying to offer a wide range of choices to consumers or manufacturers responding to retail demands for shipments.
To be sure, technological advances in communication and transportation have helped supply channels operate more effectively and efficiently in providing diverse goods. Although these changes have provided strong motivation for increased channel coordination, the development and implementation of key facilitating technologies—like bar codes, the later spread of EDI, and automated distribution centers—have been the real movers here. New channel relationships, in turn, have led to better performance, based on a variety of standards, and enhanced the competitiveness of many sectors of these U.S. industries.
Note that these significant technological, market, and environmental changes largely originated outside the apparel industry itself. As we will make clear, changes that emerge in a market economy in one sphere often have unforeseen consequences in others. Bar codes, for instance, began with the food and grocery industry in the 1970s to lower the labor costs of cashier work and avoid delays to customers.24 With the commercialization of the laser, automated checkout became more than an industry vision. A committee of CEOs from grocery manufacturers, food chain stores, and other companies met in 1970 to develop a “universal product code” for scanning purposes: the first five digits stand for the manufacturer and the last five identify the item at the stockkeeping unit (SKU) level.25 All the digits are represented in the now-familiar sequence of light and dark bars of differing widths. By 1975, bar codes had begun to spread throughout food chain stores and grocery manufacturers. But almost another decade passed before the practice was adopted by apparel retailers and manufacturers.
In later chapters about the retail revolution, inventory management, and apparel operations, we provide an in-depth look at how such new technologies have affected the related industries. For now, we present five propositions that arise from the channel perspective of this book. The conventional wisdom can no longer predict future industry dynamics or offer guideposts for private and public policies. The channel perspective, however, indicates why the demand uncertainty and risk associated with today’s apparel industry offer new opportunities for U.S. firms.
Proposition 1:  The retail, apparel, and textile sectors are increasingly linked as a channel through information and distribution relationships.
In conventional terms, these three sectors are considered distinct industries, separated by traditional market relationships. For example, arm’s-length transactions between retail buyers and apparel sellers determine prices and quantities of goods to be delivered. Apparel companies periodically made deliveries based on these contracts and the transaction was then completed. In such a world, coordination problems between the parties were of little concern.
But, as we have already emphasized, this is not the real world of apparel today. At its most fundamental level, the channel perspective reflects a revolution in retail practices. These practices have resulted in the integration of enterprises at all stages of the distribution and production chain, because of the infusion of real-time information on consumer sales. Instead of gearing planning and production decisions to forecasts and guesses made months in advance of a selling season, firms now receive periodic ongoing orders based on actual consumer expenditures. And companies in transformed retail-apparel-textile channels have established a complex web of computer hardware and software, other technologies, and managerial practices that have blurred the traditional boundaries between retailers and suppliers.
Proposition 2:  For apparel manufacturers, the key to success is no longer solely price competition but the ability to introduce sophisticated information links, forecasting capabilities, and management systems.
The conventional wisdom holds that the basis of competitive performance for apparel manufacturers is lowest price—period. According to Martin Feldstein, then chairman of President Reagan’s Council of Economic Advisers,
The labor intensive [U.S.] apparel market cannot and should not compete with much lower cost labor elsewhere. The stuff depends on somebody sitting at a sewing machine and stitching sleeves on; it is crazy to hurt American consumers by forcing them to buy that at $4 or $5 an hour of labor. We ought to be out of that business.26
Fortunately, clothing production today is more than a simple price/cost game. Successful apparel manufacturers must now focus on their capability to respond accurately and efficiently to the stringent demands placed on them by new retailing practices. This requires establishing systems to handle electronic, real-time orders, as well as creating management and information systems capable of using incoming information to forecast, plan, track production, and manufacture (or source) products in a flexible and efficient manner. Needless to say, these new skills were not part of the management arsenal of traditional apparel firms.
Yet our research indicates that apparel leaders are building these new skills. Analysis of detailed industry data demonstrates that there have been substantial increases in apparel suppliers’ investments in information technologies, distribution systems, and other associated services during the same period that new types of retailing practices emerged. In addition, we have found that those firms under greatest pressure by innovative retailers have been the most likely to make such investments, as well as to invest in innovations in other stages of manufacturing. Most important, apparel-makers that have invested in major innovations to collect and use information perform much better than those that have done little to innovate production beyond providing basic information links to retailers.
Proposition 3:  The assembly room—the traditional focus of attention for industry competitiveness—can provide competitive benefits only if other more fundamental changes in manufacturing practice have been introduced.
The inputs to garment production are relatively straightforward: fabric, thread, accessories like buttons and zippers, labor, and a modest level of capital investment. The majority of input costs are composed of materials and labor. For example, close to 50 percent of the value of shipments for men’s shirts comes from the cost of materials, while 25 percent arises from compensation costs.27 Reducing textile costs is a viable option for larger apparel manufacturers; they can exert some pressure on suppliers because of the size of their orders. Small manufacturers, however, have few such options. As a result, the conventional method of unit cost reduction revolves, once again, around reducing labor costs. Because the largest labor cost is concentrated in assembly phases, the focus of most productivity efforts has been in the sewing room.28
Garment assembly is typically done by “bundle” production, which entails breaking garment-making into a series of worksteps or operations. Each operation is assigned to a single worker, who receives a bundle of unfinished garment parts and undertakes her single operation on each item in the bundle. Completed bundles are then moved forward to the next operator in the production process. To foster productivity (physical output per worker) and constrain supervisory costs, wages are paid on a piece-rate basis, providing incentives for rapid completion of the operation.
Many industry participants have sought to improve assembly productivity, the holy grail for U.S. manufacturers. This generally involves modifications to improve the efficiency of the bundle system, using a variety of methods: “engineering” the assembly process to reduce direct labor requirements for each step, changing the incentive rate to encourage workers to increase their pace, or adopting new technologies to substitute for labor-intensive assembly steps. It is true that through ongoing refinement of apparel assembly processes American manufacturers have been able to achieve some continuous improvements in labor productivity. The International Trade Administration of the U.S. Department of Commerce expressed this view in 1990 that
The producer who hesitates to employ new strategies will not likely survive, as expected innovations in technology dramatically alter the nature of clothing manufacture. Garment-making in its current labor-intensive form will eventually be phased out in favor of automated, robotized manufacturing, geared for almost instantaneous transition from one style to another. The difficulty of handling cut fabrics by machines may be resolved in the near future, and the quest for higher operating speeds will then receive more attention, taking production levels to new heights.29
Yet here the conventional wisdom misses other significant measures of performance. Managers in well-integrated channels pay attention to inventory costs, inventory replenishment practices, information reliability, and time to market rather than the traditional direct costs of labor and materials alone. In fact, competitive performance is already being driven less by how a company manages its assembly operations and more by how it manages the logistics of its operations as a whole. Our study shows that an apparel manufacturer can still be successful with a traditionally organized sewing room; a firm with innovative and productive assembly operations, on the other hand, may not be competitively viable if it has not invested in information links with retailers and other changes in management practices.
Apparel manufacturers are not the only ones learning this lesson the hard way. The emphasis on labor productivity that has preoccupied practitioners and analysts in many industries—such as the total labor minutes required to assemble a car—no longer makes as much sense now that information technology has revolutionized retailing in many product segments. For instance, the current labor costs associated with assembly constitute 40 percent of the final cost of a car. In contrast, distribution-related costs—those associated with the traditional structure of automobile retailing—constitute anywhere between 15 and 34 percent of final cost.30 It is little wonder that car companies are currently in the throes of radically restructuring their method of automobile distribution.
Proposition 4:  Instead of fashion as the saving grace of the channel, basic and fashion-basic products will prove critical to its long-term survival.
When people consider the U.S. apparel industry, they often think of New York City’s Seventh Avenue, which is driven by new design, constantly changing seasonal offerings, and a willingness by consumers to pay a premium for the cutting edge of fashion. New York City and Los Angeles continue to have a competitive advantage in this area because a large number of designers and manufacturers are located in these cities and can respond quickly to changing demands, as well as shape them. This infrastructure allows for “quick response” on the fashion end of the women’s and, to a more limited extent, men’s markets. Once established, a variety of proponents believe, the experience at the fashion end can be diffused downward to less fashion-oriented products. As a result, some of the fashion-oriented products that had been sourced offshore can then return to the United States.
Those with a pessimistic view of domestic apparel manufacturing often assume that the high fashion end of the industry (the “top” of the fashion triangle in Figure 1.1, page 9) may be its best hope because U.S. firms can capitalize on their proximity to market. The highly acclaimed report by the MIT Commission on Industrial Productivity, Made in America, concludes:
Apparel, textile, and fiber firms and retailers have recently joined to launch the Quick Response Program, designed to improve information flow, standardize recording systems, and improve turnaround time throughout the system.... The program could be an important boon to productivity and competitiveness.... Will Quick Response succeed? According to industry experts, that depends on whether it diffuses down to the high-fashion, quick turnaround segments of the industry or, like much new technology in this industry, is adapted to suit the needs of firms still committed to mass production.31
Regardless of where Quick Response has succeeded, however, our research indicates that very different time-based competitive demands have emerged in the industry, driven not by voluntary acceptance of policies but by the changing nature of market competition among retailers. Rather than arising in the fashion, “Seventh Avenue” segment of the industry, the new form of retail competition involves basic and fashion-basic products like jeans, intimate apparel, and T-shirts—the bottom of the fashion triangle.
Basic and fashion-basic apparel categories now constitute the lion’s share of industry sales, accounting for approximately 72 percent of all shipments.32 This implies that a far larger portion of the industry may be viable in the long run than the part that could be saved by “quick response” at the fashion end.33 Bear in mind, however, that this viability depends on manufacturers using information to plan and execute production in a more sophisticated manner than usual for this and other industries.
Similar dynamics are cropping up in nonclothing areas as well. Grocery stores now stock a profusion of toothbrushes, Home Depot has shelves and shelves of different light bulbs, and Dell offers custom-configured personal computers. The growing presence of fashion-basic elements in myriad consumer products means that all retailers and suppliers may find new competitive opportunities using replenishment.
Proposition 5:  Even with full implementation of GATT, a viable apparel industry can remain in North America, drawing on a range of production processes in the United States, Canada, Mexico, the Caribbean, and Latin America.
When it comes to international trade agreements, the conventional wisdom sounds most bleak. It leads to stark conclusions about the long-term viability of the U.S. apparel industry, even with steps taken to improve assembly-room productivity and fashion-oriented quick response. The following comment is typical:
Among the factors that are expected to have a substantial impact on employment in the textiles and apparel industries, perhaps the most influential will be the trade policy agreed to in the GATT.... The apparel industry, which is far more labor intensive and less competitive internationally than the textile industry, will probably sustain most of the losses from the new trade environment.34
Even here, the channel perspective tells a somewhat different story. When domestic channels reduce lead times to market, particularly with basic and fashion-basic products, the comparative advantage of imports declines—despite the lower wage costs of foreign competitors, elimination of quotas on imports, and tariff reductions. This means that the U.S. apparel industry is not necessarily doomed by high direct labor costs, at least for certain products. In fact, we expect a resurgence in certain sectors because of the innovative practices being pursued by some manufacturers and their retailers.
To be sure, the international sourcing arrangements that have been created by retailers and manufacturers over the last twenty years reflect a quest for minimizing unit labor costs. But the long lead times they require will increasingly challenge such arrangements. Manufacturers and retailers that rely on international sourcing will therefore have to reassess the total costs associated with offshore production and revise existing arrangements.
Trade data already suggest a major restructuring in the sources of U.S. apparel imports. The surge in apparel imports in the 1980s came from low-wage countries, primarily the Asian “Big Four”—the People’s Republic of China, Hong Kong, Taiwan, and Korea. This group of nations provided 39 percent of all apparel imports in 1964 and 51 percent of all apparel imports by 1988 (measured in square-meter equivalents, a measure of quantity). But by 1996, the Big Four’s share of imports had fallen to 26 percent. Their U.S. share has been increasingly displaced by those of Mexico and Caribbean nations.35 Although these shifts in part reflect changes in U.S. trade policy, such as the North American Free Trade Agreement (NAFTA), they fundamentally arise from new sourcing patterns attributable to channel integration and the consequent need for apparel items that can be delivered in a shorter time to the U.S. market.
The implications of these changes from a private and public policy perspective are enormous. Competing in the transformed retail-apparel-textile channel now requires a set of management practices for both domestic and international sourcing. A successful U.S. apparel-maker, for instance, may assemble basic men’s khaki pants in average sizes in Mexico, taking advantage of low labor costs as well as Mexico’s proximity to the maker’s Texas distribution centers; at the same time, this company can choose to manufacture products with more variable demand, like khaki pants with narrow waists and long inseams, in the United States, providing fast turnaround for retailers and lower exposure to inventory risk.
Going to India or China for low prices alone is no longer the smartest course of action for American manufacturers. Increasingly, they will factor in demand uncertainty and product proliferation when making such sourcing decisions. As we will discuss throughout, many of the capabilities required for this model of competition are new to the apparel industry. The post-GATT competitive arena will be extremely demanding, but, based on the innovations many U.S. manufacturers are making, we believe the American apparel industry has a future.
How This Book Is Organized
Because of our separate academic perspectives and disciplines, the research underlying A Stitch in Time comes from a variety of sources. Much of our analysis is based on detailed survey data we collected from 118 business units—a sample representing about one-third of the shipments—in the apparel industry. We supplemented the original survey with microdata collected from a variety of U.S. government and private sources. Our work also draws on numerous case studies of individual enterprises and data gathered at site visits. We have modeled specific channel dynamics in order to understand what optimal practices might look like as the channel develops over time. Finally, we have worked closely with business executives, government officials, labor leaders, and our academic colleagues to exchange views, test ideas, and refine our results on a continuing basis. The appendices present a list of acronyms, a description of the HCTAR survey and other data sources, and a list of companies that we visited or at which we conducted interviews with their executives.
A Stitch in Time is organized into five sections, roughly corresponding to the channel components. The first two chapters provide an overview and historical context. Chapters 3 through 5 analyze developments in the retail sector. Chapters 6 and 7 establish a bridge between retailing and apparel/textile operations through an exploration of the problems of inventory management—a central aspect of emerging channel dynamics. Chapters 8 through 10 focus on the apparel industry; Chapters 11 and 12 look at textiles. Chapters 13 through 15 examine the channel as a whole, from global, private-performance, and public-policy perspectives.
After this introduction, Chapter 2 (“The Past as Prologue”) offers a brief history of recent technological and human resource developments in retailing, apparel production—including the role of jobbers, contractors, and manufacturers—and textile enterprises. Here we make clear that the changes wrought by lean retailing echo the last industrial transformation, which occurred in the late nineteenth century with the advent of the railroad and telegraph.
In the retailing section of the book, Chapter 3 (“The Retail Revolution”) contrasts traditional practices with the emerging method of lean retailing, starting with a comparison of Wanamaker’s, the grandest store of its time, and the companies leading the current wave of retail restructuring. Chapter 4 (“The Building Blocks of Lean Retailing”) describes how the essential elements of lean retailing—bar codes, EDI, the modern distribution center, and standards across firms—fit together. Chapter 5 (“The Impact of Lean Retailing”) presents some of the key results of our survey, indicating how lean retailers have performed over the last decade and their effects on manufacturers and suppliers.
Next, we move to the inventory “bridge” between retailers and suppliers. Product proliferation has raised the uncertainty of overall demand faced by retailers and suppliers. Chapter 6 (“Inventory Management for the Retailer”) looks at formal models of retail inventory management and discusses how they have been modified by lean retailing practices. Chapter 7 (“Inventory Management for the Manufacturer”) switches to the supplier’s point of view. Because dynamics are shifting in the channel, many suppliers are confronting new inventory challenges in their efforts to replenish items rapidly for retailers. We present two cases that emphasize the importance of using weekly demand variation for different items to help manufacturers set optimal inventory policies. This chapter also describes a new approach to production and sourcing strategies, one that balances traditional and short-cycle production lines.
The next three chapters are devoted to apparel operations and related human resource practices. Chapter 8 (“Getting Ready to Sew”) describes the preassembly steps of apparel design, marker-making, and cutting and how they are adapted to new areas like mass customization. Chapter 9 (“Assembly and the Sewing Room”) examines the technical aspects of sewing—from different kinds of sewing machines to what sewing operators do—and alternative ways of arranging the flow of assembly operations through an apparel workplace. Chapter 10 (“Human Resources in Apparel”) considers the impact of alternative methods of assembly—especially modular, or team-based, production—on firm performance. We also discuss why human resource policies cannot be treated separately from other business decisions regarding rapid replenishment.
In the textile section, Chapter 11 (“Textile Operations”) describes the technological processes involved in converting fibers to a vast range of woven and knit products. The textile sector has changed remarkably since World War II, in part because of the capital intensity and technological sophistication of textile equipment, much of which is automated. Chapter 12 (“The Economic Viability of Textiles”) places U.S. textiles in an international context, detailing the ways in which the domestic industry has adjusted over the past several decades through dramatic productivity enhancement. Because textile firms are increasingly supplying retailers and industrial users directly, as well as producing fabric for apparel-makers, we also address the multiple channels evolving in this sector.
A Stitch in Time concludes with a look at the many factors shaping today’s retail-apparel-textile channel—from the complex management challenges facing suppliers to labor standards and macroeconomic policy. Chapter 13 (“The Global Marketplace”) reviews trends in U.S. imports and exports of apparel and textiles, including information on trade by countries and specific products. It then connects these trends to changing trade policies, emphasizing the growing regionalization of trade flows in different parts of the world. Chapter 14 (“Suppliers in a Lean World”) examines our survey results from another angle, evaluating firm performance in an integrated channel. Here we highlight the importance of combining information technologies, manufacturing innovations, and new methods of management to respond to lean retailing demands.
Finally, Chapter 15 (“Information-Integrated Channels”) touches on a number of public policy issues raised by our findings. These include what can be done about the continuing problem of sweatshops, the new international economics of trade, and the effect of information integration on the business cycle and consumer prices at the macroeconomic level. Last but not least, we take a realistic look at the competitive future of the U.S. retail, apparel, and textile industries.
The information-integrated channel, with its emphasis on time and product perishability, is the basis for our cautiously optimistic—and unconventional—outlook. Even more important, the forces examined in this book provide a glimpse into processes reshaping a considerable portion of the economy. Consumers no longer line up for a special suit at a store like Bond Stores; they also expect an ever more “fashionable” array of cereal products, computers, and automobiles. As the next chapter shows, the changes now under way have their roots in new technologies, just as technical advances in transportation and communication shifted the industrial landscape at the end of the last century.





