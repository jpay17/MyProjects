{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/justinspayan/alex/')\n",
    "import sys\n",
    "#from google.cloud import speech\n",
    "\n",
    "import alex.utils.audio as audiolib\n",
    "from alex.utils.config import as_project_path, online_update\n",
    "from alex.components.tts import TTSInterface\n",
    "from alex.components.tts.exceptions import TTSException\n",
    "from alex.components.tts.preprocessing import TTSPreprocessing\n",
    "from alex.components.tts.voicerss import VoiceRssTTS\n",
    "import alex.utils.audio as audio\n",
    "import wave\n",
    "from alex.utils.config import as_project_path\n",
    "\n",
    "from alex.components.slu.da import DialogueAct\n",
    "from alex.components.nlg.template import TemplateNLG\n",
    "\n",
    "# from alex.components.asr.google import GoogleASR\n",
    "\n",
    "from alex.utils.mproc import SystemLogger\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "from alex.components.slu.dailrclassifier import DAILogRegClassifier\n",
    "\n",
    "from alex.components.slu.base import CategoryLabelDatabase, SLUPreprocessing\n",
    "from alex.components.asr.utterance import Utterance, UtteranceNBList\n",
    "from alex.components.slu.da import DialogueAct, DialogueActItem\n",
    "\n",
    "from alex.applications.PublicTransportInfoEN.hdc_slu import PTIENHDCSLU\n",
    "\n",
    "from alex.applications.PublicTransportInfoEN.preprocessing import PTIENSLUPreprocessing\n",
    "from alex.components.asr.utterance import Utterance\n",
    "#from kaldi.decoders import PyOnlineLatgenRecogniser\n",
    "#sys.path.append('/home/justinspayan/pykaldi/pykaldi/')\n",
    "# sys.path.append('/usr/include/python2.7')\n",
    "# from alex.components.asr.pykaldi import KaldiASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'Audio': {\n",
    "        'sample_rate': 16000,\n",
    "    },\n",
    "    'TTS': {\n",
    "        'type': 'VoiceRss',\n",
    "        'VoiceRss': {\n",
    "            'language': 'en-us',\n",
    "            'preprocessing': as_project_path(\"resources/tts/prep_voicerss_en.cfg\"),\n",
    "            'tempo': 1.0,\n",
    "            'api_key': 'ea29b823c83a426bbfe99f4cbce109f6'\n",
    "        }\n",
    "    },\n",
    "    'ASR': {\n",
    "        'Google': {\n",
    "            'debug': False,\n",
    "            'language': 'en',\n",
    "            'maxresults': 5,\n",
    "            'key': 'AIzaSyAL6UHbQw2ltugCfalw6mLIh3JsEZAoDgQ'\n",
    "        }\n",
    "    },\n",
    "    'NLG': {\n",
    "        'debug': True,\n",
    "        'type': 'Template',\n",
    "        'Template' : {\n",
    "            'model': as_project_path('applications/PublicTransportInfoEN/nlg_templates.cfg')\n",
    "        },\n",
    "    },\n",
    "    'Logging': {\n",
    "        'system_logger': SystemLogger(stdout=True, output_dir='./call_logs'),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "I would like to take a bus to Helsinki\n"
     ]
    }
   ],
   "source": [
    "# ASR MWE\n",
    "# obtain audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    utterance = r.recognize_google(audio)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "print(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing utterance \"I would like to take a bus to Helsinki\".\n",
      "After preprocessing: \"i would like to take a VEHICLE=bus to helsinki\".\n",
      "set([u'VEHICLE'])\n",
      "Abstracted utterance: i would like to take a VEHICLE=bus to helsinki\n",
      "Dialogue act: inform(vehicle=\"bus\")\n"
     ]
    }
   ],
   "source": [
    "# SLU MWE\n",
    "\n",
    "cldb = CategoryLabelDatabase(\"alex/applications/PublicTransportInfoEN/data/database.py\")\n",
    "# class db:\n",
    "#     database = {\n",
    "#         \"task\": {\n",
    "#             \"find_connection\": [\"find connection\", \"look for connection\", \"tell me the connection\",\n",
    "#                                 \"find connections\",\n",
    "#                                ],\n",
    "#             \"find_platform\": [\"find platform\", \"look for platform\", ],\n",
    "#             'weather': ['weather', ],\n",
    "#         },\n",
    "#         \"number\": {\n",
    "#             \"1\": [\"one\"]\n",
    "#         },\n",
    "#         \"time\": {\n",
    "#             \"now\": [\"now\", \"today\", \"right now\", ],\n",
    "#         },\n",
    "#     }\n",
    "# db_location = as_project_path()\n",
    "# cldb.load(db_location)\n",
    "preprocessing = PTIENSLUPreprocessing(cldb)\n",
    "slu = PTIENHDCSLU(preprocessing, cfg={'SLU': {PTIENHDCSLU: {\n",
    "    'utt2da': as_project_path(\"applications/PublicTransportInfoEN/data/utt2da_dict.txt\")}}})\n",
    "\n",
    "norm_utterance = slu.preprocessing.normalise_utterance(Utterance(utterance))\n",
    "abutterance, _, _ = slu.abstract_utterance(norm_utterance)\n",
    "da = slu.parse_1_best({'utt': Utterance(utterance)}, verbose=True).get_best_da()\n",
    "print \"Abstracted utterance:\", unicode(abutterance)\n",
    "print \"Dialogue act:\", unicode(da)\n",
    "# preprocessing = SLUPreprocessing(cldb)\n",
    "# clf = DAILogRegClassifier(cldb, preprocessing, features_size=4)\n",
    "\n",
    "# # Train a simple classifier.\n",
    "# das = {\n",
    "#     '1': DialogueAct('inform(task=find_connection)'),\n",
    "#     '2': DialogueAct('inform(time=now)'),\n",
    "#     '3': DialogueAct('inform(task=weather)'),\n",
    "# }\n",
    "# utterances = {\n",
    "#     '1': Utterance('find connection'),\n",
    "#     '2': Utterance('now'),\n",
    "#     '3': Utterance('weather'),\n",
    "# }\n",
    "# clf.extract_classifiers(das, utterances, verbose=False)\n",
    "# clf.prune_classifiers(min_classifier_count=0)\n",
    "# clf.gen_classifiers_data(min_pos_feature_count=0,\n",
    "#                          min_neg_feature_count=0,\n",
    "#                          verbose2=False)\n",
    "\n",
    "# clf.train(inverse_regularisation=1e1, verbose=False)\n",
    "\n",
    "# # Parse some sentences.\n",
    "# utterance_list = UtteranceNBList()\n",
    "# utterance_list.add(1, Utterance(input_utterance))\n",
    "\n",
    "# da_confnet = clf.parse_X(utterance_list, verbose=False)\n",
    "# da_confnet.items()\n",
    "# print(da_confnet.get_prob(DialogueActItem(dai='inform(task=find_connection)')))\n",
    "# print(da_confnet.get_prob(DialogueActItem(dai='inform(task=weather)')))\n",
    "# print(da_confnet.get_prob(DialogueActItem(dai='inform(time=now)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DM GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry. In now Take the bus\n"
     ]
    }
   ],
   "source": [
    "# NLG MWE\n",
    "\n",
    "nlg = TemplateNLG(cfg)\n",
    "\n",
    "da = DialogueAct('apology()&inform(time_rel=\"now\")&inform(vehicle=\"bus\")').sort()\n",
    "generated_text = nlg.generate(da)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS MWE\n",
    "text = generated_text\n",
    "wav_path = '/tmp/voice_rss_tts.wav'\n",
    "\n",
    "tts = VoiceRssTTS(cfg)\n",
    "wav = tts.synthesize(text)\n",
    "audiolib.save_wav(cfg, wav_path, wav)\n",
    "file = wave.open(wav_path)\n",
    "playcmd = \"play \" + wav_path\n",
    "os.system(playcmd)\n",
    "wav_length = float(file.getnframes()) / file.getframerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = DialogueAct('apology()&inform(from_city={Athens})&inform(to_city={Atlanta})').sort()\n",
    "generated_text = nlg.generate(da)\n",
    "wav = tts.synthesize(generated_text)\n",
    "audiolib.save_wav(cfg, wav_path, wav)\n",
    "playcmd = \"play \" + wav_path\n",
    "os.system(playcmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ASR previous attempts\n",
    "# print(os.getcwd())\n",
    "#  asr = KaldiASR(cfg)\n",
    "# # asr = GoogleASR(cfg)\n",
    "# wav = audio.load_wav(cfg, 'alex/tests/resources/test16k-mono.wav')\n",
    "\n",
    "# handle, flac_file_name = mkstemp('TmpSpeechFile.flac')\n",
    "\n",
    "# try:\n",
    "#     # convert wav to flac\n",
    "#     audio.save_flac(cfg, flac_file_name, wav)\n",
    "#     json_hypotheses = asr.get_asr_hypotheses(flac_file_name)\n",
    "#     baseurl = \"https://www.google.com/speech-api/v2/recognize?output=json&lang=en-us&key=AIzaSyAL6UHbQw2ltugCfalw6mLIh3JsEZAoDgQ\"\n",
    "# #     baseurl = \"https://speech.googleapis.com/v1/speech:recognize?xjerr=1&client=chromium&lang=%s&maxresults=%d&key=%s\" % (\n",
    "# #         cfg['ASR']['Google']['language'], cfg['ASR']['Google']['maxresults'], cfg['ASR']['Google']['key'])\n",
    "\n",
    "#     header = {\"User-Agent\": \"Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11\",\n",
    "#               \"Content-Type\": \"audio/x-flac; rate=%d\" % cfg['Audio']['sample_rate']}\n",
    "\n",
    "#     data = open(flac_file_name, \"rb\").read()\n",
    "\n",
    "#     request = urllib2.Request(baseurl, data, header)\n",
    "#     json_hypotheses = urllib2.urlopen(request).read()\n",
    "# except (urllib2.HTTPError, urllib2.URLError) as e:\n",
    "#     print('GoogleASR HTTP/URL error: %s' % e)\n",
    "#     json_hypotheses = [\n",
    "#         [{'confidence': 1.0, 'utterance': '__google__ __asr__ __exception__'}, ], ]\n",
    "# finally:\n",
    "#     os.close(handle)\n",
    "#     remove(flac_file_name)\n",
    "\n",
    "# print(json_hypotheses)\n",
    "\n",
    "# print 'calling ASR'\n",
    "# hyp = asr.recognize(wav)\n",
    "\n",
    "# print 'expected hypothesis'\n",
    "# print \"I'm looking for a bar\"\n",
    "\n",
    "# print 'hypotheses'\n",
    "# print hyp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
